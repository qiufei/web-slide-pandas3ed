[
  {
    "objectID": "qmd/pandas3ed8.html",
    "href": "qmd/pandas3ed8.html",
    "title": "```qmd",
    "section": "",
    "text": "format: revealjs: theme: sky slide-number: true show-slide-number: all preview-links: auto"
  },
  {
    "objectID": "qmd/pandas3ed8.html#introduction",
    "href": "qmd/pandas3ed8.html#introduction",
    "title": "```qmd",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nIn many applications, data is spread across multiple files or databases.\nIt may also be arranged in a format not suitable for easy analysis.\nThis chapter focuses on tools to combine, join, and rearrange data effectively.\nKey concept: Hierarchical Indexing in pandas."
  },
  {
    "objectID": "qmd/pandas3ed8.html#data-wrangling-data-mining-machine-learning",
    "href": "qmd/pandas3ed8.html#data-wrangling-data-mining-machine-learning",
    "title": "```qmd",
    "section": "Data Wrangling, Data Mining, Machine Learning",
    "text": "Data Wrangling, Data Mining, Machine Learning\n\n\n\n\n\n\nWhat is Data Wrangling?\n\n\n\nData Wrangling (or Data Munging) is the process of transforming and mapping data from one “raw” data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.\n\n\n\n\n\nWhat is Data Mining?\n\n\n\nData mining is the process of discovering patterns, anomalies, and correlations within large datasets to predict outcomes.\n\n\n\n\nWhat is Machine Learning?\n\nMachine Learning is a subfield of artificial intelligence.\nIt focuses on developing systems that can learn from and make decisions/predictions based on data.\nSupervised Learning: Uses labeled datasets to train algorithms.\nUnsupervised Learning: Discovers hidden patterns in unlabeled data.\nReinforcement Learning: Agents learn by interacting with an environment."
  },
  {
    "objectID": "qmd/pandas3ed8.html#hierarchical-indexing-in-pandas",
    "href": "qmd/pandas3ed8.html#hierarchical-indexing-in-pandas",
    "title": "```qmd",
    "section": "Hierarchical Indexing in Pandas",
    "text": "Hierarchical Indexing in Pandas\n\nA fundamental feature of pandas.\nEnables having multiple (two or more) index levels on an axis.\nAllows working with higher dimensional data in a lower dimensional form.\n\n\n\nAnalogy: Think of it like having subcategories within categories in a file cabinet.\nBenefit: Provides a structured way to represent and manipulate complex datasets."
  },
  {
    "objectID": "qmd/pandas3ed8.html#hierarchical-indexing-example",
    "href": "qmd/pandas3ed8.html#hierarchical-indexing-example",
    "title": "```qmd",
    "section": "Hierarchical Indexing: Example",
    "text": "Hierarchical Indexing: Example\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.Series(np.random.uniform(size=9),\n                 index=[[\"a\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"d\", \"d\"],\n                        [1, 2, 3, 1, 3, 1, 2, 2, 3]])\ndata\n\na  1    0.000702\n   2    0.730243\n   3    0.468818\nb  1    0.627637\n   3    0.742390\nc  1    0.010875\n   2    0.839843\nd  2    0.231688\n   3    0.539380\ndtype: float64\n\n\n\n\nWe create a Series with a list of lists as the index.\nThis creates a MultiIndex object.\nThe “gaps” in the index display indicate “use the label directly above”."
  },
  {
    "objectID": "qmd/pandas3ed8.html#understanding-the-multiindex",
    "href": "qmd/pandas3ed8.html#understanding-the-multiindex",
    "title": "```qmd",
    "section": "Understanding the MultiIndex",
    "text": "Understanding the MultiIndex\n\ndata.index\n\nMultiIndex([('a', 1),\n            ('a', 2),\n            ('a', 3),\n            ('b', 1),\n            ('b', 3),\n            ('c', 1),\n            ('c', 2),\n            ('d', 2),\n            ('d', 3)],\n           )\n\n\n\n\nThe MultiIndex object represents the hierarchical index.\nIt contains tuples of (outer level, inner level).\nHere: (‘a’, 1), (‘a’, 2), (‘a’, 3), (‘b’, 1) … represent the index pairs."
  },
  {
    "objectID": "qmd/pandas3ed8.html#partial-indexing",
    "href": "qmd/pandas3ed8.html#partial-indexing",
    "title": "```qmd",
    "section": "Partial Indexing",
    "text": "Partial Indexing\ndata[\"b\"] #Select group \"b\"\ndata[\"b\":\"c\"] # Select from \"b\" to \"c\"\ndata.loc[[\"b\", \"d\"]] #Select \"b\" and \"d\"\n\n\n\nWith hierarchical indexing, partial indexing becomes possible. This allows concisely selecting subsets of data.\n\n\n\n1    0.627637\n3    0.742390\ndtype: float64\n\n\n\n\n\n\nb  1    0.627637\n   3    0.742390\nc  1    0.010875\n   2    0.839843\ndtype: float64\n\n\n\n\nb  1    0.627637\n   3    0.742390\nd  2    0.231688\n   3    0.539380\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed8.html#selection-from-inner-level",
    "href": "qmd/pandas3ed8.html#selection-from-inner-level",
    "title": "```qmd",
    "section": "Selection from Inner Level",
    "text": "Selection from Inner Level\n\ndata.loc[:, 2] #Select all value from inner index level 2\n\na    0.730243\nc    0.839843\nd    0.231688\ndtype: float64\n\n\n\n\nWe use .loc for label-based indexing.\n: selects all outer levels.\n2 selects the inner level index equal to 2."
  },
  {
    "objectID": "qmd/pandas3ed8.html#unstack-and-stack",
    "href": "qmd/pandas3ed8.html#unstack-and-stack",
    "title": "```qmd",
    "section": "unstack() and stack()",
    "text": "unstack() and stack()\n\nunstack(): Reshapes the data into a DataFrame.\nstack(): The inverse operation of unstack().\nunstack() “pivots” a level of the (row) index to become column labels.\n\n\ndata.unstack()\n\n\n\n\n\n\n\n\n1\n2\n3\n\n\n\n\na\n0.000702\n0.730243\n0.468818\n\n\nb\n0.627637\nNaN\n0.742390\n\n\nc\n0.010875\n0.839843\nNaN\n\n\nd\nNaN\n0.231688\n0.539380\n\n\n\n\n\n\n\n\nstack() pivots the column labels to become a level in the (row) MultiIndex.\n\n\ndata.unstack().stack()\n\na  1    0.000702\n   2    0.730243\n   3    0.468818\nb  1    0.627637\n   3    0.742390\nc  1    0.010875\n   2    0.839843\nd  2    0.231688\n   3    0.539380\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed8.html#hierarchical-indexing-with-dataframes",
    "href": "qmd/pandas3ed8.html#hierarchical-indexing-with-dataframes",
    "title": "```qmd",
    "section": "Hierarchical Indexing with DataFrames",
    "text": "Hierarchical Indexing with DataFrames\n\nBoth rows and columns can have hierarchical indexes.\n\n\nframe = pd.DataFrame(np.arange(12).reshape((4, 3)),\n                     index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]],\n                     columns=[[\"Ohio\", \"Ohio\", \"Colorado\"],\n                              [\"Green\", \"Red\", \"Green\"]])\nframe\n\n\n\n\n\n\n\n\n\nOhio\nColorado\n\n\n\n\nGreen\nRed\nGreen\n\n\n\n\na\n1\n0\n1\n2\n\n\n2\n3\n4\n5\n\n\nb\n1\n6\n7\n8\n\n\n2\n9\n10\n11\n\n\n\n\n\n\n\n\nHere, we have two levels for both rows and columns."
  },
  {
    "objectID": "qmd/pandas3ed8.html#naming-index-levels",
    "href": "qmd/pandas3ed8.html#naming-index-levels",
    "title": "```qmd",
    "section": "Naming Index Levels",
    "text": "Naming Index Levels\n\nframe.index.names = [\"key1\", \"key2\"]\nframe.columns.names = [\"state\", \"color\"]\nframe\n\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\n\ncolor\nGreen\nRed\nGreen\n\n\nkey1\nkey2\n\n\n\n\n\n\n\na\n1\n0\n1\n2\n\n\n2\n3\n4\n5\n\n\nb\n1\n6\n7\n8\n\n\n2\n9\n10\n11\n\n\n\n\n\n\n\n\n\nGiving names to index levels improves readability.\nframe.index.names and frame.columns.names set the names.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nBe careful to note that the index names “state” and “color” are not part of the row labels (the frame. index values)."
  },
  {
    "objectID": "qmd/pandas3ed8.html#accessing-nlevels-attribute",
    "href": "qmd/pandas3ed8.html#accessing-nlevels-attribute",
    "title": "```qmd",
    "section": "Accessing nlevels Attribute",
    "text": "Accessing nlevels Attribute\n\nframe.index.nlevels\n\n2\n\n\n\nYou can see how many levels an index has by accessing its nlevels attribute."
  },
  {
    "objectID": "qmd/pandas3ed8.html#partial-column-indexing",
    "href": "qmd/pandas3ed8.html#partial-column-indexing",
    "title": "```qmd",
    "section": "Partial Column Indexing",
    "text": "Partial Column Indexing\nSimilar to row indexing, we can also select groups of columns:\n\nframe[\"Ohio\"]\n\n\n\n\n\n\n\n\ncolor\nGreen\nRed\n\n\nkey1\nkey2\n\n\n\n\n\n\na\n1\n0\n1\n\n\n2\n3\n4\n\n\nb\n1\n6\n7\n\n\n2\n9\n10"
  },
  {
    "objectID": "qmd/pandas3ed8.html#reordering-and-sorting-levels",
    "href": "qmd/pandas3ed8.html#reordering-and-sorting-levels",
    "title": "```qmd",
    "section": "Reordering and Sorting Levels",
    "text": "Reordering and Sorting Levels\n\nswaplevel(): Interchanges two levels.\nsort_index(): Sorts data using all index levels (lexicographically) by default. Can also sort by a specific level.\n\n\nframe.swaplevel(\"key1\", \"key2\")\n\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\n\ncolor\nGreen\nRed\nGreen\n\n\nkey2\nkey1\n\n\n\n\n\n\n\n1\na\n0\n1\n2\n\n\n2\na\n3\n4\n5\n\n\n1\nb\n6\n7\n8\n\n\n2\nb\n9\n10\n11\n\n\n\n\n\n\n\n\nframe.sort_index(level=1) # sort by level 1 (key2)\n\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\n\ncolor\nGreen\nRed\nGreen\n\n\nkey1\nkey2\n\n\n\n\n\n\n\na\n1\n0\n1\n2\n\n\nb\n1\n6\n7\n8\n\n\na\n2\n3\n4\n5\n\n\nb\n2\n9\n10\n11\n\n\n\n\n\n\n\n\nframe.swaplevel(0, 1).sort_index(level=0)\n\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\n\ncolor\nGreen\nRed\nGreen\n\n\nkey2\nkey1\n\n\n\n\n\n\n\n1\na\n0\n1\n2\n\n\nb\n6\n7\n8\n\n\n2\na\n3\n4\n5\n\n\nb\n9\n10\n11\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nData selection performance is much better on hierarchically indexed objects if the index is lexicographically sorted starting with the outermost level."
  },
  {
    "objectID": "qmd/pandas3ed8.html#summary-statistics-by-level",
    "href": "qmd/pandas3ed8.html#summary-statistics-by-level",
    "title": "```qmd",
    "section": "Summary Statistics by Level",
    "text": "Summary Statistics by Level\nMany descriptive and summary statistics have a level option:\n\nframe.groupby(level=\"key2\").sum()\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\ncolor\nGreen\nRed\nGreen\n\n\nkey2\n\n\n\n\n\n\n\n1\n6\n8\n10\n\n\n2\n12\n14\n16\n\n\n\n\n\n\n\n\nframe.groupby(level=\"color\", axis=\"columns\").sum()\n\n/tmp/ipykernel_2765/775557097.py:1: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n  frame.groupby(level=\"color\", axis=\"columns\").sum()\n\n\n\n\n\n\n\n\n\ncolor\nGreen\nRed\n\n\nkey1\nkey2\n\n\n\n\n\n\na\n1\n2\n1\n\n\n2\n8\n4\n\n\nb\n1\n14\n7\n\n\n2\n20\n10"
  },
  {
    "objectID": "qmd/pandas3ed8.html#indexing-with-a-dataframes-columns",
    "href": "qmd/pandas3ed8.html#indexing-with-a-dataframes-columns",
    "title": "```qmd",
    "section": "Indexing with a DataFrame’s Columns",
    "text": "Indexing with a DataFrame’s Columns\n\nset_index(): Creates a new DataFrame using one or more columns as the index.\nreset_index(): Moves hierarchical index levels into the columns (opposite of set_index()).\n\n\nframe = pd.DataFrame({\"a\": range(7), \"b\": range(7, 0, -1),\n                      \"c\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n                            \"two\", \"two\"],\n                      \"d\": [0, 1, 2, 0, 1, 2, 3]})\nframe\n\n\n\n\n\n\n\n\na\nb\nc\nd\n\n\n\n\n0\n0\n7\none\n0\n\n\n1\n1\n6\none\n1\n\n\n2\n2\n5\none\n2\n\n\n3\n3\n4\ntwo\n0\n\n\n4\n4\n3\ntwo\n1\n\n\n5\n5\n2\ntwo\n2\n\n\n6\n6\n1\ntwo\n3"
  },
  {
    "objectID": "qmd/pandas3ed8.html#set_index",
    "href": "qmd/pandas3ed8.html#set_index",
    "title": "```qmd",
    "section": "set_index()",
    "text": "set_index()\n\nframe2 = frame.set_index([\"c\", \"d\"])\nframe2\n\n\n\n\n\n\n\n\n\na\nb\n\n\nc\nd\n\n\n\n\n\n\none\n0\n0\n7\n\n\n1\n1\n6\n\n\n2\n2\n5\n\n\ntwo\n0\n3\n4\n\n\n1\n4\n3\n\n\n2\n5\n2\n\n\n3\n6\n1\n\n\n\n\n\n\n\n\n\nWe use columns “c” and “d” to create a MultiIndex.\nBy default, the columns used for the index are removed from the DataFrame. Use drop=False to keep them.\n\n\n\nframe.set_index([\"c\", \"d\"], drop=False)\n\n\n\n\n\n\n\n\n\na\nb\nc\nd\n\n\nc\nd\n\n\n\n\n\n\n\n\none\n0\n0\n7\none\n0\n\n\n1\n1\n6\none\n1\n\n\n2\n2\n5\none\n2\n\n\ntwo\n0\n3\n4\ntwo\n0\n\n\n1\n4\n3\ntwo\n1\n\n\n2\n5\n2\ntwo\n2\n\n\n3\n6\n1\ntwo\n3"
  },
  {
    "objectID": "qmd/pandas3ed8.html#reset_index",
    "href": "qmd/pandas3ed8.html#reset_index",
    "title": "```qmd",
    "section": "reset_index()",
    "text": "reset_index()\n\nframe2.reset_index()\n\n\n\n\n\n\n\n\nc\nd\na\nb\n\n\n\n\n0\none\n0\n0\n7\n\n\n1\none\n1\n1\n6\n\n\n2\none\n2\n2\n5\n\n\n3\ntwo\n0\n3\n4\n\n\n4\ntwo\n1\n4\n3\n\n\n5\ntwo\n2\n5\n2\n\n\n6\ntwo\n3\n6\n1\n\n\n\n\n\n\n\n\n\nreset_index() moves the hierarchical index to columns.\nIt creates a default integer index."
  },
  {
    "objectID": "qmd/pandas3ed8.html#combining-and-merging-datasets",
    "href": "qmd/pandas3ed8.html#combining-and-merging-datasets",
    "title": "```qmd",
    "section": "Combining and Merging Datasets",
    "text": "Combining and Merging Datasets\nThree main ways to combine data in pandas:\n\n\n\n\n\n\n\npandas.merge: Connects rows in DataFrames based on one or more keys (like SQL joins).\npandas.concat: Concatenates or “stacks” objects together along an axis.\ncombine_first: Splices together overlapping data (fills missing values)."
  },
  {
    "objectID": "qmd/pandas3ed8.html#database-style-dataframe-joins",
    "href": "qmd/pandas3ed8.html#database-style-dataframe-joins",
    "title": "```qmd",
    "section": "Database-Style DataFrame Joins",
    "text": "Database-Style DataFrame Joins\n\npandas.merge is the main function for join operations.\nIt’s similar to SQL joins.\nKey concept: keys (columns used to link rows)."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.merge-many-to-one-join",
    "href": "qmd/pandas3ed8.html#pandas.merge-many-to-one-join",
    "title": "```qmd",
    "section": "pandas.merge: Many-to-One Join",
    "text": "pandas.merge: Many-to-One Join\n\ndf1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n                    \"data1\": pd.Series(range(7), dtype=\"Int64\")})\ndf2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"],\n                    \"data2\": pd.Series(range(3), dtype=\"Int64\")})\n\n\ndf1\n\n\n\n\n\n\n\n\nkey\ndata1\n\n\n\n\n0\nb\n0\n\n\n1\nb\n1\n\n\n2\na\n2\n\n\n3\nc\n3\n\n\n4\na\n4\n\n\n5\na\n5\n\n\n6\nb\n6\n\n\n\n\n\n\n\n\ndf2\n\n\n\n\n\n\n\n\nkey\ndata2\n\n\n\n\n0\na\n0\n\n\n1\nb\n1\n\n\n2\nd\n2\n\n\n\n\n\n\n\n\npd.merge(df1, df2) # or pd.merge(df1, df2, on=\"key\")\n\n\n\n\n\n\n\n\nkey\ndata1\ndata2\n\n\n\n\n0\nb\n0\n1\n\n\n1\nb\n1\n1\n\n\n2\na\n2\n0\n\n\n3\na\n4\n0\n\n\n4\na\n5\n0\n\n\n5\nb\n6\n1\n\n\n\n\n\n\n\n\n\ndf1 has multiple rows labeled ‘a’ and ‘b’.\ndf2 has only one row for each value in the ‘key’ column.\nIf the join column isn’t specified, merge uses overlapping column names as keys. It is best practice to specify explicitly, though."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.merge-different-column-names",
    "href": "qmd/pandas3ed8.html#pandas.merge-different-column-names",
    "title": "```qmd",
    "section": "pandas.merge: Different Column Names",
    "text": "pandas.merge: Different Column Names\nIf column names are different, specify them separately:\n\ndf3 = pd.DataFrame({\"lkey\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n                    \"data1\": pd.Series(range(7), dtype=\"Int64\")})\ndf4 = pd.DataFrame({\"rkey\": [\"a\", \"b\", \"d\"],\n                    \"data2\": pd.Series(range(3), dtype=\"Int64\")})\npd.merge(df3, df4, left_on=\"lkey\", right_on=\"rkey\")\n\n\n\n\n\n\n\n\nlkey\ndata1\nrkey\ndata2\n\n\n\n\n0\nb\n0\nb\n1\n\n\n1\nb\n1\nb\n1\n\n\n2\na\n2\na\n0\n\n\n3\na\n4\na\n0\n\n\n4\na\n5\na\n0\n\n\n5\nb\n6\nb\n1\n\n\n\n\n\n\n\n\n\nleft_on: Column(s) in the left DataFrame.\nright_on: Column(s) in the right DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.merge-join-types",
    "href": "qmd/pandas3ed8.html#pandas.merge-join-types",
    "title": "```qmd",
    "section": "pandas.merge: Join Types",
    "text": "pandas.merge: Join Types\n\nBy default, merge does an “inner” join (intersection of keys).\nOther join types: “left”, “right”, “outer”.\n\n\npd.merge(df1, df2, how=\"outer\")\n\n\n\n\n\n\n\n\nkey\ndata1\ndata2\n\n\n\n\n0\na\n2\n0\n\n\n1\na\n4\n0\n\n\n2\na\n5\n0\n\n\n3\nb\n0\n1\n\n\n4\nb\n1\n1\n\n\n5\nb\n6\n1\n\n\n6\nc\n3\n&lt;NA&gt;\n\n\n7\nd\n&lt;NA&gt;\n2\n\n\n\n\n\n\n\n\nOuter join: Union of keys.\nLeft join: All keys from the left DataFrame.\nRight join: All keys from the right DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed8.html#join-types-with-how-argument",
    "href": "qmd/pandas3ed8.html#join-types-with-how-argument",
    "title": "```qmd",
    "section": "Join Types with how Argument",
    "text": "Join Types with how Argument\n\n\n\n\n\n\n\nOption\nBehavior\n\n\n\n\nhow=\"inner\"\nUse only the key combinations observed in both tables\n\n\nhow=\"left\"\nUse all key combinations found in the left table\n\n\nhow=\"right\"\nUse all key combinations found in the right table\n\n\nhow=\"outer\"\nUse all key combinations observed in both tables together"
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.merge-many-to-many-joins",
    "href": "qmd/pandas3ed8.html#pandas.merge-many-to-many-joins",
    "title": "```qmd",
    "section": "pandas.merge: Many-to-Many Joins",
    "text": "pandas.merge: Many-to-Many Joins\n\nMany-to-many joins form the Cartesian product of the matching keys.\n\n\ndf1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"],\n                    \"data1\": pd.Series(range(6), dtype=\"Int64\")})\ndf2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"b\", \"d\"],\n                    \"data2\": pd.Series(range(5), dtype=\"Int64\")})\n\npd.merge(df1, df2, on=\"key\", how=\"left\")\n\n\n\n\n\n\n\n\nkey\ndata1\ndata2\n\n\n\n\n0\nb\n0\n1\n\n\n1\nb\n0\n3\n\n\n2\nb\n1\n1\n\n\n3\nb\n1\n3\n\n\n4\na\n2\n0\n\n\n5\na\n2\n2\n\n\n6\nc\n3\n&lt;NA&gt;\n\n\n7\na\n4\n0\n\n\n8\na\n4\n2\n\n\n9\nb\n5\n1\n\n\n10\nb\n5\n3\n\n\n\n\n\n\n\n\n\nThere are three “b” rows in df1 and two in df2, resulting in six “b” rows in the result."
  },
  {
    "objectID": "qmd/pandas3ed8.html#merging-with-multiple-keys",
    "href": "qmd/pandas3ed8.html#merging-with-multiple-keys",
    "title": "```qmd",
    "section": "Merging with Multiple Keys",
    "text": "Merging with Multiple Keys\nPass a list of column names:\n\nleft = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\"],\n                     \"key2\": [\"one\", \"two\", \"one\"],\n                     \"lval\": pd.Series([1, 2, 3], dtype='Int64')})\nright = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\", \"bar\"],\n                      \"key2\": [\"one\", \"one\", \"one\", \"two\"],\n                      \"rval\": pd.Series([4, 5, 6, 7], dtype='Int64')})\npd.merge(left, right, on=[\"key1\", \"key2\"], how=\"outer\")\n\n\n\n\n\n\n\n\nkey1\nkey2\nlval\nrval\n\n\n\n\n0\nbar\none\n3\n6\n\n\n1\nbar\ntwo\n&lt;NA&gt;\n7\n\n\n2\nfoo\none\n1\n4\n\n\n3\nfoo\none\n1\n5\n\n\n4\nfoo\ntwo\n2\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\nThink of multiple keys as forming tuples used as a single join key."
  },
  {
    "objectID": "qmd/pandas3ed8.html#overlapping-column-names",
    "href": "qmd/pandas3ed8.html#overlapping-column-names",
    "title": "```qmd",
    "section": "Overlapping Column Names",
    "text": "Overlapping Column Names\n\nmerge has a suffixes option to handle overlapping column names.\n\n\npd.merge(left, right, on=\"key1\")\n\n\n\n\n\n\n\n\nkey1\nkey2_x\nlval\nkey2_y\nrval\n\n\n\n\n0\nfoo\none\n1\none\n4\n\n\n1\nfoo\none\n1\none\n5\n\n\n2\nfoo\ntwo\n2\none\n4\n\n\n3\nfoo\ntwo\n2\none\n5\n\n\n4\nbar\none\n3\none\n6\n\n\n5\nbar\none\n3\ntwo\n7\n\n\n\n\n\n\n\n\npd.merge(left, right, on=\"key1\", suffixes=(\"_left\", \"_right\"))\n\n\n\n\n\n\n\n\nkey1\nkey2_left\nlval\nkey2_right\nrval\n\n\n\n\n0\nfoo\none\n1\none\n4\n\n\n1\nfoo\none\n1\none\n5\n\n\n2\nfoo\ntwo\n2\none\n4\n\n\n3\nfoo\ntwo\n2\none\n5\n\n\n4\nbar\none\n3\none\n6\n\n\n5\nbar\none\n3\ntwo\n7"
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.merge-function-arguments",
    "href": "qmd/pandas3ed8.html#pandas.merge-function-arguments",
    "title": "```qmd",
    "section": "pandas.merge Function Arguments",
    "text": "pandas.merge Function Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nleft\nDataFrame to be merged on the left side.\n\n\nright\nDataFrame to be merged on the right side.\n\n\nhow\nType of join: “inner”, “outer”, “left”, or “right” (defaults to “inner”).\n\n\non\nColumn names to join on (must be in both DataFrames).\n\n\nleft_on\nColumns in left DataFrame to use as join keys.\n\n\nright_on\nAnalogous to left_on for the right DataFrame.\n\n\nleft_index\nUse row index in left as its join key(s).\n\n\nright_index\nAnalogous to left_index.\n\n\nsort\nSort merged data lexicographically by join keys (False by default).\n\n\nsuffixes\nTuple of strings to append to overlapping column names (defaults to (“_x”, “_y”)).\n\n\ncopy\nIf False, avoid copying data in some cases (defaults to copying).\n\n\nvalidate\nVerifies if the merge is of specified type (one-to-one, one-to-many, many-to-many).\n\n\nindicator\nAdds a special column _merge that indicates the source of each row (“left_only”, “right_only”, or “both”)."
  },
  {
    "objectID": "qmd/pandas3ed8.html#merging-on-index",
    "href": "qmd/pandas3ed8.html#merging-on-index",
    "title": "```qmd",
    "section": "Merging on Index",
    "text": "Merging on Index\n\nUse left_index=True or right_index=True (or both) to merge on the index.\n\n\nleft1 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"c\"],\n                      \"value\": pd.Series(range(6), dtype=\"Int64\")})\nright1 = pd.DataFrame({\"group_val\": [3.5, 7]}, index=[\"a\", \"b\"])\n\npd.merge(left1, right1, left_on=\"key\", right_index=True)\n\n\n\n\n\n\n\n\nkey\nvalue\ngroup_val\n\n\n\n\n0\na\n0\n3.5\n\n\n1\nb\n1\n7.0\n\n\n2\na\n2\n3.5\n\n\n3\na\n3\n3.5\n\n\n4\nb\n4\n7.0\n\n\n\n\n\n\n\n\n\nHere, we merge left1’s “key” column with right1’s index.\nThe index values for left1 are preserved."
  },
  {
    "objectID": "qmd/pandas3ed8.html#hierarchical-index-multiple-key-merge",
    "href": "qmd/pandas3ed8.html#hierarchical-index-multiple-key-merge",
    "title": "```qmd",
    "section": "Hierarchical Index: Multiple-Key Merge",
    "text": "Hierarchical Index: Multiple-Key Merge\nWith hierarchical indexing, joining on index is like a multiple-key merge:\n\nlefth = pd.DataFrame({\"key1\": [\"Ohio\", \"Ohio\", \"Ohio\",\n                            \"Nevada\", \"Nevada\"],\n                    \"key2\": [2000, 2001, 2002, 2001, 2002],\n                    \"data\": pd.Series(range(5), dtype=\"Int64\")})\nrighth_index = pd.MultiIndex.from_arrays([\n    [\"Nevada\", \"Nevada\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\"],\n    [2001, 2000, 2000, 2000, 2001, 2002]\n    ])\nrighth = pd.DataFrame({\"event1\": pd.Series([0, 2, 4, 6, 8, 10], dtype=\"Int64\",\n                                        index=righth_index),\n                    \"event2\": pd.Series([1, 3, 5, 7, 9, 11], dtype=\"Int64\",\n                                        index=righth_index)})\n\npd.merge(lefth, righth, left_on=[\"key1\", \"key2\"], right_index=True, how=\"outer\")\n\n\n\n\n\n\n\n\nkey1\nkey2\ndata\nevent1\nevent2\n\n\n\n\n4\nNevada\n2000\n&lt;NA&gt;\n2\n3\n\n\n3\nNevada\n2001\n3\n0\n1\n\n\n4\nNevada\n2002\n4\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n0\nOhio\n2000\n0\n4\n5\n\n\n0\nOhio\n2000\n0\n6\n7\n\n\n1\nOhio\n2001\n1\n8\n9\n\n\n2\nOhio\n2002\n2\n10\n11"
  },
  {
    "objectID": "qmd/pandas3ed8.html#dataframes-join-method",
    "href": "qmd/pandas3ed8.html#dataframes-join-method",
    "title": "```qmd",
    "section": "DataFrame’s join Method",
    "text": "DataFrame’s join Method\n\nSimplifies merging by index.\nPerforms a left join by default.\n\n\nleft2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],\n                     index=[\"a\", \"c\", \"e\"],\n                     columns=[\"Ohio\", \"Nevada\"]).astype(\"Int64\")\nright2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n                      index=[\"b\", \"c\", \"d\", \"e\"],\n                      columns=[\"Missouri\", \"Alabama\"]).astype(\"Int64\")\nleft2.join(right2, how=\"outer\")\n\n\n\n\n\n\n\n\nOhio\nNevada\nMissouri\nAlabama\n\n\n\n\na\n1\n2\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nb\n&lt;NA&gt;\n&lt;NA&gt;\n7\n8\n\n\nc\n3\n4\n9\n10\n\n\nd\n&lt;NA&gt;\n&lt;NA&gt;\n11\n12\n\n\ne\n5\n6\n13\n14\n\n\n\n\n\n\n\n\nCan join the index of the passed DataFrame on one of the columns of the calling DataFrame.\nAlso supports joining multiple DataFrames with the same or similar indexes but non-overlapping columns.\n\n\nleft1.join(right1, on=\"key\")\n\n\n\n\n\n\n\n\nkey\nvalue\ngroup_val\n\n\n\n\n0\na\n0\n3.5\n\n\n1\nb\n1\n7.0\n\n\n2\na\n2\n3.5\n\n\n3\na\n3\n3.5\n\n\n4\nb\n4\n7.0\n\n\n5\nc\n5\nNaN"
  },
  {
    "objectID": "qmd/pandas3ed8.html#concatenating-along-an-axis",
    "href": "qmd/pandas3ed8.html#concatenating-along-an-axis",
    "title": "```qmd",
    "section": "Concatenating Along an Axis",
    "text": "Concatenating Along an Axis\n\nnumpy.concatenate: Works with NumPy arrays.\n\n\narr = np.arange(12).reshape((3, 4))\nnp.concatenate([arr, arr], axis=1)\n\narray([[ 0,  1,  2,  3,  0,  1,  2,  3],\n       [ 4,  5,  6,  7,  4,  5,  6,  7],\n       [ 8,  9, 10, 11,  8,  9, 10, 11]])\n\n\n\npandas.concat: Generalizes array concatenation for Series and DataFrames. It addresses concerns like:\n\nHandling different indexes on other axes.\nIdentifying concatenated chunks.\nPreserving data on the concatenation axis."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.concat-with-series",
    "href": "qmd/pandas3ed8.html#pandas.concat-with-series",
    "title": "```qmd",
    "section": "pandas.concat with Series",
    "text": "pandas.concat with Series\n\ns1 = pd.Series([0, 1], index=[\"a\", \"b\"], dtype=\"Int64\")\ns2 = pd.Series([2, 3, 4], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\ns3 = pd.Series([5, 6], index=[\"f\", \"g\"], dtype=\"Int64\")\npd.concat([s1, s2, s3])\n\na    0\nb    1\nc    2\nd    3\ne    4\nf    5\ng    6\ndtype: Int64\n\n\n\n\nBy default, concat works along axis=\"index\" (rows), producing another Series.\nIt glues together values and indexes."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.concat-axiscolumns",
    "href": "qmd/pandas3ed8.html#pandas.concat-axiscolumns",
    "title": "```qmd",
    "section": "pandas.concat: axis=\"columns\"",
    "text": "pandas.concat: axis=\"columns\"\n\npd.concat([s1, s2, s3], axis=\"columns\")\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\na\n0\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nb\n1\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nc\n&lt;NA&gt;\n2\n&lt;NA&gt;\n\n\nd\n&lt;NA&gt;\n3\n&lt;NA&gt;\n\n\ne\n&lt;NA&gt;\n4\n&lt;NA&gt;\n\n\nf\n&lt;NA&gt;\n&lt;NA&gt;\n5\n\n\ng\n&lt;NA&gt;\n&lt;NA&gt;\n6\n\n\n\n\n\n\n\n\n\naxis=\"columns\" produces a DataFrame.\nThe result is the union (outer join) of the indexes."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.concat-joininner",
    "href": "qmd/pandas3ed8.html#pandas.concat-joininner",
    "title": "```qmd",
    "section": "pandas.concat: join=\"inner\"",
    "text": "pandas.concat: join=\"inner\"\n\ns4 = pd.concat([s1, s3])\npd.concat([s1, s4], axis=\"columns\", join=\"inner\")\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\na\n0\n0\n\n\nb\n1\n1\n\n\n\n\n\n\n\n\n\njoin=\"inner\" performs an intersection on the indexes."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.concat-keys-argument",
    "href": "qmd/pandas3ed8.html#pandas.concat-keys-argument",
    "title": "```qmd",
    "section": "pandas.concat: keys Argument",
    "text": "pandas.concat: keys Argument\n\nresult = pd.concat([s1, s1, s3], keys=[\"one\", \"two\", \"three\"])\nresult\n\none    a    0\n       b    1\ntwo    a    0\n       b    1\nthree  f    5\n       g    6\ndtype: Int64\n\n\n\nresult.unstack()\n\n\n\n\n\n\n\n\na\nb\nf\ng\n\n\n\n\none\n0\n1\n&lt;NA&gt;\n&lt;NA&gt;\n\n\ntwo\n0\n1\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nthree\n&lt;NA&gt;\n&lt;NA&gt;\n5\n6\n\n\n\n\n\n\n\n\n\nkeys creates a hierarchical index on the concatenation axis. This identifies the concatenated pieces.\nWhen combining Series along axis=\"columns\", the keys become DataFrame column headers."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.concat-with-dataframes",
    "href": "qmd/pandas3ed8.html#pandas.concat-with-dataframes",
    "title": "```qmd",
    "section": "pandas.concat with DataFrames",
    "text": "pandas.concat with DataFrames\nThe logic is the same as with Series:\n\ndf1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=[\"a\", \"b\", \"c\"],\n                   columns=[\"one\", \"two\"])\ndf2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=[\"a\", \"c\"],\n                   columns=[\"three\", \"four\"])\npd.concat([df1, df2], axis=\"columns\", keys=[\"level1\", \"level2\"])\n\n\n\n\n\n\n\n\nlevel1\nlevel2\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\na\n0\n1\n5.0\n6.0\n\n\nb\n2\n3\nNaN\nNaN\n\n\nc\n4\n5\n7.0\n8.0\n\n\n\n\n\n\n\n\nYou can name the created axis levels using the names argument.\nIf row index contains no relevant data, use ignore_index=True."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.concat-function-arguments",
    "href": "qmd/pandas3ed8.html#pandas.concat-function-arguments",
    "title": "```qmd",
    "section": "pandas.concat Function Arguments",
    "text": "pandas.concat Function Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobjs\nList or dictionary of pandas objects to be concatenated (required).\n\n\naxis\nAxis to concatenate along (defaults to “index”).\n\n\njoin\n“inner” or “outer” (defaults to “outer”).\n\n\nkeys\nValues to associate with objects, forming a hierarchical index.\n\n\nlevels\nSpecific indexes to use as hierarchical index levels.\n\n\nnames\nNames for created hierarchical levels.\n\n\nverify_integrity\nCheck new axis for duplicates and raise exception if so (defaults to False).\n\n\nignore_index\nDo not preserve indexes along concatenation axis; produce a new range(total_length) index."
  },
  {
    "objectID": "qmd/pandas3ed8.html#combining-data-with-overlap",
    "href": "qmd/pandas3ed8.html#combining-data-with-overlap",
    "title": "```qmd",
    "section": "Combining Data with Overlap",
    "text": "Combining Data with Overlap\n\nnumpy.where: Performs an array-oriented if-else operation.\n\n\na = pd.Series([np.nan, 2.5, 0.0, 3.5, 4.5, np.nan],\n              index=[\"f\", \"e\", \"d\", \"c\", \"b\", \"a\"])\nb = pd.Series([0., np.nan, 2., np.nan, np.nan, 5.],\n              index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\nnp.where(pd.isna(a), b, a)\n\narray([0. , 2.5, 0. , 3.5, 4.5, 5. ])\n\n\n\nSeries.combine_first: Lines up values by index and “patches” missing data.\n\n\na.combine_first(b)\n\na    0.0\nb    4.5\nc    3.5\nd    0.0\ne    2.5\nf    5.0\ndtype: float64\n\n\n\n\ncombine_first aligns by index (unlike np.where)."
  },
  {
    "objectID": "qmd/pandas3ed8.html#combine_first-with-dataframes",
    "href": "qmd/pandas3ed8.html#combine_first-with-dataframes",
    "title": "```qmd",
    "section": "combine_first with DataFrames",
    "text": "combine_first with DataFrames\n\ncombine_first works column by column.\nIt “patches” missing data in the calling object with data from the passed object.\n\n\ndf1 = pd.DataFrame({\"a\": [1., np.nan, 5., np.nan],\n                    \"b\": [np.nan, 2., np.nan, 6.],\n                    \"c\": range(2, 18, 4)})\ndf2 = pd.DataFrame({\"a\": [5., 4., np.nan, 3., 7.],\n                    \"b\": [np.nan, 3., 4., 6., 8.]})\ndf1.combine_first(df2)\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1.0\nNaN\n2.0\n\n\n1\n4.0\n2.0\n6.0\n\n\n2\n5.0\n4.0\n10.0\n\n\n3\n3.0\n6.0\n14.0\n\n\n4\n7.0\n8.0\nNaN"
  },
  {
    "objectID": "qmd/pandas3ed8.html#reshaping-and-pivoting",
    "href": "qmd/pandas3ed8.html#reshaping-and-pivoting",
    "title": "```qmd",
    "section": "Reshaping and Pivoting",
    "text": "Reshaping and Pivoting\n\nReshape/Pivot operations: Rearrange tabular data.\nHierarchical indexing provides a consistent way to reshape.\nTwo primary actions:\n\nstack: “Rotates” or pivots columns to rows.\nunstack: Pivots rows to columns."
  },
  {
    "objectID": "qmd/pandas3ed8.html#stack-and-unstack-example",
    "href": "qmd/pandas3ed8.html#stack-and-unstack-example",
    "title": "```qmd",
    "section": "stack and unstack: Example",
    "text": "stack and unstack: Example\n\ndata = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                    index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                    columns=pd.Index([\"one\", \"two\", \"three\"],\n                    name=\"number\"))\ndata\n\n\n\n\n\n\n\nnumber\none\ntwo\nthree\n\n\nstate\n\n\n\n\n\n\n\nOhio\n0\n1\n2\n\n\nColorado\n3\n4\n5\n\n\n\n\n\n\n\n\nresult = data.stack()\nresult\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\nresult.unstack()\n\n\n\n\n\n\n\nnumber\none\ntwo\nthree\n\n\nstate\n\n\n\n\n\n\n\nOhio\n0\n1\n2\n\n\nColorado\n3\n4\n5"
  },
  {
    "objectID": "qmd/pandas3ed8.html#unstack-with-different-levels",
    "href": "qmd/pandas3ed8.html#unstack-with-different-levels",
    "title": "```qmd",
    "section": "unstack with Different Levels",
    "text": "unstack with Different Levels\n\nBy default, the innermost level is unstacked.\nSpecify a different level by number or name.\n\n\nresult.unstack(level=0) # or result.unstack(\"state\")\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\nnumber\n\n\n\n\n\n\none\n0\n3\n\n\ntwo\n1\n4\n\n\nthree\n2\n5\n\n\n\n\n\n\n\n\n\nUnstacking might introduce missing data.\nStacking filters out missing data by default.\n\n\n\ns1 = pd.Series([0, 1, 2, 3], index=[\"a\", \"b\", \"c\", \"d\"], dtype=\"Int64\")\ns2 = pd.Series([4, 5, 6], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\ndata2 = pd.concat([s1, s2], keys=[\"one\", \"two\"])\ndata2.unstack().stack(dropna=False)\n\n/tmp/ipykernel_2765/2546955875.py:4: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n  data2.unstack().stack(dropna=False)\n\n\none  a       0\n     b       1\n     c       2\n     d       3\n     e    &lt;NA&gt;\ntwo  a    &lt;NA&gt;\n     b    &lt;NA&gt;\n     c       4\n     d       5\n     e       6\ndtype: Int64"
  },
  {
    "objectID": "qmd/pandas3ed8.html#unstack-in-a-dataframe",
    "href": "qmd/pandas3ed8.html#unstack-in-a-dataframe",
    "title": "```qmd",
    "section": "unstack in a DataFrame",
    "text": "unstack in a DataFrame\nWhen unstacking in a DataFrame, the unstacked level becomes the lowest level in the result.\n\ndf = pd.DataFrame({\"left\": result, \"right\": result + 5},\n                  columns=pd.Index([\"left\", \"right\"], name=\"side\"))\ndf\n\n\n\n\n\n\n\n\nside\nleft\nright\n\n\nstate\nnumber\n\n\n\n\n\n\nOhio\none\n0\n5\n\n\ntwo\n1\n6\n\n\nthree\n2\n7\n\n\nColorado\none\n3\n8\n\n\ntwo\n4\n9\n\n\nthree\n5\n10\n\n\n\n\n\n\n\n\ndf.unstack(level=\"state\").stack(level=\"side\")\n\n/tmp/ipykernel_2765/2617337668.py:1: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n  df.unstack(level=\"state\").stack(level=\"side\")\n\n\n\n\n\n\n\n\n\nstate\nOhio\nColorado\n\n\nnumber\nside\n\n\n\n\n\n\none\nleft\n0\n3\n\n\nright\n5\n8\n\n\ntwo\nleft\n1\n4\n\n\nright\n6\n9\n\n\nthree\nleft\n2\n5\n\n\nright\n7\n10"
  },
  {
    "objectID": "qmd/pandas3ed8.html#pivoting-long-to-wide-format",
    "href": "qmd/pandas3ed8.html#pivoting-long-to-wide-format",
    "title": "```qmd",
    "section": "Pivoting “Long” to “Wide” Format",
    "text": "Pivoting “Long” to “Wide” Format\n\nLong/Stacked Format: Common for storing multiple time series. Each row is a single observation.\nWide Format: Each variable has its own column.\n\n\ndata = pd.read_csv(\"examples/macrodata.csv\")\ndata = data.loc[:, [\"year\", \"quarter\", \"realgdp\", \"infl\", \"unemp\"]]\nperiods = pd.PeriodIndex(year=data.pop(\"year\"),\n                        quarter=data.pop(\"quarter\"),\n                        name=\"date\")\ndata.index = periods.to_timestamp(\"D\")\ndata = data.reindex(columns=[\"realgdp\", \"infl\", \"unemp\"])\ndata.columns.name = \"item\"\nlong_data = (data.stack()\n                .reset_index()\n                .rename(columns={0: \"value\"}))\nlong_data[:10]\n\n/tmp/ipykernel_2765/1472900609.py:3: FutureWarning: Constructing PeriodIndex from fields is deprecated. Use PeriodIndex.from_fields instead.\n  periods = pd.PeriodIndex(year=data.pop(\"year\"),\n\n\n\n\n\n\n\n\n\ndate\nitem\nvalue\n\n\n\n\n0\n1959-01-01\nrealgdp\n2710.349\n\n\n1\n1959-01-01\ninfl\n0.000\n\n\n2\n1959-01-01\nunemp\n5.800\n\n\n3\n1959-04-01\nrealgdp\n2778.801\n\n\n4\n1959-04-01\ninfl\n2.340\n\n\n5\n1959-04-01\nunemp\n5.100\n\n\n6\n1959-07-01\nrealgdp\n2775.488\n\n\n7\n1959-07-01\ninfl\n2.740\n\n\n8\n1959-07-01\nunemp\n5.300\n\n\n9\n1959-10-01\nrealgdp\n2785.204\n\n\n\n\n\n\n\n\nThe pivot method transforms long format to wide format.\n\n\npivoted = long_data.pivot(index=\"date\", columns=\"item\",\n                          values=\"value\")\npivoted.head()\n\n\n\n\n\n\n\nitem\ninfl\nrealgdp\nunemp\n\n\ndate\n\n\n\n\n\n\n\n1959-01-01\n0.00\n2710.349\n5.8\n\n\n1959-04-01\n2.34\n2778.801\n5.1\n\n\n1959-07-01\n2.74\n2775.488\n5.3\n\n\n1959-10-01\n0.27\n2785.204\n5.6\n\n\n1960-01-01\n2.31\n2847.699\n5.2\n\n\n\n\n\n\n\n\n\nindex: Column to use as row index.\ncolumns: Column to use for creating new columns.\nvalues: Column to fill the DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pivoting-with-multiple-value-columns",
    "href": "qmd/pandas3ed8.html#pivoting-with-multiple-value-columns",
    "title": "```qmd",
    "section": "Pivoting with Multiple Value Columns",
    "text": "Pivoting with Multiple Value Columns\n\nlong_data[\"value2\"] = np.random.standard_normal(len(long_data))\npivoted = long_data.pivot(index=\"date\", columns=\"item\")\npivoted.head()\n\n\n\n\n\n\n\n\nvalue\nvalue2\n\n\nitem\ninfl\nrealgdp\nunemp\ninfl\nrealgdp\nunemp\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n1959-01-01\n0.00\n2710.349\n5.8\n1.136942\n1.265442\n1.138561\n\n\n1959-04-01\n2.34\n2778.801\n5.1\n0.887995\n-2.114171\n0.774047\n\n\n1959-07-01\n2.74\n2775.488\n5.3\n-0.887962\n-2.122794\n-0.676487\n\n\n1959-10-01\n0.27\n2785.204\n5.6\n-0.150781\n0.488737\n-0.340528\n\n\n1960-01-01\n2.31\n2847.699\n5.2\n-0.716996\n-1.373274\n1.033034\n\n\n\n\n\n\n\n\n\nIf you omit the values argument, you get hierarchical columns."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pivot-is-equivalent-to",
    "href": "qmd/pandas3ed8.html#pivot-is-equivalent-to",
    "title": "```qmd",
    "section": "pivot is Equivalent to…",
    "text": "pivot is Equivalent to…\npivot is equivalent to using set_index followed by unstack:\n\nunstacked = long_data.set_index([\"date\", \"item\"]).unstack(level=\"item\")\nunstacked.head()\n\n\n\n\n\n\n\n\nvalue\nvalue2\n\n\nitem\ninfl\nrealgdp\nunemp\ninfl\nrealgdp\nunemp\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n1959-01-01\n0.00\n2710.349\n5.8\n1.136942\n1.265442\n1.138561\n\n\n1959-04-01\n2.34\n2778.801\n5.1\n0.887995\n-2.114171\n0.774047\n\n\n1959-07-01\n2.74\n2775.488\n5.3\n-0.887962\n-2.122794\n-0.676487\n\n\n1959-10-01\n0.27\n2785.204\n5.6\n-0.150781\n0.488737\n-0.340528\n\n\n1960-01-01\n2.31\n2847.699\n5.2\n-0.716996\n-1.373274\n1.033034"
  },
  {
    "objectID": "qmd/pandas3ed8.html#pivoting-wide-to-long-format",
    "href": "qmd/pandas3ed8.html#pivoting-wide-to-long-format",
    "title": "```qmd",
    "section": "Pivoting “Wide” to “Long” Format",
    "text": "Pivoting “Wide” to “Long” Format\n\npandas.melt: Inverse of pivot. Merges multiple columns into one, making a DataFrame longer.\n\n\ndf = pd.DataFrame({\"key\": [\"foo\", \"bar\", \"baz\"],\n                   \"A\": [1, 2, 3],\n                   \"B\": [4, 5, 6],\n                   \"C\": [7, 8, 9]})\nmelted = pd.melt(df, id_vars=\"key\")\nmelted\n\n\n\n\n\n\n\n\nkey\nvariable\nvalue\n\n\n\n\n0\nfoo\nA\n1\n\n\n1\nbar\nA\n2\n\n\n2\nbaz\nA\n3\n\n\n3\nfoo\nB\n4\n\n\n4\nbar\nB\n5\n\n\n5\nbaz\nB\n6\n\n\n6\nfoo\nC\n7\n\n\n7\nbar\nC\n8\n\n\n8\nbaz\nC\n9\n\n\n\n\n\n\n\n\nid_vars: Group indicator columns.\nvalue_vars: Columns to “unpivot”. If not specified, all other columns are used."
  },
  {
    "objectID": "qmd/pandas3ed8.html#pandas.melt",
    "href": "qmd/pandas3ed8.html#pandas.melt",
    "title": "```qmd",
    "section": "pandas.melt",
    "text": "pandas.melt\n\npd.melt(df, id_vars=\"key\", value_vars=[\"A\", \"B\"])\n\n\n\n\n\n\n\n\nkey\nvariable\nvalue\n\n\n\n\n0\nfoo\nA\n1\n\n\n1\nbar\nA\n2\n\n\n2\nbaz\nA\n3\n\n\n3\nfoo\nB\n4\n\n\n4\nbar\nB\n5\n\n\n5\nbaz\nB\n6\n\n\n\n\n\n\n\n\npd.melt(df, value_vars=[\"A\", \"B\", \"C\"]) # no group id\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nA\n1\n\n\n1\nA\n2\n\n\n2\nA\n3\n\n\n3\nB\n4\n\n\n4\nB\n5\n\n\n5\nB\n6\n\n\n6\nC\n7\n\n\n7\nC\n8\n\n\n8\nC\n9\n\n\n\n\n\n\n\n\npd.melt(df, value_vars=[\"key\", \"A\", \"B\"])\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nkey\nfoo\n\n\n1\nkey\nbar\n\n\n2\nkey\nbaz\n\n\n3\nA\n1\n\n\n4\nA\n2\n\n\n5\nA\n3\n\n\n6\nB\n4\n\n\n7\nB\n5\n\n\n8\nB\n6\n\n\n\n\n\n\n\n\nCan be used without any group identifiers."
  },
  {
    "objectID": "qmd/pandas3ed8.html#reshaping-with-melt-and-pivot",
    "href": "qmd/pandas3ed8.html#reshaping-with-melt-and-pivot",
    "title": "```qmd",
    "section": "Reshaping with melt and pivot",
    "text": "Reshaping with melt and pivot\n\nreshaped = melted.pivot(index=\"key\", columns=\"variable\",\n                        values=\"value\")\nreshaped\n\n\n\n\n\n\n\nvariable\nA\nB\nC\n\n\nkey\n\n\n\n\n\n\n\nbar\n2\n5\n8\n\n\nbaz\n3\n6\n9\n\n\nfoo\n1\n4\n7\n\n\n\n\n\n\n\n\nreshaped.reset_index() # move index back\n\n\n\n\n\n\n\nvariable\nkey\nA\nB\nC\n\n\n\n\n0\nbar\n2\n5\n8\n\n\n1\nbaz\n3\n6\n9\n\n\n2\nfoo\n1\n4\n7\n\n\n\n\n\n\n\n\n\npivot can reshape back to the original layout.\nSince pivot creates an index, reset_index() may be useful."
  },
  {
    "objectID": "qmd/pandas3ed8.html#summary",
    "href": "qmd/pandas3ed8.html#summary",
    "title": "```qmd",
    "section": "Summary",
    "text": "Summary\n\nWe covered key techniques for data wrangling in pandas:\n\nHierarchical Indexing (MultiIndex).\nmerge (database-style joins).\nconcat (concatenating along an axis).\ncombine_first (patching missing data).\nstack and unstack (reshaping with hierarchical indexing).\npivot (long to wide format).\nmelt (wide to long format).\n\nThese tools are essential for preparing data for analysis and visualization."
  },
  {
    "objectID": "qmd/pandas3ed8.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed8.html#thoughts-and-discussion",
    "title": "```qmd",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\nHow might these techniques be used in your own data analysis projects?\nCan you think of real-world examples where you might need to reshape or combine data in these ways?\nWhat are some of the challenges or limitations of these methods?\nWhich method covered today are you most interested in applying, and why?\nAre there any specific scenarios where you’d prefer merge over concat, or vice-versa?\nHow can understanding hierarchical indexing improve your ability to structure and manipulate complex datasets?"
  },
  {
    "objectID": "qmd/pandas3edA2.html",
    "href": "qmd/pandas3edA2.html",
    "title": "More on the IPython System",
    "section": "",
    "text": "In previous chapters, we touched upon the basics of the IPython shell and Jupyter notebooks.\nNow, we’ll dive deeper into IPython’s functionalities, useful both in console and Jupyter.\nThink of IPython as your enhanced Python interpreter, a powerful tool for interactive computing and data analysis.\nThis appendix supplements your learning material, like a power-up in a video game! 🎮"
  },
  {
    "objectID": "qmd/pandas3edA2.html#introduction-beyond-the-basics",
    "href": "qmd/pandas3edA2.html#introduction-beyond-the-basics",
    "title": "More on the IPython System",
    "section": "",
    "text": "In previous chapters, we touched upon the basics of the IPython shell and Jupyter notebooks.\nNow, we’ll dive deeper into IPython’s functionalities, useful both in console and Jupyter.\nThink of IPython as your enhanced Python interpreter, a powerful tool for interactive computing and data analysis.\nThis appendix supplements your learning material, like a power-up in a video game! 🎮"
  },
  {
    "objectID": "qmd/pandas3edA2.html#terminal-keyboard-shortcuts",
    "href": "qmd/pandas3edA2.html#terminal-keyboard-shortcuts",
    "title": "More on the IPython System",
    "section": "Terminal Keyboard Shortcuts ⌨️",
    "text": "Terminal Keyboard Shortcuts ⌨️\n\nIPython boasts numerous keyboard shortcuts for efficient navigation and command history interaction.\nFamiliar to users of Emacs or Unix bash shell.\nMastering these shortcuts will significantly boost your productivity! ⚡"
  },
  {
    "objectID": "qmd/pandas3edA2.html#terminal-keyboard-shortcuts-continued",
    "href": "qmd/pandas3edA2.html#terminal-keyboard-shortcuts-continued",
    "title": "More on the IPython System",
    "section": "Terminal Keyboard Shortcuts (Continued)",
    "text": "Terminal Keyboard Shortcuts (Continued)\n\n\n\n\n\n\nThe below table lists some of standard IPython keyboard shortcuts.\n\n\n\n\n\n\n\n\n\n\nKeyboard Shortcut\nDescription\n\n\n\n\nCtrl-P or Up Arrow\nSearch backward in command history (matching current text)\n\n\nCtrl-N or Down Arrow\nSearch forward in command history (matching current text)\n\n\nCtrl-R\nReadline-style reverse history search (partial matching)\n\n\nCtrl-Shift-V\nPaste text from clipboard\n\n\nCtrl-C\nInterrupt currently executing code 🛑\n\n\nCtrl-A\nMove cursor to beginning of line\n\n\nCtrl-E\nMove cursor to end of line\n\n\nCtrl-K\nDelete text from cursor to end of line\n\n\nCtrl-U\nDiscard all text on current line\n\n\nCtrl-F\nMove cursor forward one character\n\n\nCtrl-B\nMove cursor backward one character\n\n\nCtrl-L\nClear screen 💨"
  },
  {
    "objectID": "qmd/pandas3edA2.html#visualizing-shortcuts",
    "href": "qmd/pandas3edA2.html#visualizing-shortcuts",
    "title": "More on the IPython System",
    "section": "Visualizing Shortcuts 🖼️",
    "text": "Visualizing Shortcuts 🖼️\n\n\n\n\n\n\nThis figure illustrates some of the keyboard shortcuts in action within the IPython shell.\n\n\n\n\n\nC-b, C-f: Move cursor back/forward (like Ctrl-B, Ctrl-F).\nC-a, C-e: Jump to start/end of line (like Ctrl-A, Ctrl-E).\nC-k: Delete text to end of line (like Ctrl-K).\nC-u: Delete entire line (like Ctrl-U).\nThe shortcuts marked on the a_variable are operations on the text.\n\n\n\n\n\n\n\nJupyter notebooks have their own set of shortcuts. Explore Jupyter’s integrated help!"
  },
  {
    "objectID": "qmd/pandas3edA2.html#magic-commands-ipythons-superpowers",
    "href": "qmd/pandas3edA2.html#magic-commands-ipythons-superpowers",
    "title": "More on the IPython System",
    "section": "Magic Commands: IPython’s Superpowers 🧙‍♂️",
    "text": "Magic Commands: IPython’s Superpowers 🧙‍♂️\n\nMagic commands are special commands unique to IPython, not built-in Python.\nPrefixed with the percent symbol (%).\nThey streamline common tasks and allow you to control IPython’s behavior. Think of them as “shortcuts” for IPython itself!"
  },
  {
    "objectID": "qmd/pandas3edA2.html#example-timeit",
    "href": "qmd/pandas3edA2.html#example-timeit",
    "title": "More on the IPython System",
    "section": "Example: %timeit ⏱️",
    "text": "Example: %timeit ⏱️\n\n%timeit measures the execution time of a Python statement. Very useful for performance analysis!\n\nimport numpy as np\na = np.random.standard_normal((100, 100))\n%timeit np.dot(a, a)\n\nThe output shows the average execution time and standard deviation over multiple runs.\nIn the result 92.5 µs ± 3.43 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each), µs means microsecond."
  },
  {
    "objectID": "qmd/pandas3edA2.html#exploring-magic-commands",
    "href": "qmd/pandas3edA2.html#exploring-magic-commands",
    "title": "More on the IPython System",
    "section": "Exploring Magic Commands ❓",
    "text": "Exploring Magic Commands ❓\n\nUse ? after a magic command to view its “command-line” options (like a help manual).\n\n%debug?\n\n\n\n\n\n\nThis will show the detailed usage of the %debug command, including how to activate the interactive debugger, set breakpoints, and use it in post-mortem mode."
  },
  {
    "objectID": "qmd/pandas3edA2.html#automagic-magic-without-the",
    "href": "qmd/pandas3edA2.html#automagic-magic-without-the",
    "title": "More on the IPython System",
    "section": "automagic: Magic Without the % ✨",
    "text": "automagic: Magic Without the % ✨\n\nautomagic lets you use magic commands without the % prefix, as long as no variable has the same name.\nToggle it on/off with %automagic.\n\n%automagic  # Turns automagic on or off\npwd         # Equivalent to %pwd (if automagic is on and 'pwd' isn't a variable)"
  },
  {
    "objectID": "qmd/pandas3edA2.html#assigning-magic-command-output",
    "href": "qmd/pandas3edA2.html#assigning-magic-command-output",
    "title": "More on the IPython System",
    "section": "Assigning Magic Command Output",
    "text": "Assigning Magic Command Output\n\nSome magic commands behave like functions; you can assign their output to variables.\n\ndirectory = %pwd  # Stores the current working directory in 'directory'\nprint(directory)"
  },
  {
    "objectID": "qmd/pandas3edA2.html#essential-magic-commands",
    "href": "qmd/pandas3edA2.html#essential-magic-commands",
    "title": "More on the IPython System",
    "section": "Essential Magic Commands 📜",
    "text": "Essential Magic Commands 📜\n\n\n\n\n\n\nHere are some frequently used IPython magic commands:\n\n\n\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\n%quickref\nDisplay the IPython Quick Reference Card\n\n\n%magic\nDisplay detailed documentation for all available magic commands\n\n\n%debug\nEnter the interactive debugger at the last exception traceback\n\n\n%hist\nPrint command input history (with optional output)\n\n\n%pdb\nAutomatically enter debugger after any exception\n\n\n%paste\nExecute preformatted Python code from clipboard\n\n\n%cpaste\nOpen a special prompt for manually pasting code\n\n\n%reset\nDelete all variables/names in the interactive namespace\n\n\n%page OBJECT\nPretty-print an object and display it through a pager\n\n\n%run script.py\nRun a Python script inside IPython\n\n\n%prun statement\nExecute a statement with cProfile and report profiler output\n\n\n%time statement\nReport the execution time of a single statement.\n\n\n%timeit statement\nRun a statement multiple times to compute an average execution time; useful for timing code with very short execution time.\n\n\n%who, %who_ls, %whos\nDisplay variables defined in interactive namespace, with varying levels of information/verbosity.\n\n\n%xdel variable\nDelete a variable and attempt to clear any references to the object in the IPython internals.\n\n\n\n\nPress q to exit the %quickref or %magic pager."
  },
  {
    "objectID": "qmd/pandas3edA2.html#the-run-command",
    "href": "qmd/pandas3edA2.html#the-run-command",
    "title": "More on the IPython System",
    "section": "The %run Command 🏃",
    "text": "The %run Command 🏃\n\nExecutes a Python script within your IPython session.\nThe script runs in an empty namespace (no prior imports or variables).\nVariables, functions, and imports from the script become accessible in your IPython shell after execution.\n\n# In a file named 'my_script.py':\ndef my_function(x):\n    return x * 2\n\nresult = my_function(5)\n\n# In IPython:\n%run my_script.py\nprint(result)  # Output: 10"
  },
  {
    "objectID": "qmd/pandas3edA2.html#run--i-accessing-existing-variables",
    "href": "qmd/pandas3edA2.html#run--i-accessing-existing-variables",
    "title": "More on the IPython System",
    "section": "%run -i: Accessing Existing Variables",
    "text": "%run -i: Accessing Existing Variables\n\n%run -i lets the script access variables already defined in your IPython session.\n\n# In IPython:\nmy_var = 10\n\n# In 'script_with_access.py':\nprint(my_var * 3)\n\n# Back in IPython:\n%run -i script_with_access.py  # Output: 30"
  },
  {
    "objectID": "qmd/pandas3edA2.html#load-importing-scripts-into-cells-jupyter",
    "href": "qmd/pandas3edA2.html#load-importing-scripts-into-cells-jupyter",
    "title": "More on the IPython System",
    "section": "%load: Importing Scripts into Cells (Jupyter)",
    "text": "%load: Importing Scripts into Cells (Jupyter)\n\nIn Jupyter notebooks, %load imports a script directly into a code cell.\n\n# %load my_script.py  # This will be replaced by the script's content\n\nThen, the code cell content will be:\n\ndef my_function(x):\n    return x * 2\n\nresult = my_function(5)"
  },
  {
    "objectID": "qmd/pandas3edA2.html#interrupting-running-code",
    "href": "qmd/pandas3edA2.html#interrupting-running-code",
    "title": "More on the IPython System",
    "section": "Interrupting Running Code ✋",
    "text": "Interrupting Running Code ✋\n\nPress Ctrl-C to interrupt running code (whether from %run or a long command).\nRaises a KeyboardInterrupt, stopping most Python programs immediately.\nSometimes, with compiled extensions, Ctrl-C might not work instantly.\n\n\n\n\n\n\n\nIf Ctrl-C doesn’t immediately stop execution (especially when compiled extensions are involved), you may need to forcibly terminate the Python process using your operating system’s tools (e.g., Task Manager on Windows, kill on Linux)."
  },
  {
    "objectID": "qmd/pandas3edA2.html#executing-code-from-the-clipboard",
    "href": "qmd/pandas3edA2.html#executing-code-from-the-clipboard",
    "title": "More on the IPython System",
    "section": "Executing Code from the Clipboard 📋",
    "text": "Executing Code from the Clipboard 📋\n\n%paste and %cpaste are handy for running code copied from elsewhere (but not needed in Jupyter, where direct pasting works).\n%paste executes the clipboard content as a single block.\n%cpaste opens a special prompt, letting you paste multiple blocks and edit before execution. Press Ctrl-D in the prompt to execute, and press Ctrl-C to exit the prompt.\n\n# Example code on clipboard:\nx = 5\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\n# In IPython:\n%paste  # Executes the code immediately"
  },
  {
    "objectID": "qmd/pandas3edA2.html#command-history-your-ipython-memory",
    "href": "qmd/pandas3edA2.html#command-history-your-ipython-memory",
    "title": "More on the IPython System",
    "section": "Command History: Your IPython Memory 🧠",
    "text": "Command History: Your IPython Memory 🧠\n\nIPython keeps a small database of your executed commands. This is incredibly useful for:\n\nSearching and reusing past commands.\nPersisting history between sessions.\nLogging input/output to a file."
  },
  {
    "objectID": "qmd/pandas3edA2.html#searching-and-reusing-commands",
    "href": "qmd/pandas3edA2.html#searching-and-reusing-commands",
    "title": "More on the IPython System",
    "section": "Searching and Reusing Commands 🔎",
    "text": "Searching and Reusing Commands 🔎\n\nUp Arrow (Ctrl-P): Search backward in history, matching typed text.\nDown Arrow (Ctrl-N): Search forward in history.\nCtrl-R: Reverse-i-search (like in bash). Type characters, and it finds matching commands. Press Ctrl-R multiple times to cycle."
  },
  {
    "objectID": "qmd/pandas3edA2.html#input-and-output-variables",
    "href": "qmd/pandas3edA2.html#input-and-output-variables",
    "title": "More on the IPython System",
    "section": "Input and Output Variables ↩︎️",
    "text": "Input and Output Variables ↩︎️\n\nIPython stores input and output:\n\n_ (one underscore): Previous output.\n__ (two underscores): Second-to-last output.\n_iX: Input of line X (e.g., _i5 for input on line 5) - stored as a string.\n_X: Output of line X.\n\n\n2 + 2      # Output: 4\nresult = _  # result is now 4\nprint(_i1)  # Prints the string \"2 + 2\""
  },
  {
    "objectID": "qmd/pandas3edA2.html#working-with-history-hist-reset-xdel",
    "href": "qmd/pandas3edA2.html#working-with-history-hist-reset-xdel",
    "title": "More on the IPython System",
    "section": "Working with History: %hist, %reset, %xdel",
    "text": "Working with History: %hist, %reset, %xdel\n\n%hist: Prints input history (with or without line numbers).\n%reset: Clears the interactive namespace (and optionally input/output caches).\n%xdel variable: Removes a variable and tries to clear IPython’s internal references. Useful for memory management with large datasets.\n\n\n\n\n\n\n\nIPython’s input/output history can keep large objects in memory even after you del them. Use %xdel and %reset carefully to avoid memory issues."
  },
  {
    "objectID": "qmd/pandas3edA2.html#interacting-with-the-operating-system",
    "href": "qmd/pandas3edA2.html#interacting-with-the-operating-system",
    "title": "More on the IPython System",
    "section": "Interacting with the Operating System 💻",
    "text": "Interacting with the Operating System 💻\n\nIPython lets you interact with your OS without leaving the shell.\nRun shell commands, change directories, and capture command output."
  },
  {
    "objectID": "qmd/pandas3edA2.html#shell-commands-with",
    "href": "qmd/pandas3edA2.html#shell-commands-with",
    "title": "More on the IPython System",
    "section": "Shell Commands with ! 💥",
    "text": "Shell Commands with ! 💥\n\nStart a line with ! to execute it as a shell command.\n\n!ls  # Lists files in the current directory (Linux/macOS)\n!dir # Lists files (Windows)"
  },
  {
    "objectID": "qmd/pandas3edA2.html#capturing-shell-output",
    "href": "qmd/pandas3edA2.html#capturing-shell-output",
    "title": "More on the IPython System",
    "section": "Capturing Shell Output",
    "text": "Capturing Shell Output\n\nAssign the output of a ! command to a variable.\n\nfile_list = !ls\nprint(file_list)  # Prints the list of files\n\nThe returned object is a custom list containing various versions of console output."
  },
  {
    "objectID": "qmd/pandas3edA2.html#python-variables-in-shell-commands",
    "href": "qmd/pandas3edA2.html#python-variables-in-shell-commands",
    "title": "More on the IPython System",
    "section": "Python Variables in Shell Commands: $",
    "text": "Python Variables in Shell Commands: $\n\nUse $ to substitute Python variables into shell commands.\n\nmy_directory = \"data_files\"\n!ls $my_directory  # Lists files in the 'data_files' directory"
  },
  {
    "objectID": "qmd/pandas3edA2.html#aliases-and-bookmarks-shortcuts-for-commands-and-directories",
    "href": "qmd/pandas3edA2.html#aliases-and-bookmarks-shortcuts-for-commands-and-directories",
    "title": "More on the IPython System",
    "section": "Aliases and Bookmarks: Shortcuts for Commands and Directories",
    "text": "Aliases and Bookmarks: Shortcuts for Commands and Directories\n\n%alias: Create shortcuts for shell commands.\n\n%alias ll ls -l  # Creates an alias 'll' for 'ls -l'\nll /usr/bin  # Now you can use 'll'\n\n%bookmark: Create bookmarks for frequently used directories.\n\n%bookmark mydata /path/to/my/data\ncd mydata       # Jumps to the bookmarked directory\n%bookmark -l    # Lists all bookmarks\n\nAliases are not persistent between sessions (unless configured). Bookmarks are persistent."
  },
  {
    "objectID": "qmd/pandas3edA2.html#directory-history",
    "href": "qmd/pandas3edA2.html#directory-history",
    "title": "More on the IPython System",
    "section": "Directory History",
    "text": "Directory History\n\n%cd: Change directory.\n%pwd: return current directory.\n%pushd: place current directory on stack and change to target directory.\n%popd: Change to directory popped off the top of the stack.\n%dirs: Return a list containing the current directory stack.\n%dhist: Print the history of visited directories."
  },
  {
    "objectID": "qmd/pandas3edA2.html#environment-variable",
    "href": "qmd/pandas3edA2.html#environment-variable",
    "title": "More on the IPython System",
    "section": "Environment Variable",
    "text": "Environment Variable\n\n%env: Return the system environment variables as a dictionary.\n%matplotlib: Configure matplotlib integration options"
  },
  {
    "objectID": "qmd/pandas3edA2.html#software-development-tools",
    "href": "qmd/pandas3edA2.html#software-development-tools",
    "title": "More on the IPython System",
    "section": "Software Development Tools 🛠️",
    "text": "Software Development Tools 🛠️\n\nIPython isn’t just for interactive exploration; it’s also great for software development.\nKey tools:\n\nInteractive Debugger: Enhanced pdb.\nCode Timing: %time and %timeit.\nProfiling: %prun, %lprun."
  },
  {
    "objectID": "qmd/pandas3edA2.html#interactive-debugger-debug",
    "href": "qmd/pandas3edA2.html#interactive-debugger-debug",
    "title": "More on the IPython System",
    "section": "Interactive Debugger: %debug 🐞",
    "text": "Interactive Debugger: %debug 🐞\n\n%debug: Enters the debugger after an exception occurs (post-mortem debugging).\nDrops you into the stack frame where the error happened.\nEnhanced with tab completion, syntax highlighting, and traceback context.\n\n# Suppose some_script.py has an error:\n%run some_script.py\n%debug  # Enters the debugger at the error point"
  },
  {
    "objectID": "qmd/pandas3edA2.html#debugger-commands",
    "href": "qmd/pandas3edA2.html#debugger-commands",
    "title": "More on the IPython System",
    "section": "Debugger Commands 🧭",
    "text": "Debugger Commands 🧭\n\nInside the debugger:\n\nu (up): Move up the call stack.\nd (down): Move down the call stack.\ns (step): Step into a function call.\nn (next): Execute current line and move to the next line (at the current level).\nc (continue): Continue execution until the next breakpoint or the end.\nq (quit): Exit the debugger.\np variable: print value of variable\n!variable : Examine variable contents, when the variable has the same name of a debugger command."
  },
  {
    "objectID": "qmd/pandas3edA2.html#pdb-automatic-debugging",
    "href": "qmd/pandas3edA2.html#pdb-automatic-debugging",
    "title": "More on the IPython System",
    "section": "%pdb: Automatic Debugging",
    "text": "%pdb: Automatic Debugging\n\n%pdb: Automatically enters the debugger on any exception. Very useful for debugging!\n\n%pdb on  # Turns on automatic debugging\n# Now, any error will drop you into the debugger\n%pdb off # Turns it off"
  },
  {
    "objectID": "qmd/pandas3edA2.html#using-the-debugger-for-development",
    "href": "qmd/pandas3edA2.html#using-the-debugger-for-development",
    "title": "More on the IPython System",
    "section": "Using the Debugger for Development",
    "text": "Using the Debugger for Development\n\n%run -d script.py: Start the debugger before running the script. Type s to step into the script.\n%run -d -b line_number script.py: Set a breakpoint at line_number.\nset_trace(): A “poor man’s breakpoint” function you can insert into your code.\ndebug(function, *args, **kwargs) : Easily step into a specific function call."
  },
  {
    "objectID": "qmd/pandas3edA2.html#set_trace-and-debug-functions",
    "href": "qmd/pandas3edA2.html#set_trace-and-debug-functions",
    "title": "More on the IPython System",
    "section": "set_trace() and debug() functions",
    "text": "set_trace() and debug() functions\nfrom IPython.core.debugger import Pdb\n\ndef set_trace():\n    Pdb().set_trace(sys._getframe().f_back)\n\ndef debug(f, *args, **kwargs):\n    pdb = Pdb()\n    return pdb.runcall(f, *args, **kwargs)\n\nset_trace() is called within your code to create a temporary breakpoint.\ndebug(f, *args, **kwargs) allows stepping into the function f by passing f along with its positional and keyword arguments."
  },
  {
    "objectID": "qmd/pandas3edA2.html#code-timing-time-and-timeit-again",
    "href": "qmd/pandas3edA2.html#code-timing-time-and-timeit-again",
    "title": "More on the IPython System",
    "section": "Code Timing: %time and %timeit (Again)",
    "text": "Code Timing: %time and %timeit (Again)\n\n%time: Measures the execution time of a statement once.\n%timeit: Measures execution time multiple times for a more accurate average. Best for very short operations.\n\nmy_list = list(range(100000))\n%time for _ in range(100):  sum(my_list)\n%timeit sum(my_list)"
  },
  {
    "objectID": "qmd/pandas3edA2.html#basic-profiling-prun-and-run--p",
    "href": "qmd/pandas3edA2.html#basic-profiling-prun-and-run--p",
    "title": "More on the IPython System",
    "section": "Basic Profiling: %prun and %run -p 🕵️‍♀️",
    "text": "Basic Profiling: %prun and %run -p 🕵️‍♀️\n\nProfiling tells you where your code spends its time.\n%prun statement: Profiles a single Python statement.\n%run -p script.py: Profiles an entire script.\nUses cProfile under the hood.\nOutput shows:\n\nncalls: Number of calls.\ntottime: Total time spent in the function (excluding calls to sub-functions).\npercall: Time per call (tottime / ncalls).\ncumtime: Cumulative time spent in the function and its sub-functions.\npercall: Cumulative time per call (cumtime / ncalls).\nfilename:lineno(function): Location of the function.\n\n\n#Example\ndef slow_function():\n    result = []\n    for i in range(1000):\n        result.append(i * 2)\n    return result\n\n%prun slow_function()"
  },
  {
    "objectID": "qmd/pandas3edA2.html#line-profiling-lprun",
    "href": "qmd/pandas3edA2.html#line-profiling-lprun",
    "title": "More on the IPython System",
    "section": "Line Profiling: %lprun 📏",
    "text": "Line Profiling: %lprun 📏\n\n%lprun: Provides line-by-line profiling of specific functions. More detailed than %prun.\nRequires the line_profiler IPython extension.\n\nEnable: add c.InteractiveShellApp.extensions = ['line_profiler'] in ipython_config.py, or use %load_ext line_profiler.\n\nSyntax: %lprun -f function1 -f function2 statement_to_profile\nOutput shows:\n\nLine #: Line number.\nHits: Number of times the line was executed.\nTime: Total time spent on the line (in timer units).\nPer Hit: Time per execution of the line.\n% Time: Percentage of total time spent on the line.\nLine Contents: The actual code.\n\n\n# Assuming line_profiler is enabled and prof_mod.py exists:\nfrom prof_mod import add_and_sum, call_function #example file, you need create it.\n%lprun -f add_and_sum call_function()"
  },
  {
    "objectID": "qmd/pandas3edA2.html#tips-for-productive-code-development",
    "href": "qmd/pandas3edA2.html#tips-for-productive-code-development",
    "title": "More on the IPython System",
    "section": "Tips for Productive Code Development 📝",
    "text": "Tips for Productive Code Development 📝\n\nReloading Module Dependencies:\n\nProblem: Changes to imported modules aren’t automatically reflected in IPython.\nSolutions:\n\nimportlib.reload(module): Reloads a single module.\ndreload(module) (IPython-specific): Deep (recursive) reload of a module and its dependencies. More robust.\n\n\nCode Design:\n\nKeep relevant objects and data alive: Avoid putting all your code inside a main() function. Keep variables at the top level for easy inspection in IPython.\nFlat is better than nested: Avoid deeply nested code. Makes debugging and testing easier.\nOvercome a fear of longer files: Within reason, longer, well-organized modules are often better than many small, interconnected ones (reduces reloading overhead).\nMaintain high internal cohesion: Related code should be grouped together."
  },
  {
    "objectID": "qmd/pandas3edA2.html#ipython-profiles-and-configuration",
    "href": "qmd/pandas3edA2.html#ipython-profiles-and-configuration",
    "title": "More on the IPython System",
    "section": "IPython Profiles and Configuration ⚙️",
    "text": "IPython Profiles and Configuration ⚙️\n\nCustomize IPython’s appearance and behavior through configuration files (ipython_config.py).\nLocated in your IPython directory (usually ~/.ipython/profile_default/).\nYou can have multiple profiles for different projects or settings.\nCreate a new profile: ipython profile create my_profile\nLaunch with a specific profile: ipython --profile=my_profile\nJupyter has its own configuration system."
  },
  {
    "objectID": "qmd/pandas3edA2.html#conclusion",
    "href": "qmd/pandas3edA2.html#conclusion",
    "title": "More on the IPython System",
    "section": "Conclusion 📖",
    "text": "Conclusion 📖\n\nIPython and Jupyter are powerful tools for both interactive exploration and software development.\nMastering their features – shortcuts, magic commands, debugger, profiler, and configuration – will significantly enhance your productivity.\nExperiment and find a workflow that suits your style!"
  },
  {
    "objectID": "qmd/pandas3edA2.html#summary",
    "href": "qmd/pandas3edA2.html#summary",
    "title": "More on the IPython System",
    "section": "Summary",
    "text": "Summary\n\nWe explored advanced IPython features, going beyond basic shell usage.\nLearned about keyboard shortcuts, magic commands, and interacting with the OS.\nCovered debugging, code timing, and profiling tools.\nDiscussed tips for writing code that’s well-suited for interactive development in IPython.\nIntroduced IPython profile."
  },
  {
    "objectID": "qmd/pandas3edA2.html#thoughts-and-discussion",
    "href": "qmd/pandas3edA2.html#thoughts-and-discussion",
    "title": "More on the IPython System",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\nWhich IPython features do you find most useful for your workflow?\nHow can you incorporate these tools into your data analysis and coding practices?\nConsider setting up a custom IPython profile to streamline your common tasks.\nWhat are the advantages and disadvantages of using IPython compared to a traditional Python IDE?\nHow do the principles of “flat is better than nested” and “overcome a fear of longer files” apply to your own coding style?\nHow can you use the debugger and profiler to improve the correctness and efficiency of your code?\nHow does %run differ from simply executing a Python script from the command line?\nHow can you use %paste or %cpaste to quickly execute code from external sources in IPython Shell?\nWhat is the command history, and how to use it?"
  },
  {
    "objectID": "qmd/pandas3ed9.html",
    "href": "qmd/pandas3ed9.html",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Making informative visualizations (sometimes called plots) is one of the most important tasks in data analysis.\n\n\nExploratory Process: Helps identify outliers or needed data transformations.\nModel Generation: Aids in generating ideas for models.\nWeb Visualization: Building interactive visualizations can be the end goal.\n\n\n\n\n\n\n\nNote\n\n\n\nPython has many add-on libraries for visualizations, but we’ll focus on matplotlib and libraries built on top of it, such as seaborn.\n\n\n\n\n\n\nA desktop plotting package for creating publication-quality plots and figures.\nStarted by John Hunter in 2002 to provide a MATLAB-like plotting interface in Python.\n\nWhy? 🤔 To make it easier for scientists and engineers to create plots in Python, just like they did in MATLAB!\n\nCollaborated with IPython to simplify interactive plotting.\nSupports various GUI backends and export formats (PDF, SVG, JPG, PNG, BMP, GIF, etc.).\nMost graphics in many books and publications are produced using matplotlib.\n\n\n\n\n\n\n\nTip\n\n\n\nMatplotlib has spawned add-on toolkits like seaborn, enhancing its capabilities.\n\n\n\n\n\nTo display plots inline in Jupyter Notebook, use the magic command:\n%matplotlib inline\n\n\n\n\n\n\nNote\n\n\n\nThis command tells Jupyter to display matplotlib plots directly in the notebook output. Without it, you might not see your plots!\n\n\n\n\n\n\nMany new visualization libraries have emerged since 2012.\n\nBokeh and Altair: Leverage modern web tech for interactive visualizations.\n\nThis course focuses on matplotlib due to its fundamental nature and integration with pandas.\n\nWhy matplotlib? 🤔 It’s like learning to walk before you run! Understanding matplotlib helps you grasp the basics, making it easier to learn other libraries later.\n\n\n\n\n\n\n\n\nTip\n\n\n\nPrinciples learned here are adaptable to other visualization libraries.\n\n\n\n\n\nImport convention for matplotlib:\nimport matplotlib.pyplot as plt\n\n\n\n\n\n\nNote\n\n\n\nThis line imports the pyplot module from matplotlib and gives it a shorter name, plt. This is a common practice to make your code cleaner and easier to read.\n\n\n\n\n\nimport numpy as np\ndata = np.arange(10)\nplt.plot(data)\n\nnp.arange(10): Creates an array of numbers from 0 to 9.\nplt.plot(data): Plots the data as a line chart.\n\n\n\n\n\n\n\n\n\n\nFigure 9-1. Simple line plot\n\n\n\n\n\n\n\n\n\nPlots in matplotlib reside within a Figure object.\n\nWhat’s a Figure? 🤔 Think of it as a blank canvas where you can draw your plots.\n\nCreate a new figure using plt.figure():\n\nfig = plt.figure()\n\nplt.figure options:\n\nfigsize: Guarantees figure size and aspect ratio.\n\n\n\n\n\n\nYou can’t plot on a blank figure; create subplots using add_subplot:\n\nax1 = fig.add_subplot(2, 2, 1)\n\nadd_subplot(2, 2, 1) means:\n\nA 2x2 grid of subplots (4 plots total).\nSelect the 1st subplot (numbered from 1).\nAnalogy: It is just like the form in Excel to select a range of cells.\n\nCreate additional subplots:\n\nax2 = fig.add_subplot(2, 2, 2)\nax3 = fig.add_subplot(2, 2, 3)\n\n\n\n\n\n\n\n\n\nFigure 9-2. An empty matplotlib figure with three subplots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn Jupyter Notebook, plots are reset after each cell. Put all plotting commands in a single cell.\n\nWhy? 🤔 Jupyter runs each cell independently. If you split your plotting commands, you might only see the last plot!\n\n\n\nfig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 2, 2)\nax3 = fig.add_subplot(2, 2, 3)\n\n\n\n\nAxesSubplot objects have methods to create different plot types.\nPreferred over top-level functions like plt.plot.\nExample:\n\nax3.plot(np.random.standard_normal(50).cumsum(), color=\"black\", linestyle=\"dashed\")\n\n\n\n\n\n\n\n\n\nFigure 9-3. Data visualization after a single plot\n\n\n\n\n\n\n\n\n\nYou might see output like &lt;matplotlib.lines.Line2D at ...&gt;.\n\nWhat does this mean? 🤔 It’s a reference to the plot element you just added. You can usually ignore it.\n\nTo suppress the output, add a semicolon (;) at the end of the line.\n\nWhy suppress? 🧹 Keeps your notebook output clean and focused on the plots.\n\n\nax3.plot(np.random.standard_normal(50).cumsum(), color=\"black\", linestyle=\"dashed\"); # Note the semicolon\n\n\n\nax1.hist(np.random.standard_normal(100), bins=20, color=\"black\", alpha=0.3)\nax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.standard_normal(30))\n\nax1.hist(...): Creates a histogram.\nax2.scatter(...): Creates a scatter plot.\nalpha=0.3: Sets the transparency of the plot.\n\n\n\n\n\n\n\n\n\n\nFigure 9-4. Data visualization after additional plots\n\n\n\n\n\n\n\n\n\nplt.subplots creates a figure and a NumPy array of subplot objects:\n\nfig, axes = plt.subplots(2, 3)\naxes\narray([[&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;],\n       [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;]], dtype=object)\n\nAccess subplots like a 2D array: axes[0, 1].\nsharex and sharey: Share the same x or y-axis for comparing data.\n\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nnrows\nNumber of rows of subplots\n\n\nncols\nNumber of columns of subplots\n\n\nsharex\nAll subplots use the same x-axis ticks\n\n\nsharey\nAll subplots use the same y-axis ticks\n\n\nsubplot_kw\nDictionary of keywords passed to add_subplot\n\n\n**fig_kw\nAdditional keywords passed to subplots (e.g., figsize=(8, 6))\n\n\n\n\n\n\n\n\n\nTable 9-1. matplotlib.pyplot.subplots options\n\n\n\n\n\n\n\nDefault padding and spacing between subplots.\nChange spacing using the subplots_adjust method:\n\nfig.subplots_adjust(left=None, bottom=None, right=None, top=None,\n                    wspace=None, hspace=None)\n\nwspace and hspace: Control the percentage of figure width/height for spacing.\n\n\n\n\nfig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\nfor i in range(2):\n    for j in range(2):\n        axes[i, j].hist(np.random.standard_normal(500), bins=50,\n                        color=\"black\", alpha=0.5)\nfig.subplots_adjust(wspace=0, hspace=0)\n\n\n\n\n\n\n\n\n\nFigure 9-5. Data visualization with no inter-subplot spacing\n\n\n\n\n\n\n\n\n\nmatplotlib doesn’t check for overlapping labels.\nFix labels by specifying tick locations and labels.\nCovered in the “Ticks, Labels, and Legends” section.\n\n\n\n\n\nCustomize line plots with color, markers, and line styles.\nExample:\n\nax.plot(x, y, linestyle=\"--\", color=\"green\")\n\nUse color names or hex codes (e.g., \"#CECECE\").\nLine styles: Check plt.plot docstring (use plt.plot?).\n\n\n\n\n\nLine plots can have markers to show actual data points.\nUseful when interpolation might obscure point locations.\nExample:\n\nax.plot(np.random.standard_normal(30).cumsum(), color=\"black\",\n        linestyle=\"dashed\", marker=\"o\")\n\n\n\n\n\n\n\n\n\nFigure 9-6. Line plot with markers\n\n\n\n\n\n\n\n\n\nLinear interpolation is the default.\nChange with the drawstyle option:\n\nax.plot(data, color=\"black\", linestyle=\"dashed\", label=\"Default\")\nax.plot(data, color=\"black\", linestyle=\"dashed\",\n        drawstyle=\"steps-post\", label=\"steps-post\")\nax.legend()\n\n\n\n\n\n\n\n\n\nFigure 9-7. Line plot with different drawstyle options\n\n\n\n\n\n\n\n\n\nPlot decorations are accessed through matplotlib axes object methods.\nxlim, xticks, xticklabels: Control plot range, tick locations, and labels.\nTwo ways to use:\n\nNo arguments: Returns the current value (e.g., ax.xlim()).\nWith parameters: Sets the value (e.g., ax.xlim([0, 10])).\n\n\n\n\n\n\nExample: Random walk plot.\n\nfig, ax = plt.subplots()\nax.plot(np.random.standard_normal(1000).cumsum())\n\n\n\n\n\n\n\n\n\nFigure 9-8. Simple plot for illustrating xticks (with default labels)\n\n\n\n\n\n\nSet ticks and tick labels\n\nticks = ax.set_xticks([0, 250, 500, 750, 1000])\nlabels = ax.set_xticklabels([\"one\", \"two\", \"three\", \"four\", \"five\"],\n                            rotation=30, fontsize=8)\n\n\n\nax.set_xlabel(\"Stages\")\nax.set_title(\"My first matplotlib plot\")\n\n\n\n\n\n\n\n\n\nFigure 9-9. Simple plot for illustrating custom xticks\n\n\n\n\n\n\nrotation: Sets tick label rotation (e.g., 30 degrees).\nset_xlabel: Names the x-axis.\nset_title: Sets the subplot title.\n\n\n\n\n\nAxes class has a set method:\n\nax.set(title=\"My first matplotlib plot\", xlabel=\"Stages\")\n\n\n\n\nLegends identify plot elements.\nPass the label argument when adding plot elements:\n\nfig, ax = plt.subplots()\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", label=\"one\")\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", linestyle=\"dashed\", label=\"two\")\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", linestyle=\"dotted\", label=\"three\")\nax.legend()\n\n\n\n\n\n\n\n\n\nFigure 9-10. Simple plot with three lines and legend\n\n\n\n\n\n\n\n\n\nax.legend(): Automatically creates a legend.\nloc: Specifies legend location (default is \"best\").\nExclude elements: Pass no label or label=\"_nolegend_\".\n\n\n\n\n\nAdd custom annotations: text, arrows, shapes.\ntext, arrow, annotate functions.\nax.text(x, y, \"Hello world!\", family=\"monospace\", fontsize=10): Draws text at (x, y).\n\n\n\n\n\nExample: Plotting S&P 500 closing price since 2007 with annotations.\n\nfrom datetime import datetime\n\nfig, ax = plt.subplots()\n\ndata = pd.read_csv(\"examples/spx.csv\", index_col=0, parse_dates=True)\nspx = data[\"SPX\"]\n\nspx.plot(ax=ax, color=\"black\")\n\ncrisis_data = [\n    (datetime(2007, 10, 11), \"Peak of bull market\"),\n    (datetime(2008, 3, 12), \"Bear Stearns Fails\"),\n    (datetime(2008, 9, 15), \"Lehman Bankruptcy\")\n]\n\nfor date, label in crisis_data:\n    ax.annotate(label, xy=(date, spx.asof(date) + 75),\n                xytext=(date, spx.asof(date) + 225),\n                arrowprops=dict(facecolor=\"black\", headwidth=4, width=2,\n                                headlength=4),\n                horizontalalignment=\"left\", verticalalignment=\"top\")\n\n# Zoom in on 2007-2010\nax.set_xlim([\"1/1/2007\", \"1/1/2011\"])\nax.set_ylim([600, 1800])\n\nax.set_title(\"Important dates in the 2008-2009 financial crisis\")\n\n\n\n\n\n\n\n\n\nFigure 9-11. Important dates in the 2008–2009 financial crisis\n\n\n\n\n\n\n\n\n\nax.annotate: Draws labels at specified (x, y) coordinates.\nset_xlim, set_ylim: Manually set plot boundaries.\nax.set_title: Adds a main title.\n\n\n\n\n\nmatplotlib has objects called patches representing shapes.\nRectangle, Circle: Found in matplotlib.pyplot.\nFull set: matplotlib.patches.\nAdd to plot using ax.add_patch:\n\nfig, ax = plt.subplots()\n\nrect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color=\"black\", alpha=0.3)\ncirc = plt.Circle((0.7, 0.2), 0.15, color=\"blue\", alpha=0.3)\npgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]],\n                    color=\"green\", alpha=0.5)\n\nax.add_patch(rect)\nax.add_patch(circ)\nax.add_patch(pgon)\n\n\n\n\n\n\n\n\n\nFigure 9-12. Data visualization composed from three different patches\n\n\n\n\n\n\n\n\n\nsavefig instance method: Saves the active figure.\nExample:\n\nfig.savefig(\"figpath.svg\")\n\nFile type inferred from extension (e.g., .pdf, .png).\ndpi: Controls dots-per-inch resolution.\n\nfig.savefig(\"figpath.png\", dpi=400)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfname\nFilepath or Python file-like object; format inferred from extension\n\n\ndpi\nResolution in dots per inch\n\n\nfacecolor\nFigure background color outside subplots (default: \"w\" - white)\n\n\nedgecolor\nColor of the figure edge\n\n\nformat\nExplicit file format (e.g., \"png\", \"pdf\", \"svg\")\n\n\n\n\n\n\n\n\n\nTable 9-2. Some fig.savefig options\n\n\n\n\n\n\n\nmatplotlib has configurations for color schemes and defaults.\nCustomize via global parameters: figure size, subplot spacing, colors, fonts, etc.\nrc method: Modifies configuration programmatically.\nExample: Set default figure size to 10x10.\n\nplt.rc(\"figure\", figsize=(10, 10))\n\n\n\n\nCurrent settings: plt.rcParams dictionary.\nRestore defaults: plt.rcdefaults().\n\n\n\n\n\nFirst rc argument: Component to customize (e.g., \"figure\", \"axes\", \"xtick\").\nFollowed by keyword arguments for new parameters.\nExample:\n\nplt.rc(\"font\", family=\"monospace\", weight=\"bold\", size=8)\n\n\n\n\nExtensive customization: matplotlibrc file in matplotlib/mpl-data.\nPlace a customized matplotlibrc in your home directory as .matplotlibrc.\nLoaded each time you use matplotlib.\n\n\n\n\n\nseaborn uses matplotlib’s configuration system internally.\nseaborn has built-in plot themes and styles.\n\n\n\n\n\nMatplotlib can be low-level.\npandas: Built-in methods for visualizing DataFrame and Series objects.\nseaborn: High-level statistical graphics library built on matplotlib.\nseaborn simplifies creating common visualization types.\n\n\n\n\n\nSeries and DataFrame have a plot attribute.\nplot() makes line plots by default:\n\ns = pd.Series(np.random.standard_normal(10).cumsum(), index=np.arange(0, 100, 10))\ns.plot()\n\n\n\n\n\n\n\n\n\nFigure 9-13. Simple Series plot\n\n\n\n\n\n\nSeries index: Used for x-axis (disable with use_index=False).\nxticks, xlim, yticks, ylim: Adjust axis ticks and limits.\n\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlabel\nLabel for plot legend\n\n\nax\nmatplotlib subplot object to plot on\n\n\nstyle\nStyle string (e.g., \"ko--\")\n\n\nalpha\nPlot fill opacity (0 to 1)\n\n\nkind\nPlot type: \"area\", \"bar\", \"barh\", \"density\", \"hist\", \"kde\", \"line\", \"pie\"\n\n\nfigsize\nSize of the figure object\n\n\nlogx\nLogarithmic scaling on x-axis\n\n\nlogy\nLogarithmic scaling on y-axis\n\n\ntitle\nTitle for the plot\n\n\nuse_index\nUse object index for tick labels\n\n\nrot\nRotation of tick labels (0-360)\n\n\nxticks\nValues for x-axis ticks\n\n\nyticks\nValues for y-axis ticks\n\n\nxlim\nx-axis limits (e.g., [0, 10])\n\n\nylim\ny-axis limits\n\n\ngrid\nDisplay axis grid (off by default)\n\n\n\n\n\n\n\n\n\nTable 9-3. Series.plot method arguments\n\n\n\n\npandas plotting methods accept an optional ax parameter for a matplotlib subplot object.\n\n\n\n\ndf = pd.DataFrame(np.random.standard_normal((10, 4)).cumsum(0),\n                  columns=[\"A\", \"B\", \"C\", \"D\"],\n                  index=np.arange(0, 100, 10))\nplt.style.use('grayscale') #use grayscale style to adapt to black and white publication\ndf.plot()\n\n\n\n\n\n\n\n\n\nFigure 9-14. Simple DataFrame plot\n\n\n\n\n\n\nPlots each column as a separate line on the same subplot.\nCreates a legend automatically.\ndf.plot() is equivalent to df.plot.line().\n\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsubplots\nPlot each DataFrame column in a separate subplot\n\n\nlayout\n2-tuple (rows, columns) for subplot layout\n\n\nsharex\nIf subplots=True, share x-axis ticks and limits\n\n\nsharey\nIf subplots=True, share y-axis\n\n\nlegend\nAdd a subplot legend (True by default)\n\n\nsort_columns\nPlot columns in alphabetical order (default: use existing order)\n\n\n\n\n\n\n\n\n\nTable 9-4. DataFrame-specific plot arguments\n\n\n\n\nAdditional keyword arguments are passed to matplotlib plotting functions.\n\n\n\n\n\nplot.bar(): Vertical bar plots.\nplot.barh(): Horizontal bar plots.\nSeries/DataFrame index: Used for x (bar) or y (barh) ticks.\n\nfig, axes = plt.subplots(2, 1)\ndata = pd.Series(np.random.uniform(size=16), index=list(\"abcdefghijklmnop\"))\ndata.plot.bar(ax=axes[0], color=\"black\", alpha=0.7)\ndata.plot.barh(ax=axes[1], color=\"black\", alpha=0.7)\n\n\n\n\n\n\n\n\n\nFigure 9-15. Horizonal and vertical bar plot\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(np.random.uniform(size=(6, 4)),\n                  index=[\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"],\n                  columns=pd.Index([\"A\", \"B\", \"C\", \"D\"], name=\"Genus\"))\ndf.plot.bar()\n\n\n\n\n\n\n\n\n\nFigure 9-16. DataFrame bar plot\n\n\n\n\n\n\nGroups values in each row in bars, side by side.\nDataFrame column name: Used for legend title.\n\n\n\n\n\nstacked=True: Creates stacked bar plots.\nValues in each row are stacked together.\n\ndf.plot.barh(stacked=True, alpha=0.5)\n\n\n\n\n\n\n\n\n\nFigure 9-17. DataFrame stacked bar plot\n\n\n\n\n\n\n\n\n\nVisualize tipping data: Percentage of data points for each party size, per day.\nread_csv: Load data.\ncrosstab: Cross-tabulation by day and party size.\nCalculate the frequency of two columns in the dataframe.\n\ntips = pd.read_csv(\"examples/tips.csv\")\nparty_counts = pd.crosstab(tips[\"day\"], tips[\"size\"])\nparty_counts = party_counts.reindex(index=[\"Thur\", \"Fri\", \"Sat\", \"Sun\"])\n# Remove 1- and 6-person parties\nparty_counts = party_counts.loc[:, 2:5]\n\n# Normalize to sum to 1\nparty_pcts = party_counts.div(party_counts.sum(axis=\"columns\"), axis=\"index\")\nparty_pcts.plot.bar(stacked=True)\n\n\n\n\n\n\n\n\n\nFigure 9-18. Fraction of parties by size within each day\n\n\n\n\n\n\n\n\n\nseaborn simplifies plotting with aggregated/summarized data.\nExample: Tipping percentage by day.\n\nimport seaborn as sns\n\ntips[\"tip_pct\"] = tips[\"tip\"] / (tips[\"total_bill\"] - tips[\"tip\"])\nsns.barplot(x=\"tip_pct\", y=\"day\", data=tips, orient=\"h\")\n\n\n\n\n\n\n\n\n\nFigure 9-19. Tipping percentage by day with error bars\n\n\n\n\n\n\ndata: pandas DataFrame.\nOther arguments: Column names.\nBars: Average value of tip_pct.\nBlack lines: 95% confidence interval.\n\n\n\n\n\nhue option in seaborn.barplot: Split by another categorical value.\n\nsns.barplot(x=\"tip_pct\", y=\"day\", hue=\"time\", data=tips, orient=\"h\")\n\n\n\n\n\n\n\n\n\nFigure 9-20. Tipping percentage by day and time\n\n\n\n\n\n\n\n\n\nseaborn automatically adjusts plot aesthetics:\n\nColor palette.\nPlot background.\nGrid line colors.\n\nseaborn.set_style: Switch between plot appearances.\n\nsns.set_style(\"whitegrid\")\n\nFor grayscale, set a greyscale color palette:\n\nsns.set_palette(\"Greys_r\")\n\n\n\n\nHistogram: Discretized display of value frequency.\nData points are binned, and the count in each bin is plotted.\nplot.hist: Create a histogram.\n\ntips[\"tip_pct\"].plot.hist(bins=50)\n\n\n\n\n\n\n\n\n\nFigure 9-21. Histogram of tip percentages\n\n\n\n\n\n\n\n\n\nDensity plot: Estimate of a continuous probability distribution.\nApproximated as a mixture of kernels (e.g., normal distribution).\nAlso known as kernel density estimate (KDE) plots.\nplot.density: Create a density plot.\n\ntips[\"tip_pct\"].plot.density()\n\n\n\n\n\n\n\n\n\nFigure 9-22. Density plot of tip percentages\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDensity plot require SciPy: conda install scipy\n\n\n\n\n\n\nseaborn simplifies histograms and density plots.\nhistplot: Plots both histogram and continuous density estimate.\nExample: Bimodal distribution.\n\ncomp1 = np.random.standard_normal(200)\ncomp2 = 10 + 2 * np.random.standard_normal(200)\nvalues = pd.Series(np.concatenate([comp1, comp2]))\nsns.histplot(values, bins=100, color=\"black\")\n\n\n\n\n\n\n\n\n\nFigure 9-23. Normalized histogram of normal mixture\n\n\n\n\n\n\n\n\n\nExamine the relationship between two 1D data series.\nExample: Load macrodata, compute log differences.\n\nmacro = pd.read_csv(\"examples/macrodata.csv\")\ndata = macro[[\"cpi\", \"m1\", \"tbilrate\", \"unemp\"]]\ntrans_data = np.log(data).diff().dropna()\n\n\n\n\nregplot: Makes a scatter plot and fits a linear regression line.\n\nax = sns.regplot(x=\"m1\", y=\"unemp\", data=trans_data)\nax.title(\"Changes in log(m1) versus log(unemp)\")\n\n\n\n\n\n\n\n\n\nFigure 9-24. A seaborn regression/scatter plot\n\n\n\n\n\n\n\n\n\nExplore scatter plots among a group of variables.\nseaborn.pairplot: Creates a pairs plot.\nSupports histograms/density estimates on the diagonal.\n\nsns.pairplot(trans_data, diag_kind=\"kde\", plot_kws={\"alpha\": 0.2})\n\n\n\n\n\n\n\n\n\nFigure 9-25. Pair plot matrix of statsmodels macro data\n\n\n\n\n\n\n\n\n\nPass down configuration options to individual plotting calls.\nCheck seaborn.pairplot docstring for details.\n\n\n\n\n\nVisualize data with many categorical variables.\nFacet grid: 2D layout, data split across plots based on variable values.\nseaborn.catplot: Simplifies faceted plots.\n\nsns.catplot(x=\"day\", y=\"tip_pct\", hue=\"time\", col=\"smoker\",\n            kind=\"bar\", data=tips[tips.tip_pct &lt; 1])\n\n\n\n\n\n\n\n\n\nFigure 9-26. Tipping percentage by day/time/smoker\n\n\n\n\n\n\n\n\n\nAdd one row per time value:\n\nsns.catplot(x=\"day\", y=\"tip_pct\", row=\"time\",\n            col=\"smoker\", kind=\"bar\", data=tips[tips.tip_pct &lt; 1])\n\n\n\n\n\n\n\n\n\nFigure 9-27. Tipping percentage by day split by time/smoker\n\n\n\n\n\n\n\n\n\ncatplot supports other plot types (e.g., box plots).\nBox plots show median, quartiles, and outliers.\n\nsns.catplot(x=\"tip_pct\", y=\"day\", kind=\"box\",\n            data=tips[tips.tip_pct &lt; 0.5])\n\n\n\n\n\n\n\n\n\nFigure 9-28. Box plot of tipping percentage by day\n\n\n\n\n\n\n\n\n\nCreate custom facet grid plots.\nSee seaborn documentation for details.\n\n\n\n\n\nMany options for creating graphics in Python.\nFocus on interactive graphics for the web: Altair, Bokeh, Plotly.\nFor static graphics: Use matplotlib and libraries built on it (pandas, seaborn).\n\n\n\n\n\nFundamentals of Data Visualization by Claus O. Wilke.\n\nAvailable in print or online: https://clauswilke.com/dataviz\n\n\n\n\n\n\nThis chapter introduced basic data visualization with pandas, matplotlib, and seaborn.\nEffective data visualization is an active research field.\nExplore resources to learn more.\n\n\n\n\n\nmatplotlib is a powerful and flexible library for creating static plots in Python.\npandas provides convenient methods for plotting Series and DataFrame objects.\nseaborn simplifies creating many common statistical visualizations and integrates well with pandas.\nEffective data visualization is crucial for data analysis and communication.\n\n\n\n\n\nHow can you apply the visualization techniques learned in this chapter to your own data analysis projects?\nWhat are the advantages and disadvantages of using matplotlib, pandas, and seaborn for different visualization tasks?\nHow can you effectively communicate your findings through visualizations?\nWhat other Python visualization tools have you explored, and how do they compare to matplotlib, pandas, and seaborn?\nWhat are some best practices for creating clear, informative, and visually appealing plots?\nCan you think of situations where a particular type of plot (e.g., histogram, scatter plot, box plot) would be most appropriate for conveying specific insights from your data?\nHow can you customize matplotlib plots to enhance their clarity and visual impact (e.g., adjusting colors, labels, legends)?"
  },
  {
    "objectID": "qmd/pandas3ed9.html#introduction",
    "href": "qmd/pandas3ed9.html#introduction",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Making informative visualizations (sometimes called plots) is one of the most important tasks in data analysis.\n\n\nExploratory Process: Helps identify outliers or needed data transformations.\nModel Generation: Aids in generating ideas for models.\nWeb Visualization: Building interactive visualizations can be the end goal.\n\n\n\n\n\n\n\nNote\n\n\n\nPython has many add-on libraries for visualizations, but we’ll focus on matplotlib and libraries built on top of it, such as seaborn."
  },
  {
    "objectID": "qmd/pandas3ed9.html#what-is-matplotlib",
    "href": "qmd/pandas3ed9.html#what-is-matplotlib",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "A desktop plotting package for creating publication-quality plots and figures.\nStarted by John Hunter in 2002 to provide a MATLAB-like plotting interface in Python.\n\nWhy? 🤔 To make it easier for scientists and engineers to create plots in Python, just like they did in MATLAB!\n\nCollaborated with IPython to simplify interactive plotting.\nSupports various GUI backends and export formats (PDF, SVG, JPG, PNG, BMP, GIF, etc.).\nMost graphics in many books and publications are produced using matplotlib.\n\n\n\n\n\n\n\nTip\n\n\n\nMatplotlib has spawned add-on toolkits like seaborn, enhancing its capabilities."
  },
  {
    "objectID": "qmd/pandas3ed9.html#setting-up-matplotlib-in-jupyter",
    "href": "qmd/pandas3ed9.html#setting-up-matplotlib-in-jupyter",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "To display plots inline in Jupyter Notebook, use the magic command:\n%matplotlib inline\n\n\n\n\n\n\nNote\n\n\n\nThis command tells Jupyter to display matplotlib plots directly in the notebook output. Without it, you might not see your plots!"
  },
  {
    "objectID": "qmd/pandas3ed9.html#data-visualization-libraries-evolution",
    "href": "qmd/pandas3ed9.html#data-visualization-libraries-evolution",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Many new visualization libraries have emerged since 2012.\n\nBokeh and Altair: Leverage modern web tech for interactive visualizations.\n\nThis course focuses on matplotlib due to its fundamental nature and integration with pandas.\n\nWhy matplotlib? 🤔 It’s like learning to walk before you run! Understanding matplotlib helps you grasp the basics, making it easier to learn other libraries later.\n\n\n\n\n\n\n\n\nTip\n\n\n\nPrinciples learned here are adaptable to other visualization libraries."
  },
  {
    "objectID": "qmd/pandas3ed9.html#a-brief-matplotlib-api-primer",
    "href": "qmd/pandas3ed9.html#a-brief-matplotlib-api-primer",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Import convention for matplotlib:\nimport matplotlib.pyplot as plt\n\n\n\n\n\n\nNote\n\n\n\nThis line imports the pyplot module from matplotlib and gives it a shorter name, plt. This is a common practice to make your code cleaner and easier to read."
  },
  {
    "objectID": "qmd/pandas3ed9.html#creating-a-simple-plot",
    "href": "qmd/pandas3ed9.html#creating-a-simple-plot",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "import numpy as np\ndata = np.arange(10)\nplt.plot(data)\n\nnp.arange(10): Creates an array of numbers from 0 to 9.\nplt.plot(data): Plots the data as a line chart.\n\n\n\n\n\n\n\n\n\n\nFigure 9-1. Simple line plot"
  },
  {
    "objectID": "qmd/pandas3ed9.html#figures-and-subplots",
    "href": "qmd/pandas3ed9.html#figures-and-subplots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Plots in matplotlib reside within a Figure object.\n\nWhat’s a Figure? 🤔 Think of it as a blank canvas where you can draw your plots.\n\nCreate a new figure using plt.figure():\n\nfig = plt.figure()\n\nplt.figure options:\n\nfigsize: Guarantees figure size and aspect ratio."
  },
  {
    "objectID": "qmd/pandas3ed9.html#adding-subplots",
    "href": "qmd/pandas3ed9.html#adding-subplots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "You can’t plot on a blank figure; create subplots using add_subplot:\n\nax1 = fig.add_subplot(2, 2, 1)\n\nadd_subplot(2, 2, 1) means:\n\nA 2x2 grid of subplots (4 plots total).\nSelect the 1st subplot (numbered from 1).\nAnalogy: It is just like the form in Excel to select a range of cells.\n\nCreate additional subplots:\n\nax2 = fig.add_subplot(2, 2, 2)\nax3 = fig.add_subplot(2, 2, 3)\n\n\n\n\n\n\n\n\n\nFigure 9-2. An empty matplotlib figure with three subplots"
  },
  {
    "objectID": "qmd/pandas3ed9.html#plotting-commands-in-jupyter",
    "href": "qmd/pandas3ed9.html#plotting-commands-in-jupyter",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Note\n\n\n\nIn Jupyter Notebook, plots are reset after each cell. Put all plotting commands in a single cell.\n\nWhy? 🤔 Jupyter runs each cell independently. If you split your plotting commands, you might only see the last plot!\n\n\n\nfig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 2, 2)\nax3 = fig.add_subplot(2, 2, 3)"
  },
  {
    "objectID": "qmd/pandas3ed9.html#using-axes-methods",
    "href": "qmd/pandas3ed9.html#using-axes-methods",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "AxesSubplot objects have methods to create different plot types.\nPreferred over top-level functions like plt.plot.\nExample:\n\nax3.plot(np.random.standard_normal(50).cumsum(), color=\"black\", linestyle=\"dashed\")\n\n\n\n\n\n\n\n\n\nFigure 9-3. Data visualization after a single plot"
  },
  {
    "objectID": "qmd/pandas3ed9.html#understanding-matplotlib-output",
    "href": "qmd/pandas3ed9.html#understanding-matplotlib-output",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "You might see output like &lt;matplotlib.lines.Line2D at ...&gt;.\n\nWhat does this mean? 🤔 It’s a reference to the plot element you just added. You can usually ignore it.\n\nTo suppress the output, add a semicolon (;) at the end of the line.\n\nWhy suppress? 🧹 Keeps your notebook output clean and focused on the plots.\n\n\nax3.plot(np.random.standard_normal(50).cumsum(), color=\"black\", linestyle=\"dashed\"); # Note the semicolon"
  },
  {
    "objectID": "qmd/pandas3ed9.html#adding-more-plots-to-subplots",
    "href": "qmd/pandas3ed9.html#adding-more-plots-to-subplots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "ax1.hist(np.random.standard_normal(100), bins=20, color=\"black\", alpha=0.3)\nax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.standard_normal(30))\n\nax1.hist(...): Creates a histogram.\nax2.scatter(...): Creates a scatter plot.\nalpha=0.3: Sets the transparency of the plot.\n\n\n\n\n\n\n\n\n\n\nFigure 9-4. Data visualization after additional plots"
  },
  {
    "objectID": "qmd/pandas3ed9.html#convenient-subplot-creation-with-plt.subplots",
    "href": "qmd/pandas3ed9.html#convenient-subplot-creation-with-plt.subplots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "plt.subplots creates a figure and a NumPy array of subplot objects:\n\nfig, axes = plt.subplots(2, 3)\naxes\narray([[&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;],\n       [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;]], dtype=object)\n\nAccess subplots like a 2D array: axes[0, 1].\nsharex and sharey: Share the same x or y-axis for comparing data."
  },
  {
    "objectID": "qmd/pandas3ed9.html#plt.subplots-options",
    "href": "qmd/pandas3ed9.html#plt.subplots-options",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Argument\nDescription\n\n\n\n\nnrows\nNumber of rows of subplots\n\n\nncols\nNumber of columns of subplots\n\n\nsharex\nAll subplots use the same x-axis ticks\n\n\nsharey\nAll subplots use the same y-axis ticks\n\n\nsubplot_kw\nDictionary of keywords passed to add_subplot\n\n\n**fig_kw\nAdditional keywords passed to subplots (e.g., figsize=(8, 6))\n\n\n\n\n\n\n\n\n\nTable 9-1. matplotlib.pyplot.subplots options"
  },
  {
    "objectID": "qmd/pandas3ed9.html#adjusting-spacing-around-subplots",
    "href": "qmd/pandas3ed9.html#adjusting-spacing-around-subplots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Default padding and spacing between subplots.\nChange spacing using the subplots_adjust method:\n\nfig.subplots_adjust(left=None, bottom=None, right=None, top=None,\n                    wspace=None, hspace=None)\n\nwspace and hspace: Control the percentage of figure width/height for spacing."
  },
  {
    "objectID": "qmd/pandas3ed9.html#example-shrinking-spacing-to-zero",
    "href": "qmd/pandas3ed9.html#example-shrinking-spacing-to-zero",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\nfor i in range(2):\n    for j in range(2):\n        axes[i, j].hist(np.random.standard_normal(500), bins=50,\n                        color=\"black\", alpha=0.5)\nfig.subplots_adjust(wspace=0, hspace=0)\n\n\n\n\n\n\n\n\n\nFigure 9-5. Data visualization with no inter-subplot spacing"
  },
  {
    "objectID": "qmd/pandas3ed9.html#overlapping-axis-labels-겹침",
    "href": "qmd/pandas3ed9.html#overlapping-axis-labels-겹침",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "matplotlib doesn’t check for overlapping labels.\nFix labels by specifying tick locations and labels.\nCovered in the “Ticks, Labels, and Legends” section."
  },
  {
    "objectID": "qmd/pandas3ed9.html#colors-markers-and-line-styles",
    "href": "qmd/pandas3ed9.html#colors-markers-and-line-styles",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Customize line plots with color, markers, and line styles.\nExample:\n\nax.plot(x, y, linestyle=\"--\", color=\"green\")\n\nUse color names or hex codes (e.g., \"#CECECE\").\nLine styles: Check plt.plot docstring (use plt.plot?)."
  },
  {
    "objectID": "qmd/pandas3ed9.html#markers-for-highlighting-data-points",
    "href": "qmd/pandas3ed9.html#markers-for-highlighting-data-points",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Line plots can have markers to show actual data points.\nUseful when interpolation might obscure point locations.\nExample:\n\nax.plot(np.random.standard_normal(30).cumsum(), color=\"black\",\n        linestyle=\"dashed\", marker=\"o\")\n\n\n\n\n\n\n\n\n\nFigure 9-6. Line plot with markers"
  },
  {
    "objectID": "qmd/pandas3ed9.html#drawstyle-option",
    "href": "qmd/pandas3ed9.html#drawstyle-option",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Linear interpolation is the default.\nChange with the drawstyle option:\n\nax.plot(data, color=\"black\", linestyle=\"dashed\", label=\"Default\")\nax.plot(data, color=\"black\", linestyle=\"dashed\",\n        drawstyle=\"steps-post\", label=\"steps-post\")\nax.legend()\n\n\n\n\n\n\n\n\n\nFigure 9-7. Line plot with different drawstyle options"
  },
  {
    "objectID": "qmd/pandas3ed9.html#ticks-labels-and-legends",
    "href": "qmd/pandas3ed9.html#ticks-labels-and-legends",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Plot decorations are accessed through matplotlib axes object methods.\nxlim, xticks, xticklabels: Control plot range, tick locations, and labels.\nTwo ways to use:\n\nNo arguments: Returns the current value (e.g., ax.xlim()).\nWith parameters: Sets the value (e.g., ax.xlim([0, 10]))."
  },
  {
    "objectID": "qmd/pandas3ed9.html#customizing-axes",
    "href": "qmd/pandas3ed9.html#customizing-axes",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Example: Random walk plot.\n\nfig, ax = plt.subplots()\nax.plot(np.random.standard_normal(1000).cumsum())\n\n\n\n\n\n\n\n\n\nFigure 9-8. Simple plot for illustrating xticks (with default labels)\n\n\n\n\n\n\nSet ticks and tick labels\n\nticks = ax.set_xticks([0, 250, 500, 750, 1000])\nlabels = ax.set_xticklabels([\"one\", \"two\", \"three\", \"four\", \"five\"],\n                            rotation=30, fontsize=8)"
  },
  {
    "objectID": "qmd/pandas3ed9.html#setting-title-and-axis-labels",
    "href": "qmd/pandas3ed9.html#setting-title-and-axis-labels",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "ax.set_xlabel(\"Stages\")\nax.set_title(\"My first matplotlib plot\")\n\n\n\n\n\n\n\n\n\nFigure 9-9. Simple plot for illustrating custom xticks\n\n\n\n\n\n\nrotation: Sets tick label rotation (e.g., 30 degrees).\nset_xlabel: Names the x-axis.\nset_title: Sets the subplot title."
  },
  {
    "objectID": "qmd/pandas3ed9.html#batch-setting-of-plot-properties",
    "href": "qmd/pandas3ed9.html#batch-setting-of-plot-properties",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Axes class has a set method:\n\nax.set(title=\"My first matplotlib plot\", xlabel=\"Stages\")"
  },
  {
    "objectID": "qmd/pandas3ed9.html#adding-legends",
    "href": "qmd/pandas3ed9.html#adding-legends",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Legends identify plot elements.\nPass the label argument when adding plot elements:\n\nfig, ax = plt.subplots()\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", label=\"one\")\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", linestyle=\"dashed\", label=\"two\")\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", linestyle=\"dotted\", label=\"three\")\nax.legend()\n\n\n\n\n\n\n\n\n\nFigure 9-10. Simple plot with three lines and legend"
  },
  {
    "objectID": "qmd/pandas3ed9.html#ax.legend-options",
    "href": "qmd/pandas3ed9.html#ax.legend-options",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "ax.legend(): Automatically creates a legend.\nloc: Specifies legend location (default is \"best\").\nExclude elements: Pass no label or label=\"_nolegend_\"."
  },
  {
    "objectID": "qmd/pandas3ed9.html#annotations-and-drawing-on-a-subplot",
    "href": "qmd/pandas3ed9.html#annotations-and-drawing-on-a-subplot",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Add custom annotations: text, arrows, shapes.\ntext, arrow, annotate functions.\nax.text(x, y, \"Hello world!\", family=\"monospace\", fontsize=10): Draws text at (x, y)."
  },
  {
    "objectID": "qmd/pandas3ed9.html#annotating-the-sp-500-index",
    "href": "qmd/pandas3ed9.html#annotating-the-sp-500-index",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Example: Plotting S&P 500 closing price since 2007 with annotations.\n\nfrom datetime import datetime\n\nfig, ax = plt.subplots()\n\ndata = pd.read_csv(\"examples/spx.csv\", index_col=0, parse_dates=True)\nspx = data[\"SPX\"]\n\nspx.plot(ax=ax, color=\"black\")\n\ncrisis_data = [\n    (datetime(2007, 10, 11), \"Peak of bull market\"),\n    (datetime(2008, 3, 12), \"Bear Stearns Fails\"),\n    (datetime(2008, 9, 15), \"Lehman Bankruptcy\")\n]\n\nfor date, label in crisis_data:\n    ax.annotate(label, xy=(date, spx.asof(date) + 75),\n                xytext=(date, spx.asof(date) + 225),\n                arrowprops=dict(facecolor=\"black\", headwidth=4, width=2,\n                                headlength=4),\n                horizontalalignment=\"left\", verticalalignment=\"top\")\n\n# Zoom in on 2007-2010\nax.set_xlim([\"1/1/2007\", \"1/1/2011\"])\nax.set_ylim([600, 1800])\n\nax.set_title(\"Important dates in the 2008-2009 financial crisis\")\n\n\n\n\n\n\n\n\n\nFigure 9-11. Important dates in the 2008–2009 financial crisis"
  },
  {
    "objectID": "qmd/pandas3ed9.html#important-points-on-the-sp-500-plot",
    "href": "qmd/pandas3ed9.html#important-points-on-the-sp-500-plot",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "ax.annotate: Draws labels at specified (x, y) coordinates.\nset_xlim, set_ylim: Manually set plot boundaries.\nax.set_title: Adds a main title."
  },
  {
    "objectID": "qmd/pandas3ed9.html#drawing-shapes-patches",
    "href": "qmd/pandas3ed9.html#drawing-shapes-patches",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "matplotlib has objects called patches representing shapes.\nRectangle, Circle: Found in matplotlib.pyplot.\nFull set: matplotlib.patches.\nAdd to plot using ax.add_patch:\n\nfig, ax = plt.subplots()\n\nrect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color=\"black\", alpha=0.3)\ncirc = plt.Circle((0.7, 0.2), 0.15, color=\"blue\", alpha=0.3)\npgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]],\n                    color=\"green\", alpha=0.5)\n\nax.add_patch(rect)\nax.add_patch(circ)\nax.add_patch(pgon)\n\n\n\n\n\n\n\n\n\nFigure 9-12. Data visualization composed from three different patches"
  },
  {
    "objectID": "qmd/pandas3ed9.html#saving-plots-to-file",
    "href": "qmd/pandas3ed9.html#saving-plots-to-file",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "savefig instance method: Saves the active figure.\nExample:\n\nfig.savefig(\"figpath.svg\")\n\nFile type inferred from extension (e.g., .pdf, .png).\ndpi: Controls dots-per-inch resolution.\n\nfig.savefig(\"figpath.png\", dpi=400)"
  },
  {
    "objectID": "qmd/pandas3ed9.html#savefig-options",
    "href": "qmd/pandas3ed9.html#savefig-options",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Argument\nDescription\n\n\n\n\nfname\nFilepath or Python file-like object; format inferred from extension\n\n\ndpi\nResolution in dots per inch\n\n\nfacecolor\nFigure background color outside subplots (default: \"w\" - white)\n\n\nedgecolor\nColor of the figure edge\n\n\nformat\nExplicit file format (e.g., \"png\", \"pdf\", \"svg\")\n\n\n\n\n\n\n\n\n\nTable 9-2. Some fig.savefig options"
  },
  {
    "objectID": "qmd/pandas3ed9.html#matplotlib-configuration",
    "href": "qmd/pandas3ed9.html#matplotlib-configuration",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "matplotlib has configurations for color schemes and defaults.\nCustomize via global parameters: figure size, subplot spacing, colors, fonts, etc.\nrc method: Modifies configuration programmatically.\nExample: Set default figure size to 10x10.\n\nplt.rc(\"figure\", figsize=(10, 10))"
  },
  {
    "objectID": "qmd/pandas3ed9.html#restoring-default-configuration-values",
    "href": "qmd/pandas3ed9.html#restoring-default-configuration-values",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Current settings: plt.rcParams dictionary.\nRestore defaults: plt.rcdefaults()."
  },
  {
    "objectID": "qmd/pandas3ed9.html#customizing-specific-components",
    "href": "qmd/pandas3ed9.html#customizing-specific-components",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "First rc argument: Component to customize (e.g., \"figure\", \"axes\", \"xtick\").\nFollowed by keyword arguments for new parameters.\nExample:\n\nplt.rc(\"font\", family=\"monospace\", weight=\"bold\", size=8)"
  },
  {
    "objectID": "qmd/pandas3ed9.html#matplotlibrc-configuration-file",
    "href": "qmd/pandas3ed9.html#matplotlibrc-configuration-file",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Extensive customization: matplotlibrc file in matplotlib/mpl-data.\nPlace a customized matplotlibrc in your home directory as .matplotlibrc.\nLoaded each time you use matplotlib."
  },
  {
    "objectID": "qmd/pandas3ed9.html#seaborn-and-matplotlib-configuration",
    "href": "qmd/pandas3ed9.html#seaborn-and-matplotlib-configuration",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "seaborn uses matplotlib’s configuration system internally.\nseaborn has built-in plot themes and styles."
  },
  {
    "objectID": "qmd/pandas3ed9.html#plotting-with-pandas-and-seaborn",
    "href": "qmd/pandas3ed9.html#plotting-with-pandas-and-seaborn",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Matplotlib can be low-level.\npandas: Built-in methods for visualizing DataFrame and Series objects.\nseaborn: High-level statistical graphics library built on matplotlib.\nseaborn simplifies creating common visualization types."
  },
  {
    "objectID": "qmd/pandas3ed9.html#line-plots-with-pandas",
    "href": "qmd/pandas3ed9.html#line-plots-with-pandas",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Series and DataFrame have a plot attribute.\nplot() makes line plots by default:\n\ns = pd.Series(np.random.standard_normal(10).cumsum(), index=np.arange(0, 100, 10))\ns.plot()\n\n\n\n\n\n\n\n\n\nFigure 9-13. Simple Series plot\n\n\n\n\n\n\nSeries index: Used for x-axis (disable with use_index=False).\nxticks, xlim, yticks, ylim: Adjust axis ticks and limits."
  },
  {
    "objectID": "qmd/pandas3ed9.html#series.plot-method-arguments",
    "href": "qmd/pandas3ed9.html#series.plot-method-arguments",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Argument\nDescription\n\n\n\n\nlabel\nLabel for plot legend\n\n\nax\nmatplotlib subplot object to plot on\n\n\nstyle\nStyle string (e.g., \"ko--\")\n\n\nalpha\nPlot fill opacity (0 to 1)\n\n\nkind\nPlot type: \"area\", \"bar\", \"barh\", \"density\", \"hist\", \"kde\", \"line\", \"pie\"\n\n\nfigsize\nSize of the figure object\n\n\nlogx\nLogarithmic scaling on x-axis\n\n\nlogy\nLogarithmic scaling on y-axis\n\n\ntitle\nTitle for the plot\n\n\nuse_index\nUse object index for tick labels\n\n\nrot\nRotation of tick labels (0-360)\n\n\nxticks\nValues for x-axis ticks\n\n\nyticks\nValues for y-axis ticks\n\n\nxlim\nx-axis limits (e.g., [0, 10])\n\n\nylim\ny-axis limits\n\n\ngrid\nDisplay axis grid (off by default)\n\n\n\n\n\n\n\n\n\nTable 9-3. Series.plot method arguments\n\n\n\n\npandas plotting methods accept an optional ax parameter for a matplotlib subplot object."
  },
  {
    "objectID": "qmd/pandas3ed9.html#dataframe-line-plots",
    "href": "qmd/pandas3ed9.html#dataframe-line-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "df = pd.DataFrame(np.random.standard_normal((10, 4)).cumsum(0),\n                  columns=[\"A\", \"B\", \"C\", \"D\"],\n                  index=np.arange(0, 100, 10))\nplt.style.use('grayscale') #use grayscale style to adapt to black and white publication\ndf.plot()\n\n\n\n\n\n\n\n\n\nFigure 9-14. Simple DataFrame plot\n\n\n\n\n\n\nPlots each column as a separate line on the same subplot.\nCreates a legend automatically.\ndf.plot() is equivalent to df.plot.line()."
  },
  {
    "objectID": "qmd/pandas3ed9.html#dataframe.plot-options",
    "href": "qmd/pandas3ed9.html#dataframe.plot-options",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Argument\nDescription\n\n\n\n\nsubplots\nPlot each DataFrame column in a separate subplot\n\n\nlayout\n2-tuple (rows, columns) for subplot layout\n\n\nsharex\nIf subplots=True, share x-axis ticks and limits\n\n\nsharey\nIf subplots=True, share y-axis\n\n\nlegend\nAdd a subplot legend (True by default)\n\n\nsort_columns\nPlot columns in alphabetical order (default: use existing order)\n\n\n\n\n\n\n\n\n\nTable 9-4. DataFrame-specific plot arguments\n\n\n\n\nAdditional keyword arguments are passed to matplotlib plotting functions."
  },
  {
    "objectID": "qmd/pandas3ed9.html#bar-plots",
    "href": "qmd/pandas3ed9.html#bar-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "plot.bar(): Vertical bar plots.\nplot.barh(): Horizontal bar plots.\nSeries/DataFrame index: Used for x (bar) or y (barh) ticks.\n\nfig, axes = plt.subplots(2, 1)\ndata = pd.Series(np.random.uniform(size=16), index=list(\"abcdefghijklmnop\"))\ndata.plot.bar(ax=axes[0], color=\"black\", alpha=0.7)\ndata.plot.barh(ax=axes[1], color=\"black\", alpha=0.7)\n\n\n\n\n\n\n\n\n\nFigure 9-15. Horizonal and vertical bar plot"
  },
  {
    "objectID": "qmd/pandas3ed9.html#dataframe-bar-plots",
    "href": "qmd/pandas3ed9.html#dataframe-bar-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "df = pd.DataFrame(np.random.uniform(size=(6, 4)),\n                  index=[\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"],\n                  columns=pd.Index([\"A\", \"B\", \"C\", \"D\"], name=\"Genus\"))\ndf.plot.bar()\n\n\n\n\n\n\n\n\n\nFigure 9-16. DataFrame bar plot\n\n\n\n\n\n\nGroups values in each row in bars, side by side.\nDataFrame column name: Used for legend title."
  },
  {
    "objectID": "qmd/pandas3ed9.html#stacked-bar-plots",
    "href": "qmd/pandas3ed9.html#stacked-bar-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "stacked=True: Creates stacked bar plots.\nValues in each row are stacked together.\n\ndf.plot.barh(stacked=True, alpha=0.5)\n\n\n\n\n\n\n\n\n\nFigure 9-17. DataFrame stacked bar plot"
  },
  {
    "objectID": "qmd/pandas3ed9.html#example-restaurant-tipping-data",
    "href": "qmd/pandas3ed9.html#example-restaurant-tipping-data",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Visualize tipping data: Percentage of data points for each party size, per day.\nread_csv: Load data.\ncrosstab: Cross-tabulation by day and party size.\nCalculate the frequency of two columns in the dataframe.\n\ntips = pd.read_csv(\"examples/tips.csv\")\nparty_counts = pd.crosstab(tips[\"day\"], tips[\"size\"])\nparty_counts = party_counts.reindex(index=[\"Thur\", \"Fri\", \"Sat\", \"Sun\"])\n# Remove 1- and 6-person parties\nparty_counts = party_counts.loc[:, 2:5]\n\n# Normalize to sum to 1\nparty_pcts = party_counts.div(party_counts.sum(axis=\"columns\"), axis=\"index\")\nparty_pcts.plot.bar(stacked=True)\n\n\n\n\n\n\n\n\n\nFigure 9-18. Fraction of parties by size within each day"
  },
  {
    "objectID": "qmd/pandas3ed9.html#seaborn-for-simpler-aggregation-and-summarization",
    "href": "qmd/pandas3ed9.html#seaborn-for-simpler-aggregation-and-summarization",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "seaborn simplifies plotting with aggregated/summarized data.\nExample: Tipping percentage by day.\n\nimport seaborn as sns\n\ntips[\"tip_pct\"] = tips[\"tip\"] / (tips[\"total_bill\"] - tips[\"tip\"])\nsns.barplot(x=\"tip_pct\", y=\"day\", data=tips, orient=\"h\")\n\n\n\n\n\n\n\n\n\nFigure 9-19. Tipping percentage by day with error bars\n\n\n\n\n\n\ndata: pandas DataFrame.\nOther arguments: Column names.\nBars: Average value of tip_pct.\nBlack lines: 95% confidence interval."
  },
  {
    "objectID": "qmd/pandas3ed9.html#splitting-by-additional-categorical-values",
    "href": "qmd/pandas3ed9.html#splitting-by-additional-categorical-values",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "hue option in seaborn.barplot: Split by another categorical value.\n\nsns.barplot(x=\"tip_pct\", y=\"day\", hue=\"time\", data=tips, orient=\"h\")\n\n\n\n\n\n\n\n\n\nFigure 9-20. Tipping percentage by day and time"
  },
  {
    "objectID": "qmd/pandas3ed9.html#seaborn-plot-aesthetics",
    "href": "qmd/pandas3ed9.html#seaborn-plot-aesthetics",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "seaborn automatically adjusts plot aesthetics:\n\nColor palette.\nPlot background.\nGrid line colors.\n\nseaborn.set_style: Switch between plot appearances.\n\nsns.set_style(\"whitegrid\")\n\nFor grayscale, set a greyscale color palette:\n\nsns.set_palette(\"Greys_r\")"
  },
  {
    "objectID": "qmd/pandas3ed9.html#histograms-and-density-plots",
    "href": "qmd/pandas3ed9.html#histograms-and-density-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Histogram: Discretized display of value frequency.\nData points are binned, and the count in each bin is plotted.\nplot.hist: Create a histogram.\n\ntips[\"tip_pct\"].plot.hist(bins=50)\n\n\n\n\n\n\n\n\n\nFigure 9-21. Histogram of tip percentages"
  },
  {
    "objectID": "qmd/pandas3ed9.html#density-plots",
    "href": "qmd/pandas3ed9.html#density-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Density plot: Estimate of a continuous probability distribution.\nApproximated as a mixture of kernels (e.g., normal distribution).\nAlso known as kernel density estimate (KDE) plots.\nplot.density: Create a density plot.\n\ntips[\"tip_pct\"].plot.density()\n\n\n\n\n\n\n\n\n\nFigure 9-22. Density plot of tip percentages\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDensity plot require SciPy: conda install scipy"
  },
  {
    "objectID": "qmd/pandas3ed9.html#seaborns-histplot",
    "href": "qmd/pandas3ed9.html#seaborns-histplot",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "seaborn simplifies histograms and density plots.\nhistplot: Plots both histogram and continuous density estimate.\nExample: Bimodal distribution.\n\ncomp1 = np.random.standard_normal(200)\ncomp2 = 10 + 2 * np.random.standard_normal(200)\nvalues = pd.Series(np.concatenate([comp1, comp2]))\nsns.histplot(values, bins=100, color=\"black\")\n\n\n\n\n\n\n\n\n\nFigure 9-23. Normalized histogram of normal mixture"
  },
  {
    "objectID": "qmd/pandas3ed9.html#scatter-or-point-plots",
    "href": "qmd/pandas3ed9.html#scatter-or-point-plots",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Examine the relationship between two 1D data series.\nExample: Load macrodata, compute log differences.\n\nmacro = pd.read_csv(\"examples/macrodata.csv\")\ndata = macro[[\"cpi\", \"m1\", \"tbilrate\", \"unemp\"]]\ntrans_data = np.log(data).diff().dropna()"
  },
  {
    "objectID": "qmd/pandas3ed9.html#seaborns-regplot",
    "href": "qmd/pandas3ed9.html#seaborns-regplot",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "regplot: Makes a scatter plot and fits a linear regression line.\n\nax = sns.regplot(x=\"m1\", y=\"unemp\", data=trans_data)\nax.title(\"Changes in log(m1) versus log(unemp)\")\n\n\n\n\n\n\n\n\n\nFigure 9-24. A seaborn regression/scatter plot"
  },
  {
    "objectID": "qmd/pandas3ed9.html#pairs-plot-or-scatter-plot-matrix",
    "href": "qmd/pandas3ed9.html#pairs-plot-or-scatter-plot-matrix",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Explore scatter plots among a group of variables.\nseaborn.pairplot: Creates a pairs plot.\nSupports histograms/density estimates on the diagonal.\n\nsns.pairplot(trans_data, diag_kind=\"kde\", plot_kws={\"alpha\": 0.2})\n\n\n\n\n\n\n\n\n\nFigure 9-25. Pair plot matrix of statsmodels macro data"
  },
  {
    "objectID": "qmd/pandas3ed9.html#plot_kws-argument",
    "href": "qmd/pandas3ed9.html#plot_kws-argument",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Pass down configuration options to individual plotting calls.\nCheck seaborn.pairplot docstring for details."
  },
  {
    "objectID": "qmd/pandas3ed9.html#facet-grids-and-categorical-data",
    "href": "qmd/pandas3ed9.html#facet-grids-and-categorical-data",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Visualize data with many categorical variables.\nFacet grid: 2D layout, data split across plots based on variable values.\nseaborn.catplot: Simplifies faceted plots.\n\nsns.catplot(x=\"day\", y=\"tip_pct\", hue=\"time\", col=\"smoker\",\n            kind=\"bar\", data=tips[tips.tip_pct &lt; 1])\n\n\n\n\n\n\n\n\n\nFigure 9-26. Tipping percentage by day/time/smoker"
  },
  {
    "objectID": "qmd/pandas3ed9.html#expanding-facet-grids",
    "href": "qmd/pandas3ed9.html#expanding-facet-grids",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Add one row per time value:\n\nsns.catplot(x=\"day\", y=\"tip_pct\", row=\"time\",\n            col=\"smoker\", kind=\"bar\", data=tips[tips.tip_pct &lt; 1])\n\n\n\n\n\n\n\n\n\nFigure 9-27. Tipping percentage by day split by time/smoker"
  },
  {
    "objectID": "qmd/pandas3ed9.html#other-plot-types-with-catplot",
    "href": "qmd/pandas3ed9.html#other-plot-types-with-catplot",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "catplot supports other plot types (e.g., box plots).\nBox plots show median, quartiles, and outliers.\n\nsns.catplot(x=\"tip_pct\", y=\"day\", kind=\"box\",\n            data=tips[tips.tip_pct &lt; 0.5])\n\n\n\n\n\n\n\n\n\nFigure 9-28. Box plot of tipping percentage by day"
  },
  {
    "objectID": "qmd/pandas3ed9.html#seaborn.facetgrid",
    "href": "qmd/pandas3ed9.html#seaborn.facetgrid",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Create custom facet grid plots.\nSee seaborn documentation for details."
  },
  {
    "objectID": "qmd/pandas3ed9.html#other-python-visualization-tools",
    "href": "qmd/pandas3ed9.html#other-python-visualization-tools",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Many options for creating graphics in Python.\nFocus on interactive graphics for the web: Altair, Bokeh, Plotly.\nFor static graphics: Use matplotlib and libraries built on it (pandas, seaborn)."
  },
  {
    "objectID": "qmd/pandas3ed9.html#recommended-reading",
    "href": "qmd/pandas3ed9.html#recommended-reading",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "Fundamentals of Data Visualization by Claus O. Wilke.\n\nAvailable in print or online: https://clauswilke.com/dataviz"
  },
  {
    "objectID": "qmd/pandas3ed9.html#conclusion",
    "href": "qmd/pandas3ed9.html#conclusion",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "This chapter introduced basic data visualization with pandas, matplotlib, and seaborn.\nEffective data visualization is an active research field.\nExplore resources to learn more."
  },
  {
    "objectID": "qmd/pandas3ed9.html#summary",
    "href": "qmd/pandas3ed9.html#summary",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "matplotlib is a powerful and flexible library for creating static plots in Python.\npandas provides convenient methods for plotting Series and DataFrame objects.\nseaborn simplifies creating many common statistical visualizations and integrates well with pandas.\nEffective data visualization is crucial for data analysis and communication."
  },
  {
    "objectID": "qmd/pandas3ed9.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed9.html#thoughts-and-discussion",
    "title": "Plotting and Visualization",
    "section": "",
    "text": "How can you apply the visualization techniques learned in this chapter to your own data analysis projects?\nWhat are the advantages and disadvantages of using matplotlib, pandas, and seaborn for different visualization tasks?\nHow can you effectively communicate your findings through visualizations?\nWhat other Python visualization tools have you explored, and how do they compare to matplotlib, pandas, and seaborn?\nWhat are some best practices for creating clear, informative, and visually appealing plots?\nCan you think of situations where a particular type of plot (e.g., histogram, scatter plot, box plot) would be most appropriate for conveying specific insights from your data?\nHow can you customize matplotlib plots to enhance their clarity and visual impact (e.g., adjusting colors, labels, legends)?"
  },
  {
    "objectID": "qmd/pandas3ed5.html",
    "href": "qmd/pandas3ed5.html",
    "title": "",
    "section": "",
    "text": "---\ntitle: \"Getting Started with pandas\"\nauthor: \"Your Name\"\nformat:\n  revealjs:\n    theme: sky\n    slide-number: true\n    show-slide-number: all\n    preview-links: auto\n---\n\n## Introduction to pandas 🐼\n\n::: {layout-ncol=2}\n- **What is pandas?**\n    -  A powerful Python library for data manipulation and analysis.\n    -  Think of it as Excel, but much more powerful and flexible, all within Python.\n    -  Provides data structures like `Series` (1D) and `DataFrame` (2D) to efficiently store and process data.\n-   **Why use pandas?**\n    -  Simplifies data cleaning, transformation, and analysis.\n    -  Integrates well with other Python libraries (NumPy, SciPy, scikit-learn, matplotlib).\n    -  Handles heterogeneous data (different data types in different columns).\n    - Large and active open source community\n\n![](./figs/pandas-logo.png)\n:::\n\n## Key Concepts: Data Structures\n\n- **Series:**\n    -  A one-dimensional labeled array.  Like a single column in a spreadsheet.\n    -  Can hold data of various types (integers, floats, strings, etc.).\n    -  Has an *index*, which labels each element.\n    -  Analogy: A list with custom labels (the index) for each item.\n\n- **DataFrame:**\n    -  A two-dimensional labeled data structure.  Like a spreadsheet or a SQL table.\n    -  Essentially a collection of Series that share the same index.\n    -  Each column can have a different data type.\n    -  Analogy: A dictionary where each key is a column name and each value is a Series (the column's data).\n\n## Importing pandas and Conventions\n\n- The standard way to import pandas:\n\n```python\nimport pandas as pd  # 'pd' is the conventional alias\nimport numpy as np   # NumPy is often used with pandas"
  },
  {
    "objectID": "qmd/pandas3ed5.html#series-your-first-pandas-data-structure",
    "href": "qmd/pandas3ed5.html#series-your-first-pandas-data-structure",
    "title": "",
    "section": "Series: Your First pandas Data Structure",
    "text": "Series: Your First pandas Data Structure\n\nCreating a simple Series:\n\nobj = pd.Series([4, 7, -5, 3])\nobj\n\n0    4\n1    7\n2   -5\n3    3\ndtype: int64\n\n\nExplanation:\n\nThe left column is the index (automatically generated here: 0, 1, 2, 3).\nThe right column contains the values.\ndtype: int64 indicates the data type (64-bit integer)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#accessing-series-data",
    "href": "qmd/pandas3ed5.html#accessing-series-data",
    "title": "",
    "section": "Accessing Series Data",
    "text": "Accessing Series Data\n# Get the values as a PandasArray\nobj.array\n\n&lt;PandasArray&gt;\n[4, 7, -5, 3]\nLength: 4, dtype: int64\n\n# Get the index\nobj.index\n\nRangeIndex(start=0, stop=4, step=1)\n\n\n.array provides the underlying data. Usually a NumPy array, but can hold “extension array types” (more advanced).\n.index gives you the index object (labels for each value)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#series-with-custom-index",
    "href": "qmd/pandas3ed5.html#series-with-custom-index",
    "title": "",
    "section": "Series with Custom Index",
    "text": "Series with Custom Index\nobj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])\nobj2\n\nd    4\nb    7\na   -5\nc    3\ndtype: int64\n\nobj2.index\n\nIndex(['d', 'b', 'a', 'c'], dtype='object')\n\n\nNow, we have custom labels (strings) instead of default integer indices.\ndtype='object' indicates the index type (strings are considered “objects” in pandas)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#selecting-data-in-a-series",
    "href": "qmd/pandas3ed5.html#selecting-data-in-a-series",
    "title": "",
    "section": "Selecting Data in a Series",
    "text": "Selecting Data in a Series\n\nUse index labels, similar to dictionary keys:\n\nobj2['a']  # Access the value at index 'a'\n-5\nobj2['d'] = 6 # Modify the value at index 'd'\nobj2[['c', 'a', 'd']]  # Select multiple values\n\nc    3\na   -5\nd    6\ndtype: int64\n\n\nKey difference from NumPy: You can use your custom labels for selection!"
  },
  {
    "objectID": "qmd/pandas3ed5.html#filtering-and-operations",
    "href": "qmd/pandas3ed5.html#filtering-and-operations",
    "title": "",
    "section": "Filtering and Operations",
    "text": "Filtering and Operations\n\nNumPy-like operations work on Series and preserve the index-value links:\n\nobj2[obj2 &gt; 0]  # Boolean indexing (select values &gt; 0)\n\nd    6\nb    7\nc    3\ndtype: int64\n\nobj2 * 2  # Scalar multiplication\n\nd    12\nb    14\na   -10\nc     6\ndtype: int64\n\nimport numpy as np\nnp.exp(obj2)  # Apply a NumPy function (exponential)\n\nd     403.428793\nb    1096.633158\na       0.006738\nc      20.085537\ndtype: float64\n\n\nImportant: The index is always maintained!"
  },
  {
    "objectID": "qmd/pandas3ed5.html#series-as-ordered-dictionaries",
    "href": "qmd/pandas3ed5.html#series-as-ordered-dictionaries",
    "title": "",
    "section": "Series as Ordered Dictionaries",
    "text": "Series as Ordered Dictionaries\n\nA Series is like a fixed-length, ordered dictionary.\n\n'b' in obj2  # Check if index 'b' exists\nTrue\n'e' in obj2\nFalse\n:::\n\nYou can create a Series directly from a Python dictionary:\n\nsdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\nobj3 = pd.Series(sdata)\nobj3\n\nOhio      35000\nTexas     71000\nOregon    16000\nUtah       5000\ndtype: int64\n\n\nKeys become the index, and values become the Series values.\nto_dict method:\n\nobj3.to_dict()\n\n{'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}"
  },
  {
    "objectID": "qmd/pandas3ed5.html#controlling-the-index-order",
    "href": "qmd/pandas3ed5.html#controlling-the-index-order",
    "title": "",
    "section": "Controlling the Index Order",
    "text": "Controlling the Index Order\nstates = ['California', 'Ohio', 'Oregon', 'Texas']\nobj4 = pd.Series(sdata, index=states)\nobj4\n\nCalifornia        NaN\nOhio          35000.0\nOregon        16000.0\nTexas         71000.0\ndtype: float64\n\n\nExplanation:\n\nWe provide a specific index (states).\n‘California’ is in states but not in sdata, so it gets a NaN (Not a Number) value, representing missing data.\n‘Utah’ is in sdata but not in states, so it’s excluded."
  },
  {
    "objectID": "qmd/pandas3ed5.html#handling-missing-data",
    "href": "qmd/pandas3ed5.html#handling-missing-data",
    "title": "",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\n\nNaN (Not a Number) is pandas’ way of representing missing values.\nFunctions to detect missing data:\n\npd.isna(obj4)  # Check for NaN values\n\nCalifornia     True\nOhio          False\nOregon        False\nTexas         False\ndtype: bool\n\npd.notna(obj4) # Check for non-NaN values (the opposite)\n\nCalifornia    False\nOhio           True\nOregon         True\nTexas          True\ndtype: bool\n\nobj4.isna()  # Series also has these as methods\n\nCalifornia     True\nOhio          False\nOregon        False\nTexas         False\ndtype: bool"
  },
  {
    "objectID": "qmd/pandas3ed5.html#data-alignment",
    "href": "qmd/pandas3ed5.html#data-alignment",
    "title": "",
    "section": "Data Alignment",
    "text": "Data Alignment\n\nA powerful feature: Arithmetic operations automatically align data by index label.\n\nobj3\n\nOhio      35000\nTexas     71000\nOregon    16000\nUtah       5000\ndtype: int64\n\nobj4\n\nCalifornia        NaN\nOhio          35000.0\nOregon        16000.0\nTexas         71000.0\ndtype: float64\n\nobj3 + obj4\n\nCalifornia         NaN\nOhio           70000.0\nOregon         32000.0\nTexas         142000.0\nUtah               NaN\ndtype: float64\n\n\nExplanation:\n\nOnly indices present in both Series are used in the calculation.\nIf an index is in one Series but not the other, the result is NaN.\nSimilar to a database join operation."
  },
  {
    "objectID": "qmd/pandas3ed5.html#naming-series-and-their-index",
    "href": "qmd/pandas3ed5.html#naming-series-and-their-index",
    "title": "",
    "section": "Naming Series and their Index",
    "text": "Naming Series and their Index\nobj4.name = 'population'  # Name the Series itself\nobj4.index.name = 'state' # Name the index\nobj4\n\nstate\nCalifornia        NaN\nOhio          35000.0\nOregon        16000.0\nTexas         71000.0\nName: population, dtype: float64\n\n\nThese names are used in various pandas operations and outputs."
  },
  {
    "objectID": "qmd/pandas3ed5.html#changing-the-index-in-place",
    "href": "qmd/pandas3ed5.html#changing-the-index-in-place",
    "title": "",
    "section": "Changing the Index In-Place",
    "text": "Changing the Index In-Place\nobj\n\n0    4\n1    7\n2   -5\n3    3\ndtype: int64\n\nobj.index = ['Bob', 'Steve', 'Jeff', 'Ryan']  # Assign a new index\nobj\n\nBob      4\nSteve    7\nJeff    -5\nRyan     3\ndtype: int64\n\n\nBe careful: The new index must have the same length as the Series."
  },
  {
    "objectID": "qmd/pandas3ed5.html#dataframe-the-spreadsheet-of-pandas",
    "href": "qmd/pandas3ed5.html#dataframe-the-spreadsheet-of-pandas",
    "title": "",
    "section": "DataFrame: The Spreadsheet of pandas",
    "text": "DataFrame: The Spreadsheet of pandas\n\nCreating a DataFrame from a dictionary:\n\ndata = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\nframe = pd.DataFrame(data)\nframe\n\nExplanation:\n\nEach key in the data dictionary becomes a column name.\nEach value (a list) becomes the data for that column.\nThe index is automatically generated (0, 1, 2, …).\n\nDisplayed as a nicely formatted table in Jupyter."
  },
  {
    "objectID": "qmd/pandas3ed5.html#dataframe.head-and-dataframe.tail",
    "href": "qmd/pandas3ed5.html#dataframe.head-and-dataframe.tail",
    "title": "",
    "section": "DataFrame.head() and DataFrame.tail()",
    "text": "DataFrame.head() and DataFrame.tail()\n\nframe.head() shows the first five rows.\nframe.tail() shows the last five rows.\nUseful for quickly inspecting large DataFrames.\n\nframe.head()\n\n    state  year  pop\n0    Ohio  2000  1.5\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n\nframe.tail()\n\n    state  year  pop\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n5  Nevada  2003  3.2"
  },
  {
    "objectID": "qmd/pandas3ed5.html#specifying-column-order",
    "href": "qmd/pandas3ed5.html#specifying-column-order",
    "title": "",
    "section": "Specifying Column Order",
    "text": "Specifying Column Order\npd.DataFrame(data, columns=['year', 'state', 'pop'])\n\n   year   state  pop\n0  2000    Ohio  1.5\n1  2001    Ohio  1.7\n2  2002    Ohio  3.6\n3  2001  Nevada  2.4\n4  2002  Nevada  2.9\n5  2003  Nevada  3.2\n\n\nThe columns parameter lets you control the order of the columns."
  },
  {
    "objectID": "qmd/pandas3ed5.html#handling-missing-columns",
    "href": "qmd/pandas3ed5.html#handling-missing-columns",
    "title": "",
    "section": "Handling Missing Columns",
    "text": "Handling Missing Columns\nframe2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'])\nframe2\n\n   year   state  pop  debt\n0  2000    Ohio  1.5   NaN\n1  2001    Ohio  1.7   NaN\n2  2002    Ohio  3.6   NaN\n3  2001  Nevada  2.4   NaN\n4  2002  Nevada  2.9   NaN\n5  2003  Nevada  3.2   NaN\n\n\nframe2.columns\n\nIndex(['year', 'state', 'pop', 'debt'], dtype='object')\n\n\nIf you include a column name that’s not in the data dictionary (like ‘debt’), it will be filled with NaN values."
  },
  {
    "objectID": "qmd/pandas3ed5.html#retrieving-columns",
    "href": "qmd/pandas3ed5.html#retrieving-columns",
    "title": "",
    "section": "Retrieving Columns",
    "text": "Retrieving Columns\n\nTwo ways to get a column (as a Series):\n\nframe2['state']  # Dictionary-like notation (works for any column name)\n0      Ohio\n1      Ohio\n2      Ohio\n3    Nevada\n4    Nevada\n5    Nevada\nName: state, dtype: object\nframe2.year  # Attribute-like notation (only works for valid Python variable names)\n0    2000\n1    2001\n2    2002\n3    2001\n4    2002\n5    2003\nName: year, dtype: int64\n\nImportant: frame2.column_name only works if the column name is a valid Python variable name (no spaces, special characters, etc.) and doesn’t conflict with DataFrame methods."
  },
  {
    "objectID": "qmd/pandas3ed5.html#retrieving-rows-loc-and-iloc",
    "href": "qmd/pandas3ed5.html#retrieving-rows-loc-and-iloc",
    "title": "",
    "section": "Retrieving Rows: loc and iloc",
    "text": "Retrieving Rows: loc and iloc\nframe2.loc[1]  # Select row by label (index value)\nyear     2001\nstate    Ohio\npop       1.7\ndebt      NaN\nName: 1, dtype: object\nframe2.iloc[2]  # Select row by integer position\nyear     2002\nstate    Ohio\npop       3.6\ndebt      NaN\nName: 2, dtype: object\n\nloc: Selects by label.\niloc: Selects by integer position.\nKey Concept: These are very important for selecting data in DataFrames."
  },
  {
    "objectID": "qmd/pandas3ed5.html#modifying-columns",
    "href": "qmd/pandas3ed5.html#modifying-columns",
    "title": "",
    "section": "Modifying Columns",
    "text": "Modifying Columns\n\nAssign a single value to a column:\n\nframe2['debt'] = 16.5  # Assign 16.5 to all rows in the 'debt' column\nframe2\n\n   year   state  pop  debt\n0  2000    Ohio  1.5  16.5\n1  2001    Ohio  1.7  16.5\n2  2002    Ohio  3.6  16.5\n3  2001  Nevada  2.4  16.5\n4  2002  Nevada  2.9  16.5\n5  2003  Nevada  3.2  16.5\n\n\nAssign an array or Series:\n\nframe2['debt'] = np.arange(6.)  # Assign values from 0 to 5\nframe2\n\n   year   state  pop  debt\n0  2000    Ohio  1.5   0.0\n1  2001    Ohio  1.7   1.0\n2  2002    Ohio  3.6   2.0\n3  2001  Nevada  2.4   3.0\n4  2002  Nevada  2.9   4.0\n5  2003  Nevada  3.2   5.0\n\n\nWhen assigning a Series, it aligns by index:\n\nval = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five']) #No Effect\nframe2['debt'] = val\nframe2\n\n   year   state  pop  debt\n0  2000    Ohio  1.5   NaN\n1  2001    Ohio  1.7   NaN\n2  2002    Ohio  3.6   NaN\n3  2001  Nevada  2.4   NaN\n4  2002  Nevada  2.9   NaN\n5  2003  Nevada  3.2   NaN\n\nval = pd.Series([-1.2, -1.5, -1.7], index=[2, 4, 5]) #Have Effect\nframe2['debt'] = val\nframe2\n\n   year   state  pop  debt\n0  2000    Ohio  1.5   NaN\n1  2001    Ohio  1.7   NaN\n2  2002    Ohio  3.6  -1.2\n3  2001  Nevada  2.4   NaN\n4  2002  Nevada  2.9  -1.5\n5  2003  Nevada  3.2  -1.7"
  },
  {
    "objectID": "qmd/pandas3ed5.html#creating-and-deleting-columns",
    "href": "qmd/pandas3ed5.html#creating-and-deleting-columns",
    "title": "",
    "section": "Creating and Deleting Columns",
    "text": "Creating and Deleting Columns\n\nAssigning to a non-existent column creates a new column:\n\nframe2['eastern'] = frame2['state'] == 'Ohio'  # Create 'eastern' based on a condition\nframe2\n\n   year   state  pop  debt  eastern\n0  2000    Ohio  1.5   NaN     True\n1  2001    Ohio  1.7   NaN     True\n2  2002    Ohio  3.6  -1.2     True\n3  2001  Nevada  2.4   NaN    False\n4  2002  Nevada  2.9  -1.5    False\n5  2003  Nevada  3.2  -1.7    False\n\n\nDelete a column using del:\n\ndel frame2['eastern']\nframe2.columns\n\nIndex(['year', 'state', 'pop', 'debt'], dtype='object')\n\n\nImportant: New columns cannot be created using the attribute-like syntax (e.g., frame2.eastern = ... will not work)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#nested-dictionaries",
    "href": "qmd/pandas3ed5.html#nested-dictionaries",
    "title": "",
    "section": "Nested Dictionaries",
    "text": "Nested Dictionaries\n\nYou can create a DataFrame from a nested dictionary:\n\npopulations = {'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6},\n               'Nevada': {2001: 2.4, 2002: 2.9}}\nframe3 = pd.DataFrame(populations)\nframe3\n\n      Ohio  Nevada\n2000   1.5     NaN\n2001   1.7     2.4\n2002   3.6     2.9\n\n\nExplanation:\n\nOuter keys become column names.\nInner keys become row indices."
  },
  {
    "objectID": "qmd/pandas3ed5.html#transposing-a-dataframe",
    "href": "qmd/pandas3ed5.html#transposing-a-dataframe",
    "title": "",
    "section": "Transposing a DataFrame",
    "text": "Transposing a DataFrame\n\nSwap rows and columns using .T:\n\nframe3.T\n\n        2000  2001  2002\nOhio     1.5   1.7   3.6\nNevada   NaN   2.4   2.9"
  },
  {
    "objectID": "qmd/pandas3ed5.html#dataframe-from-series",
    "href": "qmd/pandas3ed5.html#dataframe-from-series",
    "title": "",
    "section": "DataFrame from Series",
    "text": "DataFrame from Series\npdata = {'Ohio': frame3['Ohio'][:-1],\n         'Nevada': frame3['Nevada'][:2]}\npd.DataFrame(pdata)\n\n      Ohio  Nevada\n2000   1.5     NaN\n2001   1.7     2.4\n\n\nExplanation:\n\nframe3['Ohio'][:-1] selects all but the last element of the ‘Ohio’ column.\nframe3['Nevada'][:2] selects the first two elements of the ‘Nevada’ column.\nThe index is formed by the union of the indices of the Series."
  },
  {
    "objectID": "qmd/pandas3ed5.html#dataframe-indexcolumn-names-and-values",
    "href": "qmd/pandas3ed5.html#dataframe-indexcolumn-names-and-values",
    "title": "",
    "section": "DataFrame Index/Column Names, and Values",
    "text": "DataFrame Index/Column Names, and Values\nframe3.index.name = 'year'\nframe3.columns.name = 'state'\nframe3\n\nstate  Ohio  Nevada\nyear\n2000    1.5     NaN\n2001    1.7     2.4\n2002    3.6     2.9\n\nframe3.to_numpy() # or frame3.values (older versions of pandas)\n\narray([[1.5, nan],\n       [1.7, 2.4],\n       [3.6, 2.9]])\n\n\n.to_numpy() returns a 2D NumPy array.\nIf columns have different data types, the array’s dtype will accommodate all columns (often object)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#index-objects",
    "href": "qmd/pandas3ed5.html#index-objects",
    "title": "",
    "section": "Index Objects",
    "text": "Index Objects\n\npandas Index objects hold axis labels and metadata.\n\nobj = pd.Series(np.arange(3), index=['a', 'b', 'c'])\nindex = obj.index\nindex\n\nIndex(['a', 'b', 'c'], dtype='object')\n\nindex[1:]\n\nIndex(['b', 'c'], dtype='object')\n\n\nImmutability: Index objects are immutable (you can’t change them directly).\n\n# index[1] = 'd'  # This will raise a TypeError\n\nImmutability makes it safer to share Index objects between data structures.\n\nlabels = pd.Index(np.arange(3))\nobj2 = pd.Series([1.5, -2.5, 0], index=labels)\nobj2.index is labels\nTrue"
  },
  {
    "objectID": "qmd/pandas3ed5.html#index-as-a-fixed-size-set",
    "href": "qmd/pandas3ed5.html#index-as-a-fixed-size-set",
    "title": "",
    "section": "Index as a Fixed-Size Set",
    "text": "Index as a Fixed-Size Set\n\nAn Index behaves like an array and a fixed-size set.\n\nframe3\n\nstate  Ohio  Nevada\nyear\n2000    1.5     NaN\n2001    1.7     2.4\n2002    3.6     2.9\n\nframe3.columns\n\nIndex(['Ohio', 'Nevada'], dtype='object', name='state')\n\n'Ohio' in frame3.columns\nTrue\n2003 in frame3.index\nFalse\n\nDifference from Python sets: pandas Indexes can contain duplicate labels.\n\npd.Index(['foo', 'foo', 'bar', 'bar'])\nIndex(['foo', 'foo', 'bar', 'bar'], dtype='object')"
  },
  {
    "objectID": "qmd/pandas3ed5.html#index-methods-and-properties",
    "href": "qmd/pandas3ed5.html#index-methods-and-properties",
    "title": "",
    "section": "Index Methods and Properties",
    "text": "Index Methods and Properties\n\n\n\n\n\n\n\nMethod/Property\nDescription\n\n\n\n\nappend()\nConcatenate with additional Index objects, producing a new Index.\n\n\ndifference()\nCompute the set difference as an Index.\n\n\nintersection()\nCompute the set intersection.\n\n\nunion()\nCompute the set union.\n\n\nisin()\nCompute a boolean array indicating whether each value is contained in the passed collection.\n\n\ndelete()\nCompute a new Index with the element at index i deleted.\n\n\ndrop()\nCompute a new Index by deleting passed values.\n\n\ninsert()\nCompute a new Index by inserting an element at index i.\n\n\nis_monotonic\nReturns True if each element is greater than or equal to the previous element.\n\n\nis_unique\nReturns True if the Index has no duplicate values.\n\n\nunique()\nCompute the array of unique values in the Index."
  },
  {
    "objectID": "qmd/pandas3ed5.html#reindexing",
    "href": "qmd/pandas3ed5.html#reindexing",
    "title": "",
    "section": "Reindexing",
    "text": "Reindexing\n\nreindex: Create a new object with data aligned to a new index.\n\nobj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\nobj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])\nobj2\n\na   -5.3\nb    7.2\nc    3.6\nd    4.5\ne    NaN\ndtype: float64\n\n\nExplanation:\n\nRearranges data according to the new index.\nIntroduces NaN for missing values (‘e’ was not in the original index)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#interpolation-with-reindex",
    "href": "qmd/pandas3ed5.html#interpolation-with-reindex",
    "title": "",
    "section": "Interpolation with reindex",
    "text": "Interpolation with reindex\n\nFor ordered data (e.g., time series), you can fill missing values during reindexing.\n\nobj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])\nobj3.reindex(np.arange(6), method='ffill')  # Forward fill\n\n0      blue\n1      blue\n2    purple\n3    purple\n4    yellow\n5    yellow\ndtype: object\n\n\nmethod='ffill' forward-fills the values (carries the previous valid value forward)."
  },
  {
    "objectID": "qmd/pandas3ed5.html#reindexing-dataframes",
    "href": "qmd/pandas3ed5.html#reindexing-dataframes",
    "title": "",
    "section": "Reindexing DataFrames",
    "text": "Reindexing DataFrames\n\nreindex can modify rows, columns, or both.\n\nframe = pd.DataFrame(np.arange(9).reshape((3, 3)),\n                     index=['a', 'c', 'd'],\n                     columns=['Ohio', 'Texas', 'California'])\nframe2 = frame.reindex(index=['a', 'b', 'c', 'd'])\nframe2\n\n   Ohio  Texas  California\na   0.0    1.0         2.0\nb   NaN    NaN         NaN\nc   3.0    4.0         5.0\nd   6.0    7.0         8.0\n\nstates = ['Texas', 'Utah', 'California']\nframe.reindex(columns=states)\n\n   Texas  Utah  California\na      1   NaN           2\nc      4   NaN           5\nd      7   NaN           8\n\n\nYou can also use axis='columns' or axis='index' explicitly.\n\nframe.reindex(states, axis=\"columns\")\n\nTexas  Utah  California\na      1   NaN           2\nc      4   NaN           5\nd      7   NaN           8\n\n\nKey Concept: Reindexing is a fundamental operation for aligning and reshaping data.\nMore arguments for reindex are in Table 5-3."
  },
  {
    "objectID": "qmd/pandas3ed5.html#dropping-entries",
    "href": "qmd/pandas3ed5.html#dropping-entries",
    "title": "",
    "section": "Dropping Entries",
    "text": "Dropping Entries\n\ndrop: Remove rows or columns by label.\n\nobj = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])\nnew_obj = obj.drop('c') # drop row 'c'\nnew_obj\n\na    0.0\nb    1.0\nd    3.0\ne    4.0\ndtype: float64\n\nobj.drop(['d', 'c']) # drop multiple rows\n\na    0.0\nb    1.0\ne    4.0\ndtype: float64\n\n\nDropping from a DataFrame:\n\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\ndata.drop(index=['Colorado', 'Ohio']) # drop by row label.\n\n          one  two  three  four\nUtah        8    9     10    11\nNew York   12   13     14    15\n\ndata.drop(columns=['two']) # drop by column label\n\n          one  three  four\nOhio        0      2     3\nColorado    4      6     7\nUtah        8     10    11\nNew York   12     14    15\n\ndata.drop('two', axis=1)  # axis=1 is equivalent to columns='two'\n\n          one  three  four\nOhio        0      2     3\nColorado    4      6     7\nUtah        8     10    11\nNew York   12     14    15\n\ndata.drop(['two', 'four'], axis='columns') # drop multiple columns\n\n          one  three\nOhio        0      2\nColorado    4      6\nUtah        8     10\nNew York   12     14"
  },
  {
    "objectID": "qmd/pandas3ed5.html#indexing-selection-and-filtering",
    "href": "qmd/pandas3ed5.html#indexing-selection-and-filtering",
    "title": "",
    "section": "Indexing, Selection, and Filtering",
    "text": "Indexing, Selection, and Filtering\n\nSeries indexing works like NumPy array indexing, but you can use index labels.\n\nobj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\nobj['b']  # Select by label\n1.0\nobj[1]  # Select by integer position\n1.0\nobj[2:4]  # Slicing\n\nc    2.0\nd    3.0\ndtype: float64\n\nobj[['b', 'a', 'd']]  # Selection with a list of labels\n\nb    1.0\na    0.0\nd    3.0\ndtype: float64\n\nobj[[1, 3]] # Selection with a list of integer\n\nb    1.0\nd    3.0\ndtype: float64\n\nobj[obj &lt; 2]  # Boolean indexing\n\na    0.0\nb    1.0\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed5.html#loc-and-iloc-for-series",
    "href": "qmd/pandas3ed5.html#loc-and-iloc-for-series",
    "title": "",
    "section": "loc and iloc for Series",
    "text": "loc and iloc for Series\n\nPreferred way to select by label or integer position:\n\nobj.loc[['b', 'a', 'd']]  # Select by label (loc)\n\nb    1.0\na    0.0\nd    3.0\ndtype: float64\n\n\nWhy use loc? Avoids ambiguity with integer indexes.\n\nobj[1] might be interpreted as a label or a position, depending on the index type.\nloc is always interpreted as a label.\n\n\nobj1 = pd.Series([1, 2, 3], index=[2, 0, 1])\nobj2 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\nobj1\n\n2    1\n0    2\n1    3\ndtype: int64\n\nobj2\n\na    1\nb    2\nc    3\ndtype: int64\n\nobj1[[0, 1, 2]] # Ambiguous: label or position?\n\n0    2\n1    3\n2    1\ndtype: int64\n\nobj2[[0, 1, 2]] # Also ambiguous\n\na    1\nb    2\nc    3\ndtype: int64\n\n# obj2.loc[[0, 1]] # Error: 0 and 1 are not labels in obj2\n\niloc is always interpreted as an integer position:\n\nobj1.iloc[[0, 1, 2]]  # Select by integer position (iloc)\n\n2    1\n0    2\n1    3\ndtype: int64\n\nobj2.iloc[[0, 1, 2]]\n\na    1\nb    2\nc    3\ndtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed5.html#slicing-with-labels",
    "href": "qmd/pandas3ed5.html#slicing-with-labels",
    "title": "",
    "section": "Slicing with Labels",
    "text": "Slicing with Labels\n\nImportant difference: Slicing with labels includes the endpoint (unlike regular Python slicing).\n\nobj2.loc['b':'c']  # Includes 'c'\n\nb    2\nc    3\ndtype: int64\n\n\nYou can assign values using slicing:\n\nobj2.loc['b':'c'] = 5\nobj2\n\na    1\nb    5\nc    5\ndtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed5.html#dataframe-indexing",
    "href": "qmd/pandas3ed5.html#dataframe-indexing",
    "title": "",
    "section": "DataFrame Indexing",
    "text": "DataFrame Indexing\n\nIndexing into a DataFrame retrieves one or more columns.\n\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\ndata['two']  # Select column 'two'\n\nOhio         1\nColorado     5\nUtah         9\nNew York    13\nName: two, dtype: int64\n\ndata[['three', 'one']]  # Select multiple columns\n\n          three  one\nOhio          2    0\nColorado      6    4\nUtah         10    8\nNew York     14   12\n\n\nSpecial cases: Slicing or boolean arrays select rows.\n\ndata[:2]  # Select rows by integer position (slice)\n\n          one  two  three  four\nOhio        0    1      2     3\nColorado    4    5      6     7\n\ndata[data['three'] &gt; 5]  # Select rows where 'three' &gt; 5\n\n          one  two  three  four\nColorado    4    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15"
  },
  {
    "objectID": "qmd/pandas3ed5.html#boolean-dataframe-indexing",
    "href": "qmd/pandas3ed5.html#boolean-dataframe-indexing",
    "title": "",
    "section": "Boolean DataFrame Indexing",
    "text": "Boolean DataFrame Indexing\ndata &lt; 5  # Element-wise comparison, creating a boolean DataFrame\n\n            one    two  three   four\nOhio       True   True   True   True\nColorado   True  False  False  False\nUtah      False  False  False  False\nNew York  False  False  False  False\n\ndata[data &lt; 5] = 0  # Set values &lt; 5 to 0\ndata\n\n          one  two  three  four\nOhio        0    0      0     0\nColorado    0    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15"
  },
  {
    "objectID": "qmd/pandas3ed5.html#selection-on-dataframe-with-loc-and-iloc",
    "href": "qmd/pandas3ed5.html#selection-on-dataframe-with-loc-and-iloc",
    "title": "",
    "section": "Selection on DataFrame with loc and iloc",
    "text": "Selection on DataFrame with loc and iloc\n\nloc: Select rows and columns by label.\niloc: Select rows and columns by integer position.\n\ndata.loc['Colorado']  # Select row by label\n\none      0\ntwo      5\nthree    6\nfour     7\nName: Colorado, dtype: int64\n\ndata.loc[['Colorado', 'New York']]  # Select multiple rows\n\n          one  two  three  four\nColorado    0    5      6     7\nNew York   12   13     14    15\n\ndata.loc['Colorado', ['two', 'three']]  # Select rows and columns\n\ntwo      5\nthree    6\nName: Colorado, dtype: int64\n\n\niloc examples:\n\ndata.iloc[2]  # Select row by integer position\n\none       8\ntwo       9\nthree    10\nfour     11\nName: Utah, dtype: int64\n\ndata.iloc[[2, 1]] # Select multiple rows by integer position\n\n          one  two  three  four\nUtah        8    9     10    11\nColorado    0    5      6     7\n\ndata.iloc[2, [3, 0, 1]]  # Select rows and columns by integer position\n\nfour    11\none      8\ntwo      9\nName: Utah, dtype: int64\n\ndata.iloc[[1, 2], [3, 0, 1]]\n\n          four  one  two\nColorado     7    0    5\nUtah        11    8    9"
  },
  {
    "objectID": "qmd/pandas3ed5.html#slicing-with-loc-and-iloc",
    "href": "qmd/pandas3ed5.html#slicing-with-loc-and-iloc",
    "title": "",
    "section": "Slicing with loc and iloc",
    "text": "Slicing with loc and iloc\n\nBoth loc and iloc work with slicing.\n\ndata.loc[:'Utah', 'two']  # Slicing with labels (inclusive)\n\nOhio        0\nColorado    5\nUtah        9\nName: two, dtype: int64\n\ndata.iloc[:, :3][data.three &gt; 5]  # Combine slicing and boolean indexing\n\n          one  two  three\nColorado    0    5      6\nUtah        8    9     10\nNew York   12   13     14\n\n\nBoolean arrays work with loc but not iloc:\n\ndata.loc[data.three &gt;= 2]\n\n          one  two  three  four\nUtah        8    9     10    11\nNew York   12   13     14    15\n\n\nSummary of indexing options: See Table 5-4."
  },
  {
    "objectID": "qmd/pandas3ed5.html#integer-indexing-pitfalls",
    "href": "qmd/pandas3ed5.html#integer-indexing-pitfalls",
    "title": "",
    "section": "Integer Indexing Pitfalls",
    "text": "Integer Indexing Pitfalls\n\nInteger indexing can be tricky because it’s label-oriented if the index contains integers.\n\nser = pd.Series(np.arange(3.))\n# ser[-1]  # Error: -1 is not a label in the integer index\n\nUse loc (for labels) or iloc (for integer positions) to be explicit and avoid ambiguity.\n\nser.iloc[-1]\n2.0\n\nSlicing with integers is always integer-oriented:\n\nser[:2]\n\n0    0.0\n1    1.0\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed5.html#pitfalls-with-chained-indexing",
    "href": "qmd/pandas3ed5.html#pitfalls-with-chained-indexing",
    "title": "",
    "section": "Pitfalls with Chained Indexing",
    "text": "Pitfalls with Chained Indexing\n\nAvoid chained indexing when assigning values.\n\n# Bad:\n# data.loc[data.three == 5]['three'] = 6  # Might modify a copy, not the original\n\nUse a single loc or iloc operation instead:\n\n# Good:\ndata.loc[data.three == 5, 'three'] = 6  # Modifies the original DataFrame\n\nRule of thumb: Avoid chained indexing in assignments. It can lead to subtle bugs and SettingWithCopyWarning."
  },
  {
    "objectID": "qmd/pandas3ed5.html#arithmetic-and-data-alignment",
    "href": "qmd/pandas3ed5.html#arithmetic-and-data-alignment",
    "title": "",
    "section": "Arithmetic and Data Alignment",
    "text": "Arithmetic and Data Alignment\n\npandas simplifies working with objects that have different indexes.\nWhen adding objects, the result’s index is the union of the input indexes.\n\ns1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])\ns2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'])\ns1 + s2  # Aligns by index, introduces NaN where labels don't match\n\na    5.2\nc    1.1\nd    NaN\ne    0.0\nf    NaN\ng    NaN\ndtype: float64\n\n\nDataFrame alignment applies to both rows and columns:\n\ndf1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'),\n                   index=['Ohio', 'Texas', 'Colorado'])\ndf2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'),\n                   index=['Utah', 'Ohio', 'Texas', 'Oregon'])\ndf1 + df2\n\n            b   c     d   e\nColorado  NaN NaN   NaN NaN\nOhio      3.0 NaN   6.0 NaN\nOregon    NaN NaN   NaN NaN\nTexas     9.0 NaN  12.0 NaN\nUtah      NaN NaN   NaN NaN"
  },
  {
    "objectID": "qmd/pandas3ed5.html#arithmetic-methods-with-fill-values",
    "href": "qmd/pandas3ed5.html#arithmetic-methods-with-fill-values",
    "title": "",
    "section": "Arithmetic Methods with Fill Values",
    "text": "Arithmetic Methods with Fill Values\n\nUse arithmetic methods (like add, sub, div, mul) with fill_value to handle missing values.\n\ndf1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\ndf2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\ndf2.loc[1, 'b'] = np.nan\ndf1.add(df2, fill_value=0)  # Fill missing values with 0 before adding\n\n      a     b     c     d     e\n0   0.0   2.0   4.0   6.0   4.0\n1   9.0   5.0  13.0  15.0   9.0\n2  18.0  20.0  22.0  24.0  14.0\n3  15.0  16.0  17.0  18.0  19.0\n\n\nImportant: fill_value is used before the operation.\nThere are also “r”-prefixed methods (e.g., rdiv for reversed division: 1 / df1 is equivalent to df1.rdiv(1)).\n\n1 / df1\n\n          a         b         c         d\n0       inf  1.000000  0.500000  0.333333\n1  0.250000  0.200000  0.166667  0.142857\n2  0.125000  0.111111  0.100000  0.090909\n\ndf1.rdiv(1)\n\n          a         b         c         d\n0       inf  1.000000  0.500000  0.333333\n1  0.250000  0.200000  0.166667  0.142857\n2  0.125000  0.111111  0.100000  0.090909\n\ndf1.reindex(columns=df2.columns, fill_value=0)\n\n   a    b     c     d  e\n0  0.0  1.0   2.0   3.0  0\n1  4.0  5.0   6.0   7.0  0\n2  8.0  9.0  10.0  11.0  0\n\n\nFlexible arithmetic methods: See Table 5-5."
  },
  {
    "objectID": "qmd/pandas3ed5.html#operations-between-dataframe-and-series",
    "href": "qmd/pandas3ed5.html#operations-between-dataframe-and-series",
    "title": "",
    "section": "Operations between DataFrame and Series",
    "text": "Operations between DataFrame and Series\n\nBroadcasting: Operations between a DataFrame and a Series are applied row-wise or column-wise.\n\nframe = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n                     columns=list('bde'),\n                     index=['Utah', 'Ohio', 'Texas', 'Oregon'])\nseries = frame.iloc[0]  # Series is the first row of the DataFrame\nframe - series  # Subtract the Series from each row (broadcasting)\n\n          b    d    e\nUtah    0.0  0.0  0.0\nOhio    3.0  3.0  3.0\nTexas   6.0  6.0  6.0\nOregon  9.0  9.0  9.0\n\n\nMatching is done on the columns by default.\nIf an index value isn’t found in both, the result will be reindexed:\n\nseries2 = pd.Series(np.arange(3), index=['b', 'e', 'f'])\nframe + series2\n\n          b   d     e   f\nUtah    0.0 NaN   3.0 NaN\nOhio    3.0 NaN   6.0 NaN\nTexas   6.0 NaN   9.0 NaN\nOregon  9.0 NaN  12.0 NaN\n\n\nTo broadcast over columns, use arithmetic methods and specify the axis:\n\nseries3 = frame['d']\nframe.sub(series3, axis='index')  # Subtract series3 from each column (match on rows)\n\n          b    d    e\nUtah   -1.0  0.0  1.0\nOhio   -1.0  0.0  1.0\nTexas  -1.0  0.0  1.0\nOregon -1.0  0.0  1.0\n\n\nKey concept: axis='index' or axis=0 means you want to match on the rows and broadcast across the columns."
  },
  {
    "objectID": "qmd/pandas3ed5.html#function-application-and-mapping",
    "href": "qmd/pandas3ed5.html#function-application-and-mapping",
    "title": "",
    "section": "Function Application and Mapping",
    "text": "Function Application and Mapping\n\nNumPy ufuncs (element-wise array methods) work with pandas objects:\n\nframe = pd.DataFrame(np.random.standard_normal((4, 3)),\n                     columns=list('bde'),\n                     index=['Utah', 'Ohio', 'Texas', 'Oregon'])\nnp.abs(frame)  # Apply NumPy's absolute value function element-wise\n\n              b         d         e\nUtah   0.204708  0.478943  0.519439\nOhio   0.555730  1.965781  1.393406\nTexas  0.092908  0.281746  0.769023\nOregon 1.246435  1.007189  1.296221\n\n\napply: Apply a function along an axis (row-wise or column-wise).\n\ndef f1(x):\n    return x.max() - x.min()\n\nframe.apply(f1)  # Apply f1 to each column (default)\n\nb    1.802165\nd    1.684034\ne    2.689627\ndtype: float64\n\nframe.apply(f1, axis='columns')  # Apply f1 to each row\n\nUtah      0.998382\nOhio      2.521511\nTexas     0.676115\nOregon    2.542656\ndtype: float64\n\n\nThe function passed to apply can return a scalar or a Series.\nMany common array statistics are DataFrame methods (e.g., sum, mean), so apply isn’t always needed.\n\ndef f2(x):\n    return pd.Series([x.min(), x.max()], index=['min', 'max'])\nframe.apply(f2)\n\n            b         d         e\nmin -0.555730  0.281746 -1.296221\nmax  1.246435  1.965781  1.393406\n\n\napplymap: Apply a function element-wise to a DataFrame.\n\ndef my_format(x):\n    return f'{x:.2f}'\n\nframe.applymap(my_format)  # Format each value as a string with 2 decimal places\n\n           b      d      e\nUtah    -0.20   0.48  -0.52\nOhio    -0.56   1.97   1.39\nTexas    0.09   0.28   0.77\nOregon   1.25   1.01  -1.30\n\n\nmap: Apply a function element-wise to a Series.\n\nframe['e'].map(my_format)\n\nUtah      -0.52\nOhio       1.39\nTexas      0.77\nOregon    -1.30\nName: e, dtype: object"
  },
  {
    "objectID": "qmd/pandas3ed5.html#sorting-and-ranking",
    "href": "qmd/pandas3ed5.html#sorting-and-ranking",
    "title": "",
    "section": "Sorting and Ranking",
    "text": "Sorting and Ranking\n\nsort_index: Sort by row or column labels.\n\nobj = pd.Series(np.arange(4), index=['d', 'a', 'b', 'c'])\nobj.sort_index()  # Sort by index labels\n\na    1\nb    2\nc    3\nd    0\ndtype: int64\n\nframe = pd.DataFrame(np.arange(8).reshape((2, 4)),\n                     index=['three', 'one'],\n                     columns=['d', 'a', 'b', 'c'])\nframe.sort_index()  # Sort by row labels\n\n       d  a  b  c\none    4  5  6  7\nthree  0  1  2  3\n\nframe.sort_index(axis='columns')  # Sort by column labels\n\n       a  b  c  d\nthree  1  2  3  0\none    5  6  7  4\n\nframe.sort_index(axis='columns', ascending=False) #Descending sort\n\n       d  c  b  a\nthree  0  3  2  1\none    4  7  6  5\n\n\nsort_values: Sort by the values in a Series or DataFrame.\n\nobj = pd.Series([4, 7, -3, 2])\nobj.sort_values()  # Sort by values\n\n2   -3\n3    2\n0    4\n1    7\ndtype: int64\n\nobj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\nobj.sort_values() #Missing values are sorted to the end by default.\n\n4   -3.0\n5    2.0\n0    4.0\n2    7.0\n1    NaN\n3    NaN\ndtype: float64\n\nobj.sort_values(na_position=\"first\")\n\n1    NaN\n3    NaN\n4   -3.0\n5    2.0\n0    4.0\n2    7.0\ndtype: float64\n\n\nFor a DataFrame, you can sort by one or more columns:\n\nframe = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\nframe.sort_values('b')  # Sort by column 'b'\n\n   b  a\n2 -3  0\n3  2  1\n0  4  0\n1  7  1\n\nframe.sort_values(['a', 'b'])  # Sort by 'a' first, then 'b'\n\n   b  a\n2 -3  0\n0  4  0\n3  2  1\n1  7  1\n\n\nrank: Assign ranks to data (from lowest to highest).\n\nobj = pd.Series([7, -5, 7, 4, 2, 0, 4])\nobj.rank()  # Default: average rank for ties\n\n0    6.5\n1    1.0\n2    6.5\n3    4.5\n4    3.0\n5    2.0\n6    4.5\ndtype: float64\n\nobj.rank(method='first')  # Rank according to order in data\n\n0    6.0\n1    1.0\n2    7.0\n3    4.0\n4    3.0\n5    2.0\n6    5.0\ndtype: float64\n\nobj.rank(ascending=False) #Descending rank\n\n0    1.5\n1    7.0\n2    1.5\n3    3.5\n4    5.0\n5    6.0\n6    3.5\ndtype: float64\n\n\nDataFrame can compute ranks over rows or columns:\n\nframe = pd.DataFrame({'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1],\n                      'c': [-2, 5, 8, -2.5]})\nframe.rank(axis='columns')\n\n     b    a    c\n0  3.0  2.0  1.0\n1  3.0  1.0  2.0\n2  1.0  2.0  3.0\n3  3.0  2.0  1.0\n\n\nTie-breaking methods: See Table 5-6."
  },
  {
    "objectID": "qmd/pandas3ed5.html#axis-indexes-with-duplicate-labels",
    "href": "qmd/pandas3ed5.html#axis-indexes-with-duplicate-labels",
    "title": "",
    "section": "Axis Indexes with Duplicate Labels",
    "text": "Axis Indexes with Duplicate Labels\n\npandas allows duplicate index labels (unlike many other data analysis tools).\n\nobj = pd.Series(np.arange(5), index=['a', 'a', 'b', 'b', 'c'])\nobj.index.is_unique  # Check if index labels are unique\n\nFalse\n\n\nIndexing a label with multiple entries returns a Series:\n\nobj['a']\n\na    0\na    1\ndtype: int64\n\n\nIndexing a unique label returns a scalar:\n\nobj['c']\n\n4\n\n\nImportant: This can make your code’s behavior depend on whether labels are unique or not. Be mindful of this when working with data that might have duplicate labels.\nThe same logic applies to DataFrames:\n\ndf = pd.DataFrame(np.random.standard_normal((5, 3)),\n                  index=['a', 'a', 'b', 'b', 'c'])\ndf.loc['b']\n\n          0         1         2\nb  1.669025 -0.438570 -0.539741\nb  0.476985  3.248944 -1.021228\n\ndf.loc['c']\n\n0   -0.577087\n1    0.124121\n2    0.302614\nName: c, dtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed5.html#summarizing-and-computing-descriptive-statistics",
    "href": "qmd/pandas3ed5.html#summarizing-and-computing-descriptive-statistics",
    "title": "",
    "section": "Summarizing and Computing Descriptive Statistics",
    "text": "Summarizing and Computing Descriptive Statistics\n\npandas objects have built-in methods for common statistical calculations.\nThese methods automatically handle missing data (unlike NumPy).\n\ndf = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n                   [np.nan, np.nan], [0.75, -1.3]],\n                  index=['a', 'b', 'c', 'd'],\n                  columns=['one', 'two'])\ndf.sum()  # Sum of each column\n\none    9.25\ntwo   -5.80\ndtype: float64\n\ndf.sum(axis='columns')  # Sum of each row\n\na    1.40\nb    2.60\nc    0.00\nd   -0.55\ndtype: float64\n\n\nskipna: Controls whether missing values are excluded (default is True).\n\ndf.sum(axis='index', skipna=False)\n\none   NaN\ntwo   NaN\ndtype: float64\n\ndf.sum(axis='columns', skipna=False)\n\na     NaN\nb    2.60\nc     NaN\nd   -0.55\ndtype: float64\n\n\nSome methods require at least one non-NA value:\n\ndf.mean(axis='columns')\n\na    1.400\nb    1.300\nc      NaN\nd   -0.275\ndtype: float64\n\n\nidxmax, idxmin: Return the index label where the maximum or minimum value occurs.\n\ndf.idxmax()\n\none    b\ntwo    d\ndtype: object\n\n\ncumsum: Cumulative sum.\n\ndf.cumsum()\n\n    one  two\na  1.40  NaN\nb  8.50 -4.5\nc   NaN  NaN\nd  9.25 -5.8\n\n\ndescribe: Generate multiple summary statistics in one go.\n\ndf.describe()\n\n         one       two\ncount  3.000000  2.000000\nmean   3.083333 -2.900000\nstd    3.493685  2.262742\nmin    0.750000 -4.500000\n25%    1.075000 -3.700000\n50%    1.400000 -2.900000\n75%    4.250000 -2.100000\nmax    7.100000 -1.300000\n\n\nFor non-numeric data, describe provides different summaries:\n\nobj = pd.Series(['a', 'a', 'b', 'c'] * 4)\nobj.describe()\n\ncount     16\nunique     3\ntop        a\nfreq       8\ndtype: object\n\n\nList of descriptive statistics methods: See Table 5-8.\nOptions for reduction methods: See Table 5-7."
  },
  {
    "objectID": "qmd/pandas3ed5.html#correlation-and-covariance",
    "href": "qmd/pandas3ed5.html#correlation-and-covariance",
    "title": "",
    "section": "Correlation and Covariance",
    "text": "Correlation and Covariance\n# Assume 'price' and 'volume' DataFrames are already loaded (see book for details)\n# In real situations, you could load the data using:\n# price = pd.read_pickle(\"examples/yahoo_price.pkl\")\n# volume = pd.read_pickle(\"examples/yahoo_volume.pkl\")\n\n# For demonstration, create dummy DataFrames:\n\nprice = pd.DataFrame({\n    'AAPL': [150, 152, 151, 153],\n    'GOOG': [2500, 2520, 2510, 2530],\n    'IBM': [90, 91, 90.5, 91.5],\n    'MSFT': [300, 305, 303, 306]\n}, index=pd.to_datetime(['2023-10-26', '2023-10-27', '2023-10-30', '2023-10-31']))\n\nvolume = pd.DataFrame({\n    'AAPL': [100000, 105000, 98000, 102000],\n    'GOOG': [50000, 52000, 49000, 51000],\n    'IBM': [40000, 41000, 39000, 40500],\n    'MSFT': [60000, 62000, 59000, 61000]\n}, index=pd.to_datetime(['2023-10-26', '2023-10-27', '2023-10-30', '2023-10-31']))\n\n\nreturns = price.pct_change()  # Compute percent changes\nreturns.tail()\n\n\n             AAPL      GOOG       IBM      MSFT\n2023-10-26 NaN NaN NaN NaN 2023-10-27 0.013333 0.008000 0.011111 0.016667 2023-10-30 -0.006579 -0.003968 -0.005495 -0.006557 2023-10-31 0.013245 0.007968 0.011050 0.009901\n:::\n\n- `corr`, `cov`: Compute correlation and covariance.\n\n```python\nreturns['MSFT'].corr(returns['IBM'])  # Correlation between MSFT and IBM returns\n0.8291737285918034\nreturns['MSFT'].cov(returns['IBM'])  # Covariance\n8.688717548738278e-05\n\nSince MSFT is a valid Python variable name, we can also select these columns using more concise syntax:\n\nreturns.MSFT.corr(returns.IBM)\n0.8291737285918034\n\nDataFrame methods return full correlation/covariance matrices:\n\nreturns.corr()\n\n          AAPL      GOOG       IBM      MSFT\nAAPL  1.000000  0.854256  0.924038  0.989172\nGOOG  0.854256  1.000000  0.719842  0.882348\nIBM   0.924038  0.719842  1.000000  0.829174\nMSFT  0.989172  0.882348  0.829174  1.000000\n\nreturns.cov()\n\n          AAPL          GOOG           IBM          MSFT\nAAPL  0.000177  1.567807e-04  1.575587e-04  1.828619e-04\nGOOG  0.000157  1.885524e-04  1.282353e-04  1.641686e-04\nIBM   0.000158  1.282353e-04  1.754194e-04  1.499066e-04\nMSFT  0.000183  1.641686e-04  1.499066e-04  1.968199e-04\n\n\ncorrwith: Compute pairwise correlations between a DataFrame’s columns/rows and another Series/DataFrame.\n\nreturns.corrwith(returns['IBM'])  # Correlation with IBM returns\n\nAAPL    0.924038\nGOOG    0.719842\nIBM     1.000000\nMSFT    0.829174\ndtype: float64\n\nreturns.corrwith(volume)  # Correlation with volume\n\nAAPL   -0.974948\nGOOG   -0.999841\nIBM    -0.824252\nMSFT   -0.957479\ndtype: float64\n\n\nUnique Values, Value Counts, and Membership\nobj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])\nuniques = obj.unique()  # Get unique values (not necessarily sorted)\nuniques\n\narray(['c', 'a', 'd', 'b'], dtype=object)\n\nobj.value_counts()  # Count occurrences of each value (sorted by frequency)\n\nc    3\na    3\nb    2\nd    1\nName: count, dtype: int64\n\npd.value_counts(obj.to_numpy(), sort=False)  # Can be used with NumPy arrays too\n\nc    3\na    3\nd    1\nb    2\nName: count, dtype: int64\n\n\nisin: Check membership (vectorized set membership).\n\nmask = obj.isin(['b', 'c'])  # Check if each value is in ['b', 'c']\nmask\n\n0     True\n1    False\n2    False\n3    False\n4    False\n5     True\n6     True\n7     True\n8     True\ndtype: bool\n\nobj[mask]  # Select values where mask is True\n\n0    c\n5    b\n6    b\n7    c\n8    c\ndtype: object\n\n\nIndex.get_indexer: Get index locations for an array of values.\n\nto_match = pd.Series(['c', 'a', 'b', 'b', 'c', 'a'])\nunique_vals = pd.Series(['c', 'b', 'a'])\nindices = pd.Index(unique_vals).get_indexer(to_match)\nindices\n\narray([0, 2, 1, 1, 0, 2])\n\n\nUnique, value counts, and set membership methods: See Table 5-9.\n\n\n\nHistograms\n\nYou can compute histograms on multiple related columns using apply and pd.value_counts.\n\ndata = pd.DataFrame({'Qu1': [1, 3, 4, 3, 4],\n                     'Qu2': [2, 3, 1, 2, 3],\n                     'Qu3': [1, 5, 2, 4, 4]})\nresult = data.apply(pd.value_counts).fillna(0) # fillna(0) replace NaN with 0\nresult\n\n   Qu1  Qu2  Qu3\n1  1.0  1.0  1.0\n2  0.0  2.0  1.0\n3  2.0  2.0  0.0\n4  2.0  0.0  2.0\n5  0.0  0.0  1.0\n\n\nThe row labels are the distinct values, and the values are the counts.\nThere is also a DataFrame.value_counts method, but it computes counts considering each row of the DataFrame as a tuple\n\ndata = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\ndata.value_counts()\n\na  b\n1  0    2\n2  0    2\n1  1    1\nName: count, dtype: int64\n\n\n\nSummary\n\n\n\n\n\n\n\npandas is your essential tool for data analysis in Python.\nSeries and DataFrames are the core data structures.\nMaster indexing ([], .loc, .iloc) for selecting and modifying data.\nUnderstand data alignment – how pandas handles operations on objects with different indexes.\nUse built-in methods for common tasks (arithmetic, statistics, sorting, etc.).\nBe aware of integer indexing pitfalls and chained indexing.\nMissing data (NaN) is handled gracefully.\nReindexing and dropping are important for reshaping data.\n\n\n\n\n\n\n\n\n\nThoughts and Discussion 🤔\n\nHow does pandas’ data alignment feature compare to joining tables in SQL? What are the advantages and disadvantages?\nWhen might you prefer to use loc versus iloc for selecting data? Give specific examples.\nHow does the apply method enable you to perform more complex operations on DataFrames? Can you think of a real-world example where you might use it?\nWhy is it important to be aware of duplicate index labels in pandas? How might this affect your analysis?\nConsider a dataset with missing values. How would you decide whether to drop rows/columns with missing data, fill them with a specific value, or use interpolation? What are the trade-offs?\nPractice and experiment with these concepts. The more you use pandas, the more intuitive it will become!"
  },
  {
    "objectID": "qmd/pandas3ed5.html#unique-values-value-counts-and-membership",
    "href": "qmd/pandas3ed5.html#unique-values-value-counts-and-membership",
    "title": "",
    "section": "Unique Values, Value Counts, and Membership",
    "text": "Unique Values, Value Counts, and Membership\nobj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])\nuniques = obj.unique()  # Get unique values (not necessarily sorted)\nuniques\n\narray(['c', 'a', 'd', 'b'], dtype=object)\n\nobj.value_counts()  # Count occurrences of each value (sorted by frequency)\n\nc    3\na    3\nb    2\nd    1\nName: count, dtype: int64\n\npd.value_counts(obj.to_numpy(), sort=False)  # Can be used with NumPy arrays too\n\nc    3\na    3\nd    1\nb    2\nName: count, dtype: int64\n\n\nisin: Check membership (vectorized set membership).\n\nmask = obj.isin(['b', 'c'])  # Check if each value is in ['b', 'c']\nmask\n\n0     True\n1    False\n2    False\n3    False\n4    False\n5     True\n6     True\n7     True\n8     True\ndtype: bool\n\nobj[mask]  # Select values where mask is True\n\n0    c\n5    b\n6    b\n7    c\n8    c\ndtype: object\n\n\nIndex.get_indexer: Get index locations for an array of values.\n\nto_match = pd.Series(['c', 'a', 'b', 'b', 'c', 'a'])\nunique_vals = pd.Series(['c', 'b', 'a'])\nindices = pd.Index(unique_vals).get_indexer(to_match)\nindices\n\narray([0, 2, 1, 1, 0, 2])\n\n\nUnique, value counts, and set membership methods: See Table 5-9."
  },
  {
    "objectID": "qmd/pandas3ed5.html#histograms",
    "href": "qmd/pandas3ed5.html#histograms",
    "title": "",
    "section": "Histograms",
    "text": "Histograms\n\nYou can compute histograms on multiple related columns using apply and pd.value_counts.\n\ndata = pd.DataFrame({'Qu1': [1, 3, 4, 3, 4],\n                     'Qu2': [2, 3, 1, 2, 3],\n                     'Qu3': [1, 5, 2, 4, 4]})\nresult = data.apply(pd.value_counts).fillna(0) # fillna(0) replace NaN with 0\nresult\n\n   Qu1  Qu2  Qu3\n1  1.0  1.0  1.0\n2  0.0  2.0  1.0\n3  2.0  2.0  0.0\n4  2.0  0.0  2.0\n5  0.0  0.0  1.0\n\n\nThe row labels are the distinct values, and the values are the counts.\nThere is also a DataFrame.value_counts method, but it computes counts considering each row of the DataFrame as a tuple\n\ndata = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\ndata.value_counts()\n\na  b\n1  0    2\n2  0    2\n1  1    1\nName: count, dtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed5.html#summary",
    "href": "qmd/pandas3ed5.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\npandas is your essential tool for data analysis in Python.\nSeries and DataFrames are the core data structures.\nMaster indexing ([], .loc, .iloc) for selecting and modifying data.\nUnderstand data alignment – how pandas handles operations on objects with different indexes.\nUse built-in methods for common tasks (arithmetic, statistics, sorting, etc.).\nBe aware of integer indexing pitfalls and chained indexing.\nMissing data (NaN) is handled gracefully.\nReindexing and dropping are important for reshaping data."
  },
  {
    "objectID": "qmd/pandas3ed5.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed5.html#thoughts-and-discussion",
    "title": "",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\nHow does pandas’ data alignment feature compare to joining tables in SQL? What are the advantages and disadvantages?\nWhen might you prefer to use loc versus iloc for selecting data? Give specific examples.\nHow does the apply method enable you to perform more complex operations on DataFrames? Can you think of a real-world example where you might use it?\nWhy is it important to be aware of duplicate index labels in pandas? How might this affect your analysis?\nConsider a dataset with missing values. How would you decide whether to drop rows/columns with missing data, fill them with a specific value, or use interpolation? What are the trade-offs?\nPractice and experiment with these concepts. The more you use pandas, the more intuitive it will become!"
  },
  {
    "objectID": "qmd/pandas3ed10.html",
    "href": "qmd/pandas3ed10.html",
    "title": "Data Aggregation and Group Operations",
    "section": "",
    "text": "This chapter focuses on a critical part of data analysis: data aggregation and group operations. We’ll explore how to categorize a dataset and apply functions to each group, a fundamental step in many data workflows.\n\n\n\n\n\n\nNote\n\n\n\nWe will learn how to use pandas’s versatile groupby interface to slice, dice, and summarize datasets, similar to how SQL works with relational databases, but with greater flexibility.\n\n\n\n\n\nWe’ll cover the following key operations:\n\nSplitting a pandas object into groups using one or more keys.\nCalculating group summary statistics (e.g., count, mean, standard deviation).\nApplying transformations within groups (e.g., normalization, linear regression).\nComputing pivot tables and cross-tabulations.\nPerforming quantile analysis and other statistical group analyses.\nUsing transform and apply methods for general group-wise operations.\n\n\n\n\nGrouping and aggregating data allows us to:\n\nGain insights from large datasets by summarizing information.\nCompare different groups within the data.\nPrepare data for further analysis or visualization.\nUncover patterns and relationships that might not be apparent in the raw data."
  },
  {
    "objectID": "qmd/pandas3ed10.html#what-well-learn",
    "href": "qmd/pandas3ed10.html#what-well-learn",
    "title": "Data Aggregation and Group Operations",
    "section": "",
    "text": "This chapter focuses on a critical part of data analysis: data aggregation and group operations. We’ll explore how to categorize a dataset and apply functions to each group, a fundamental step in many data workflows.\n\n\n\n\n\n\nNote\n\n\n\nWe will learn how to use pandas’s versatile groupby interface to slice, dice, and summarize datasets, similar to how SQL works with relational databases, but with greater flexibility."
  },
  {
    "objectID": "qmd/pandas3ed10.html#key-operations",
    "href": "qmd/pandas3ed10.html#key-operations",
    "title": "Data Aggregation and Group Operations",
    "section": "",
    "text": "We’ll cover the following key operations:\n\nSplitting a pandas object into groups using one or more keys.\nCalculating group summary statistics (e.g., count, mean, standard deviation).\nApplying transformations within groups (e.g., normalization, linear regression).\nComputing pivot tables and cross-tabulations.\nPerforming quantile analysis and other statistical group analyses.\nUsing transform and apply methods for general group-wise operations."
  },
  {
    "objectID": "qmd/pandas3ed10.html#why-is-this-important",
    "href": "qmd/pandas3ed10.html#why-is-this-important",
    "title": "Data Aggregation and Group Operations",
    "section": "",
    "text": "Grouping and aggregating data allows us to:\n\nGain insights from large datasets by summarizing information.\nCompare different groups within the data.\nPrepare data for further analysis or visualization.\nUncover patterns and relationships that might not be apparent in the raw data."
  },
  {
    "objectID": "qmd/pandas3ed10.html#the-split-apply-combine-paradigm",
    "href": "qmd/pandas3ed10.html#the-split-apply-combine-paradigm",
    "title": "Data Aggregation and Group Operations",
    "section": "The Split-Apply-Combine Paradigm 💡",
    "text": "The Split-Apply-Combine Paradigm 💡\nHadley Wickham coined the term “split-apply-combine” to describe group operations. It’s a powerful way to think about data manipulation. This process involves three steps:\n\nSplit: Data is divided into groups based on one or more “keys”.\nApply: A function is applied to each group independently.\nCombine: The results from each group are combined into a final result."
  },
  {
    "objectID": "qmd/pandas3ed10.html#visualizing-split-apply-combine",
    "href": "qmd/pandas3ed10.html#visualizing-split-apply-combine",
    "title": "Data Aggregation and Group Operations",
    "section": "Visualizing Split-Apply-Combine 📊",
    "text": "Visualizing Split-Apply-Combine 📊\n\n\n\n\n\ngraph LR\n    A[Data] --&gt; B(Split by Key)\n    B --&gt; C1[Group 1]\n    B --&gt; C2[Group 2]\n    B --&gt; C3[Group 3]\n    C1 --&gt; D1(Apply Function)\n    C2 --&gt; D2(Apply Function)\n    C3 --&gt; D3(Apply Function)\n    D1 --&gt; E[Combine Results]\n    D2 --&gt; E\n    D3 --&gt; E"
  },
  {
    "objectID": "qmd/pandas3ed10.html#grouping-keys",
    "href": "qmd/pandas3ed10.html#grouping-keys",
    "title": "Data Aggregation and Group Operations",
    "section": "Grouping Keys 🔑",
    "text": "Grouping Keys 🔑\nGrouping keys can take many forms:\n\nA list or array of values.\nA column name in a DataFrame.\nA dictionary or Series mapping values to group names.\nA function applied to the axis index or labels.\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to realize the latter three methods are shortcuts for producing an array of values to be used to split up the object."
  },
  {
    "objectID": "qmd/pandas3ed10.html#example-simple-group-aggregation",
    "href": "qmd/pandas3ed10.html#example-simple-group-aggregation",
    "title": "Data Aggregation and Group Operations",
    "section": "Example: Simple Group Aggregation",
    "text": "Example: Simple Group Aggregation\nLet’s look at the image provided in the material.\n#| echo: false\n#| out.width: \"80%\"\n#knitr::include_graphics(\"images/groupby.png\")\n\n\nKey and Data: The initial table shows a ‘Key’ column and a ‘Data’ column.\nSplit: The data is split into three groups (A, B, C) based on the ‘Key’ column.\nApply: The Sum function is applied to the ‘Data’ column of each group.\nCombine: The sums for each group are combined into a new table."
  },
  {
    "objectID": "qmd/pandas3ed10.html#grouping-by-a-single-column",
    "href": "qmd/pandas3ed10.html#grouping-by-a-single-column",
    "title": "Data Aggregation and Group Operations",
    "section": "Grouping by a Single Column",
    "text": "Grouping by a Single Column\nLet’s calculate the mean of data1 for each group in key1.\n\ngrouped = df[\"data1\"].groupby(df[\"key1\"])\ngrouped.mean()\n\nkey1\na   -0.222295\nb   -0.611658\nName: data1, dtype: float64\n\n\n\ndf[\"data1\"]: Selects the data1 column.\n.groupby(df[\"key1\"]): Groups the data by the values in key1.\ngrouped is now a special GroupBy object that stores the group information.\n.mean(): Calculates the mean for each group.\nNote the automatic exclusion of None values in key1."
  },
  {
    "objectID": "qmd/pandas3ed10.html#grouping-by-multiple-columns",
    "href": "qmd/pandas3ed10.html#grouping-by-multiple-columns",
    "title": "Data Aggregation and Group Operations",
    "section": "Grouping by Multiple Columns",
    "text": "Grouping by Multiple Columns\nWe can also group by multiple columns, creating a hierarchical index.\n\n# 修改聚合方式\ngrouped = df.groupby([\"key1\", \"key2\"])\ngrouped.agg({\"data1\": [\"mean\", \"std\"],\n             \"data2\": [\"mean\", \"std\"]})\n\nNow, the data is grouped by unique combinations of key1 and key2."
  },
  {
    "objectID": "qmd/pandas3ed10.html#unstacking",
    "href": "qmd/pandas3ed10.html#unstacking",
    "title": "Data Aggregation and Group Operations",
    "section": "Unstacking",
    "text": "Unstacking\nThe unstack() method can reshape the result for easier readability.\n\nimport pandas as pd\nimport numpy as np\n# Create sample data\ndf = pd.DataFrame({\n    \"key1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n    \"key2\": [1, 2, 1, 2, 1],\n    \"data1\": np.random.randn(5),\n    \"data2\": np.random.randn(5)\n})\n\n# Group by multiple columns and calculate means\nmeans = df.groupby([\"key1\", \"key2\"])[\"data1\"].mean()\nmeans\n\nkey1  key2\na     1      -0.561434\n      2      -0.094709\nb     1       1.491390\n      2      -0.638902\nName: data1, dtype: float64\n\n\n\n# Now unstack works because means is defined\nmeans.unstack()\n\n\n\n\n\n\n\nkey2\n1\n2\n\n\nkey1\n\n\n\n\n\n\na\n-0.561434\n-0.094709\n\n\nb\n1.491390\n-0.638902"
  },
  {
    "objectID": "qmd/pandas3ed10.html#grouping-with-series-and-arrays",
    "href": "qmd/pandas3ed10.html#grouping-with-series-and-arrays",
    "title": "Data Aggregation and Group Operations",
    "section": "Grouping with Series and Arrays",
    "text": "Grouping with Series and Arrays\nThe grouping keys can be Series or arrays, not just DataFrame columns.\n\n# 修改示例代码\nimport pandas as pd\nimport numpy as np\n\n# 创建新的DataFrame示例\ndf = pd.DataFrame({\n    \"key1\": [\"a\", \"a\", \"b\", \"b\", \"a\", \"b\", \"a\"],\n    \"key2\": [1, 2, 1, 2, 1, 2, 1],\n    \"data1\": np.random.randn(7),  # 增加到7行以匹配states和years的长度\n    \"data2\": np.random.randn(7)\n})\n\n# 外部数组用于分组\nstates = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\nyears = np.array([2005, 2005, 2006, 2005, 2006, 2005, 2006])\n\n# 现在进行分组计算\nresult = df[\"data1\"].groupby([states, years]).mean()\nprint(\"\\n分组结果:\")\nprint(result)\n\n# 使用unstack()来重塑结果\nprint(\"\\n重塑后的结果:\")\nprint(result.unstack())\n\n\n分组结果:\nCA  2005    0.426490\n    2006   -0.935834\nOH  2005    0.956599\n    2006   -0.173388\nName: data1, dtype: float64\n\n重塑后的结果:\n        2005      2006\nCA  0.426490 -0.935834\nOH  0.956599 -0.173388\n\n\nHere, we group data1 by states and years, which are external arrays."
  },
  {
    "objectID": "qmd/pandas3ed10.html#grouping-using-column-names-directly",
    "href": "qmd/pandas3ed10.html#grouping-using-column-names-directly",
    "title": "Data Aggregation and Group Operations",
    "section": "Grouping Using Column Names Directly",
    "text": "Grouping Using Column Names Directly\nIf the grouping information is within the DataFrame, we can use column names directly.\n\ndf.groupby(\"key1\").mean()\n\n\n\n\n\n\n\n\nkey2\ndata1\ndata2\n\n\nkey1\n\n\n\n\n\n\n\na\n1.250000\n0.470331\n-1.266804\n\n\nb\n1.666667\n-0.132585\n-0.962969\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nkey2 will be included in the result, and non-numeric column key1 is automatically excluded as a nuisance column.\n\n\n\ndf.groupby([\"key1\", \"key2\"]).mean()\n\n\n\n\n\n\n\n\n\ndata1\ndata2\n\n\nkey1\nkey2\n\n\n\n\n\n\na\n1\n0.130198\n-1.642382\n\n\n2\n1.490732\n-0.140069\n\n\nb\n1\n-0.935834\n-0.861755\n\n\n2\n0.269039\n-1.013576"
  },
  {
    "objectID": "qmd/pandas3ed10.html#group-size",
    "href": "qmd/pandas3ed10.html#group-size",
    "title": "Data Aggregation and Group Operations",
    "section": "Group Size",
    "text": "Group Size\nThe size() method shows the number of data points in each group.\n\ndf.groupby([\"key1\", \"key2\"]).size()\n\nkey1  key2\na     1       3\n      2       1\nb     1       1\n      2       2\ndtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#handling-missing-values-in-group-keys",
    "href": "qmd/pandas3ed10.html#handling-missing-values-in-group-keys",
    "title": "Data Aggregation and Group Operations",
    "section": "Handling Missing Values in Group Keys",
    "text": "Handling Missing Values in Group Keys\nBy default, missing values in group keys are excluded. We can include them with dropna=False.\n\ndf.groupby(\"key1\", dropna=False).size()\n\nkey1\na    4\nb    3\ndtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#iterating-with-a-single-key",
    "href": "qmd/pandas3ed10.html#iterating-with-a-single-key",
    "title": "Data Aggregation and Group Operations",
    "section": "Iterating with a Single Key",
    "text": "Iterating with a Single Key\nThe GroupBy object supports iteration, yielding the group name and the data chunk.\n\nfor name, group in df.groupby(\"key1\"):\n    print(f\"Group Name: {name}\")\n    print(group)\n\nGroup Name: a\n  key1  key2     data1     data2\n0    a     1  0.737369 -1.428681\n1    a     2  1.490732 -0.140069\n4    a     1 -1.253881 -2.798589\n6    a     1  0.907105 -0.699877\nGroup Name: b\n  key1  key2     data1     data2\n2    b     1 -0.935834 -0.861755\n3    b     2  1.175829 -0.255619\n5    b     2 -0.637752 -1.771533"
  },
  {
    "objectID": "qmd/pandas3ed10.html#iterating-with-multiple-keys",
    "href": "qmd/pandas3ed10.html#iterating-with-multiple-keys",
    "title": "Data Aggregation and Group Operations",
    "section": "Iterating with Multiple Keys",
    "text": "Iterating with Multiple Keys\nWhen grouping by multiple keys, the group name is a tuple.\n\nfor (k1, k2), group in df.groupby([\"key1\", \"key2\"]):\n    print(f\"Group Keys: {(k1, k2)}\")\n    print(group)\n\nGroup Keys: ('a', np.int64(1))\n  key1  key2     data1     data2\n0    a     1  0.737369 -1.428681\n4    a     1 -1.253881 -2.798589\n6    a     1  0.907105 -0.699877\nGroup Keys: ('a', np.int64(2))\n  key1  key2     data1     data2\n1    a     2  1.490732 -0.140069\nGroup Keys: ('b', np.int64(1))\n  key1  key2     data1     data2\n2    b     1 -0.935834 -0.861755\nGroup Keys: ('b', np.int64(2))\n  key1  key2     data1     data2\n3    b     2  1.175829 -0.255619\n5    b     2 -0.637752 -1.771533"
  },
  {
    "objectID": "qmd/pandas3ed10.html#creating-a-dictionary-of-data-pieces",
    "href": "qmd/pandas3ed10.html#creating-a-dictionary-of-data-pieces",
    "title": "Data Aggregation and Group Operations",
    "section": "Creating a Dictionary of Data Pieces",
    "text": "Creating a Dictionary of Data Pieces\nA useful one-liner creates a dictionary where keys are group names and values are data chunks.\n\npieces = dict(list(df.groupby(\"key1\")))\npieces[\"b\"]\n\n\n\n\n\n\n\n\nkey1\nkey2\ndata1\ndata2\n\n\n\n\n2\nb\n1\n-0.935834\n-0.861755\n\n\n3\nb\n2\n1.175829\n-0.255619\n\n\n5\nb\n2\n-0.637752\n-1.771533"
  },
  {
    "objectID": "qmd/pandas3ed10.html#selecting-a-single-column",
    "href": "qmd/pandas3ed10.html#selecting-a-single-column",
    "title": "Data Aggregation and Group Operations",
    "section": "Selecting a Single Column",
    "text": "Selecting a Single Column\nTo aggregate only specific columns, index the GroupBy object.\n\n# SeriesGroupBy\ndf.groupby([\"key1\", \"key2\"])[\"data2\"].mean()\n\nkey1  key2\na     1      -1.642382\n      2      -0.140069\nb     1      -0.861755\n      2      -1.013576\nName: data2, dtype: float64\n\n\nThis is a shorthand for df[\"data2\"].groupby([df[\"key1\"], df[\"key2\"]]).mean(). The result is a Series."
  },
  {
    "objectID": "qmd/pandas3ed10.html#selecting-multiple-columns",
    "href": "qmd/pandas3ed10.html#selecting-multiple-columns",
    "title": "Data Aggregation and Group Operations",
    "section": "Selecting Multiple Columns",
    "text": "Selecting Multiple Columns\n\n# DataFrameGroupBy\ndf.groupby([\"key1\", \"key2\"])[[\"data2\"]].mean()\n\n\n\n\n\n\n\n\n\ndata2\n\n\nkey1\nkey2\n\n\n\n\n\na\n1\n-1.642382\n\n\n2\n-0.140069\n\n\nb\n1\n-0.861755\n\n\n2\n-1.013576\n\n\n\n\n\n\n\nThis is equivalent to df[[\"data2\"]].groupby([df[\"key1\"], df[\"key2\"]]).mean(). The result is a DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed10.html#optimized-aggregation-methods",
    "href": "qmd/pandas3ed10.html#optimized-aggregation-methods",
    "title": "Data Aggregation and Group Operations",
    "section": "Optimized Aggregation Methods",
    "text": "Optimized Aggregation Methods\nData aggregation transforms arrays into scalar values. pandas provides optimized methods for common aggregations. Here are some of them.\n\n\ncount: Number of non-NA values\nsum: Sum of non-NA values\nmean: Mean of non-NA values\nmedian: Arithmetic median of non-NA values\nstd, var: Sample standard deviation and variance\nmin, max: Minimum and maximum of non-NA values\nprod: Product of non-NA values\nfirst, last: First and last non-NA values\nany, all: Return True if any (one or more values) or all non-NA values are “truthy”\ncummin, cummax: Cumulative minimum and maximum of non-NA values\ncumsum: Cumulative sum of non-NA values\ncumprod: Cumulative product of non-NA values\nnth: Retrieve value that would appear at position n with the data in sorted order\nohlc: Compute four “open-high-low-close” statistics for time series-like data\nquantile: Compute sample quantile\nrank: Ordinal ranks of non-NA values, like calling Series.rank\nsize: Compute group sizes, returning result as a Series"
  },
  {
    "objectID": "qmd/pandas3ed10.html#using-your-own-aggregation-functions",
    "href": "qmd/pandas3ed10.html#using-your-own-aggregation-functions",
    "title": "Data Aggregation and Group Operations",
    "section": "Using Your Own Aggregation Functions",
    "text": "Using Your Own Aggregation Functions\nYou can define custom aggregation functions using the agg (or aggregate) method.\n\ndef peak_to_peak(arr):\n    return arr.max() - arr.min()\n\ngrouped = df.groupby(\"key1\")\ngrouped.agg(peak_to_peak)\n\n\n\n\n\n\n\n\nkey2\ndata1\ndata2\n\n\nkey1\n\n\n\n\n\n\n\na\n1\n2.744613\n2.658520\n\n\nb\n1\n2.111663\n1.515914"
  },
  {
    "objectID": "qmd/pandas3ed10.html#the-describe-method",
    "href": "qmd/pandas3ed10.html#the-describe-method",
    "title": "Data Aggregation and Group Operations",
    "section": "The describe Method",
    "text": "The describe Method\nEven methods like describe, which aren’t strictly aggregations, can be used with GroupBy.\n\ngrouped.describe()\n\n\n\n\n\n\n\n\nkey2\ndata1\ndata2\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\ncount\nmean\n...\n75%\nmax\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nkey1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na\n4.0\n1.250000\n0.50000\n1.0\n1.0\n1.0\n1.25\n2.0\n4.0\n0.470331\n...\n1.053012\n1.490732\n4.0\n-1.266804\n1.149421\n-2.798589\n-1.771158\n-1.064279\n-0.559925\n-0.140069\n\n\nb\n3.0\n1.666667\n0.57735\n1.0\n1.5\n2.0\n2.00\n2.0\n3.0\n-0.132585\n...\n0.269039\n1.175829\n3.0\n-0.962969\n0.763008\n-1.771533\n-1.316644\n-0.861755\n-0.558687\n-0.255619\n\n\n\n\n2 rows × 24 columns"
  },
  {
    "objectID": "qmd/pandas3ed10.html#multiple-functions-on-a-single-column",
    "href": "qmd/pandas3ed10.html#multiple-functions-on-a-single-column",
    "title": "Data Aggregation and Group Operations",
    "section": "Multiple Functions on a Single Column",
    "text": "Multiple Functions on a Single Column\nLet’s load a tips dataset.\n\ntips = pd.read_csv(\"examples/tips.csv\")\n\ntips[\"tip_pct\"] = tips[\"tip\"] / tips[\"total_bill\"]\n\nWe can apply multiple functions to tip_pct.\n\ngrouped = tips.groupby([\"day\", \"smoker\"])\ngrouped_pct = grouped[\"tip_pct\"]\ngrouped_pct.agg([\"mean\", \"std\", peak_to_peak])\n\n\n\n\n\n\n\n\n\nmean\nstd\npeak_to_peak\n\n\nday\nsmoker\n\n\n\n\n\n\n\nFri\nNo\n0.151650\n0.028123\n0.067349\n\n\nYes\n0.174783\n0.051293\n0.159925\n\n\nSat\nNo\n0.158048\n0.039767\n0.235193\n\n\nYes\n0.147906\n0.061375\n0.290095\n\n\nSun\nNo\n0.160113\n0.042347\n0.193226\n\n\nYes\n0.187250\n0.154134\n0.644685\n\n\nThur\nNo\n0.160298\n0.038774\n0.193350\n\n\nYes\n0.163863\n0.039389\n0.151240"
  },
  {
    "objectID": "qmd/pandas3ed10.html#custom-column-names",
    "href": "qmd/pandas3ed10.html#custom-column-names",
    "title": "Data Aggregation and Group Operations",
    "section": "Custom Column Names",
    "text": "Custom Column Names\nWe can provide custom names for the aggregated columns using (name, function) tuples.\n\ngrouped_pct.agg([(\"average\", \"mean\"), (\"stdev\", np.std)])\n\n\n\n\n\n\n\n\n\naverage\nstdev\n\n\nday\nsmoker\n\n\n\n\n\n\nFri\nNo\n0.151650\n0.028123\n\n\nYes\n0.174783\n0.051293\n\n\nSat\nNo\n0.158048\n0.039767\n\n\nYes\n0.147906\n0.061375\n\n\nSun\nNo\n0.160113\n0.042347\n\n\nYes\n0.187250\n0.154134\n\n\nThur\nNo\n0.160298\n0.038774\n\n\nYes\n0.163863\n0.039389"
  },
  {
    "objectID": "qmd/pandas3ed10.html#different-functions-for-different-columns",
    "href": "qmd/pandas3ed10.html#different-functions-for-different-columns",
    "title": "Data Aggregation and Group Operations",
    "section": "Different Functions for Different Columns",
    "text": "Different Functions for Different Columns\nWe can apply different functions to different columns using a dictionary.\n\nfunctions = [\"count\", \"mean\", \"max\"]\nresult = grouped[[\"tip_pct\", \"total_bill\"]].agg(functions)\nresult\n\n\n\n\n\n\n\n\n\ntip_pct\ntotal_bill\n\n\n\n\ncount\nmean\nmax\ncount\nmean\nmax\n\n\nday\nsmoker\n\n\n\n\n\n\n\n\n\n\nFri\nNo\n4\n0.151650\n0.187735\n4\n18.420000\n22.75\n\n\nYes\n15\n0.174783\n0.263480\n15\n16.813333\n40.17\n\n\nSat\nNo\n45\n0.158048\n0.291990\n45\n19.661778\n48.33\n\n\nYes\n42\n0.147906\n0.325733\n42\n21.276667\n50.81\n\n\nSun\nNo\n57\n0.160113\n0.252672\n57\n20.506667\n48.17\n\n\nYes\n19\n0.187250\n0.710345\n19\n24.120000\n45.35\n\n\nThur\nNo\n45\n0.160298\n0.266312\n45\n17.113111\n41.19\n\n\nYes\n17\n0.163863\n0.241255\n17\n19.190588\n43.11\n\n\n\n\n\n\n\n\ngrouped.agg({\"tip\" : np.max, \"size\" : \"sum\"})\n\n\n\n\n\n\n\n\n\ntip\nsize\n\n\nday\nsmoker\n\n\n\n\n\n\nFri\nNo\n3.50\n9\n\n\nYes\n4.73\n31\n\n\nSat\nNo\n9.00\n115\n\n\nYes\n10.00\n104\n\n\nSun\nNo\n6.00\n167\n\n\nYes\n6.50\n49\n\n\nThur\nNo\n6.70\n112\n\n\nYes\n5.00\n40\n\n\n\n\n\n\n\n\ngrouped.agg({\"tip_pct\" : [\"min\", \"max\", \"mean\", \"std\"],\n             \"size\" : \"sum\"})\n\n\n\n\n\n\n\n\n\ntip_pct\nsize\n\n\n\n\nmin\nmax\nmean\nstd\nsum\n\n\nday\nsmoker\n\n\n\n\n\n\n\n\n\nFri\nNo\n0.120385\n0.187735\n0.151650\n0.028123\n9\n\n\nYes\n0.103555\n0.263480\n0.174783\n0.051293\n31\n\n\nSat\nNo\n0.056797\n0.291990\n0.158048\n0.039767\n115\n\n\nYes\n0.035638\n0.325733\n0.147906\n0.061375\n104\n\n\nSun\nNo\n0.059447\n0.252672\n0.160113\n0.042347\n167\n\n\nYes\n0.065660\n0.710345\n0.187250\n0.154134\n49\n\n\nThur\nNo\n0.072961\n0.266312\n0.160298\n0.038774\n112\n\n\nYes\n0.090014\n0.241255\n0.163863\n0.039389\n40"
  },
  {
    "objectID": "qmd/pandas3ed10.html#the-power-of-apply",
    "href": "qmd/pandas3ed10.html#the-power-of-apply",
    "title": "Data Aggregation and Group Operations",
    "section": "The Power of apply 💪",
    "text": "The Power of apply 💪\nThe apply method is the most general-purpose GroupBy method. It splits the data, applies a function to each piece, and concatenates the results."
  },
  {
    "objectID": "qmd/pandas3ed10.html#example-selecting-top-rows",
    "href": "qmd/pandas3ed10.html#example-selecting-top-rows",
    "title": "Data Aggregation and Group Operations",
    "section": "Example: Selecting Top Rows",
    "text": "Example: Selecting Top Rows\n\ndef top(df, n=5, column=\"tip_pct\"):\n    return df.sort_values(column, ascending=False)[:n]\n\ntips.groupby(\"smoker\").apply(top)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsmoker\nday\ntime\nsize\ntip_pct\n\n\nsmoker\n\n\n\n\n\n\n\n\n\n\n\n\nNo\n232\n11.61\n3.39\nNo\nSat\nDinner\n2\n0.291990\n\n\n149\n7.51\n2.00\nNo\nThur\nLunch\n2\n0.266312\n\n\n51\n10.29\n2.60\nNo\nSun\nDinner\n2\n0.252672\n\n\n185\n20.69\n5.00\nNo\nSun\nDinner\n5\n0.241663\n\n\n88\n24.71\n5.85\nNo\nThur\nLunch\n2\n0.236746\n\n\nYes\n172\n7.25\n5.15\nYes\nSun\nDinner\n2\n0.710345\n\n\n178\n9.60\n4.00\nYes\nSun\nDinner\n2\n0.416667\n\n\n67\n3.07\n1.00\nYes\nSat\nDinner\n1\n0.325733\n\n\n183\n23.17\n6.50\nYes\nSun\nDinner\n4\n0.280535\n\n\n109\n14.31\n4.00\nYes\nSat\nDinner\n2\n0.279525"
  },
  {
    "objectID": "qmd/pandas3ed10.html#passing-arguments-to-apply",
    "href": "qmd/pandas3ed10.html#passing-arguments-to-apply",
    "title": "Data Aggregation and Group Operations",
    "section": "Passing Arguments to apply",
    "text": "Passing Arguments to apply\n\ntips.groupby([\"smoker\", \"day\"]).apply(top, n=1, column=\"total_bill\")\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsmoker\nday\ntime\nsize\ntip_pct\n\n\nsmoker\nday\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nFri\n94\n22.75\n3.25\nNo\nFri\nDinner\n2\n0.142857\n\n\nSat\n212\n48.33\n9.00\nNo\nSat\nDinner\n4\n0.186220\n\n\nSun\n156\n48.17\n5.00\nNo\nSun\nDinner\n6\n0.103799\n\n\nThur\n142\n41.19\n5.00\nNo\nThur\nLunch\n5\n0.121389\n\n\nYes\nFri\n95\n40.17\n4.73\nYes\nFri\nDinner\n4\n0.117750\n\n\nSat\n170\n50.81\n10.00\nYes\nSat\nDinner\n3\n0.196812\n\n\nSun\n182\n45.35\n3.50\nYes\nSun\nDinner\n3\n0.077178\n\n\nThur\n197\n43.11\n5.00\nYes\nThur\nLunch\n4\n0.115982"
  },
  {
    "objectID": "qmd/pandas3ed10.html#suppressing-group-keys-in-apply",
    "href": "qmd/pandas3ed10.html#suppressing-group-keys-in-apply",
    "title": "Data Aggregation and Group Operations",
    "section": "Suppressing Group Keys in apply",
    "text": "Suppressing Group Keys in apply\nUse group_keys=False to prevent group keys from being added to the index.\n\ntips.groupby(\"smoker\", group_keys=False).apply(top)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsmoker\nday\ntime\nsize\ntip_pct\n\n\n\n\n232\n11.61\n3.39\nNo\nSat\nDinner\n2\n0.291990\n\n\n149\n7.51\n2.00\nNo\nThur\nLunch\n2\n0.266312\n\n\n51\n10.29\n2.60\nNo\nSun\nDinner\n2\n0.252672\n\n\n185\n20.69\n5.00\nNo\nSun\nDinner\n5\n0.241663\n\n\n88\n24.71\n5.85\nNo\nThur\nLunch\n2\n0.236746\n\n\n172\n7.25\n5.15\nYes\nSun\nDinner\n2\n0.710345\n\n\n178\n9.60\n4.00\nYes\nSun\nDinner\n2\n0.416667\n\n\n67\n3.07\n1.00\nYes\nSat\nDinner\n1\n0.325733\n\n\n183\n23.17\n6.50\nYes\nSun\nDinner\n4\n0.280535\n\n\n109\n14.31\n4.00\nYes\nSat\nDinner\n2\n0.279525"
  },
  {
    "objectID": "qmd/pandas3ed10.html#using-cut-and-qcut-with-groupby",
    "href": "qmd/pandas3ed10.html#using-cut-and-qcut-with-groupby",
    "title": "Data Aggregation and Group Operations",
    "section": "Using cut and qcut with groupby",
    "text": "Using cut and qcut with groupby\nThe cut and qcut functions can be combined with groupby for bucket and quantile analysis.\n\nframe = pd.DataFrame({\"data1\": np.random.standard_normal(1000),\n                      \"data2\": np.random.standard_normal(1000)})\nquartiles = pd.cut(frame[\"data1\"], 4)\n\ndef get_stats(group):\n    return pd.DataFrame(\n        {\"min\": group.min(), \"max\": group.max(),\n        \"count\": group.count(), \"mean\": group.mean()}\n    )\n\ngrouped = frame.groupby(quartiles)\ngrouped.apply(get_stats)\n\n\n\n\n\n\n\n\n\nmin\nmax\ncount\nmean\n\n\ndata1\n\n\n\n\n\n\n\n\n\n(-3.238, -1.53]\ndata1\n-3.231055\n-1.530513\n71\n-1.952386\n\n\ndata2\n-3.587494\n2.067490\n71\n-0.057670\n\n\n(-1.53, 0.17]\ndata1\n-1.518108\n0.168722\n525\n-0.506486\n\n\ndata2\n-3.801378\n2.850708\n525\n0.038355\n\n\n(0.17, 1.871]\ndata1\n0.177192\n1.868726\n384\n0.817880\n\n\ndata2\n-2.780837\n2.555894\n384\n0.028667\n\n\n(1.871, 3.572]\ndata1\n1.875801\n3.571579\n20\n2.253871\n\n\ndata2\n-2.352358\n1.573240\n20\n-0.358152\n\n\n\n\n\n\n\nAnd same result could have been computed more simply with:\n\ngrouped.agg([\"min\", \"max\", \"count\", \"mean\"])\n\n\n\n\n\n\n\n\ndata1\ndata2\n\n\n\nmin\nmax\ncount\nmean\nmin\nmax\ncount\nmean\n\n\ndata1\n\n\n\n\n\n\n\n\n\n\n\n\n(-3.238, -1.53]\n-3.231055\n-1.530513\n71\n-1.952386\n-3.587494\n2.067490\n71\n-0.057670\n\n\n(-1.53, 0.17]\n-1.518108\n0.168722\n525\n-0.506486\n-3.801378\n2.850708\n525\n0.038355\n\n\n(0.17, 1.871]\n0.177192\n1.868726\n384\n0.817880\n-2.780837\n2.555894\n384\n0.028667\n\n\n(1.871, 3.572]\n1.875801\n3.571579\n20\n2.253871\n-2.352358\n1.573240\n20\n-0.358152"
  },
  {
    "objectID": "qmd/pandas3ed10.html#equal-size-buckets-with-qcut",
    "href": "qmd/pandas3ed10.html#equal-size-buckets-with-qcut",
    "title": "Data Aggregation and Group Operations",
    "section": "Equal-Size Buckets with qcut",
    "text": "Equal-Size Buckets with qcut\n\nquartiles_samp = pd.qcut(frame[\"data1\"], 4, labels=False)  # labels=False for indices\ngrouped = frame.groupby(quartiles_samp)\ngrouped.apply(get_stats)\n\n\n\n\n\n\n\n\n\nmin\nmax\ncount\nmean\n\n\ndata1\n\n\n\n\n\n\n\n\n\n0\ndata1\n-3.231055\n-0.683226\n250\n-1.305832\n\n\ndata2\n-3.587494\n2.273105\n250\n-0.042877\n\n\n1\ndata1\n-0.682765\n-0.038321\n250\n-0.341488\n\n\ndata2\n-2.362864\n2.850708\n250\n0.120847\n\n\n2\ndata1\n-0.035605\n0.630488\n250\n0.265004\n\n\ndata2\n-3.801378\n2.555894\n250\n0.039723\n\n\n3\ndata1\n0.631948\n3.571579\n250\n1.200791\n\n\ndata2\n-2.780837\n2.547870\n250\n-0.038145"
  },
  {
    "objectID": "qmd/pandas3ed10.html#filling-with-the-mean",
    "href": "qmd/pandas3ed10.html#filling-with-the-mean",
    "title": "Data Aggregation and Group Operations",
    "section": "Filling with the Mean",
    "text": "Filling with the Mean\n\ns = pd.Series(np.random.standard_normal(6))\ns[::2] = np.nan\ns.fillna(s.mean())\n\n0   -0.753499\n1   -0.715937\n2   -0.753499\n3    0.269473\n4   -0.753499\n5   -1.814033\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#filling-with-group-specific-means",
    "href": "qmd/pandas3ed10.html#filling-with-group-specific-means",
    "title": "Data Aggregation and Group Operations",
    "section": "Filling with Group-Specific Means",
    "text": "Filling with Group-Specific Means\n\nstates = [\"Ohio\", \"New York\", \"Vermont\", \"Florida\",\n          \"Oregon\", \"Nevada\", \"California\", \"Idaho\"]\ngroup_key = [\"East\"] * 4 + [\"West\"] * 4\ndata = pd.Series(np.random.standard_normal(8), index=states)\ndata[[\"Vermont\", \"Nevada\", \"Idaho\"]] = np.nan\n\ndef fill_mean(group):\n    return group.fillna(group.mean())\n\ndata.groupby(group_key).apply(fill_mean)\n\nEast  Ohio          0.115240\n      New York      1.162630\n      Vermont       0.419994\n      Florida      -0.017888\nWest  Oregon        0.403002\n      Nevada       -0.143319\n      California   -0.689640\n      Idaho        -0.143319\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#predefined-fill-values",
    "href": "qmd/pandas3ed10.html#predefined-fill-values",
    "title": "Data Aggregation and Group Operations",
    "section": "Predefined Fill Values",
    "text": "Predefined Fill Values\n\nfill_values = {\"East\": 0.5, \"West\": -1}\ndef fill_func(group):\n    return group.fillna(fill_values[group.name])\n\ndata.groupby(group_key).apply(fill_func)\n\nEast  Ohio          0.115240\n      New York      1.162630\n      Vermont       0.500000\n      Florida      -0.017888\nWest  Oregon        0.403002\n      Nevada       -1.000000\n      California   -0.689640\n      Idaho        -1.000000\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#simulating-a-deck-of-cards",
    "href": "qmd/pandas3ed10.html#simulating-a-deck-of-cards",
    "title": "Data Aggregation and Group Operations",
    "section": "Simulating a Deck of Cards",
    "text": "Simulating a Deck of Cards\n\nsuits = [\"H\", \"S\", \"C\", \"D\"]\ncard_val = (list(range(1, 11)) + [10] * 3) * 4\nbase_names = [\"A\"] + list(range(2, 11)) + [\"J\", \"K\", \"Q\"]\ncards = []\nfor suit in suits:\n    cards.extend(str(num) + suit for num in base_names)\n\ndeck = pd.Series(card_val, index=cards)"
  },
  {
    "objectID": "qmd/pandas3ed10.html#drawing-a-random-hand",
    "href": "qmd/pandas3ed10.html#drawing-a-random-hand",
    "title": "Data Aggregation and Group Operations",
    "section": "Drawing a Random Hand",
    "text": "Drawing a Random Hand\n\ndef draw(deck, n=5):\n    return deck.sample(n)\n\ndraw(deck)\n\n7C    7\n5C    5\n8S    8\n5S    5\n6H    6\ndtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#drawing-two-random-cards-from-each-suit",
    "href": "qmd/pandas3ed10.html#drawing-two-random-cards-from-each-suit",
    "title": "Data Aggregation and Group Operations",
    "section": "Drawing Two Random Cards from Each Suit",
    "text": "Drawing Two Random Cards from Each Suit\n\ndef get_suit(card):\n    return card[-1]  # last letter is suit\n\ndeck.groupby(get_suit).apply(draw, n=2)\n\nC  7C      7\n   KC     10\nD  6D      6\n   10D    10\nH  2H      2\n   10H    10\nS  AS      1\n   4S      4\ndtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#group-weighted-average",
    "href": "qmd/pandas3ed10.html#group-weighted-average",
    "title": "Data Aggregation and Group Operations",
    "section": "Group Weighted Average",
    "text": "Group Weighted Average\n\ndf = pd.DataFrame({\"category\": [\"a\", \"a\", \"a\", \"a\",\n                                \"b\", \"b\", \"b\", \"b\"],\n                   \"data\": np.random.standard_normal(8),\n                   \"weights\": np.random.uniform(size=8)})\n\ngrouped = df.groupby(\"category\")\ndef get_wavg(group):\n    return np.average(group[\"data\"], weights=group[\"weights\"])\n\ngrouped.apply(get_wavg)\n\ncategory\na   -0.054703\nb    0.515110\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#correlation-with-spx-sp-500-index",
    "href": "qmd/pandas3ed10.html#correlation-with-spx-sp-500-index",
    "title": "Data Aggregation and Group Operations",
    "section": "Correlation with SPX (S&P 500 Index)",
    "text": "Correlation with SPX (S&P 500 Index)\n\nclose_px = pd.read_csv(\"examples/stock_px.csv\", parse_dates=True,\n                       index_col=0) # Make sure stock_px.csv in the same dir\n\nrets = close_px.pct_change().dropna()\n\ndef get_year(x):\n    return x.year\n\nby_year = rets.groupby(get_year)\n\ndef spx_corr(group):\n    return group.corrwith(group[\"SPX\"])\nby_year.apply(spx_corr)\n\n\n\n\n\n\n\n\nAAPL\nMSFT\nXOM\nSPX\n\n\n\n\n2003\n0.541124\n0.745174\n0.661265\n1.0\n\n\n2004\n0.374283\n0.588531\n0.557742\n1.0\n\n\n2005\n0.467540\n0.562374\n0.631010\n1.0\n\n\n2006\n0.428267\n0.406126\n0.518514\n1.0\n\n\n2007\n0.508118\n0.658770\n0.786264\n1.0\n\n\n2008\n0.681434\n0.804626\n0.828303\n1.0\n\n\n2009\n0.707103\n0.654902\n0.797921\n1.0\n\n\n2010\n0.710105\n0.730118\n0.839057\n1.0\n\n\n2011\n0.691931\n0.800996\n0.859975\n1.0"
  },
  {
    "objectID": "qmd/pandas3ed10.html#intercolumn-correlation-apple-and-microsoft",
    "href": "qmd/pandas3ed10.html#intercolumn-correlation-apple-and-microsoft",
    "title": "Data Aggregation and Group Operations",
    "section": "Intercolumn Correlation (Apple and Microsoft)",
    "text": "Intercolumn Correlation (Apple and Microsoft)\n\ndef corr_aapl_msft(group):\n    return group[\"AAPL\"].corr(group[\"MSFT\"])\n\nby_year.apply(corr_aapl_msft)\n\n2003    0.480868\n2004    0.259024\n2005    0.300093\n2006    0.161735\n2007    0.417738\n2008    0.611901\n2009    0.432738\n2010    0.571946\n2011    0.581987\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#the-transform-method",
    "href": "qmd/pandas3ed10.html#the-transform-method",
    "title": "Data Aggregation and Group Operations",
    "section": "The transform Method",
    "text": "The transform Method\nThe transform method is similar to apply but with more constraints:\n\nIt can produce a scalar value to broadcast.\nIt can produce an object of the same shape as the input group.\nIt must not mutate its input.\n\n\ndf = pd.DataFrame({'key': ['a', 'b', 'c'] * 4,\n                   'value': np.arange(12.)})\ng = df.groupby('key')['value']\n\ndef get_mean(group):\n      return group.mean()\ng.transform(get_mean)\n\n0     4.5\n1     5.5\n2     6.5\n3     4.5\n4     5.5\n5     6.5\n6     4.5\n7     5.5\n8     6.5\n9     4.5\n10    5.5\n11    6.5\nName: value, dtype: float64\n\n\nWe can pass a string alias as with the GroupBy agg method:\n\ng.transform('mean')\n\n0     4.5\n1     5.5\n2     6.5\n3     4.5\n4     5.5\n5     6.5\n6     4.5\n7     5.5\n8     6.5\n9     4.5\n10    5.5\n11    6.5\nName: value, dtype: float64\n\n\nLike apply, transform works with functions that return Series, but the result must be the same size as the input. For example, we can multiply each group by 2 using a helper function:\n\ndef times_two(group):\n      return group * 2\ng.transform(times_two)\n\n0      0.0\n1      2.0\n2      4.0\n3      6.0\n4      8.0\n5     10.0\n6     12.0\n7     14.0\n8     16.0\n9     18.0\n10    20.0\n11    22.0\nName: value, dtype: float64\n\n\nAs a more complicated example, we can compute the ranks in descending order for each group:\n\ndef get_ranks(group):\n    return group.rank(ascending=False)\ng.transform(get_ranks)\n\n0     4.0\n1     4.0\n2     4.0\n3     3.0\n4     3.0\n5     3.0\n6     2.0\n7     2.0\n8     2.0\n9     1.0\n10    1.0\n11    1.0\nName: value, dtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#unwrapped-group-operations",
    "href": "qmd/pandas3ed10.html#unwrapped-group-operations",
    "title": "Data Aggregation and Group Operations",
    "section": "“Unwrapped” Group Operations",
    "text": "“Unwrapped” Group Operations\nConsider a group transformation function composed from simple aggregations:\n\ndef normalize(x):\n      return (x - x.mean()) / x.std()\n\nWe can obtain equivalent results in this case using either transform or apply:\n\ng.transform(normalize)\n\n0    -1.161895\n1    -1.161895\n2    -1.161895\n3    -0.387298\n4    -0.387298\n5    -0.387298\n6     0.387298\n7     0.387298\n8     0.387298\n9     1.161895\n10    1.161895\n11    1.161895\nName: value, dtype: float64\n\n\n\ng.apply(normalize)\n\nkey    \na    0    -1.161895\n     3    -0.387298\n     6     0.387298\n     9     1.161895\nb    1    -1.161895\n     4    -0.387298\n     7     0.387298\n     10    1.161895\nc    2    -1.161895\n     5    -0.387298\n     8     0.387298\n     11    1.161895\nName: value, dtype: float64\n\n\n“Unwrapped” group operations combine multiple GroupBy operations arithmetically, often faster than using apply directly.\n\nnormalized = (df['value'] - g.transform('mean')) / g.transform('std')\nnormalized\n\n0    -1.161895\n1    -1.161895\n2    -1.161895\n3    -0.387298\n4    -0.387298\n5    -0.387298\n6     0.387298\n7     0.387298\n8     0.387298\n9     1.161895\n10    1.161895\n11    1.161895\nName: value, dtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed10.html#what-is-a-pivot-table",
    "href": "qmd/pandas3ed10.html#what-is-a-pivot-table",
    "title": "Data Aggregation and Group Operations",
    "section": "What is a Pivot Table? 🤔",
    "text": "What is a Pivot Table? 🤔\nA pivot table aggregates data by one or more keys, arranging the data in a rectangle. It’s a common tool in spreadsheet software."
  },
  {
    "objectID": "qmd/pandas3ed10.html#pivot-tables-with-pandas",
    "href": "qmd/pandas3ed10.html#pivot-tables-with-pandas",
    "title": "Data Aggregation and Group Operations",
    "section": "Pivot Tables with pandas",
    "text": "Pivot Tables with pandas\npandas provides the pivot_table method and function, leveraging groupby and hierarchical indexing.\n\n#tips.pivot_table(index=[\"day\", \"smoker\"])\n\n# 指定要聚合的值列\ntips.pivot_table(\n    values=['total_bill', 'tip'],  # 指定要聚合的数值列\n    index=['day', 'smoker'],       # 行索引\n    aggfunc='mean'                 # 聚合函数\n)\n\n\n\n\n\n\n\n\n\ntip\ntotal_bill\n\n\nday\nsmoker\n\n\n\n\n\n\nFri\nNo\n2.812500\n18.420000\n\n\nYes\n2.714000\n16.813333\n\n\nSat\nNo\n3.102889\n19.661778\n\n\nYes\n2.875476\n21.276667\n\n\nSun\nNo\n3.167895\n20.506667\n\n\nYes\n3.516842\n24.120000\n\n\nThur\nNo\n2.673778\n17.113111\n\n\nYes\n3.030000\n19.190588"
  },
  {
    "objectID": "qmd/pandas3ed10.html#grouping-by-multiple-variables",
    "href": "qmd/pandas3ed10.html#grouping-by-multiple-variables",
    "title": "Data Aggregation and Group Operations",
    "section": "Grouping by Multiple Variables",
    "text": "Grouping by Multiple Variables\n\ntips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n                 values=[\"tip_pct\", \"size\"])\n\n\n\n\n\n\n\n\n\nsize\ntip_pct\n\n\n\nsmoker\nNo\nYes\nNo\nYes\n\n\ntime\nday\n\n\n\n\n\n\n\n\nDinner\nFri\n2.000000\n2.222222\n0.139622\n0.165347\n\n\nSat\n2.555556\n2.476190\n0.158048\n0.147906\n\n\nSun\n2.929825\n2.578947\n0.160113\n0.187250\n\n\nThur\n2.000000\nNaN\n0.159744\nNaN\n\n\nLunch\nFri\n3.000000\n1.833333\n0.187735\n0.188937\n\n\nThur\n2.500000\n2.352941\n0.160311\n0.163863"
  },
  {
    "objectID": "qmd/pandas3ed10.html#adding-margins-partial-totals",
    "href": "qmd/pandas3ed10.html#adding-margins-partial-totals",
    "title": "Data Aggregation and Group Operations",
    "section": "Adding Margins (Partial Totals)",
    "text": "Adding Margins (Partial Totals)\n\ntips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n                 values=[\"tip_pct\", \"size\"], margins=True)\n\n\n\n\n\n\n\n\n\nsize\ntip_pct\n\n\n\nsmoker\nNo\nYes\nAll\nNo\nYes\nAll\n\n\ntime\nday\n\n\n\n\n\n\n\n\n\n\nDinner\nFri\n2.000000\n2.222222\n2.166667\n0.139622\n0.165347\n0.158916\n\n\nSat\n2.555556\n2.476190\n2.517241\n0.158048\n0.147906\n0.153152\n\n\nSun\n2.929825\n2.578947\n2.842105\n0.160113\n0.187250\n0.166897\n\n\nThur\n2.000000\nNaN\n2.000000\n0.159744\nNaN\n0.159744\n\n\nLunch\nFri\n3.000000\n1.833333\n2.000000\n0.187735\n0.188937\n0.188765\n\n\nThur\n2.500000\n2.352941\n2.459016\n0.160311\n0.163863\n0.161301\n\n\nAll\n\n2.668874\n2.408602\n2.569672\n0.159328\n0.163196\n0.160803"
  },
  {
    "objectID": "qmd/pandas3ed10.html#using-different-aggregation-functions",
    "href": "qmd/pandas3ed10.html#using-different-aggregation-functions",
    "title": "Data Aggregation and Group Operations",
    "section": "Using Different Aggregation Functions",
    "text": "Using Different Aggregation Functions\n\ntips.pivot_table(index=[\"time\", \"smoker\"], columns=\"day\",\n                 values=\"tip_pct\", aggfunc=len, margins=True)\n\n\n\n\n\n\n\n\nday\nFri\nSat\nSun\nThur\nAll\n\n\ntime\nsmoker\n\n\n\n\n\n\n\n\n\nDinner\nNo\n3.0\n45.0\n57.0\n1.0\n106\n\n\nYes\n9.0\n42.0\n19.0\nNaN\n70\n\n\nLunch\nNo\n1.0\nNaN\nNaN\n44.0\n45\n\n\nYes\n6.0\nNaN\nNaN\n17.0\n23\n\n\nAll\n\n19.0\n87.0\n76.0\n62.0\n244"
  },
  {
    "objectID": "qmd/pandas3ed10.html#cross-tabulations-crosstab",
    "href": "qmd/pandas3ed10.html#cross-tabulations-crosstab",
    "title": "Data Aggregation and Group Operations",
    "section": "Cross-Tabulations (Crosstab)",
    "text": "Cross-Tabulations (Crosstab)\nA crosstab is a special case of a pivot table that computes group frequencies.\n\nfrom io import StringIO\nimport pandas as pd\n\ndata = pd.read_table(StringIO(\"\"\"Sample Nationality Handedness\n1 USA Right-handed\n2 Japan Left-handed\n3 USA Right-handed\n4 Japan Right-handed\n5 Japan Left-handed\n6 Japan Right-handed\n7 USA Right-handed\n8 USA Left-handed\n9 Japan Right-handed\n10 USA Right-handed\"\"\"), sep=\"\\s+\")\n\npd.crosstab(data[\"Nationality\"], data[\"Handedness\"], margins=True)\n\n\n\n\n\n\n\nHandedness\nLeft-handed\nRight-handed\nAll\n\n\nNationality\n\n\n\n\n\n\n\nJapan\n2\n3\n5\n\n\nUSA\n1\n4\n5\n\n\nAll\n3\n7\n10\n\n\n\n\n\n\n\n\npd.crosstab([tips[\"time\"], tips[\"day\"]], tips[\"smoker\"], margins=True)\n\n\n\n\n\n\n\n\nsmoker\nNo\nYes\nAll\n\n\ntime\nday\n\n\n\n\n\n\n\nDinner\nFri\n3\n9\n12\n\n\nSat\n45\n42\n87\n\n\nSun\n57\n19\n76\n\n\nThur\n1\n0\n1\n\n\nLunch\nFri\n1\n6\n7\n\n\nThur\n44\n17\n61\n\n\nAll\n\n151\n93\n244"
  },
  {
    "objectID": "qmd/pandas3ed12.html",
    "href": "qmd/pandas3ed12.html",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "",
    "text": "This chapter introduces how to use Python for modeling, bridging the gap between data wrangling with pandas and model building with specialized libraries. We’ll focus on how to interface pandas with modeling libraries like statsmodels and scikit-learn. This is a vital step in the data analysis workflow."
  },
  {
    "objectID": "qmd/pandas3ed12.html#introduction",
    "href": "qmd/pandas3ed12.html#introduction",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "",
    "text": "This chapter introduces how to use Python for modeling, bridging the gap between data wrangling with pandas and model building with specialized libraries. We’ll focus on how to interface pandas with modeling libraries like statsmodels and scikit-learn. This is a vital step in the data analysis workflow."
  },
  {
    "objectID": "qmd/pandas3ed12.html#key-concepts",
    "href": "qmd/pandas3ed12.html#key-concepts",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Key Concepts",
    "text": "Key Concepts\nBefore we dive into the specifics, let’s define some crucial terms:\n\n\nData Mining: The process of discovering patterns, anomalies, and insights from large datasets. It often involves using various techniques, including machine learning.\nMachine Learning (ML): A subset of artificial intelligence (AI) that focuses on enabling systems to learn from data without explicit programming. ML algorithms build models based on sample data, known as “training data,” to make predictions or decisions.\nStatistical Learning: A framework for understanding data using statistical methods. It overlaps significantly with machine learning but often emphasizes inference and interpretability.\nFeature Engineering: The process of using domain knowledge to select, transform, and create relevant features (variables) from raw data to improve the performance of machine learning models. It’s a critical step in building effective models."
  },
  {
    "objectID": "qmd/pandas3ed12.html#relationships-between-dm-ml-and-sl",
    "href": "qmd/pandas3ed12.html#relationships-between-dm-ml-and-sl",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Relationships between DM, ML and SL",
    "text": "Relationships between DM, ML and SL\nThe relationship between Data Mining, Machine Learning, and Statistical Learning can be represented with a Venn Diagram:\n\n\n\n\n\ngraph LR\n    A[Data Mining] --&gt; C(Common Ground)\n    B[Machine Learning] --&gt; C\n    D[Statistical Learning] --&gt; C\n    C --&gt; E[Insights & Predictions]\n\n\n\n\n\n\nAll three disciplines aim to extract insights and make predictions from data. Machine Learning and Statistical Learning often provide the tools and techniques used within the broader context of Data Mining."
  },
  {
    "objectID": "qmd/pandas3ed12.html#pythons-role-in-data-analysis",
    "href": "qmd/pandas3ed12.html#pythons-role-in-data-analysis",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Python’s Role in Data Analysis",
    "text": "Python’s Role in Data Analysis\nPython has become a dominant language for data analysis due to its:\n\nRich Ecosystem: Libraries like pandas (data manipulation), NumPy (numerical computation), statsmodels (statistical modeling), scikit-learn (machine learning), and Matplotlib/Seaborn (visualization) provide a comprehensive toolkit.\nEase of Use: Python’s clear syntax and interactive nature (e.g., using Jupyter Notebooks) make it relatively easy to learn and use, even for those without a strong programming background.\nCommunity Support: A large and active community contributes to the development of libraries, provides support, and creates extensive documentation."
  },
  {
    "objectID": "qmd/pandas3ed12.html#common-workflow",
    "href": "qmd/pandas3ed12.html#common-workflow",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Common Workflow",
    "text": "Common Workflow\nA typical workflow for model development in Python looks like this:\n\n\n\n\n\ngraph LR\n    A[Data Loading (pandas)] --&gt; B[Data Cleaning (pandas)]\n    B --&gt; C[Feature Engineering (pandas, other tools)]\n    C --&gt; D[Model Building (statsmodels, scikit-learn)]\n    D --&gt; E[Model Evaluation (statsmodels, scikit-learn)]\n    E --&gt; F[Prediction/Inference]\n\n\n\n\n\n\n\nData Loading: Use pandas to read data from various sources (CSV, Excel, databases, etc.).\nData Cleaning: Handle missing values, correct errors, and transform data into a suitable format using pandas.\nFeature Engineering: Create new features or transform existing ones to improve model performance.\nModel Building: Use libraries like statsmodels or scikit-learn to train a model on the prepared data.\nModel Evaluation: Assess the model’s performance using appropriate metrics and techniques.\nPrediction/Inference: Use the trained model to make predictions on new data or draw inferences about the underlying relationships."
  },
  {
    "objectID": "qmd/pandas3ed12.html#interfacing-between-pandas-and-model-code",
    "href": "qmd/pandas3ed12.html#interfacing-between-pandas-and-model-code",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Interfacing Between pandas and Model Code",
    "text": "Interfacing Between pandas and Model Code\nThe primary interface between pandas and modeling libraries is often NumPy arrays. pandas DataFrames are built on top of NumPy, making this conversion straightforward."
  },
  {
    "objectID": "qmd/pandas3ed12.html#dataframe-to-numpy-array",
    "href": "qmd/pandas3ed12.html#dataframe-to-numpy-array",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "DataFrame to NumPy Array",
    "text": "DataFrame to NumPy Array\nYou can easily convert a pandas DataFrame to a NumPy array using the .to_numpy() method.\n\nImportant: .to_numpy() is preferred over the older .values attribute for clarity and consistency.\n\nLet’s see an example:\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame({\n    'x0': [1, 2, 3, 4, 5],\n    'x1': [0.01, -0.01, 0.25, -4.1, 0.],\n    'y': [-1.5, 0., 3.6, 1.3, -2.]\n})\n\nprint(data)\ndata_array = data.to_numpy()\nprint(\"\\nNumPy Array:\")\nprint(data_array)\n\n   x0    x1    y\n0   1  0.01 -1.5\n1   2 -0.01  0.0\n2   3  0.25  3.6\n3   4 -4.10  1.3\n4   5  0.00 -2.0\n\nNumPy Array:\n[[ 1.    0.01 -1.5 ]\n [ 2.   -0.01  0.  ]\n [ 3.    0.25  3.6 ]\n [ 4.   -4.1   1.3 ]\n [ 5.    0.   -2.  ]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#numpy-array-to-dataframe",
    "href": "qmd/pandas3ed12.html#numpy-array-to-dataframe",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "NumPy Array to DataFrame",
    "text": "NumPy Array to DataFrame\nConversely, you can create a DataFrame from a NumPy array:\n\ndf2 = pd.DataFrame(data_array, columns=['one', 'two', 'three'])\nprint(df2)\n\n   one   two  three\n0  1.0  0.01   -1.5\n1  2.0 -0.01    0.0\n2  3.0  0.25    3.6\n3  4.0 -4.10    1.3\n4  5.0  0.00   -2.0\n\n\n\nNotice how we provided column names when creating the DataFrame from the array."
  },
  {
    "objectID": "qmd/pandas3ed12.html#homogeneous-vs.-heterogeneous-data",
    "href": "qmd/pandas3ed12.html#homogeneous-vs.-heterogeneous-data",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Homogeneous vs. Heterogeneous Data",
    "text": "Homogeneous vs. Heterogeneous Data\n\nHomogeneous Data: If your DataFrame contains data of the same type (e.g., all numbers), .to_numpy() will produce a NumPy array with that data type.\nHeterogeneous Data: If your DataFrame has mixed data types (e.g., numbers and strings), .to_numpy() will result in an array with a dtype=object. This means the array holds Python objects, which can be less efficient for numerical computations.\n\n\ndf3 = data.copy()\ndf3['strings'] = ['a', 'b', 'c', 'd', 'e']\nprint(df3)\n\nprint(\"\\nHeterogeneous array:\")\nprint(df3.to_numpy())\n\n   x0    x1    y strings\n0   1  0.01 -1.5       a\n1   2 -0.01  0.0       b\n2   3  0.25  3.6       c\n3   4 -4.10  1.3       d\n4   5  0.00 -2.0       e\n\nHeterogeneous array:\n[[1 0.01 -1.5 'a']\n [2 -0.01 0.0 'b']\n [3 0.25 3.6 'c']\n [4 -4.1 1.3 'd']\n [5 0.0 -2.0 'e']]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#selecting-subsets-of-columns",
    "href": "qmd/pandas3ed12.html#selecting-subsets-of-columns",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Selecting Subsets of Columns",
    "text": "Selecting Subsets of Columns\nFor modeling, you often work with a subset of columns. Use .loc for label-based indexing before converting to a NumPy array:\n\nmodel_cols = ['x0', 'x1']\nprint(data.loc[:, model_cols].to_numpy())\n\n[[ 1.    0.01]\n [ 2.   -0.01]\n [ 3.    0.25]\n [ 4.   -4.1 ]\n [ 5.    0.  ]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#categorical-data-and-dummy-variables",
    "href": "qmd/pandas3ed12.html#categorical-data-and-dummy-variables",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Categorical Data and Dummy Variables",
    "text": "Categorical Data and Dummy Variables\nCategorical variables (e.g., ‘male’, ‘female’) need to be converted into numerical representations for most machine learning models. One common approach is to create dummy variables (also known as one-hot encoding)."
  },
  {
    "objectID": "qmd/pandas3ed12.html#pandas-get_dummies",
    "href": "qmd/pandas3ed12.html#pandas-get_dummies",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "pandas get_dummies()",
    "text": "pandas get_dummies()\nThe pd.get_dummies() function simplifies creating dummy variables:\n\ndata['category'] = pd.Categorical(['a', 'b', 'a', 'a', 'b'], categories=['a', 'b'])\nprint(data)\n\ndummies = pd.get_dummies(data.category, prefix='category')\nprint(\"\\nDummy Variables:\")\nprint(dummies)\n\ndata_with_dummies = data.drop('category', axis=1).join(dummies)\nprint(\"\\nDataFrame with Dummy Variables:\")\nprint(data_with_dummies)\n\n   x0    x1    y category\n0   1  0.01 -1.5        a\n1   2 -0.01  0.0        b\n2   3  0.25  3.6        a\n3   4 -4.10  1.3        a\n4   5  0.00 -2.0        b\n\nDummy Variables:\n   category_a  category_b\n0        True       False\n1       False        True\n2        True       False\n3        True       False\n4       False        True\n\nDataFrame with Dummy Variables:\n   x0    x1    y  category_a  category_b\n0   1  0.01 -1.5        True       False\n1   2 -0.01  0.0       False        True\n2   3  0.25  3.6        True       False\n3   4 -4.10  1.3        True       False\n4   5  0.00 -2.0       False        True\n\n\n\nThe prefix argument adds a prefix to the dummy variable column names (e.g., category_a, category_b)."
  },
  {
    "objectID": "qmd/pandas3ed12.html#creating-model-descriptions-with-patsy",
    "href": "qmd/pandas3ed12.html#creating-model-descriptions-with-patsy",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Creating Model Descriptions with Patsy",
    "text": "Creating Model Descriptions with Patsy\nPatsy is a Python library that provides a convenient way to specify statistical models using a formula syntax, similar to R. It’s particularly useful for linear models. It is installed automatically with statsmodels. conda install statsmodels"
  },
  {
    "objectID": "qmd/pandas3ed12.html#patsy-formulas",
    "href": "qmd/pandas3ed12.html#patsy-formulas",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Patsy Formulas",
    "text": "Patsy Formulas\nPatsy formulas use a string-based syntax:\ny ~ x0 + x1\n\ny represents the dependent variable (response).\nx0 and x1 represent independent variables (predictors).\n~ separates the left-hand side (response) from the right-hand side (predictors).\n+ indicates including terms, not mathematical addition."
  },
  {
    "objectID": "qmd/pandas3ed12.html#patsy.dmatrices",
    "href": "qmd/pandas3ed12.html#patsy.dmatrices",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "patsy.dmatrices()",
    "text": "patsy.dmatrices()\nThe dmatrices() function takes a formula and a dataset (e.g., a DataFrame) and returns design matrices:\n\nimport patsy\n\ny, X = patsy.dmatrices('y ~ x0 + x1', data)\n\nprint(\"y (Design Matrix for Response):\")\nprint(y)\nprint(\"\\nX (Design Matrix for Predictors):\")\nprint(X)\n\ny (Design Matrix for Response):\n[[-1.5]\n [ 0. ]\n [ 3.6]\n [ 1.3]\n [-2. ]]\n\nX (Design Matrix for Predictors):\n[[ 1.    1.    0.01]\n [ 1.    2.   -0.01]\n [ 1.    3.    0.25]\n [ 1.    4.   -4.1 ]\n [ 1.    5.    0.  ]]\n\n\n\nBy default, Patsy includes an intercept term (a column of 1s). This represents the baseline value of the response variable when all predictors are zero."
  },
  {
    "objectID": "qmd/pandas3ed12.html#suppressing-the-intercept",
    "href": "qmd/pandas3ed12.html#suppressing-the-intercept",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Suppressing the Intercept",
    "text": "Suppressing the Intercept\nTo remove the intercept, add + 0 to the formula:\n\nX_no_intercept = patsy.dmatrices('y ~ x0 + x1 + 0', data)[1]  # [1] to get only the X matrix\nprint(X_no_intercept)\n\n[[ 1.    0.01]\n [ 2.   -0.01]\n [ 3.    0.25]\n [ 4.   -4.1 ]\n [ 5.    0.  ]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#using-patsy-with-numpy-and-statsmodels",
    "href": "qmd/pandas3ed12.html#using-patsy-with-numpy-and-statsmodels",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Using Patsy with NumPy and statsmodels",
    "text": "Using Patsy with NumPy and statsmodels\nThe design matrices created by Patsy can be used directly with NumPy functions (like np.linalg.lstsq for ordinary least squares regression) or with statsmodels.\n\nimport numpy as np\ncoef, resid, _, _ = np.linalg.lstsq(X, y, rcond=None) # Added rcond=None\nprint(coef)\n\n# Convert coefficients to a pandas Series with meaningful names:\ncoef = pd.Series(coef.squeeze(), index=X.design_info.column_names)\nprint(coef)\n\n[[ 0.31290976]\n [-0.07910564]\n [-0.26546384]]\nIntercept    0.312910\nx0          -0.079106\nx1          -0.265464\ndtype: float64"
  },
  {
    "objectID": "qmd/pandas3ed12.html#data-transformations-in-patsy-formulas",
    "href": "qmd/pandas3ed12.html#data-transformations-in-patsy-formulas",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Data Transformations in Patsy Formulas",
    "text": "Data Transformations in Patsy Formulas\nYou can incorporate Python code directly into Patsy formulas for data transformations:\n\ny, X = patsy.dmatrices('y ~ x0 + np.log(np.abs(x1) + 1)', data)\nprint(X)\n\n[[1.         1.         0.00995033]\n [1.         2.         0.00995033]\n [1.         3.         0.22314355]\n [1.         4.         1.62924054]\n [1.         5.         0.        ]]\n\n\nHere, we apply a log transformation to x1. Patsy will look for functions like np.log in the enclosing scope."
  },
  {
    "objectID": "qmd/pandas3ed12.html#built-in-transformations-standardize-and-center",
    "href": "qmd/pandas3ed12.html#built-in-transformations-standardize-and-center",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Built-in Transformations: standardize and center",
    "text": "Built-in Transformations: standardize and center\nPatsy provides built-in functions for common transformations:\n\nstandardize(x): Scales x to have mean 0 and standard deviation 1.\ncenter(x): Subtracts the mean of x from each value.\n\n\ny, X = patsy.dmatrices('y ~ standardize(x0) + center(x1)', data)\nprint(X)\n\n[[ 1.         -1.41421356  0.78      ]\n [ 1.         -0.70710678  0.76      ]\n [ 1.          0.          1.02      ]\n [ 1.          0.70710678 -3.33      ]\n [ 1.          1.41421356  0.77      ]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#stateful-transformations-and-build_design_matrices",
    "href": "qmd/pandas3ed12.html#stateful-transformations-and-build_design_matrices",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Stateful Transformations and build_design_matrices",
    "text": "Stateful Transformations and build_design_matrices\nWhen apply transformations, such as center and standardize, you should use the original dataset when transforming the new dataset. patsy.build_design_matrices function can achieve this.\n\nnew_data = pd.DataFrame({\n    'x0': [6, 7, 8, 9],\n    'x1': [3.1, -0.5, 0, 2.3],\n    'y' : [1, 2, 3, 4]\n})\n\nnew_X = patsy.build_design_matrices([X.design_info], new_data) # Use design_info from original X\nprint(new_X)\n\n[DesignMatrix with shape (4, 3)\n  Intercept  standardize(x0)  center(x1)\n          1          2.12132        3.87\n          1          2.82843        0.27\n          1          3.53553        0.77\n          1          4.24264        3.07\n  Terms:\n    'Intercept' (column 0)\n    'standardize(x0)' (column 1)\n    'center(x1)' (column 2)]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#adding-columns-by-name",
    "href": "qmd/pandas3ed12.html#adding-columns-by-name",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Adding Columns by Name",
    "text": "Adding Columns by Name\nTo add columns in the context of Patsy formulas, wrap them in the special I() function:\n\ny, X = patsy.dmatrices('y ~ I(x0 + x1)', data)\nprint(X)\n\n[[ 1.    1.01]\n [ 1.    1.99]\n [ 1.    3.25]\n [ 1.   -0.1 ]\n [ 1.    5.  ]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#categorical-data-and-patsy",
    "href": "qmd/pandas3ed12.html#categorical-data-and-patsy",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Categorical Data and Patsy",
    "text": "Categorical Data and Patsy\nPatsy handles categorical variables automatically by creating dummy variables.\n\ndata = pd.DataFrame({\n    'key1': ['a', 'a', 'b', 'b', 'a', 'b', 'a', 'b'],\n    'key2': [0, 1, 0, 1, 0, 1, 0, 0],\n    'v1': [1, 2, 3, 4, 5, 6, 7, 8],\n    'v2': [-1, 0, 2.5, -0.5, 4.0, -1.2, 0.2, -1.7]\n    })\n\ny, X = patsy.dmatrices('v2 ~ key1', data)\nprint(X)\n\n[[1. 0.]\n [1. 0.]\n [1. 1.]\n [1. 1.]\n [1. 0.]\n [1. 1.]\n [1. 0.]\n [1. 1.]]\n\n\n\nBy default, Patsy omits one level of the categorical variable to avoid collinearity (when there’s an intercept)."
  },
  {
    "objectID": "qmd/pandas3ed12.html#no-intercept-with-categorical-variables",
    "href": "qmd/pandas3ed12.html#no-intercept-with-categorical-variables",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "No Intercept with Categorical Variables",
    "text": "No Intercept with Categorical Variables\nIf you omit the intercept, then columns for each category value will be included in the model design matrix.\n\ny, X = patsy.dmatrices('v2 ~ key1 + 0', data)\nprint(X)\n\n[[1. 0.]\n [1. 0.]\n [0. 1.]\n [0. 1.]\n [1. 0.]\n [0. 1.]\n [1. 0.]\n [0. 1.]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#numerical-columns-as-categorical",
    "href": "qmd/pandas3ed12.html#numerical-columns-as-categorical",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Numerical Columns as Categorical",
    "text": "Numerical Columns as Categorical\nUse the C() function to treat numerical columns as categorical:\n\ny, X = patsy.dmatrices('v2 ~ C(key2)', data)\nprint(X)\n\n[[1. 0.]\n [1. 1.]\n [1. 0.]\n [1. 1.]\n [1. 0.]\n [1. 1.]\n [1. 0.]\n [1. 0.]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#interaction-terms",
    "href": "qmd/pandas3ed12.html#interaction-terms",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Interaction Terms",
    "text": "Interaction Terms\nInteraction terms model the combined effect of two or more variables. Use : to create interaction terms:\n\ndata['key2'] = data['key2'].map({0: 'zero', 1: 'one'})\nprint(data)\ny, X = patsy.dmatrices('v2 ~ key1 + key2 + key1:key2', data)\nprint(X)\n\n  key1  key2  v1   v2\n0    a  zero   1 -1.0\n1    a   one   2  0.0\n2    b  zero   3  2.5\n3    b   one   4 -0.5\n4    a  zero   5  4.0\n5    b   one   6 -1.2\n6    a  zero   7  0.2\n7    b  zero   8 -1.7\n[[1. 0. 1. 0.]\n [1. 0. 0. 0.]\n [1. 1. 1. 1.]\n [1. 1. 0. 0.]\n [1. 0. 1. 0.]\n [1. 1. 0. 0.]\n [1. 0. 1. 0.]\n [1. 1. 1. 1.]]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#introduction-to-statsmodels",
    "href": "qmd/pandas3ed12.html#introduction-to-statsmodels",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Introduction to statsmodels",
    "text": "Introduction to statsmodels\nstatsmodels is a Python library for statistical modeling, hypothesis testing, and data exploration. It complements scikit-learn by focusing on statistical inference rather than prediction."
  },
  {
    "objectID": "qmd/pandas3ed12.html#types-of-models-in-statsmodels",
    "href": "qmd/pandas3ed12.html#types-of-models-in-statsmodels",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Types of Models in statsmodels",
    "text": "Types of Models in statsmodels\nstatsmodels includes a wide range of models, including:\n\nLinear Models: Ordinary Least Squares (OLS), Generalized Least Squares (GLS), etc.\nGeneralized Linear Models (GLMs): For different types of response variables (e.g., binary, count data).\nTime Series Analysis: ARIMA models, Vector Autoregression (VAR), etc.\nAnd many more…"
  },
  {
    "objectID": "qmd/pandas3ed12.html#estimating-linear-models-with-statsmodels",
    "href": "qmd/pandas3ed12.html#estimating-linear-models-with-statsmodels",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Estimating Linear Models with statsmodels",
    "text": "Estimating Linear Models with statsmodels\nLet’s demonstrate how to fit a linear model using statsmodels. We’ll use both the array-based and formula-based APIs.\nFirst, let’s create sample data:\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# To make the example reproducible\nrng = np.random.default_rng(seed=12345)\n\ndef dnorm(mean, variance, size=1):\n    if isinstance(size, int):\n        size = size,\n    return mean + np.sqrt(variance) * rng.standard_normal(*size)\nN = 100\nX = np.c_[dnorm(0, 0.4, size=N),\n          dnorm(0, 0.6, size=N),\n          dnorm(0, 0.2, size=N)]\neps = dnorm(0, 0.1, size=N)\nbeta = [0.1, 0.3, 0.5]\ny = np.dot(X, beta) + eps"
  },
  {
    "objectID": "qmd/pandas3ed12.html#array-based-api",
    "href": "qmd/pandas3ed12.html#array-based-api",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Array-Based API",
    "text": "Array-Based API\n\nX_model = sm.add_constant(X) # Add an intercept\nmodel = sm.OLS(y, X_model) # Ordinary Least Squares\nresults = model.fit()\nprint(results.params) # Estimated parameters\nprint(results.summary()) # Detailed summary of results\n\n[-0.02079903  0.06581276  0.26897046  0.44941894]\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.470\nModel:                            OLS   Adj. R-squared:                  0.453\nMethod:                 Least Squares   F-statistic:                     28.36\nDate:                Tue, 18 Feb 2025   Prob (F-statistic):           3.23e-13\nTime:                        03:07:22   Log-Likelihood:                -25.390\nNo. Observations:                 100   AIC:                             58.78\nDf Residuals:                      96   BIC:                             69.20\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.0208      0.032     -0.653      0.516      -0.084       0.042\nx1             0.0658      0.054      1.220      0.226      -0.041       0.173\nx2             0.2690      0.043      6.312      0.000       0.184       0.354\nx3             0.4494      0.068      6.567      0.000       0.314       0.585\n==============================================================================\nOmnibus:                        0.429   Durbin-Watson:                   1.878\nProb(Omnibus):                  0.807   Jarque-Bera (JB):                0.296\nSkew:                           0.133   Prob(JB):                        0.863\nKurtosis:                       2.995   Cond. No.                         2.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nsm.add_constant(X) adds a column of 1s to the predictor matrix X to include an intercept term in the model."
  },
  {
    "objectID": "qmd/pandas3ed12.html#formula-based-api",
    "href": "qmd/pandas3ed12.html#formula-based-api",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Formula-Based API",
    "text": "Formula-Based API\n\ndata = pd.DataFrame(X, columns=['col0', 'col1', 'col2'])\ndata['y'] = y\nresults = smf.ols('y ~ col0 + col1 + col2', data=data).fit() # Formula API\nprint(results.params)\nprint(results.tvalues) # t-statistics for parameters\nprint(results.predict(data[:5]))\n\nIntercept   -0.020799\ncol0         0.065813\ncol1         0.268970\ncol2         0.449419\ndtype: float64\nIntercept   -0.652501\ncol0         1.219768\ncol1         6.312369\ncol2         6.567428\ndtype: float64\n0   -0.592959\n1   -0.531160\n2    0.058636\n3    0.283658\n4   -0.102947\ndtype: float64\n\n\n\nThe formula API automatically handles the intercept and works seamlessly with pandas DataFrames."
  },
  {
    "objectID": "qmd/pandas3ed12.html#estimating-time-series-processes",
    "href": "qmd/pandas3ed12.html#estimating-time-series-processes",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Estimating Time Series Processes",
    "text": "Estimating Time Series Processes\nstatsmodels also provides tools for time series analysis. Here’s an example of fitting an Autoregressive (AR) model:\n\nfrom statsmodels.tsa.ar_model import AutoReg\n\ninit_x = 4\nvalues = [init_x, init_x]\nN = 1000\nb0 = 0.8\nb1 = -0.4\nnoise = dnorm(0, 0.1, N)\nfor i in range(N):\n    new_x = values[-1] * b0 + values[-2] * b1 + noise[i]\n    values.append(new_x)\n\nMAXLAGS = 5\nmodel = AutoReg(values, MAXLAGS)\nresults = model.fit()\nprint(results.params)\n\n[ 0.02346612  0.8096828  -0.42865278 -0.03336517  0.04267874 -0.05671529]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#introduction-to-scikit-learn",
    "href": "qmd/pandas3ed12.html#introduction-to-scikit-learn",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Introduction to scikit-learn",
    "text": "Introduction to scikit-learn\nscikit-learn is a powerful and widely-used library for machine learning in Python. It offers a wide range of algorithms for classification, regression, clustering, dimensionality reduction, and more."
  },
  {
    "objectID": "qmd/pandas3ed12.html#key-features-of-scikit-learn",
    "href": "qmd/pandas3ed12.html#key-features-of-scikit-learn",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Key Features of scikit-learn",
    "text": "Key Features of scikit-learn\n\nSimple and Consistent API: scikit-learn provides a user-friendly and consistent API across different algorithms.\nWide Range of Algorithms: Covers many common machine learning tasks.\nModel Selection and Evaluation: Tools for cross-validation, hyperparameter tuning, and performance evaluation.\nData Preprocessing: Utilities for data scaling, feature selection, and more."
  },
  {
    "objectID": "qmd/pandas3ed12.html#titanic-survival-prediction-example",
    "href": "qmd/pandas3ed12.html#titanic-survival-prediction-example",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Titanic Survival Prediction Example",
    "text": "Titanic Survival Prediction Example\nLet’s use the classic Titanic dataset to illustrate a basic scikit-learn workflow.\n\ntrain = pd.read_csv('datasets/titanic/train.csv')\ntest = pd.read_csv('datasets/titanic/test.csv')\n\n\ntrain.head(4)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS"
  },
  {
    "objectID": "qmd/pandas3ed12.html#data-preprocessing",
    "href": "qmd/pandas3ed12.html#data-preprocessing",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\n\nprint(train.isna().sum())\nprint(test.isna().sum())\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\n\nWe can observe that there are many missing data.\n\nimpute_value = train['Age'].median()\ntrain['Age'] = train['Age'].fillna(impute_value)\ntest['Age'] = test['Age'].fillna(impute_value)\n\ntrain['IsFemale'] = (train['Sex'] == 'female').astype(int)\ntest['IsFemale'] = (test['Sex'] == 'female').astype(int)\n\npredictors = ['Pclass', 'IsFemale', 'Age']\nX_train = train[predictors].to_numpy()\nX_test = test[predictors].to_numpy()\ny_train = train['Survived'].to_numpy()\nprint(X_train[:5])\nprint(y_train[:5])\n\n[[ 3.  0. 22.]\n [ 1.  1. 38.]\n [ 3.  1. 26.]\n [ 1.  1. 35.]\n [ 3.  0. 35.]]\n[0 1 1 1 0]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#model-training-and-prediction",
    "href": "qmd/pandas3ed12.html#model-training-and-prediction",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Model Training and Prediction",
    "text": "Model Training and Prediction\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train) # Train the model\ny_predict = model.predict(X_test) # Make predictions\nprint(y_predict[:10])\n\n[0 0 0 0 1 0 1 0 1 0]"
  },
  {
    "objectID": "qmd/pandas3ed12.html#cross-validation",
    "href": "qmd/pandas3ed12.html#cross-validation",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Cross-Validation",
    "text": "Cross-Validation\n\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import cross_val_score\n\nmodel_cv = LogisticRegressionCV(Cs=10) # Logistic Regression with cross-validation\nmodel_cv.fit(X_train, y_train)\nmodel = LogisticRegression(C=10)\nscores = cross_val_score(model, X_train, y_train, cv=4) # 4-fold cross-validation\nprint(scores)\n\n[0.77578475 0.79820628 0.77578475 0.78828829]\n\n\nCross-validation helps to avoid overfitting and obtain more robust model."
  },
  {
    "objectID": "qmd/pandas3ed12.html#summary",
    "href": "qmd/pandas3ed12.html#summary",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Summary",
    "text": "Summary\n\nWe’ve explored how to bridge the gap between data wrangling with pandas and model building with statsmodels and scikit-learn.\nThe key is often converting pandas DataFrames to NumPy arrays using .to_numpy().\nPatsy provides a powerful formula syntax for specifying statistical models.\nstatsmodels excels at statistical inference and hypothesis testing.\nscikit-learn is a versatile library for a wide range of machine learning tasks."
  },
  {
    "objectID": "qmd/pandas3ed12.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed12.html#thoughts-and-discussion",
    "title": "Introduction to Modeling Libraries in Python",
    "section": "Thoughts and Discussion",
    "text": "Thoughts and Discussion\n\nHow might you choose between statsmodels and scikit-learn for a particular project? Consider the goals of your analysis (inference vs. prediction).\nFeature engineering is often the most critical step in building effective models. What are some ways you could improve the features used in the Titanic example?\nWhat are some other modeling libraries or frameworks in Python that you’re interested in exploring? (e.g., TensorFlow, PyTorch, XGBoost)\nHow does the material covered in this chapter relate to your own projects or research interests?\nHow do you think the field of data analysis and modeling will evolve in the coming years?"
  },
  {
    "objectID": "qmd/pandas3ed13.html",
    "href": "qmd/pandas3ed13.html",
    "title": "",
    "section": "",
    "text": "---\ntitle: \"Python for Data Analysis: Data Analysis Examples\"\nauthor: \"[Your Name]\"\nformat:\n  revealjs:\n    theme: sky\n    slide-number: true\n    show-slide-number: all\n    preview-links: true\n    \n---\n\n## Introduction: Chapter 13 - Data Analysis Examples\n\n::: {layout-ncol=2}\n![](chapter13_introduction.png)\n\n-   We've reached the final chapter! 🥳\n-   Focus: Applying data analysis techniques to real-world datasets.\n-   Goal: Extract meaningful insights from raw data.\n-   The techniques demonstrated are widely applicable.\n-   Datasets are available in the book's GitHub/Gitee repository.\n:::\n\n## Data Mining, Machine Learning, and Statistical Learning\n\n::: {layout-ncol=2}\n- Data mining, machine learning, and statistical learning share a common goal: to extract valuable insights and make predictions from data.\n\n- The core of difference is the means to achieve the common goal.\n\n```{mermaid}\ngraph LR\n    A[Data Mining] --&gt; C(Common Ground)\n    B[Machine Learning] --&gt; C\n    D[Statistical Learning] --&gt; C\n    C --&gt; E[Insights & Predictions]\n:::"
  },
  {
    "objectID": "qmd/pandas3ed13.html#data-mining",
    "href": "qmd/pandas3ed13.html#data-mining",
    "title": "",
    "section": "Data Mining",
    "text": "Data Mining\n\n\n\n\n\n\n\nDefinition: The process of discovering patterns, anomalies, and relationships in large datasets to predict outcomes.\nFocus: Discovering previously unknown patterns. It’s about exploration and finding something new.\nTechniques: Often uses a combination of methods from machine learning, statistics, and database systems.\nExample: A supermarket analyzing purchase data to discover that customers who buy diapers often also buy beer. This is an unexpected association."
  },
  {
    "objectID": "qmd/pandas3ed13.html#machine-learning",
    "href": "qmd/pandas3ed13.html#machine-learning",
    "title": "",
    "section": "Machine Learning",
    "text": "Machine Learning\n\n\n\n\n\n\n\nDefinition: The study of computer algorithms that improve automatically through experience (data). Focuses on prediction and decision making.\nFocus: Building systems that can learn from and make decisions or predictions based on data, without explicit rules.\nTypes:\n\nSupervised Learning: Training a model on a labeled dataset (e.g., classifying emails as spam or not spam).\nUnsupervised Learning: Discovering hidden structures in unlabeled data (e.g., customer segmentation).\nReinforcement Learning: Training agents to make a sequence of decisions by interacting with an environment (e.g., training a robot to walk).\n\nExample: Training a model to predict house prices based on features like size, location, and number of bedrooms. The algorithm learns the relationship between features and price."
  },
  {
    "objectID": "qmd/pandas3ed13.html#statistical-learning",
    "href": "qmd/pandas3ed13.html#statistical-learning",
    "title": "",
    "section": "Statistical Learning",
    "text": "Statistical Learning\n\n\n\n\n\n\n\nDefinition: A set of tools for modeling and understanding complex datasets. It’s a framework for applying statistical methods to learn from data.\nFocus: Emphasis on models and their interpretability, as well as precision and uncertainty. It bridges the gap between statistics and machine learning.\nKey Concepts:\n\nBias-Variance Tradeoff: Balancing the error introduced by approximating a real-world problem (bias) with the error introduced by the model’s sensitivity to the training data (variance).\nModel Selection: Choosing the best model from a set of candidate models.\nRegularization: Techniques to prevent overfitting by adding a penalty for complexity.\n\nExample: Using linear regression to understand the relationship between advertising spending and sales, including confidence intervals for the coefficients."
  },
  {
    "objectID": "qmd/pandas3ed13.html#bitly-data-from-1.usa.gov",
    "href": "qmd/pandas3ed13.html#bitly-data-from-1.usa.gov",
    "title": "",
    "section": "13.1 Bitly Data from 1.USA.gov",
    "text": "13.1 Bitly Data from 1.USA.gov\n\n\n\n\n\n\n\nBackground:\n\nIn 2011, Bitly (URL shortening service) partnered with USA.gov.\nProvided anonymized data from users shortening links ending in .gov or .mil.\nData was available as hourly snapshots (text files).\nService is now discontinued, but the data is preserved for analysis.\n\nData Format:\n\nEach line in the file is a JSON (JavaScript Object Notation) object.\nJSON is a human-readable text format for representing data."
  },
  {
    "objectID": "qmd/pandas3ed13.html#json-data-example",
    "href": "qmd/pandas3ed13.html#json-data-example",
    "title": "",
    "section": "JSON Data Example",
    "text": "JSON Data Example\n{ \"a\": \"Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11 (KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11\", \"c\": \"US\", \"nk\": 1, \"tz\": \"America\\/New_York\", \"gr\": \"MA\", \"g\": \"A6q0VH\", \"h\": \"wfLQtf\", \"l\": \"orofrog\", \"al\": \"en-US,en;q=0.8\", \"hh\": \"1.usa.gov\", \"r\": \"http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf\", \"u\": \"http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991\", \"t\": 1331923247, \"hc\": 1331822918, \"cy\": \"Danvers\", \"ll\": [ 42.576698, -70.954903 ] }\n\nStructure: JSON objects are enclosed in curly braces {}.\nKey-Value Pairs: Data is stored as key-value pairs (e.g., \"a\": \"Mozilla/...\").\nData Types: Values can be strings, numbers, arrays (like \"ll\"), or other JSON objects.\nPython and JSON: Python has built-in libraries like json which easily converts JSON string into Python Dictionary."
  },
  {
    "objectID": "qmd/pandas3ed13.html#reading-json-data-in-python",
    "href": "qmd/pandas3ed13.html#reading-json-data-in-python",
    "title": "",
    "section": "Reading JSON Data in Python",
    "text": "Reading JSON Data in Python\nimport json\n\npath = \"datasets/bitly_usagov/example.txt\"\n\nwith open(path) as f:\n    records = [json.loads(line) for line in f]  # List comprehension\n\nprint(records[0]) # Print the first record\n\nimport json: Imports the necessary JSON library.\nopen(path): Opens the file.\njson.loads(line): Parses a single line of JSON text into a Python dictionary.\nList Comprehension: [... for line in f] efficiently creates a list of dictionaries, one for each line in the file.\nrecords: Now holds a list of Python dictionaries, each representing a record from the dataset."
  },
  {
    "objectID": "qmd/pandas3ed13.html#accessing-data-in-the-dictionary",
    "href": "qmd/pandas3ed13.html#accessing-data-in-the-dictionary",
    "title": "",
    "section": "Accessing Data in the Dictionary",
    "text": "Accessing Data in the Dictionary\nprint(records[0]['tz'])  # Accessing the 'tz' (time zone) field of the first record\n\nAfter loading the JSON data, you can access individual fields within each record using standard dictionary key access (square brackets).\nrecords[0] gets the first dictionary in the list.\n['tz'] accesses the value associated with the key “tz”."
  },
  {
    "objectID": "qmd/pandas3ed13.html#counting-time-zones-pure-python",
    "href": "qmd/pandas3ed13.html#counting-time-zones-pure-python",
    "title": "",
    "section": "Counting Time Zones (Pure Python)",
    "text": "Counting Time Zones (Pure Python)\n\nObjective: Determine the most frequent time zones in the dataset (the tz field).\nApproach 1: Using a Dictionary and Loop\nApproach 2： Using defaultdict\n\nfrom collections import defaultdict\n\ndef get_counts2(sequence):\n    counts = defaultdict(int)  # Values will initialize to 0\n    for x in sequence:\n        counts[x] += 1\n    return counts\n\ndefaultdict(int): Creates a dictionary where, if a key is not found, it’s automatically added with a default value of 0 (provided by int()). This avoids the if x in counts check."
  },
  {
    "objectID": "qmd/pandas3ed13.html#counting-time-zones-pure-python---continued",
    "href": "qmd/pandas3ed13.html#counting-time-zones-pure-python---continued",
    "title": "",
    "section": "Counting Time Zones (Pure Python) - continued",
    "text": "Counting Time Zones (Pure Python) - continued\n\nKey Error Explanation: If the data does not contain the 'tz' key, a KeyError will be raised, as shown on the slide.\n\n#Initial Code (causes KeyError)\n# time_zones = [rec[\"tz\"] for rec in records]\n\n#Corrected with if condition\ntime_zones = [rec[\"tz\"] for rec in records if \"tz\" in rec]\nprint(time_zones[:10])\n\nThe corrected code adds an if \"tz\" in rec condition to the list comprehension. This ensures that we only try to access the tz key if it actually exists in the record. This prevents the KeyError."
  },
  {
    "objectID": "qmd/pandas3ed13.html#counting-time-zones-pure-python---continued-1",
    "href": "qmd/pandas3ed13.html#counting-time-zones-pure-python---continued-1",
    "title": "",
    "section": "Counting Time Zones (Pure Python) - continued",
    "text": "Counting Time Zones (Pure Python) - continued\n\nTop 10 Time Zones:\n\ndef top_counts(count_dict, n=10):\n    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]\n    value_key_pairs.sort()\n    return value_key_pairs[-n:]\n\n#OR Using the Counter Class\nfrom collections import Counter\ncounts = Counter(time_zones)\nprint(counts.most_common(10))\n\ntop_counts function: A custom function to get the top n most frequent items. It sorts the (count, item) pairs.\nCounter class: A more efficient and Pythonic way to count items. most_common(10) directly returns the top 10."
  },
  {
    "objectID": "qmd/pandas3ed13.html#counting-time-zones-pandas",
    "href": "qmd/pandas3ed13.html#counting-time-zones-pandas",
    "title": "",
    "section": "Counting Time Zones (pandas)",
    "text": "Counting Time Zones (pandas)\n\npandas DataFrame: A much more powerful and convenient way to work with tabular data.\n\nimport pandas as pd\n\nframe = pd.DataFrame(records)  # Create a DataFrame from the list of dictionaries\nprint(frame.info()) # Summary information about DataFrame\n\npd.DataFrame(records): Converts the list of dictionaries (records) into a pandas DataFrame. pandas automatically infers column names and data types.\nframe.info(): Provides a concise summary of the DataFrame, including:\n\nNumber of rows and columns.\nColumn names and data types.\nNon-null value counts (shows missing data).\nMemory usage."
  },
  {
    "objectID": "qmd/pandas3ed13.html#frame.info-output-explained",
    "href": "qmd/pandas3ed13.html#frame.info-output-explained",
    "title": "",
    "section": "frame.info() Output Explained",
    "text": "frame.info() Output Explained\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3560 entries, 0 to 3559\nData columns (total 18 columns):\n #   Column       Non-Null Count  Dtype\n---  ------       --------------  -----\n 0   a            3440 non-null   object\n 1   c            2919 non-null   object\n ...\n 16  _heartbeat_  120 non-null    float64\n 17  kw           93 non-null     object\ndtypes: float64(4), object(14)\nmemory usage: 500.8+ KB\n\nRangeIndex: Shows the total number of rows (3560) and their index range (0 to 3559).\nData columns: Lists each column, its non-null count, and data type.\n\nobject: Usually means text (strings).\nfloat64: Floating-point numbers.\nint64: Integer numbers.\n\nNon-Null Count: Highlights missing values. For example, the c column has only 2919 non-null values, meaning 3560 - 2919 = 641 values are missing.\ndtypes and memory usage: Summary information."
  },
  {
    "objectID": "qmd/pandas3ed13.html#working-with-time-zones-in-pandas",
    "href": "qmd/pandas3ed13.html#working-with-time-zones-in-pandas",
    "title": "",
    "section": "Working with Time Zones in pandas",
    "text": "Working with Time Zones in pandas\nprint(frame['tz'].head())  # Display the first few time zones\n\ntz_counts = frame['tz'].value_counts()  # Count occurrences of each time zone\nprint(tz_counts.head())\n\n# Handling Missing Data\nclean_tz = frame['tz'].fillna('Missing')  # Replace NaN values with \"Missing\"\nclean_tz[clean_tz == ''] = 'Unknown'      # Replace empty strings with \"Unknown\"\ntz_counts = clean_tz.value_counts()\nprint(tz_counts.head())\n\nframe['tz']: Selects the ‘tz’ column (a pandas Series).\n.head(): Shows the first 5 rows (by default).\n.value_counts(): Calculates the number of occurrences of each unique value in the Series. This is a much easier way to count time zones than the pure Python methods.\n.fillna('Missing'): Replaces missing values (represented as NaN in pandas) with the string “Missing”.\nclean_tz[clean_tz == ''] = 'Unknown': Replaces empty strings (which represent unknown time zones) with “Unknown”. This is boolean indexing."
  },
  {
    "objectID": "qmd/pandas3ed13.html#visualization-with-seaborn",
    "href": "qmd/pandas3ed13.html#visualization-with-seaborn",
    "title": "",
    "section": "Visualization with seaborn",
    "text": "Visualization with seaborn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsubset = tz_counts.head()\nsns.barplot(y=subset.index, x=subset.to_numpy())\nplt.show() # Display the plot\n\n\n\n\n\n\n\nimport seaborn as sns: Imports the seaborn library, which is built on top of matplotlib and provides a higher-level interface for creating attractive statistical graphics.\nsubset = tz_counts.head(): use the top few time zones for clearer visualization.\nsns.barplot(y=subset.index, x=subset.to_numpy()): Creates a horizontal bar plot.\n\ny=subset.index: Sets the time zone names (the index of the tz_counts Series) as the y-axis labels.\nx=subset.to_numpy(): Sets the counts as the x-axis values. Convert subset Series to numpy array.\n\nplt.show(): Displays the plot. Without this, the plot might not be shown.\n\n\n\n\n\n\n‘Top time zones in the 1.usa.gov sample data’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#analyzing-browseragent-information",
    "href": "qmd/pandas3ed13.html#analyzing-browseragent-information",
    "title": "",
    "section": "Analyzing Browser/Agent Information",
    "text": "Analyzing Browser/Agent Information\nprint(frame['a'][1])\nprint(frame['a'][50])\nprint(frame['a'][51][:50])  # Show first 50 characters\n\nresults = pd.Series([x.split()[0] for x in frame['a'].dropna()])\nprint(results.head())\nprint(results.value_counts().head(8))\n\nThe a field contains information about the user’s browser, device, or application.\nframe['a'][1] ,etc.: Access and print specific agent strings.\n.dropna(): Removes rows where the ‘a’ value is missing (NaN) before splitting.\nx.split()[0]: Splits the agent string by spaces and takes the first element. This usually gives you the main browser identifier (e.g., “Mozilla/5.0”, “GoogleMaps/RochesterNY”).\npd.Series(...): Creates a pandas Series from the list of split agent strings.\nresults.value_counts().head(8): Counts the occurrences of each unique browser identifier and shows the top 8."
  },
  {
    "objectID": "qmd/pandas3ed13.html#windows-vs.-non-windows-users",
    "href": "qmd/pandas3ed13.html#windows-vs.-non-windows-users",
    "title": "",
    "section": "Windows vs. Non-Windows Users",
    "text": "Windows vs. Non-Windows Users\nimport numpy as np\n\ncframe = frame[frame['a'].notna()].copy()  # Create a copy to avoid warnings\ncframe['os'] = np.where(cframe['a'].str.contains('Windows'), 'Windows', 'Not Windows')\nprint(cframe['os'].head())\n\nby_tz_os = cframe.groupby(['tz', 'os'])\nagg_counts = by_tz_os.size().unstack().fillna(0) # Group, count, reshape, and fill missing values\nprint(agg_counts.head())\n\nGoal: Analyze time zone data separately for Windows and non-Windows users.\ncframe = frame[frame['a'].notna()].copy(): Creates a copy of the DataFrame, filtering out rows where the ‘a’ field is missing. Using .copy() avoids a SettingWithCopyWarning that pandas might raise.\ncframe['a'].str.contains('Windows'): Checks if the agent string contains “Windows” (case-sensitive). Returns a boolean Series.\nnp.where(...): A vectorized way to create a new ‘os’ column based on the condition. If the agent string contains “Windows”, the ‘os’ value is “Windows”; otherwise, it’s “Not Windows”.\ncframe.groupby(['tz', 'os']): Groups the data by time zone and operating system.\n.size(): Counts the number of records in each group (similar to value_counts(), but for grouped data).\n.unstack(): Reshapes the data. It pivots the ‘os’ level from the index to become columns, making it easier to compare Windows and Not Windows counts for each time zone.\n.fillna(0): Replaces any missing values (which would occur if a time zone had only Windows or only Not Windows users) with 0."
  },
  {
    "objectID": "qmd/pandas3ed13.html#finding-the-most-popular-time-zones",
    "href": "qmd/pandas3ed13.html#finding-the-most-popular-time-zones",
    "title": "",
    "section": "Finding the Most Popular Time Zones",
    "text": "Finding the Most Popular Time Zones\n# Method 1: Using argsort\nindexer = agg_counts.sum(axis=\"columns\").argsort()\nprint(indexer.values[:10])\ncount_subset = agg_counts.take(indexer[-10:])\nprint(count_subset)\n\n# Method 2: Using nlargest (more convenient)\nprint(agg_counts.sum(axis=\"columns\").nlargest(10))\n\nGoal: Identify the time zones with the highest overall counts (combining Windows and Not Windows).\nagg_counts.sum(axis=\"columns\"): Calculates the total count for each time zone (summing across the ‘Windows’ and ‘Not Windows’ columns).\nargsort(): Returns the indices that would sort the array. indexer now holds the indices of time zones, from least frequent to most frequent.\n.take(indexer[-10:]): Selects the rows corresponding to the top 10 time zones (the last 10 indices in indexer).\nnlargest(10): A more direct way to get the top 10 time zones. It returns a Series with the time zones and their counts."
  },
  {
    "objectID": "qmd/pandas3ed13.html#visualizing-windows-and-non-windows-users",
    "href": "qmd/pandas3ed13.html#visualizing-windows-and-non-windows-users",
    "title": "",
    "section": "Visualizing Windows and Non-Windows Users",
    "text": "Visualizing Windows and Non-Windows Users\n# Prepare data for plotting\ncount_subset = count_subset.stack()\ncount_subset.name = 'total'\ncount_subset = count_subset.reset_index()\nprint(count_subset.head())\nsns.barplot(x='total', y='tz', hue='os', data=count_subset)\nplt.show()\n\n\n\n\n\n\n\ncount_subset.stack(): Pivots the ‘os’ column back into the index, creating a multi-level index (tz, os). This is the opposite of unstack(). It’s a common preparation step for seaborn plotting.\ncount_subset.name = 'total': Assigns the name “total” to the Series values (the counts).\ncount_subset.reset_index(): Converts the multi-level index (‘tz’, ‘os’) into regular columns. This makes the data suitable for seaborn’s barplot.\nsns.barplot(x='total', y='tz', hue='os', data=count_subset): Creates a grouped bar plot.\n\nx='total': The ‘total’ column (counts) is used for the x-axis.\ny='tz': The ‘tz’ column (time zone names) is used for the y-axis.\nhue='os': The ‘os’ column is used to color the bars (creating separate bars for Windows and Not Windows).\ndata=count_subset: Specifies the DataFrame to use.\n\n\n\n\n\n\n\n‘Top time zones by Windows and non-Windows users’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#normalizing-counts",
    "href": "qmd/pandas3ed13.html#normalizing-counts",
    "title": "",
    "section": "Normalizing Counts",
    "text": "Normalizing Counts\ndef norm_total(group):\n    group['normed_total'] = group['total'] / group['total'].sum()\n    return group\n\nresults = count_subset.groupby('tz').apply(norm_total)\nsns.barplot(x='normed_total', y='tz', hue='os', data=results)\nplt.show()\n\n\n\n\n\n\n\nGoal: Compare the proportion of Windows and non-Windows users within each time zone, rather than the raw counts.\nnorm_total(group) function:\n\nTakes a group (DataFrame) as input.\nCalculates normed_total: the count for each OS within the time zone, divided by the total count for that time zone. This gives the proportion.\nReturns the modified group.\n\ncount_subset.groupby('tz').apply(norm_total): Applies the norm_total function to each time zone group.\nsns.barplot(...): Creates a bar plot, similar to before, but now using ‘normed_total’ to show proportions. This makes it easier to compare the relative prevalence of Windows and non-Windows users in different time zones.\n\n\n\n\n\n\n‘Percentage Windows and non-Windows users in top occurring time zones’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#movielens-1m-dataset",
    "href": "qmd/pandas3ed13.html#movielens-1m-dataset",
    "title": "",
    "section": "13.2 MovieLens 1M Dataset",
    "text": "13.2 MovieLens 1M Dataset\n\n\n\n\n\n\n\nDataset: MovieLens 1M, collected by GroupLens Research.\nContents:\n\n1 million movie ratings.\n~6,000 users.\n~4,000 movies.\n\nData Format: Three tables:\n\nusers: User demographics (age, gender, occupation, zip code).\nratings: User ID, movie ID, rating, timestamp.\nmovies: Movie title, genres.\n\nGoal: Explore relationships between ratings, demographics, and movie genres.\nLoading Data:\n\n\n\nimport pandas as pd\nunames = ['user_id', 'gender', 'age', 'occupation', 'zip']\nusers = pd.read_table('datasets/movielens/users.dat', sep='::',\n                      header=None, names=unames, engine='python')\nrnames = ['user_id', 'movie_id', 'rating', 'timestamp']\nratings = pd.read_table('datasets/movielens/ratings.dat', sep='::',\n                        header=None, names=rnames, engine='python')\n\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('datasets/movielens/movies.dat', sep='::',\n                       header=None, names=mnames, engine='python')\n\n\n\n\n\nKey Arguments of pd.read_table:\n\nsep='::': The separator between fields is two colons, and the default separator is a comma.\nheader=None: The data files don’t have header rows, so we specify None.\nnames=unames (etc.): We provide the column names.\nengine='python': Use the python parsing engine, because the default C parsing engine does not support multi-character separators."
  },
  {
    "objectID": "qmd/pandas3ed13.html#merging-the-data",
    "href": "qmd/pandas3ed13.html#merging-the-data",
    "title": "",
    "section": "Merging the Data",
    "text": "Merging the Data\ndata = pd.merge(pd.merge(ratings, users), movies)\nprint(data.head())\nprint(data.iloc[0])  # Access the first row using iloc\n\npd.merge(): Combines DataFrames based on common columns. pandas automatically finds the common columns (e.g., ‘user_id’, ‘movie_id’).\nTwo Merges:\n\npd.merge(ratings, users): Merges ratings and users based on user_id.\npd.merge(..., movies): Merges the result with movies based on movie_id.\n\ndata: Now contains all the information in a single DataFrame.\ndata.iloc[0]: show the first record in the combined data."
  },
  {
    "objectID": "qmd/pandas3ed13.html#analyzing-ratings-by-gender",
    "href": "qmd/pandas3ed13.html#analyzing-ratings-by-gender",
    "title": "",
    "section": "Analyzing Ratings by Gender",
    "text": "Analyzing Ratings by Gender\nmean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')\nprint(mean_ratings.head())\n\ndata.pivot_table(...): A powerful way to reshape and aggregate data.\n\n'rating': The values to aggregate (we want the average rating).\nindex='title': The movie title will be the row index.\ncolumns='gender': Gender (‘M’ and ‘F’) will be the columns.\naggfunc='mean' (default): Calculates the mean rating for each title/gender combination."
  },
  {
    "objectID": "qmd/pandas3ed13.html#filtering-by-number-of-ratings",
    "href": "qmd/pandas3ed13.html#filtering-by-number-of-ratings",
    "title": "",
    "section": "Filtering by Number of Ratings",
    "text": "Filtering by Number of Ratings\nratings_by_title = data.groupby('title').size()\nprint(ratings_by_title.head())\nactive_titles = ratings_by_title.index[ratings_by_title &gt;= 250]\nprint(active_titles)\n\nmean_ratings = mean_ratings.loc[active_titles]\nprint(mean_ratings)\n\nGoal: Focus on movies with a sufficient number of ratings.\ndata.groupby('title').size(): Counts the number of ratings for each movie title. .size() is used for grouped data (similar to value_counts() for Series).\nactive_titles = ...: Creates a list of movie titles that have at least 250 ratings (an arbitrary threshold).\nmean_ratings.loc[active_titles]: Filters the mean_ratings DataFrame to include only the movies in active_titles. This focuses the analysis on movies with more substantial rating data."
  },
  {
    "objectID": "qmd/pandas3ed13.html#sorting-and-finding-top-films",
    "href": "qmd/pandas3ed13.html#sorting-and-finding-top-films",
    "title": "",
    "section": "Sorting and Finding Top Films",
    "text": "Sorting and Finding Top Films\ntop_female_ratings = mean_ratings.sort_values(\"F\", ascending=False)\nprint(top_female_ratings.head())\n\nmean_ratings.sort_values(\"F\", ascending=False): Sorts the mean_ratings DataFrame by the ‘F’ (female) column in descending order. This puts the movies with the highest average female ratings at the top."
  },
  {
    "objectID": "qmd/pandas3ed13.html#measuring-rating-disagreement",
    "href": "qmd/pandas3ed13.html#measuring-rating-disagreement",
    "title": "",
    "section": "Measuring Rating Disagreement",
    "text": "Measuring Rating Disagreement\nmean_ratings['diff'] = mean_ratings['M'] - mean_ratings['F']\nsorted_by_diff = mean_ratings.sort_values('diff')\nprint(sorted_by_diff.head())  # Movies preferred by women\nprint(sorted_by_diff[::-1].head())  # Movies preferred by men\n\n# Standard deviation of rating, grouped by title\nrating_std_by_title = data.groupby('title')['rating'].std()\n# Filter down to active_titles\nrating_std_by_title = rating_std_by_title.loc[active_titles]\n# Order Series by value in descending order\nprint(rating_std_by_title.sort_values(ascending=False)[:10])\n\nmean_ratings['diff'] = ...: Creates a new column ‘diff’ that stores the difference between the average male rating and the average female rating.\nsorted_by_diff = ...: Sorts the DataFrame by the ‘diff’ column.\n\nsorted_by_diff.head(): Shows movies where women rated significantly higher than men.\nsorted_by_diff[::-1].head(): Reverses the order ([::-1]) and shows movies where men rated significantly higher than women.\n\nThe standard deviation is another disagreement."
  },
  {
    "objectID": "qmd/pandas3ed13.html#handling-movie-genres",
    "href": "qmd/pandas3ed13.html#handling-movie-genres",
    "title": "",
    "section": "Handling Movie Genres",
    "text": "Handling Movie Genres\n# Original genres format: \"Animation|Children's|Comedy\"\nmovies['genre'] = movies.pop('genres').str.split('|')\nprint(movies.head())\nmovies_exploded = movies.explode('genre')\nprint(movies_exploded[:10])\n\nProblem: Movie genres are stored as pipe-separated strings (e.g., “Action|Adventure|Thriller”). This is difficult to analyze directly.\nmovies['genres'].str.split('|'): Splits the ‘genres’ string by the ‘|’ character, creating a list of genres for each movie.\n.pop('genres'): Removes the original ‘genres’ column and returns it. This is done to replace the original column with the new list-based one.\nmovies.explode('genre'): Transforms the DataFrame so that each movie-genre combination gets its own row. This is crucial for analyzing ratings by genre. For example, if a movie is both “Action” and “Comedy”, it will now have two rows in movies_exploded."
  },
  {
    "objectID": "qmd/pandas3ed13.html#combining-all-data-and-grouping-by-genre",
    "href": "qmd/pandas3ed13.html#combining-all-data-and-grouping-by-genre",
    "title": "",
    "section": "Combining All Data and Grouping by Genre",
    "text": "Combining All Data and Grouping by Genre\nratings_with_genre = pd.merge(pd.merge(movies_exploded, ratings), users)\nprint(ratings_with_genre.iloc[0])\n\ngenre_ratings = (ratings_with_genre.groupby(['genre', 'age'])\n                 ['rating'].mean()\n                 .unstack('age'))\nprint(genre_ratings[:10])\n\nratings_with_genre = ...: Merges all three tables (movies_exploded, ratings, and users) to create a single DataFrame where each row represents a single rating, along with user demographics and the individual genre.\nratings_with_genre.iloc[0]: Displays the first row of this combined DataFrame.\ngenre_ratings = ...: Calculates the average rating for each genre/age group combination.\n\ngroupby(['genre', 'age']): Groups by genre and age.\n['rating'].mean(): Calculates the mean rating for each group.\n.unstack('age'): Pivots the ‘age’ level from the index to become columns, making it easy to compare ratings across age groups for each genre."
  },
  {
    "objectID": "qmd/pandas3ed13.html#us-baby-names-18802010",
    "href": "qmd/pandas3ed13.html#us-baby-names-18802010",
    "title": "",
    "section": "13.3 US Baby Names 1880–2010",
    "text": "13.3 US Baby Names 1880–2010\n\n\n\n\n\n\n\nDataset: US Social Security Administration (SSA) baby name data.\nTime Period: 1880-2010.\nData Format: One file per year, each containing:\n\nName\nSex\nNumber of births\n\nExample File (yob1880.txt):\nMary,F,7065\nAnna,F,2604\n...\nPotential Analyses:\n\nName popularity trends over time.\nRelative rank of names.\nChanges in naming diversity.\nAnalysis of first/last letters, vowel/consonant usage."
  },
  {
    "objectID": "qmd/pandas3ed13.html#loading-and-combining-the-data",
    "href": "qmd/pandas3ed13.html#loading-and-combining-the-data",
    "title": "",
    "section": "Loading and Combining the Data",
    "text": "Loading and Combining the Data\nimport pandas as pd\n\n# Load a single year (for demonstration)\nnames1880 = pd.read_csv('datasets/babynames/yob1880.txt',\n                        names=['name', 'sex', 'births'])\nprint(names1880)\nprint(names1880.groupby('sex')['births'].sum())\n\n# Load all years and combine into a single DataFrame\nyears = range(1880, 2011)\npieces = []\nfor year in years:\n    path = f'datasets/babynames/yob{year}.txt'\n    frame = pd.read_csv(path, names=['name', 'sex', 'births'])\n    frame['year'] = year  # Add a 'year' column\n    pieces.append(frame)\n\nnames = pd.concat(pieces, ignore_index=True)\nprint(names)\n\nnames1880 = pd.read_csv(...): Loads a single year’s data into a DataFrame. names argument assigns column titles.\nnames1880.groupby('sex')['births'].sum(): Calculates the total births for each sex in 1880.\nLooping through years:\n\nrange(1880, 2011): Iterates through the years.\nf'datasets/babynames/yob{year}.txt': Uses an f-string to construct the file path for each year.\nframe['year'] = year: Adds a ‘year’ column to each year’s DataFrame.\npieces.append(frame): Adds each year’s DataFrame to the pieces list.\n\nnames = pd.concat(pieces, ignore_index=True): Combines all the DataFrames in the pieces list into a single DataFrame (names).\n\nignore_index=True: Resets the index, so we don’t have duplicate index values from the individual year files."
  },
  {
    "objectID": "qmd/pandas3ed13.html#aggregating-by-year-and-sex",
    "href": "qmd/pandas3ed13.html#aggregating-by-year-and-sex",
    "title": "",
    "section": "Aggregating by Year and Sex",
    "text": "Aggregating by Year and Sex\ntotal_births = names.pivot_table('births', index='year',\n                                 columns='sex', aggfunc=sum)\nprint(total_births.tail())\ntotal_births.plot(title='Total births by sex and year')\nplt.show()\n\n\n\n\n\n\n\nnames.pivot_table(...): Calculates the total births for each year/sex combination.\n\n'births': The values to aggregate (total births).\nindex='year': The year will be the row index.\ncolumns='sex': Sex (‘F’ and ‘M’) will be the columns.\naggfunc=sum: Calculates the sum of births for each year/sex combination.\n\ntotal_births.tail(): Displays the last few rows of the result.\ntotal_births.plot(...): Creates a line plot showing the trend of total births over time, separated by sex.\n\n\n\n\n\n\n‘Total births by sex and year’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#calculating-proportion-of-each-name",
    "href": "qmd/pandas3ed13.html#calculating-proportion-of-each-name",
    "title": "",
    "section": "Calculating Proportion of Each Name",
    "text": "Calculating Proportion of Each Name\ndef add_prop(group):\n    group['prop'] = group['births'] / group['births'].sum()\n    return group\n\nnames = names.groupby(['year', 'sex']).apply(add_prop)\nprint(names)\n\nGoal: Determine the proportion of babies given each name within each year and sex. This normalizes the data, accounting for changes in the total number of births.\nadd_prop(group) function:\n\nTakes a group (DataFrame) as input. A group represents a specific year and sex.\ngroup['births'] / group['births'].sum(): Calculates the proportion. It divides the births for each name by the total births for that year and sex.\nReturns the modified group with the new ‘prop’ column.\n\nnames.groupby(['year', 'sex']).apply(add_prop): Applies the add_prop function to each year/sex group. This adds the ‘prop’ column to the entire names DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed13.html#verifying-the-proportions",
    "href": "qmd/pandas3ed13.html#verifying-the-proportions",
    "title": "",
    "section": "Verifying the Proportions",
    "text": "Verifying the Proportions\nprint(names.groupby(['year', 'sex'])['prop'].sum())\n\nSanity Check: It’s a good practice to verify that the calculations are correct.\nnames.groupby(['year', 'sex'])['prop'].sum(): Groups by year and sex, and then sums the ‘prop’ column for each group. The result should be 1.0 for each year/sex combination, because the proportions should add up to 100%."
  },
  {
    "objectID": "qmd/pandas3ed13.html#extracting-the-top-1000-names",
    "href": "qmd/pandas3ed13.html#extracting-the-top-1000-names",
    "title": "",
    "section": "Extracting the Top 1000 Names",
    "text": "Extracting the Top 1000 Names\ndef get_top1000(group):\n    return group.sort_values('births', ascending=False)[:1000]\n\ngrouped = names.groupby(['year', 'sex'])\ntop1000 = grouped.apply(get_top1000)\ntop1000 = top1000.reset_index(drop=True)  # Drop the hierarchical index\nprint(top1000)\n\nGoal: For each year and sex, find the 1000 most popular names. This subset is used for further analysis.\nget_top1000(group) function:\n\nTakes a group (DataFrame) as input (a specific year and sex).\ngroup.sort_values('births', ascending=False): Sorts the names within the group by the number of births in descending order (most popular first).\n[:1000]: Selects the top 1000 rows (the top 1000 names).\nReturns the top 1000 names.\n\nnames.groupby(['year', 'sex']).apply(get_top1000): Applies the get_top1000 function to each year/sex group, creating top1000 DataFrame.\ntop1000.reset_index(drop=True): remove the multi-level index"
  },
  {
    "objectID": "qmd/pandas3ed13.html#analyzing-naming-trends",
    "href": "qmd/pandas3ed13.html#analyzing-naming-trends",
    "title": "",
    "section": "Analyzing Naming Trends",
    "text": "Analyzing Naming Trends\nboys = top1000[top1000['sex'] == 'M']\ngirls = top1000[top1000['sex'] == 'F']\n\ntotal_births = top1000.pivot_table('births', index='year', columns='name',\n                                    aggfunc=sum)\nprint(total_births.info())\n\nsubset = total_births[['John', 'Harry', 'Mary', 'Marilyn']]\nsubset.plot(subplots=True, figsize=(12, 10), title=\"Number of births per year\")\nplt.show()\n\n\n\n\n\n\n\nboys = top1000[top1000['sex'] == 'M'] and girls = ...: Creates separate DataFrames for boy and girl names.\ntotal_births = top1000.pivot_table(...): Creates a pivot table to analyze the trend of specific names over time.\n\n'births': The values to aggregate (total births).\nindex='year': The year will be the row index.\ncolumns='name': Each unique name will become a column.\naggfunc=sum: Sums the births for each name in each year.\n\nsubset.plot(...): Plots the trends of selected names over time.\n\nsubplots=True: Creates a separate subplot for each name.\nfigsize=(12, 10): Sets the figure size.\n\n\n\n\n\n\n\n‘A few boy and girl names over time’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#measuring-the-increase-in-naming-diversity",
    "href": "qmd/pandas3ed13.html#measuring-the-increase-in-naming-diversity",
    "title": "",
    "section": "Measuring the Increase in Naming Diversity",
    "text": "Measuring the Increase in Naming Diversity\ntable = top1000.pivot_table('prop', index='year', columns='sex', aggfunc=sum)\ntable.plot(title='Sum of table1000.prop by year and sex',\n           yticks=np.linspace(0, 1.2, 13))\nplt.show()\n\ndf = boys[boys['year'] == 2010]\nprop_cumsum = df['prop'].sort_values(ascending=False).cumsum()\nprint(prop_cumsum[:10])\nprint(prop_cumsum.searchsorted(0.5)) # result 116, plus 1\n\ndf = boys[boys.year == 1900]\nin1900 = df.sort_values('prop', ascending=False).prop.cumsum()\nprint(in1900.searchsorted(0.5) + 1) #result 25\n\n\n\n\n\n\n\nGoal: Investigate whether naming has become more diverse over time (i.e., are parents choosing from a wider variety of names?).\ntable = top1000.pivot_table(...): Calculates the sum of the ‘prop’ column for each year and sex. This shows the total proportion of births represented by the top 1000 names. If this proportion decreases over time, it suggests increasing diversity.\nprop_cumsum = ... .cumsum(): Calculates the cumulative sum of the ‘prop’ column for boy names in 2010 (after sorting in descending order). This is a key step to find the number of names needed to reach 50% of total births.\nprop_cumsum.searchsorted(0.5): Finds the index where the cumulative sum reaches 0.5 (50%). Because array index start from 0, plus 1.\nSimilar steps for 1900.\n\n\n\n\n\n\n‘Proportion of births represented in top one thousand names by sex’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#measuring-the-increase-in-naming-diversity-cont.",
    "href": "qmd/pandas3ed13.html#measuring-the-increase-in-naming-diversity-cont.",
    "title": "",
    "section": "Measuring the Increase in Naming Diversity (Cont.)",
    "text": "Measuring the Increase in Naming Diversity (Cont.)\ndef get_quantile_count(group, q=0.5):\n    group = group.sort_values('prop', ascending=False)\n    return group.prop.cumsum().searchsorted(q) + 1\n\ndiversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count)\ndiversity = diversity.unstack()\n\nfig = plt.figure()\ndiversity.plot(title=\"Number of popular names in top 50%\")\nplt.show()\n\n\n\n\n\n\n\nget_quantile_count(group, q=0.5) function:\n\nTakes a group (year/sex) and a quantile (defaulting to 0.5 for 50%) as input.\nSorts the group by ‘prop’ in descending order.\nCalculates the cumulative sum of ‘prop’.\nUses searchsorted(q) to find the index where the cumulative sum reaches the specified quantile (0.5). Plus 1.\nReturns the index.\n\ntop1000.groupby(['year', 'sex']).apply(get_quantile_count): Applies this function to each year/sex group to calculate the number of names needed to reach 50% of births for each group.\ndiversity.unstack(): Reshapes the result for easier plotting.\nThe plot shows how the number of names required to reach 50% of total births has changed over time, separated by sex.\n\n\n\n\n\n\n‘Plot of diversity metric by year’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#the-last-letter-revolution",
    "href": "qmd/pandas3ed13.html#the-last-letter-revolution",
    "title": "",
    "section": "The “Last Letter” Revolution",
    "text": "The “Last Letter” Revolution\ndef get_last_letter(x):\n    return x[-1]\n\nlast_letters = names['name'].map(get_last_letter)\nlast_letters.name = 'last_letter'\n\ntable = names.pivot_table('births', index=last_letters,\n                          columns=['sex', 'year'], aggfunc=sum)\nsubtable = table.reindex(columns=[1910, 1960, 2010], level='year')\nprint(subtable.head())\nprint(subtable.sum())\n\nletter_prop = subtable / subtable.sum()\nprint(letter_prop.head())\n\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 8))\nletter_prop['M'].plot(kind='bar', rot=0, ax=axes[0], title='Male')\nletter_prop['F'].plot(kind='bar', rot=0, ax=axes[1], title='Female',\n                      legend=False)\nplt.show()\n\n\n\n\n\n\n\nIdea: Analyze the distribution of the last letters of baby names over time.\nget_last_letter(x) function: Returns the last character of a string.\nnames['name'].map(get_last_letter): Applies this function to the ‘name’ column, creating a new Series last_letters containing the last letter of each name.\ntable = names.pivot_table(...): Creates a pivot table to count births by last letter, sex, and year.\nsubtable = ...: Selects data for specific years (1910, 1960, 2010) for comparison.\nletter_prop = subtable / subtable.sum(): Calculates the proportion of names ending in each letter for each sex and year. This normalizes the data.\nplt.subplots(2, 1, ...): Creates a figure with two subplots (one for male, one for female).\nletter_prop['M'].plot(...) and letter_prop['F'].plot(...): Creates bar plots showing the distribution of last letters for each sex.\n\n\n\n\n\n\n‘Proportion of boy and girl names ending in each letter’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#the-last-letter-revolution-cont.",
    "href": "qmd/pandas3ed13.html#the-last-letter-revolution-cont.",
    "title": "",
    "section": "The “Last Letter” Revolution (Cont.)",
    "text": "The “Last Letter” Revolution (Cont.)\nletter_prop = table / table.sum()\ndny_ts = letter_prop.loc[['d', 'n', 'y'], 'M'].T\nprint(dny_ts.head())\ndny_ts.plot()\nplt.show()\n\n\n\n\n\n\n\nletter_prop = table / table.sum(): Calculates proportions based on the full table (all years).\ndny_ts = letter_prop.loc[['d', 'n', 'y'], 'M'].T: Selects data for specific letters (‘d’, ‘n’, ‘y’) and for males (‘M’), and then transposes the result (. T). This creates a time series where each column is a letter and each row is a year.\ndny_ts.plot(): Plots the trends of these letters over time.\n\n\n\n\n\n\n‘Proportion of boys born with names ending in d/n/y over time’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#boy-names-that-became-girl-names-and-vice-versa",
    "href": "qmd/pandas3ed13.html#boy-names-that-became-girl-names-and-vice-versa",
    "title": "",
    "section": "Boy Names That Became Girl Names (and Vice Versa)",
    "text": "Boy Names That Became Girl Names (and Vice Versa)\nall_names = pd.Series(top1000['name'].unique())\nlesley_like = all_names[all_names.str.contains('Lesl')]\nprint(lesley_like)\n\nfiltered = top1000[top1000['name'].isin(lesley_like)]\nprint(filtered.groupby('name')['births'].sum())\n\ntable = filtered.pivot_table('births', index='year',\n                            columns='sex', aggfunc='sum')\ntable = table.div(table.sum(axis=\"columns\"), axis=\"index\")\nprint(table.tail())\ntable.plot(style={'M': 'k-', 'F': 'k--'})\nplt.show()\n\n\n\n\n\n\n\nGoal: Identify names that have switched gender preference over time.\nall_names = ...: Gets a list of all unique names in the top1000 DataFrame.\nlesley_like = ...: Filters this list to find names containing “Lesl” (e.g., Lesley, Leslie, Leslee).\nfiltered = ...: Selects rows from top1000 where the name is in the lesley_like list.\nfiltered.groupby('name')['births'].sum(): Calculates the total births for each of the “Lesley-like” names.\ntable = filtered.pivot_table(...): Creates a pivot table showing the number of births for each sex in each year.\ntable = table.div(..., axis=\"index\"): Calculates the proportion of births for each sex in each year. This normalizes the data.\ntable.plot(...): Plots the trend of male vs. female proportions for “Lesley-like” names over time.\n\n\n\n\n\n\n‘Proportion of male/female Lesley-like names over time’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#usda-food-database",
    "href": "qmd/pandas3ed13.html#usda-food-database",
    "title": "",
    "section": "13.4 USDA Food Database",
    "text": "13.4 USDA Food Database\n\n\n\n\n\n\n\nDataset: USDA (United States Department of Agriculture) food nutrient database.\nData Format: JSON.\nExample Record: (See the JSON structure in the original slide content).\nGoal: Analyze nutrient information for different foods.\n\n\n\n{\n  \"id\": 21441,\n  \"description\": \"KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY, Wing, meat and skin with breading\",\n  \"tags\": [\"KFC\"],\n  \"manufacturer\": \"Kentucky Fried Chicken\",\n  \"group\": \"Fast Foods\",\n  \"portions\": [\n    {\n      \"amount\": 1,\n      \"unit\": \"wing, with skin\",\n      \"grams\": 68.0\n    }\n  ],\n  \"nutrients\": [\n    {\n      \"value\": 20.8,\n      \"units\": \"g\",\n      \"description\": \"Protein\",\n      \"group\": \"Composition\"\n    }\n  ]\n}"
  },
  {
    "objectID": "qmd/pandas3ed13.html#loading-and-exploring-the-data",
    "href": "qmd/pandas3ed13.html#loading-and-exploring-the-data",
    "title": "",
    "section": "Loading and Exploring the Data",
    "text": "Loading and Exploring the Data\nimport json\nimport pandas as pd\n\ndb = json.load(open('datasets/usda_food/database.json'))\nprint(len(db))\nprint(db[0].keys())\nprint(db[0]['nutrients'][0])\n\nnutrients = pd.DataFrame(db[0]['nutrients'])\nprint(nutrients.head(7))\n\nimport json: Imports the json library for working with JSON data.\ndb = json.load(...): Loads the JSON data from the file into a Python object (db). db will be a list of dictionaries.\nlen(db): Shows the number of food records in the database.\ndb[0].keys(): Shows the keys (fields) in the first food record.\ndb[0]['nutrients'][0]: Shows the first nutrient record for the first food.\nnutrients = pd.DataFrame(...): Creates a DataFrame from the list of nutrients for the first food. This is just a preliminary step."
  },
  {
    "objectID": "qmd/pandas3ed13.html#extracting-food-information",
    "href": "qmd/pandas3ed13.html#extracting-food-information",
    "title": "",
    "section": "Extracting Food Information",
    "text": "Extracting Food Information\ninfo_keys = ['description', 'group', 'id', 'manufacturer']\ninfo = pd.DataFrame(db, columns=info_keys)\nprint(info.head())\nprint(info.info())\nprint(pd.value_counts(info['group'])[:10])\n\nGoal: Create a DataFrame (info) containing basic information about each food.\ninfo_keys = [...]: Defines a list of the keys we want to extract.\ninfo = pd.DataFrame(db, columns=info_keys): Creates the DataFrame, selecting only the specified columns.\ninfo.head(): Displays the first few rows.\ninfo.info(): Provides summary information (column names, data types, missing values).\npd.value_counts(info['group'])[:10]: Counts the occurrences of each food group and shows the top 10."
  },
  {
    "objectID": "qmd/pandas3ed13.html#processing-nutrient-data",
    "href": "qmd/pandas3ed13.html#processing-nutrient-data",
    "title": "",
    "section": "Processing Nutrient Data",
    "text": "Processing Nutrient Data\nnutrients = []\n\nfor rec in db:\n    fnuts = pd.DataFrame(rec['nutrients'])\n    fnuts['id'] = rec['id']\n    nutrients.append(fnuts)\n\nnutrients = pd.concat(nutrients, ignore_index=True)\nprint(nutrients)\n\nGoal: Create a single DataFrame (nutrients) containing all nutrient information for all foods.\nLooping through records:\n\nfor rec in db:: Iterates through each food record in the db list.\nfnuts = pd.DataFrame(rec['nutrients']): Creates a DataFrame from the list of nutrients for the current food.\nfnuts['id'] = rec['id']: Adds the food ID to the fnuts DataFrame. This is crucial for linking nutrients back to the correct food.\nnutrients.append(fnuts): Appends the fnuts DataFrame to the nutrients list.\n\nnutrients = pd.concat(nutrients, ignore_index=True): Combines all the individual nutrient DataFrames into a single DataFrame. ignore_index=True is important to avoid duplicate index values."
  },
  {
    "objectID": "qmd/pandas3ed13.html#handling-duplicates-and-renaming",
    "href": "qmd/pandas3ed13.html#handling-duplicates-and-renaming",
    "title": "",
    "section": "Handling Duplicates and Renaming",
    "text": "Handling Duplicates and Renaming\nnutrients.duplicated().sum()  # Check for duplicates\nnutrients = nutrients.drop_duplicates()  # Remove duplicates\n\ncol_mapping = {'description' : 'food',\n               'group'       : 'fgroup'}\ninfo = info.rename(columns=col_mapping, copy=False)\nprint(info.info())\n\ncol_mapping = {'description' : 'nutrient',\n               'group' : 'nutgroup'}\nnutrients = nutrients.rename(columns=col_mapping, copy=False)\nprint(nutrients)\n\nDuplicate Check: It is found that some rows of nutritional information are duplicated and need to be removed before proceeding.\nnutrients.duplicated().sum(): Counts the number of duplicate rows in the nutrients DataFrame.\nnutrients = nutrients.drop_duplicates(): Removes duplicate rows.\nRenaming columns:\n\ncol_mapping = ...: Creates dictionaries to map old column names to new ones. This improves clarity.\ninfo = info.rename(..., copy=False): Renames columns in the info DataFrame. copy=False modifies the DataFrame in place (more efficient).\nnutrients = nutrients.rename(...): Renames columns in the nutrients DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed13.html#merging-dataframes",
    "href": "qmd/pandas3ed13.html#merging-dataframes",
    "title": "",
    "section": "Merging DataFrames",
    "text": "Merging DataFrames\nndata = pd.merge(nutrients, info, on='id')\nprint(ndata.info())\nprint(ndata.iloc[30000])\n\nndata = pd.merge(nutrients, info, on='id'): Combines the nutrients and info DataFrames based on the common ‘id’ column. This creates a single DataFrame with all food and nutrient information.\nndata.info(): Displays summary information about the merged DataFrame.\nndata.iloc[30000]: Shows a specific row (nutrient record) to illustrate the structure of the merged data."
  },
  {
    "objectID": "qmd/pandas3ed13.html#plotting-median-nutrient-values",
    "href": "qmd/pandas3ed13.html#plotting-median-nutrient-values",
    "title": "",
    "section": "Plotting Median Nutrient Values",
    "text": "Plotting Median Nutrient Values\nresult = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0.5)\nresult['Zinc, Zn'].sort_values().plot(kind='barh')\nplt.show()\n\n\n\n\n\n\n\nGoal: Visualize the median values of nutrients for different food groups.\nresult = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0.5):\n\ngroupby(['nutrient', 'fgroup']): Groups the data by nutrient and food group.\n['value'].quantile(0.5): Calculates the median (50th percentile) of the ‘value’ column (nutrient amount) for each group.\n\nresult['Zinc, Zn'].sort_values().plot(kind='barh'):\n\nresult['Zinc, Zn']: Selects the data for Zinc.\n.sort_values(): Sorts the median Zinc values in ascending order.\n.plot(kind='barh'): Creates a horizontal bar plot.\n\n\n\n\n\n\n\n‘Median zinc values by food group’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#finding-foods-with-maximum-nutrient-values",
    "href": "qmd/pandas3ed13.html#finding-foods-with-maximum-nutrient-values",
    "title": "",
    "section": "Finding Foods with Maximum Nutrient Values",
    "text": "Finding Foods with Maximum Nutrient Values\nby_nutrient = ndata.groupby(['nutgroup', 'nutrient'])\n\ndef get_maximum(x):\n    return x.loc[x.value.idxmax()]\n\nmax_foods = by_nutrient.apply(get_maximum)[['value', 'food']]\nmax_foods['food'] = max_foods['food'].str[:50]\nprint(max_foods.loc['Amino Acids']['food'])\n\nGoal: Identify the food that has the highest value for each nutrient.\nby_nutrient = ndata.groupby(['nutgroup', 'nutrient']): Groups the data by nutrient group and nutrient name.\nget_maximum(x) function:\n\nTakes a group (DataFrame) as input.\nx.value.idxmax(): Finds the index of the row with the maximum value in the ‘value’ column (the nutrient amount).\nx.loc[...]: Selects the row with the maximum value.\nReturns the selected row.\n\nmax_foods = by_nutrient.apply(get_maximum)[['value', 'food']]: Applies the get_maximum function to each group and selects the ‘value’ and ‘food’ columns.\nmax_foods['food'] = max_foods['food'].str[:50]: Shortens the food names to the first 50 characters for better display."
  },
  {
    "objectID": "qmd/pandas3ed13.html#federal-election-commission-database",
    "href": "qmd/pandas3ed13.html#federal-election-commission-database",
    "title": "",
    "section": "13.5 2012 Federal Election Commission Database",
    "text": "13.5 2012 Federal Election Commission Database\n\n\n\n\n\n\n\nDataset: 2012 US Federal Election Commission (FEC) campaign contribution data.\nContents:\n\nContributor names.\nOccupation and employer.\nAddress.\nContribution amount.\n\nData Format: CSV (Comma-Separated Values).\nFile: P00000001-ALL.csv (in the book’s data repository).\nGoal: Analyze patterns in campaign contributions.\n\n\n\nimport pandas as pd\nfec = pd.read_csv('datasets/fec/P00000001-ALL.csv', low_memory=False)\nprint(fec.info())\nprint(fec.iloc[123456])\n\n\n\n\n\nfec = pd.read_csv(...): Loads the CSV data into a DataFrame.\nlow_memory=False: An important option. The file is large, and pandas might guess data types incorrectly if low_memory=True (the default). Setting it to False ensures more accurate type inference, but uses more memory.\nfec.info(): Provides a summary of the DataFrame (columns, data types, missing values).\nfec.iloc[123456]: Displays a sample record."
  },
  {
    "objectID": "qmd/pandas3ed13.html#adding-party-affiliation",
    "href": "qmd/pandas3ed13.html#adding-party-affiliation",
    "title": "",
    "section": "Adding Party Affiliation",
    "text": "Adding Party Affiliation\nunique_cands = fec['cand_nm'].unique()\nprint(unique_cands)\n\nparties = {'Bachmann, Michelle': 'Republican',\n           'Cain, Herman': 'Republican',\n           'Gingrich, Newt': 'Republican',\n           'Huntsman, Jon': 'Republican',\n           'Johnson, Gary Earl': 'Republican',\n           'McCotter, Thaddeus G': 'Republican',\n           'Obama, Barack': 'Democrat',\n           'Paul, Ron': 'Republican',\n           'Pawlenty, Timothy': 'Republican',\n           'Perry, Rick': 'Republican',\n           \"Roemer, Charles E. 'Buddy' III\": 'Republican',\n           'Romney, Mitt': 'Republican',\n           'Santorum, Rick': 'Republican'}\n\nprint(fec['cand_nm'][123456:123461])\nprint(fec['cand_nm'][123456:123461].map(parties))\n\nfec['party'] = fec['cand_nm'].map(parties)\nprint(fec['party'].value_counts())\n\nunique_cands = fec['cand_nm'].unique(): Gets a list of all unique candidate names.\nparties = {...}: Creates a dictionary mapping candidate names to their political party affiliations.\nfec['cand_nm'][123456:123461].map(parties): Uses the map method to apply the parties dictionary to a subset of the ‘cand_nm’ column. This shows how the mapping works.\nfec['party'] = fec['cand_nm'].map(parties): Creates a new ‘party’ column in the fec DataFrame, assigning a party affiliation to each record based on the candidate’s name.\nfec['party'].value_counts(): Counts the number of records for each political party."
  },
  {
    "objectID": "qmd/pandas3ed13.html#filtering-contributions",
    "href": "qmd/pandas3ed13.html#filtering-contributions",
    "title": "",
    "section": "Filtering Contributions",
    "text": "Filtering Contributions\nprint((fec['contb_receipt_amt'] &gt; 0).value_counts())\n\nfec = fec[fec['contb_receipt_amt'] &gt; 0]\n\nProblem: The dataset includes both contributions (positive amounts) and refunds (negative amounts).\n(fec['contb_receipt_amt'] &gt; 0).value_counts(): Checks how many contributions are positive and how many are negative.\nfec = fec[fec['contb_receipt_amt'] &gt; 0]: Filters the fec DataFrame to keep only records where the contribution amount is positive. This focuses the analysis on actual contributions."
  },
  {
    "objectID": "qmd/pandas3ed13.html#filtering-by-candidate",
    "href": "qmd/pandas3ed13.html#filtering-by-candidate",
    "title": "",
    "section": "Filtering by Candidate",
    "text": "Filtering by Candidate\nfec_mrbo = fec[fec['cand_nm'].isin(['Obama, Barack', 'Romney, Mitt'])]\n\nGoal: Focus on contributions to the two main candidates (Obama and Romney).\nfec_mrbo = fec[fec['cand_nm'].isin(['Obama, Barack', 'Romney, Mitt'])]: Filters the fec DataFrame to keep only records where the candidate name is either “Obama, Barack” or “Romney, Mitt”."
  },
  {
    "objectID": "qmd/pandas3ed13.html#donation-statistics-by-occupation-and-employer",
    "href": "qmd/pandas3ed13.html#donation-statistics-by-occupation-and-employer",
    "title": "",
    "section": "Donation Statistics by Occupation and Employer",
    "text": "Donation Statistics by Occupation and Employer\nprint(fec['contbr_occupation'].value_counts()[:10])\n\nocc_mapping = {\n    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',\n    'INFORMATION REQUESTED' : 'NOT PROVIDED',\n    'INFORMATION REQUESTED (BEST EFFORTS)' : 'NOT PROVIDED',\n    'C.E.O.': 'CEO'\n}\n\ndef get_occ(x):\n    # If no mapping provided, return x\n    return occ_mapping.get(x, x)\n\nfec['contbr_occupation'] = fec['contbr_occupation'].map(get_occ)\n\nfec['contbr_occupation'].value_counts()[:10]: Counts the number of contributions for each occupation and shows the top 10.\nProblem: There are many variations of similar occupations (e.g., “INFORMATION REQUESTED” in multiple forms). We need to clean this up.\nocc_mapping = {...}: Creates a dictionary to map variations of occupations to a standardized form (e.g., mapping all “INFORMATION REQUESTED” variants to “NOT PROVIDED”).\nget_occ(x) function:\n\nUses the get method of the occ_mapping dictionary. If the occupation x is found in the dictionary, it returns the mapped value. If not, it returns the original occupation x (this is the “pass-through” behavior).\n\nfec['contbr_occupation'] = fec['contbr_occupation'].map(get_occ): Applies the get_occ function to the ‘contbr_occupation’ column to standardize the occupations."
  },
  {
    "objectID": "qmd/pandas3ed13.html#donation-statistics-by-occupation-and-employer-cont.",
    "href": "qmd/pandas3ed13.html#donation-statistics-by-occupation-and-employer-cont.",
    "title": "",
    "section": "Donation Statistics by Occupation and Employer (Cont.)",
    "text": "Donation Statistics by Occupation and Employer (Cont.)\nemp_mapping = {\n    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',\n    'INFORMATION REQUESTED' : 'NOT PROVIDED',\n    'SELF' : 'SELF-EMPLOYED',\n    'SELF EMPLOYED' : 'SELF-EMPLOYED',\n}\n\ndef get_emp(x):\n    # If no mapping provided, return x\n    return emp_mapping.get(x, x)\n\nfec['contbr_employer'] = fec['contbr_employer'].map(get_emp)\n\nby_occupation = fec.pivot_table('contb_receipt_amt',\n                                index='contbr_occupation',\n                                columns='party', aggfunc='sum')\n\nover_2mm = by_occupation[by_occupation.sum(axis=\"columns\") &gt; 2000000]\nprint(over_2mm)\n\nThe process for employer is almost identical to occupation.\nby_occupation = fec.pivot_table(...): Creates a pivot table to analyze contributions by occupation and party.\n\n'contb_receipt_amt': The values to aggregate (contribution amounts).\nindex='contbr_occupation': Occupation will be the row index.\ncolumns='party': Party (‘Democrat’ and ‘Republican’) will be the columns.\naggfunc='sum': Calculates the total contribution amount for each occupation/party combination.\n\nover_2mm = ...: Filters the by_occupation DataFrame to keep only occupations with total contributions (across both parties) greater than $2 million.\nprint(over_2mm): Displays the resulting DataFrame.\n\nover_2mm.plot(kind='barh')\nplt.show()\n\n\n\n\n\n\n\nover_2mm.plot(kind='barh'): Creates a horizontal bar plot of the over_2mm DataFrame, visualizing total contributions by occupation and party.\n\n\n\n\n\n\n‘Total donations by party for top occupations’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#top-donor-occupations-and-employers",
    "href": "qmd/pandas3ed13.html#top-donor-occupations-and-employers",
    "title": "",
    "section": "Top Donor Occupations and Employers",
    "text": "Top Donor Occupations and Employers\ndef get_top_amounts(group, key, n=5):\n    totals = group.groupby(key)['contb_receipt_amt'].sum()\n    return totals.nlargest(n)\n\ngrouped = fec_mrbo.groupby('cand_nm')\nprint(grouped.apply(get_top_amounts, 'contbr_occupation', n=7))\nprint(grouped.apply(get_top_amounts, 'contbr_employer', n=10))\n\nget_top_amounts(group, key, n=5) function:\n\ngroup: A DataFrame group (e.g., contributions for a specific candidate).\nkey: The column to group by (e.g., ‘contbr_occupation’ or ‘contbr_employer’).\nn: The number of top items to return.\ntotals = group.groupby(key)['contb_receipt_amt'].sum(): Calculates the total contribution amount for each unique value of the key (e.g., for each occupation).\nreturn totals.nlargest(n): Returns the top n values (largest contributions).\n\ngrouped = fec_mrbo.groupby('cand_nm'): Groups the fec_mrbo DataFrame by candidate name.\ngrouped.apply(get_top_amounts, 'contbr_occupation', n=7): Applies the get_top_amounts function to each candidate group, finding the top 7 occupations for each candidate.\ngrouped.apply(get_top_amounts, 'contbr_employer', n=10): Does the same, but for employers and returns the top 10."
  },
  {
    "objectID": "qmd/pandas3ed13.html#bucketing-donation-amounts",
    "href": "qmd/pandas3ed13.html#bucketing-donation-amounts",
    "title": "",
    "section": "Bucketing Donation Amounts",
    "text": "Bucketing Donation Amounts\nimport numpy as np\n\nbins = np.array([0, 1, 10, 100, 1000, 10000, 100_000, 1_000_000, 10_000_000])\nlabels = pd.cut(fec_mrbo['contb_receipt_amt'], bins)\nprint(labels)\n\ngrouped = fec_mrbo.groupby(['cand_nm', labels])\nprint(grouped.size().unstack(level=0))\n\nbucket_sums = grouped['contb_receipt_amt'].sum().unstack(level=0)\nnormed_sums = bucket_sums.div(bucket_sums.sum(axis=\"columns\"),\n                              axis=\"index\")\nprint(normed_sums)\nnormed_sums[:-2].plot(kind='barh')\nplt.show()\n\n\n\n\n\n\n\nGoal: Analyze contributions based on donation size brackets.\nbins = np.array([...]): Defines the boundaries of the donation amount buckets.\nlabels = pd.cut(fec_mrbo['contb_receipt_amt'], bins): Uses the cut function to assign each contribution to a bucket based on its amount. labels is a pandas Categorical object.\ngrouped = fec_mrbo.groupby(['cand_nm', labels]): Groups the data by candidate name and donation bucket.\ngrouped.size().unstack(level=0): Counts the number of contributions in each bucket for each candidate and reshapes the data for easier analysis.\nbucket_sums = ...: Calculates the total contribution amount within each bucket for each candidate.\nnormed_sums = ...: Normalizes the data to show the percentage of total donations from each bucket for each candidate.\nnormed_sums[:-2].plot(kind='barh'): Creates a horizontal bar plot, excluding the two largest buckets (which are likely from organizations, not individuals).\n\n\n\n\n\n\n‘Percentage of total donations received by candidates for each donation size’"
  },
  {
    "objectID": "qmd/pandas3ed13.html#donation-statistics-by-state",
    "href": "qmd/pandas3ed13.html#donation-statistics-by-state",
    "title": "",
    "section": "Donation Statistics by State",
    "text": "Donation Statistics by State\ngrouped = fec_mrbo.groupby(['cand_nm', 'contbr_st'])\ntotals = grouped['contb_receipt_amt'].sum().unstack(level=0).fillna(0)\ntotals = totals[totals.sum(axis=\"columns\") &gt; 100000]\nprint(totals.head(10))\n\npercent = totals.div(totals.sum(axis=\"columns\"), axis=\"index\")\nprint(percent.head(10))\n\nGoal: Analyze contributions based on the state of the contributor.\ngrouped = fec_mrbo.groupby(['cand_nm', 'contbr_st']): Groups the data by candidate name and contributor state.\ntotals = grouped['contb_receipt_amt'].sum().unstack(level=0).fillna(0): Calculates the total contribution amount from each state for each candidate.\n\nunstack(level=0) pivots the candidate names to columns, and fillna(0) handles cases where a state might have no contributions for a particular candidate. - totals = totals[totals.sum(axis=\"columns\") &gt; 100000]: Filters the data to keep only states with total contributions (across both candidates) greater than $100,000. - percent = totals.div(totals.sum(axis=\"columns\"), axis=\"index\"): Calculates the percentage of contributions from each state for each candidate. This normalizes the data."
  },
  {
    "objectID": "qmd/pandas3ed13.html#summary",
    "href": "qmd/pandas3ed13.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\n\nThis chapter demonstrated how to apply Python data analysis techniques to real-world datasets.\nWe explored data from Bitly/USA.gov, MovieLens, US baby names, USDA food nutrients, and FEC campaign contributions.\nKey techniques covered:\n\nData loading (text files, JSON, CSV).\nData cleaning and transformation (handling missing data, string manipulation, data type conversions).\nData aggregation and grouping (using groupby, pivot_table, apply).\nData merging and reshaping (merge, concat, unstack, stack).\nData visualization (using matplotlib and seaborn).\nWorking with time series data.\n\nThe chapter emphasized iterative data exploration: starting with raw data, cleaning and transforming it, and gradually building up analyses to answer specific questions."
  },
  {
    "objectID": "qmd/pandas3ed13.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed13.html#thoughts-and-discussion",
    "title": "",
    "section": "Thoughts and Discussion",
    "text": "Thoughts and Discussion\n\nHow could these analyses be extended or refined? What other questions could you ask of these datasets?\nConsider the limitations of the data and the analyses. What assumptions were made? What biases might be present?\nHow could these techniques be applied to other datasets you’re interested in?\nWhat are the ethical considerations when working with real-world data, especially data about people (like baby names, movie ratings, or political contributions)?\nDiscuss the trade-offs between using pure Python, the collections module (Counter, defaultdict), and pandas for different tasks. When is each approach most appropriate?\nHow does the choice of visualization (bar plots, line plots, etc.) affect the insights you can gain from the data?\nExplore the official documents of pandas.DataFrame.merge, pandas.DataFrame.groupby, pandas.DataFrame.plot and pandas.DataFrame.apply to deepen your understanding.\nConsider how these skills are useful for a business major, providing a competitive edge in a future career."
  },
  {
    "objectID": "qmd/pandas3ed6.html",
    "href": "qmd/pandas3ed6.html",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "",
    "text": "Data loading is the crucial first step in any data analysis project. It involves reading data from various sources and making it accessible for processing.\nThe term parsing is often used interchangeably with data loading, referring to the process of interpreting text data and converting it into structured formats like tables with specific data types.\nWhile various libraries exist, this chapter focuses on using pandas, a powerful Python library, for data input and output.\nThis chapter focuses on loading from text files, efficient storage format, database, and interact with web APIs."
  },
  {
    "objectID": "qmd/pandas3ed6.html#introduction-to-data-loading",
    "href": "qmd/pandas3ed6.html#introduction-to-data-loading",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "",
    "text": "Data loading is the crucial first step in any data analysis project. It involves reading data from various sources and making it accessible for processing.\nThe term parsing is often used interchangeably with data loading, referring to the process of interpreting text data and converting it into structured formats like tables with specific data types.\nWhile various libraries exist, this chapter focuses on using pandas, a powerful Python library, for data input and output.\nThis chapter focuses on loading from text files, efficient storage format, database, and interact with web APIs."
  },
  {
    "objectID": "qmd/pandas3ed6.html#why-data-loading-matters",
    "href": "qmd/pandas3ed6.html#why-data-loading-matters",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Why Data Loading Matters",
    "text": "Why Data Loading Matters\n\n\nFoundation for Analysis: Without loading data, you can’t perform any analysis! 🤯\nData Variety: Data comes in many shapes and sizes: text files, databases, web APIs, and more. Learning to handle these different formats is essential.\nEfficiency: Efficient data loading techniques can save you significant time and computational resources, especially with large datasets.\nData Cleaning: The loading process often involves initial data cleaning, such as handling missing values or inconsistent formatting."
  },
  {
    "objectID": "qmd/pandas3ed6.html#core-concepts-data-mining-and-machine-learning",
    "href": "qmd/pandas3ed6.html#core-concepts-data-mining-and-machine-learning",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Core Concepts: Data Mining and Machine Learning",
    "text": "Core Concepts: Data Mining and Machine Learning\n\nBefore diving into data loading, let’s clarify some fundamental concepts.\n\nData Mining: The process of discovering patterns, anomalies, and insights from large datasets. It’s like searching for gold 🪙 in a mountain of data!\nMachine Learning (ML): A subfield of artificial intelligence (AI) where algorithms learn from data without explicit programming. Think of it as teaching a computer to learn from examples. 🤖\nStatistical Learning: Often used synonymously with Machine Learning, it emphasizes the statistical foundations of learning algorithms. It focuses on building mathematical models to understand and predict data."
  },
  {
    "objectID": "qmd/pandas3ed6.html#relationship-between-these-concepts",
    "href": "qmd/pandas3ed6.html#relationship-between-these-concepts",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Relationship Between These Concepts",
    "text": "Relationship Between These Concepts\n\n\n\n\n\ngraph LR\n    A[Data Mining] --&gt; C(Common Ground)\n    B[Machine Learning] --&gt; C\n    D[Statistical Learning] --&gt; C\n    C --&gt; E[Insights & Predictions]\n\n\n\n\n\n\n\n\nData mining often uses machine learning techniques to find patterns.\nMachine Learning builds on Statistical Learning.\nAll aim to extract insights and make predictions from data."
  },
  {
    "objectID": "qmd/pandas3ed6.html#introduction-to-python-and-pandas",
    "href": "qmd/pandas3ed6.html#introduction-to-python-and-pandas",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Introduction to Python and Pandas",
    "text": "Introduction to Python and Pandas\n\n\nPython: A versatile, high-level programming language known for its readability and extensive libraries. It’s a favorite for data analysis and machine learning. 🐍\nPandas: A powerful Python library specifically designed for data manipulation and analysis. It provides data structures like DataFrame to efficiently store and work with tabular data. Think of it as Excel, but supercharged! 💪\nWhy Pandas?\n\nEasy-to-use data structures.\nPowerful data manipulation tools.\nExcellent for handling missing data.\nBuilt-in functions for data loading, cleaning, and analysis."
  },
  {
    "objectID": "qmd/pandas3ed6.html#reading-and-writing-data-in-text-format-with-pandas",
    "href": "qmd/pandas3ed6.html#reading-and-writing-data-in-text-format-with-pandas",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Reading and Writing Data in Text Format with Pandas",
    "text": "Reading and Writing Data in Text Format with Pandas\n\n\nPandas provides several functions for reading tabular data into a DataFrame object.\nread_csv is one of the most commonly used functions, designed for reading comma-separated values (CSV) files. But it’s much more flexible than just CSV!\nOther functions handle different formats (see the table below)."
  },
  {
    "objectID": "qmd/pandas3ed6.html#pandas-data-loading-functions-part-1",
    "href": "qmd/pandas3ed6.html#pandas-data-loading-functions-part-1",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Pandas Data Loading Functions (Part 1)",
    "text": "Pandas Data Loading Functions (Part 1)\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nread_csv\nLoad delimited data (comma is the default).\n\n\nread_fwf\nRead data in fixed-width column format.\n\n\nread_clipboard\nReads data from the clipboard (useful for web tables).\n\n\nread_excel\nRead data from Excel XLS or XLSX files.\n\n\nread_hdf\nRead HDF5 files written by pandas.\n\n\nread_html\nRead all tables from an HTML document.\n\n\nread_json\nRead data from a JSON string, file, or URL."
  },
  {
    "objectID": "qmd/pandas3ed6.html#pandas-data-loading-functions-part-2",
    "href": "qmd/pandas3ed6.html#pandas-data-loading-functions-part-2",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Pandas Data Loading Functions (Part 2)",
    "text": "Pandas Data Loading Functions (Part 2)\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nread_feather\nRead the Feather binary file format.\n\n\nread_orc\nRead the Apache ORC binary file format.\n\n\nread_parquet\nRead the Apache Parquet binary file format.\n\n\nread_pickle\nRead a pandas object stored in Python pickle format.\n\n\nread_sas\nRead a SAS dataset.\n\n\nread_spss\nRead a data file created by SPSS.\n\n\nread_sql\nRead the result of a SQL query.\n\n\nread_sql_table\nRead a whole SQL table.\n\n\nread_stata\nRead a dataset from Stata file format.\n\n\nread_xml\nRead a table of data from an XML file."
  },
  {
    "objectID": "qmd/pandas3ed6.html#common-read_csv-optional-arguments",
    "href": "qmd/pandas3ed6.html#common-read_csv-optional-arguments",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Common read_csv Optional Arguments",
    "text": "Common read_csv Optional Arguments\n\nThe read_csv function (and others) has many optional arguments, categorized as:\n\nIndexing: Control which columns become the DataFrame’s index (row labels).\nType Inference and Data Conversion: Pandas tries to automatically detect data types (integer, float, string, etc.). You can customize this.\nDate and Time Parsing: Combine and parse date/time information spread across multiple columns.\nIterating: For very large files, read the file in chunks.\nUnclean Data Issues: Handle issues like skipping rows, comments, and unusual numeric formats.\n\nDon’t be overwhelmed by all the options! The pandas documentation has excellent examples. 📚"
  },
  {
    "objectID": "qmd/pandas3ed6.html#example-reading-a-simple-csv",
    "href": "qmd/pandas3ed6.html#example-reading-a-simple-csv",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Example: Reading a Simple CSV",
    "text": "Example: Reading a Simple CSV\n\nLet’s start with a basic CSV file (ex1.csv):\na,b,c,d,message\n1,2,3,4,hello\n5,6,7,8,world\n9,10,11,12,foo\nWe can read this using pd.read_csv:\nimport pandas as pd\ndf = pd.read_csv(\"examples/ex1.csv\")\nprint(df)\n\n\n\n\n\n\n\n\nThe output is:\n   a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo\n\n\n\n\nPandas automatically detected the header row and inferred the data types.\nThe DataFrame is displayed with row indices (0, 1, 2) and column names."
  },
  {
    "objectID": "qmd/pandas3ed6.html#example-no-header-row",
    "href": "qmd/pandas3ed6.html#example-no-header-row",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Example: No Header Row",
    "text": "Example: No Header Row\n\nConsider ex2.csv:\n1,2,3,4,hello\n5,6,7,8,world\n9,10,11,12,foo\n\n\n\nOption 1: Let pandas assign default column names:\ndf = pd.read_csv(\"examples/ex2.csv\", header=None)\nprint(df)\n\n\n\n\n\n\n\n   0   1   2   3      4\n0  1   2   3   4  hello\n1  5   6   7   8  world\n2  9  10  11  12    foo\n\n\n\n\n\n\nOption 2: Specify column names:\ndf = pd.read_csv(\"examples/ex2.csv\", names=[\"a\", \"b\", \"c\", \"d\", \"message\"])\nprint(df)\n\n\n\n\n\n\n\n   a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo"
  },
  {
    "objectID": "qmd/pandas3ed6.html#setting-the-index",
    "href": "qmd/pandas3ed6.html#setting-the-index",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Setting the Index",
    "text": "Setting the Index\n\nYou can specify which column(s) should be the index using index_col:\nnames = [\"a\", \"b\", \"c\", \"d\", \"message\"]\ndf = pd.read_csv(\"examples/ex2.csv\", names=names, index_col=\"message\")\nprint(df)\n\n\n\n\n\n\n         a   b   c   d\nmessage\nhello    1   2   3   4\nworld    5   6   7   8\nfoo      9  10  11  12"
  },
  {
    "objectID": "qmd/pandas3ed6.html#hierarchical-index",
    "href": "qmd/pandas3ed6.html#hierarchical-index",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Hierarchical Index",
    "text": "Hierarchical Index\n\n\nCreate a hierarchical (multi-level) index by passing a list of column names or indices to index_col:\n\n# Assuming a file 'csv_mindex.csv' with columns: key1,key2,value1,value2\nparsed = pd.read_csv(\"examples/csv_mindex.csv\", index_col=[\"key1\", \"key2\"])\nprint(parsed)\n\n\n\n\n\n\n           value1  value2\nkey1 key2\none  a          1       2\n     b          3       4\n     c          5       6\n     d          7       8\ntwo  a          9      10\n     b         11      12\n     c         13      14\n     d         15      16"
  },
  {
    "objectID": "qmd/pandas3ed6.html#handling-non-standard-delimiters",
    "href": "qmd/pandas3ed6.html#handling-non-standard-delimiters",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Handling Non-Standard Delimiters",
    "text": "Handling Non-Standard Delimiters\n\n\nIf your file uses a delimiter other than a comma (e.g., spaces, tabs), use the sep argument.\nFor variable whitespace, use a regular expression: sep='\\s+'\n\n# Assuming a file 'ex3.txt' with whitespace as a delimiter\nresult = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\nprint(result)\n\n\n\n\n\n\n         A         B         C\naaa -0.264438 -1.026059 -0.619500\nbbb  0.927272  0.302904 -0.032399\nccc -0.264273 -0.386314 -0.217601\nddd -0.871858 -0.348382  1.100491\n\n\n\n\nPandas infers the first column as the index because there’s one fewer column name than data rows."
  },
  {
    "objectID": "qmd/pandas3ed6.html#skipping-rows",
    "href": "qmd/pandas3ed6.html#skipping-rows",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Skipping Rows",
    "text": "Skipping Rows\n\n\nUse skiprows to skip specific rows:\n\n# Assuming a file 'ex4.csv' with comments and a header\ndf = pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])\nprint(df)\n\n\n\n\n\n\n   a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo"
  },
  {
    "objectID": "qmd/pandas3ed6.html#handling-missing-values",
    "href": "qmd/pandas3ed6.html#handling-missing-values",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Handling Missing Values",
    "text": "Handling Missing Values\n\n\nMissing data is common in real-world datasets.\nPandas uses sentinels like NA and NULL to represent missing values.\nYou can customize these using na_values:\nresult = pd.read_csv(\"examples/ex5.csv\", na_values=[\"NULL\"])\nDisable default NA values with keep_default_na=False.\nSpecify different sentinels per column using a dictionary:\nsentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\nresult = pd.read_csv(\"examples/ex5.csv\", na_values=sentinels, keep_default_na=False)"
  },
  {
    "objectID": "qmd/pandas3ed6.html#pd.isna",
    "href": "qmd/pandas3ed6.html#pd.isna",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "pd.isna()",
    "text": "pd.isna()\n\n\nUse pd.isna(dataframe) to check for missing values, which returns a boolean DataFrame.\n\nresult = pd.read_csv(\"examples/ex5.csv\")\nprint(pd.isna(result))\n\n\n\n\n\n\n  something      a      b      c      d  message\n0     False  False  False  False  False     True\n1     False  False  False   True  False    False\n2     False  False  False  False  False    False"
  },
  {
    "objectID": "qmd/pandas3ed6.html#more-read_csv-arguments",
    "href": "qmd/pandas3ed6.html#more-read_csv-arguments",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "More read_csv Arguments",
    "text": "More read_csv Arguments\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\nFilesystem location, URL, or file-like object.\n\n\nsep/delimiter\nCharacter sequence or regular expression to split fields.\n\n\nheader\nRow number to use as column names (default is 0, None for no header).\n\n\nindex_col\nColumn number(s) or name(s) to use as the row index.\n\n\nnames\nList of column names.\n\n\nskiprows\nNumber of rows to skip or list of row numbers to skip.\n\n\nna_values\nSequence of values to replace with NA.\n\n\nkeep_default_na\nWhether to use the default NA value list.\n\n\ncomment\nCharacter(s) to split comments off the end of lines.\n\n\nparse_dates\nAttempt to parse data to datetime (False by default).\n\n\nconverters\nDictionary containing column number or name mapping to functions.\n\n\nnrows\nNumber of rows to read from beginning of file"
  },
  {
    "objectID": "qmd/pandas3ed6.html#even-more-read_csv-arguments",
    "href": "qmd/pandas3ed6.html#even-more-read_csv-arguments",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Even More read_csv Arguments",
    "text": "Even More read_csv Arguments\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\niterator\nReturn a TextFileReader object for reading the file piecemeal.\n\n\nchunksize\nFor iteration, the size of file chunks.\n\n\nskip_footer\nNumber of lines to ignore at the end of the file.\n\n\nverbose\nPrint various parsing information.\n\n\nencoding\nText encoding (e.g., ‘utf-8’).\n\n\nsqueeze\nIf the parsed data only contains one column, return a Series.\n\n\nthousands\nSeparator for thousands (e.g., ‘,’ or ‘.’).\n\n\ndecimal\nDecimal separator in numbers (e.g., ‘.’ or ‘,’).\n\n\nengine\nCSV parsing engine (‘c’, ‘python’, or ‘pyarrow’). ‘c’ is the default and fastest, ‘pyarrow’ is newer and faster for some files, ‘python’ is slower but has more features."
  },
  {
    "objectID": "qmd/pandas3ed6.html#reading-text-files-in-pieces",
    "href": "qmd/pandas3ed6.html#reading-text-files-in-pieces",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Reading Text Files in Pieces",
    "text": "Reading Text Files in Pieces\n\n\nFor very large files, read in chunks using chunksize:\n\nchunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\ntot = pd.Series([], dtype='int64')\nfor piece in chunker:\n    tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)\n\ntot = tot.sort_values(ascending=False)\nprint(tot[:10])\n\nThe TextFileReader object returned by read_csv with chunksize allows iteration.\nYou can also use the nrows arguments to read small number of rows."
  },
  {
    "objectID": "qmd/pandas3ed6.html#writing-data-to-text-format",
    "href": "qmd/pandas3ed6.html#writing-data-to-text-format",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Writing Data to Text Format",
    "text": "Writing Data to Text Format\n\n\nUse the to_csv method to write a DataFrame to a CSV file:\ndata = pd.read_csv(\"examples/ex5.csv\")\ndata.to_csv(\"examples/out.csv\")\nCustomize the delimiter using sep:\nimport sys\ndata.to_csv(sys.stdout, sep=\"|\") # Output to console for demonstration"
  },
  {
    "objectID": "qmd/pandas3ed6.html#handling-missing-values-in-output",
    "href": "qmd/pandas3ed6.html#handling-missing-values-in-output",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Handling Missing Values in Output",
    "text": "Handling Missing Values in Output\n\n\nBy default, missing values are represented as empty strings.\nUse na_rep to specify a different representation:\n\ndata.to_csv(sys.stdout, na_rep=\"NULL\")"
  },
  {
    "objectID": "qmd/pandas3ed6.html#controlling-row-and-column-labels",
    "href": "qmd/pandas3ed6.html#controlling-row-and-column-labels",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Controlling Row and Column Labels",
    "text": "Controlling Row and Column Labels\n\nBy default, both row and column labels are written.\nDisable them using index=False and header=False:\n\ndata.to_csv(sys.stdout, index=False, header=False)\n\nWrite a subset of columns in a specific order:\n\ndata.to_csv(sys.stdout, index=False, columns=[\"a\", \"b\", \"c\"])"
  },
  {
    "objectID": "qmd/pandas3ed6.html#working-with-other-delimited-formats",
    "href": "qmd/pandas3ed6.html#working-with-other-delimited-formats",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Working with Other Delimited Formats",
    "text": "Working with Other Delimited Formats\n\n\nFor files with single-character delimiters, use Python’s built-in csv module:\n\nimport csv\nf = open(\"examples/ex7.csv\")\nreader = csv.reader(f)\nfor line in reader:\n    print(line)\nf.close()\n\nYou can create a dictionary of data columns like this:\n\nwith open(\"examples/ex7.csv\") as f:\n    lines = list(csv.reader(f))\n\nheader, values = lines[0], lines[1:]\ndata_dict = {h: v for h, v in zip(header, zip(*values))}\nprint(data_dict)"
  },
  {
    "objectID": "qmd/pandas3ed6.html#csv-dialect-options",
    "href": "qmd/pandas3ed6.html#csv-dialect-options",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "CSV Dialect Options",
    "text": "CSV Dialect Options\n\n\nCustomize CSV parsing with the csv.Dialect class or by passing options directly to csv.reader:\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndelimiter\nOne-character string to separate fields (default is ‘,’).\n\n\nlineterminator\nLine terminator for writing (default is ‘’).\n\n\nquotechar\nQuote character for fields with special characters (default is ‘“’).\n\n\nquoting\nQuoting convention (e.g., csv.QUOTE_MINIMAL).\n\n\nskipinitialspace\nIgnore whitespace after each delimiter (default is False).\n\n\ndoublequote\nHow to handle quoting character inside a field.\n\n\nescapechar\nString to escape the delimiter if quoting is set to csv.QUOTE_NONE."
  },
  {
    "objectID": "qmd/pandas3ed6.html#json-data",
    "href": "qmd/pandas3ed6.html#json-data",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "JSON Data",
    "text": "JSON Data\n\n\nJSON (JavaScript Object Notation) is a common format for web data.\nIt’s more free-form than CSV.\nUse the json module to work with JSON data:\n\nimport json\nobj = \"\"\"\n{\"name\": \"Wes\",\n \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n \"pet\": null,\n \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n}\n\"\"\"\nresult = json.loads(obj) # Convert JSON string to Python object\nprint(result)\n\nasjson = json.dumps(result) # Convert Python object back to JSON\nprint(asjson)"
  },
  {
    "objectID": "qmd/pandas3ed6.html#json-and-pandas",
    "href": "qmd/pandas3ed6.html#json-and-pandas",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "JSON and Pandas",
    "text": "JSON and Pandas\n\n\nConvert a list of dictionaries (from JSON) to a DataFrame:\nsiblings = pd.DataFrame(result[\"siblings\"], columns=[\"name\", \"age\"])\nprint(siblings)\npd.read_json can automatically convert JSON datasets into a Series or DataFrame:\ndata = pd.read_json(\"examples/example.json\")\nprint(data)\nExport data to JSON using to_json: python     print(data.to_json())     print(data.to_json(orient=\"records\"))"
  },
  {
    "objectID": "qmd/pandas3ed6.html#xml-and-html-web-scraping",
    "href": "qmd/pandas3ed6.html#xml-and-html-web-scraping",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "XML and HTML: Web Scraping",
    "text": "XML and HTML: Web Scraping\n\n\nPython libraries like lxml, Beautiful Soup, and html5lib are used for parsing HTML and XML.\npandas.read_html uses these libraries to parse tables from HTML files:\n\ntables = pd.read_html(\"examples/fdic_failed_bank_list.html\")\nfailures = tables[0]\nprint(failures.head())\n\nYou can perform data cleaning and analysis, for example, calculating bank failures by year: python     close_timestamps = pd.to_datetime(failures['Closing Date'])     print(close_timestamps.dt.year.value_counts())"
  },
  {
    "objectID": "qmd/pandas3ed6.html#parsing-xml-with-lxml.objectify",
    "href": "qmd/pandas3ed6.html#parsing-xml-with-lxml.objectify",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Parsing XML with lxml.objectify",
    "text": "Parsing XML with lxml.objectify\n\n\nFor more complex, structured XML data use lxml.objectify\n\nfrom lxml import objectify\n\npath = \"datasets/mta_perf/Performance_MNR.xml\"\nwith open(path) as f:\n    parsed = objectify.parse(f)\n\nroot = parsed.getroot()\n\ndata = []\nskip_fields = [\"PARENT_SEQ\", \"INDICATOR_SEQ\", \"DESIRED_CHANGE\", \"DECIMAL_PLACES\"]\n\nfor elt in root.INDICATOR:\n  el_data = {}\n  for child in elt.getchildren():\n    if child.tag in skip_fields:\n        continue\n    el_data[child.tag] = child.pyval\n  data.append(el_data)\n\nperf = pd.DataFrame(data)\nprint(perf.head())\n\npandas.read_xml provides a one-line solution for this example: python     perf2 = pd.read_xml(path)     print(perf2.head())"
  },
  {
    "objectID": "qmd/pandas3ed6.html#binary-data-formats",
    "href": "qmd/pandas3ed6.html#binary-data-formats",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Binary Data Formats",
    "text": "Binary Data Formats\n\n\nPickle: Python’s built-in serialization module. Use to_pickle and read_pickle for short-term storage. python     frame = pd.read_csv(\"examples/ex1.csv\")     frame.to_pickle(\"examples/frame_pickle\")     pd.read_pickle(\"examples/frame_pickle\")\nCaution: Pickle is not recommended for long-term storage due to potential compatibility issues. ⚠️\nOther binary formats supported by pandas: HDF5, ORC, Parquet, etc. These offer advantages like compression and efficient I/O, especially for large datasets."
  },
  {
    "objectID": "qmd/pandas3ed6.html#reading-microsoft-excel-files",
    "href": "qmd/pandas3ed6.html#reading-microsoft-excel-files",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Reading Microsoft Excel Files",
    "text": "Reading Microsoft Excel Files\n\n\nUse pandas.ExcelFile or pandas.read_excel:\n\n# Using ExcelFile (efficient for multiple sheets)\nxlsx = pd.ExcelFile(\"examples/ex1.xlsx\")\ndf = xlsx.parse(sheet_name=\"Sheet1\", index_col=0) #read first sheet\n\n#Using read_excel\nframe = pd.read_excel(\"examples/ex1.xlsx\", sheet_name=\"Sheet1\")\n\nWrite pandas data to excel:\n\nwriter = pd.ExcelWriter(\"examples/ex2.xlsx\")\nframe.to_excel(writer, \"Sheet1\")\nwriter.save()\n\nOr simply: frame.to_excel(\"examples/ex2.xlsx\")"
  },
  {
    "objectID": "qmd/pandas3ed6.html#using-hdf5-format",
    "href": "qmd/pandas3ed6.html#using-hdf5-format",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Using HDF5 Format",
    "text": "Using HDF5 Format\n\n\nHDF5 (Hierarchical Data Format) is designed for storing large, scientific array data.\nInstall PyTables: conda install pytables or pip install tables\n\nframe = pd.DataFrame({\"a\": np.random.standard_normal(100)})\nstore = pd.HDFStore(\"examples/mydata.h5\")  # Create HDFStore object\nstore[\"obj1\"] = frame         # Store DataFrame like a dictionary\nstore[\"obj1_col\"] = frame[\"a\"] # Store a Series\nprint(store[\"obj1\"]) #retrieve stored objects\n\nHDFStore supports two storage schemas: fixed and table.\n\n-table schema support query operation, like:\nstore.put(\"obj2\", frame, format=\"table\")\nprint(store.select(\"obj2\", where=[\"index &gt;= 10 and index &lt;= 15\"]))\nstore.close()\n\npandas.read_hdf provides a shortcut.\nHDF5 is not a database. It’s best for write-once, read-many datasets."
  },
  {
    "objectID": "qmd/pandas3ed6.html#interacting-with-web-apis",
    "href": "qmd/pandas3ed6.html#interacting-with-web-apis",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Interacting with Web APIs",
    "text": "Interacting with Web APIs\n\n\nMany websites offer data through public APIs, often returning JSON.\nUse the requests library to access these APIs:\nimport requests\nurl = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\nresp = requests.get(url)\nresp.raise_for_status() # Check for HTTP errors\ndata = resp.json()      # Parse JSON response\nCreate a DataFrame from the API response: python     issues = pd.DataFrame(data, columns=[\"number\", \"title\", \"labels\", \"state\"])     print(issues)"
  },
  {
    "objectID": "qmd/pandas3ed6.html#interacting-with-databases",
    "href": "qmd/pandas3ed6.html#interacting-with-databases",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Interacting with Databases",
    "text": "Interacting with Databases\n\n\nSQL-based relational databases are common in business settings.\nUse sqlite3 (built-in) for a simple example:\n\nimport sqlite3\nquery = \"\"\"\nCREATE TABLE test\n(a VARCHAR(20), b VARCHAR(20),\n c REAL,        d INTEGER\n);\"\"\"\ncon = sqlite3.connect(\"mydata.sqlite\")\ncon.execute(query)\ncon.commit()\n\ndata = [(\"Atlanta\", \"Georgia\", 1.25, 6),\n        (\"Tallahassee\", \"Florida\", 2.6, 3),\n        (\"Sacramento\", \"California\", 1.7, 5)]\nstmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\ncon.executemany(stmt, data)\ncon.commit()"
  },
  {
    "objectID": "qmd/pandas3ed6.html#reading-data-from-database",
    "href": "qmd/pandas3ed6.html#reading-data-from-database",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Reading Data from Database",
    "text": "Reading Data from Database\n\n\nRetrieve data and create a DataFrame:\ncursor = con.execute(\"SELECT * FROM test\")\nrows = cursor.fetchall()\ndf = pd.DataFrame(rows, columns=[x[0] for x in cursor.description])\nprint(df)\nSQLAlchemy provides a higher-level interface, abstracting differences between SQL databases. Install using conda install sqlalchemy. python     import sqlalchemy as sqla     db = sqla.create_engine(\"sqlite:///mydata.sqlite\")     df_sql = pd.read_sql(\"SELECT * FROM test\", db)     print(df_sql)"
  },
  {
    "objectID": "qmd/pandas3ed6.html#summary",
    "href": "qmd/pandas3ed6.html#summary",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Summary",
    "text": "Summary\n\n\nWe’ve covered a wide range of data loading techniques using pandas:\n\nReading and writing text files (CSV, delimited).\nHandling various file formats (JSON, XML, HTML, Excel, HDF5).\nInteracting with web APIs and databases.\n\nThese skills are fundamental for any data analysis project.\nEfficient data loading is key to efficient analysis! ⚡️"
  },
  {
    "objectID": "qmd/pandas3ed6.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed6.html#thoughts-and-discussion",
    "title": "Chapter 6: Data Loading, Storage, and File Formats",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\n\nWhich data formats have you encountered in your own work or studies?\nWhat are some challenges you’ve faced when loading data?\nHow might you choose between different file formats (e.g., CSV, JSON, HDF5) for a particular project? Consider factors like file size, complexity, and read/write frequency.\nCan you think of other web APIs that might be interesting to explore?\nHow can efficient data loading techniques improve the overall data analysis workflow?\nBeyond the tools discussed, what are some other data sources you might encounter (e.g., streaming data, sensor data)?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "我是邱飞，这是我的个人网站，\n用于分享一些数据分析文章，还有个人的记录和资料。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "python语言与数据分析",
    "section": "",
    "text": "教材采用《Python for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter 3rd Edition》\n\n\n\nPython for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter 3rd Edition\n\n\n教材官网：Python for Data Analysis"
  },
  {
    "objectID": "index.html#教材",
    "href": "index.html#教材",
    "title": "python语言与数据分析",
    "section": "",
    "text": "教材采用《Python for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter 3rd Edition》\n\n\n\nPython for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter 3rd Edition\n\n\n教材官网：Python for Data Analysis"
  },
  {
    "objectID": "index.html#ppt",
    "href": "index.html#ppt",
    "title": "python语言与数据分析",
    "section": "ppt",
    "text": "ppt\n 第一章 \n 第二章 \n 第三章 \n 第四章 \n 第五章 \n 第六章 \n 第七章 \n 第八章 \n 第九章 \n 第十章 \n 第十一章 \n 第十二章 \n 第十三章"
  },
  {
    "objectID": "qmd/pandas3ed2.html",
    "href": "qmd/pandas3ed2.html",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "This chapter introduces the fundamental concepts of Python, IPython, and Jupyter Notebooks, which are essential tools for data analysis. We’ll cover:\n\nPython Language Basics: Core syntax and semantics.\nIPython: An enhanced interactive Python shell.\nJupyter Notebooks: Web-based interactive computing environments.\n\nThe evolution of Python’s data analysis capabilities is akin to a “chicken-and-egg” scenario. Initially, libraries like pandas, scikit-learn, and statsmodels were less developed. Today, these libraries are mature, forming a robust ecosystem for data science, machine learning, and statistical computing. This makes Python a great tool for anyone who is interested in working with data.\n\n\n\n\n\n\n\n\n\n\nIdeal for Data Wrangling: Python excels at transforming messy, unstructured data into a clean, tabular format. This is crucial for preparing datasets for analysis.\nRich Ecosystem of Libraries: Libraries like pandas, NumPy, scikit-learn, and Matplotlib provide powerful tools for data manipulation, analysis, and visualization.\nExpressive and Readable Syntax: The readability makes Python easy to learn and use, especially for beginners in programming.\n\n\n\n\n\n\n\n\n\n\nThe best way to learn is by doing! We’ll explore many of these concepts through live IPython or Jupyter sessions. Follow along with the examples to maximize your learning experience.\n\nFamiliarity with the commands of the keyboard-driven, console-like development environment is also part of the learning process.\n\n\n\n\n\nPython is an interpreted language. The interpreter executes code line by line.\nLaunch the standard interpreter with the python command.\n\n$ python\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\n[GCC 10.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; a = 5\n&gt;&gt;&gt; print(a)\n5\n\n&gt;&gt;&gt; is the prompt where you type your code.\nExit with exit() or Ctrl-D (Linux/macOS).\n\n\n\n\n\nCreate a .py file (e.g., hello_world.py).\nRun it from the terminal: python hello_world.py. Make sure the file is in your current working directory.\n\n\n# hello_world.py\nprint(\"Hello world\")\n\nHello world\n\n\n$ python hello_world.py\nHello world\n\n\n\n\nIPython is an enhanced Python interpreter. It’s designed for interactive data analysis.\nJupyter Notebooks are web-based environments built on top of IPython. They provide a rich, interactive experience for coding, visualization, and documentation.\nLaunch IPython with the ipython command.\n\n$ ipython\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.31.1 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]:\n\nNotice the In [1]: prompt, which is different from the standard &gt;&gt;&gt;.\n\n\n\n\n\nExecute code by typing it and pressing Enter.\nIPython displays a string representation of objects when you type their name.\n\n\nIn [1]: a = 5\n\nIn [2]: a\nOut[2]: 5\n\nIn [3]: import numpy as np\n\nIn [4]: data = [np.random.standard_normal() for i in range(7)]\n\nIn [5]: data\nOut[5]:\n[-0.20470765948471295,\n 0.47894333805754824,\n -0.5194387150567381,\n -0.55573030434749,\n 1.9657805725027142,\n 1.3934058329729904,\n 0.09290787674371767]\n\n\nIPython’s output is often more readable than standard Python’s print().\n\n\n\n\n\nJupyter Notebook is a powerful interactive document for code, text (with Markdown), visualizations, and more.\nLaunch with: jupyter notebook\n\n$ jupyter notebook\n[I 15:20:52.739 NotebookApp] Serving notebooks from local directory:\n/home/wesm/code/pydata-book\n...\n[I 15:20:52.740 NotebookApp] Use Control-C to stop this server and shut down\nall kernels...\n\nJupyter usually opens automatically in your web browser. If not, navigate to the address provided (e.g., http://localhost:8888).\n\n\n\n\n\n\nLanding Page: Shows files in the directory where you started Jupyter.\nNew Notebook: Click “New” -&gt; “Python 3” to create a new notebook.\n\n\n\n\n\n\nCode Cells: Where you write and execute Python code. Press Shift-Enter to run a cell.\nMarkdown Cells: For text, explanations, and documentation (using Markdown syntax).\nSave the notebook, it will create a file with the extension .ipynb, which is a self-contained file format that contains all the current content of the notebook.\n\n\n\n\n\nThis image displays an example of an existing Jupyter notebook containing code for data analysis, along with descriptive text. The notebook includes:\n\nTitle: “Introductory examples”.\nSection Heading: “1.usa.gov data from bit.ly”.\nCode Cells:\n\n%pwd: Displays the current working directory.\nReading and processing data from a file.\nUsing the json library to work with JSON data.\nAccessing and printing specific elements within the data.\n\nText Cell: A brief note on “Counting time zones in pure Python”.\n\n\n\n\n\nTab Completion: A huge time-saver! Press Tab while typing to:\n\nComplete variable names.\nShow available methods and attributes of objects.\nComplete file paths.\nSee function keyword arguments.\n\n\n\nIn [1]: an_apple = 27\n\nIn [2]: an_example = 42\n\nIn [3]: an&lt;Tab&gt;  # Press Tab here\nan_apple  an_example  any\n\n\n\n\n\nIn [3]: b = [1, 2, 3]\n\nIn [4]: b.&lt;Tab&gt; # Press Tab after the dot\nappend()  count()   insert()  reverse()\nclear()   extend()  pop()     sort()\ncopy()    index()   remove()\n\n\nIn [1]: import datetime\n\nIn [2]: datetime.&lt;Tab&gt; # Press Tab after the dot\ndate       MAXYEAR    timedelta\ndatetime   MINYEAR    timezone\ndatetime_CAPI time      tzinfo\n\n\nIPython hides methods and attributes starting with underscores by default.\n\n\n\n\n\n\nTab completion also works for function keyword arguments, including the = sign!\n\n\n\n\n\nIntrospection: Get information about an object using ?.\n\n\nIn [1]: b = [1, 2, 3]\n\nIn [2]: b?\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:\nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\nUse ? after a function to see its docstring (if available).\nIntrospection also shows function or instance method and docstrings.\n\n\n\n\n\ndef add_numbers(a, b):\n    \"\"\"\n    Add two numbers together\n\n    Returns\n    -------\n    the_sum : type of arguments\n    \"\"\"\n    return a + b\n\nIn [6]: add_numbers?\nSignature: add_numbers(a, b)\nDocstring:\nAdd two numbers together\n\nReturns\n-------\nthe_sum : type of arguments\nFile:      &lt;ipython-input-9-6a548a216e27&gt;\nType:      function\n\n\nThe ? operator displays the docstring, providing information about the function’s purpose and usage.\n\n\n\n\n\nUse * with ? to search the IPython namespace.\n\n\nIn [9]: import numpy as np\n\nIn [10]: np.*load*?\nnp.__loader__\nnp.load\nnp.loads\nnp.loadtxt\n\n\nThis shows all names in the NumPy namespace containing “load”.\n\n\n\n\nNow, let’s dive into the core syntax and semantics of the Python language itself.\n\n\n\nPython emphasizes readability, simplicity, and explicitness. It’s often described as “executable pseudocode.”\n\n\n\n\n\nPython uses indentation (spaces or tabs) to structure code, not curly braces {} like many other languages.\n\n\nfor x in array:\n    if x &lt; pivot:\n        less.append(x)\n    else:\n        greater.append(x)\n\n\nA colon : indicates the start of an indented block.\nConsistent indentation is crucial! Use four spaces for indentation.\n\n\n\n\n\n\n\nNote\n\n\n\nIt is highly recommended to use four spaces as the default indent and to replace tabs with four spaces. Many text editors have settings that will automatically replace tab stops with spaces.\n\n\n\n\n\n\n\nPython statements generally do not need to be terminated by semicolons.\nSemicolons can separate multiple statements on a single line, but this is generally discouraged for readability.\n\n\na = 5; b = 6; c = 7  # Generally avoid this style\n\n\n\n\n\nIn Python, everything is an object: numbers, strings, lists, functions, classes, modules, etc.\nEach object has a type (e.g., int, str, list, function) and internal data.\nThis makes Python very flexible.\n\n\n\n\n\nUse the hash mark # to create comments. Anything after # on a line is ignored by the interpreter.\n\n\nresults = []\nfor line in file_handle:\n    # keep the empty lines for now\n    # if len(line) == 0:\n    #     continue\n    results.append(line.replace(\"foo\", \"bar\"))\n\nprint(\"Reached this line\")  # Simple status report\n\n\n\n\n\nCall functions with parentheses () and pass arguments (if any).\nObjects often have methods (functions attached to the object) that you call using the dot . syntax.\n\n\nresult = f(x, y, z)\ng()\n\nobj.some_method(x, y, z)\n\nresult = f(a, b, c, d=5, e=\"foo\")  # Positional and keyword arguments\n\n\n\n\n\nAssigning a variable creates a reference to the object on the right-hand side of the =.\n\n\na = [1, 2, 3]\nb = a  # b now refers to the *same* list as a\na.append(4)\nprint(b)  # Output: [1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n\n\nImportant: In Python, a and b point to the same object in memory, not copies.\n\n\n\n\n\n\nThis diagram illustrates that a and b are simply names that refer to the same list object in memory.\n\n\n\n\n\n\n\nNote\n\n\n\nAssignment is also known as binding because we are binding a name to an object. Assigned variable names are sometimes referred to as bound variables.\n\n\n\n\n\n\nVariables in Python don’t have an inherent type. The type is associated with the object the variable refers to.\n\n\na = 5\nprint(type(a))  # Output: &lt;class 'int'&gt;\n\na = \"foo\"\nprint(type(a))  # Output: &lt;class 'str'&gt;\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n\n\n\nPython is strongly typed: Objects have specific types, and implicit conversions are limited.\n\n\n# \"5\" + 5  # This would cause a TypeError\n\n\n\n\n\na = 4.5\nb = 2\nprint(f\"a is {type(a)}, b is {type(b)}\")  # String formatting\nprint(a / b)\n\na is &lt;class 'float'&gt;, b is &lt;class 'int'&gt;\n2.25\n\n\n\nString formatting is f”a is {type(a)}, b is {type(b)}”\n\n\nEven though b is an integer, it’s implicitly converted to a float for the division.\n\n\n\n\n\nUse isinstance() to check if an object is an instance of a particular type (or one of several types).\n\n\na = 5\nprint(isinstance(a, int))  # Output: True\n\nb = 4.5\nprint(isinstance(a, (int, float)))  # Output: True\nprint(isinstance(b, (int, float)))  # Output: True\n\nTrue\nTrue\nTrue\n\n\n\n\n\n\nObjects have attributes (data stored “inside” the object) and methods (functions associated with the object).\nAccess them using obj.attribute_name.\nWe use getattr function can get object’s attributes and methods by name.\n\n\na = \"foo\"\n# a.&lt;Press Tab&gt;  # See available attributes and methods\n\nprint(getattr(a, \"split\"))\n\n&lt;built-in method split of str object at 0x7f008a5394d0&gt;\n\n\n\n\n\n\n“If it walks like a duck and quacks like a duck, then it’s a duck.”\nCheck for specific behavior (e.g., iterability) rather than strict type.\n\n\ndef isiterable(obj):\n    try:\n        iter(obj)\n        return True\n    except TypeError:  # not iterable\n        return False\n\nprint(isiterable(\"a string\"))  # Output: True\nprint(isiterable([1, 2, 3]))  # Output: True\nprint(isiterable(5))  # Output: False\n\nTrue\nTrue\nFalse\n\n\n\n\n\n\nA module is a .py file containing Python code.\nUse import to access variables and functions from other modules.\n\n\n# some_module.py\nPI = 3.14159\n\ndef f(x):\n    return x + 2\n\ndef g(a, b):\n    return a + b\n\n\n# In another file:\nimport some_module\nresult = some_module.f(5)\npi = some_module.PI\n\n# Or:\nfrom some_module import g, PI\nresult = g(5, PI)\n\n# Or with different names:\nimport some_module as sm\nfrom some_module import PI as pi, g as gf\n\n\n\n\n\nPython uses standard mathematical syntax for binary operations and comparisons.\n\n\nprint(5 - 7)\nprint(12 + 21.5)\nprint(5 &lt;= 2)\n\n-2\n33.5\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\nOperation\nDescription\n\n\n\n\na + b\nAdd a and b\n\n\na - b\nSubtract b from a\n\n\na * b\nMultiply a by b\n\n\na / b\nDivide a by b\n\n\na // b\nFloor-divide a by b, dropping any fractional remainder\n\n\na ** b\nRaise a to the b power\n\n\na & b\nTrue if both a and b are True; for integers, take the bitwise AND\n\n\na \\| b\nTrue if either a or b is True; for integers, take the bitwise OR\n\n\na ^ b\nFor Booleans, True if a or b is True, but not both; for integers, take the bitwise EXCLUSIVE-OR\n\n\na == b\nTrue if a equals b\n\n\na != b\nTrue if a is not equal to b\n\n\na &lt; b, a &lt;= b\nTrue if a is less than (less than or equal to) b\n\n\na &gt; b, a &gt;= b\nTrue if a is greater than (greater than or equal to) b\n\n\na is b\nTrue if a and b reference the same Python object\n\n\na is not b\nTrue if a and b reference different Python objects\n\n\n\n\n\n\n\nis checks if two variables refer to the same object.\nis not check if two objects are not the same\n== checks for equality of value.\n\n\na = [1, 2, 3]\nb = a\nc = list(a)  # Creates a *new* list (a copy)\n\nprint(a is b)      # Output: True\nprint(a is not c)  # Output: True\nprint(a == c)      # Output: True\n\nTrue\nTrue\nTrue\n\n\n\n\n\n\nMutable objects (lists, dicts, NumPy arrays, etc.) can be modified in place.\nImmutable objects (strings, tuples) cannot be changed after creation.\n\n\na_list = [\"foo\", 2, [4, 5]]\na_list[2] = (3, 4)\nprint(a_list)  # Output: ['foo', 2, (3, 4)]\n\n# a_tuple = (3, 5, (4, 5))\n# a_tuple[1] = \"four\"  # This would cause a TypeError\n\n['foo', 2, (3, 4)]\n\n\n\n\n\n\nPython has built-in types for handling numerical data, strings, Booleans, and dates/times. These are called scalar types.\n\n\n\n\nType\nDescription\n\n\n\n\nNone\nThe Python “null” value\n\n\nstr\nString type; holds Unicode strings\n\n\nbytes\nRaw binary data\n\n\nfloat\nDouble-precision floating-point number\n\n\nbool\nA Boolean True or False value\n\n\nint\nArbitrary precision integer\n\n\n\n\n\n\n\nint: Can store arbitrarily large integers.\nfloat: Represents double-precision floating-point numbers (like double in C/C++).\n\n\nival = 17239871\nprint(ival ** 6)\n\nfval = 7.243\nfval2 = 6.78e-5  # Scientific notation\n\n26254519291092456596965462913230729701102721\n\n\n\nInteger division resulting in a non-whole number always yields a float. Use // for floor division.\n\n\n\n\n\nUse single quotes '...' or double quotes \"...\" to create string literals.\nTriple quotes '''...''' or \"\"\"...\"\"\" for multiline strings.\n\n\na = 'one way of writing a string'\nb = \"another way\"\nc = \"\"\"\nThis is a longer string that\nspans multiple lines\n\"\"\"\n\n\nPython strings are immutable.\n\n\n\n\n\nMany built-in string methods are available (e.g., count(), replace(), split()).\n\n\na = \"this is a string\"\n# a[10] = 'f'  # TypeError: 'str' object does not support item assignment\n\nb = a.replace(\"string\", \"longer string\")\nprint(b)\nprint(a)\n\nthis is a longer string\nthis is a string\n\n\n\nConvert other objects to strings using str().\n\n\n\n\n\nStrings are sequences of Unicode characters and can be treated like lists/tuples.\n\n\ns = \"python\"\nprint(list(s))\nprint(s[:3])\n\n['p', 'y', 't', 'h', 'o', 'n']\npyt\n\n\n\nBackslash \\ is an escape character. Use raw strings (prefix with r) to avoid escaping.\n\n\ns = \"12\\\\\\\\34\"  # String with two backslashes\nprint(s)\n\nraw_string = r\"this\\has\\no\\special\\characters\"\nprint(raw_string)\n\n12\\\\34\nthis\\has\\no\\special\\characters\n\n\n\n\n\n\nAdding strings together concatenates them.\n\n\na = \"this is the first half \"\nb = \"and this is the second half\"\nprint(a + b)\n\nthis is the first half and this is the second half\n\n\n\nUse string formatting (the format() method or f-strings) for more complex string construction.\n\n\n\n\n\namount = 10\nrate = 88.46\ncurrency = \"Pesos\"\nresult = f\"{amount} {currency} is worth US${amount / rate:.2f}\"\nprint(result)\n\n10 Pesos is worth US$0.11\n\n\n\nf-strings (formatted string literals) are a concise way to embed expressions inside strings.\n\n\n\n\n\nIn Python 3, Unicode is the first-class string type.\nencode() converts a Unicode string to bytes (e.g., UTF-8).\ndecode() converts bytes back to a Unicode string.\n\n\nval = \"español\"\nval_utf8 = val.encode(\"utf-8\")\nprint(val_utf8)\nprint(type(val_utf8))\n\nprint(val_utf8.decode(\"utf-8\"))\n\nb'espa\\xc3\\xb1ol'\n&lt;class 'bytes'&gt;\nespañol\n\n\n\n\n\n\nTrue and False are the Boolean values.\nComparisons and conditional expressions evaluate to True or False.\nCombine with and, or, and not.\n\n\nprint(True and True)\nprint(False or True)\n\nprint(int(False))  # Output: 0\nprint(int(True))   # Output: 1\n\nTrue\nTrue\n0\n1\n\n\n\n\n\n\nstr(), bool(), int(), and float() can be used to cast values to different types.\n\n\ns = \"3.14159\"\nfval = float(s)\nprint(type(fval))\nprint(int(fval))\nprint(bool(fval))\nprint(bool(0))  # 0 casts to False, other numbers to True\n\n&lt;class 'float'&gt;\n3\nTrue\nFalse\n\n\n\n\n\n\nNone is the Python null value type. It represents the absence of a value.\nIt is also the default return value of a function if there isn’t return statement in the function.\n\n\na = None\nprint(a is None)  # Output: True\n\nb = 5\nprint(b is not None)  # Output: True\n\nTrue\nTrue\n\n\n\nNone is often used as a default value for function arguments.\n\n\n\n\n\nThe datetime module provides datetime, date, and time types.\n\n\nfrom datetime import datetime, date, time\n\ndt = datetime(2011, 10, 29, 20, 30, 21)\nprint(dt.day)\nprint(dt.minute)\nprint(dt.date())\nprint(dt.time())\n\n29\n30\n2011-10-29\n20:30:21\n\n\n\n\n\n\nstrftime() formats a datetime object as a string.\nstrptime() parses a string into a datetime object.\n\n\nprint(dt.strftime(\"%Y-%m-%d %H:%M\"))\n\ndt2 = datetime.strptime(\"20091031\", \"%Y%m%d\")\nprint(dt2)\n\n2011-10-29 20:30\n2009-10-31 00:00:00\n\n\n\nRefer to Python’s documentation for a complete list of format codes.\nSince datetime.datetime is an immutable type, methods like strftime and strptime will always produce new objects.\n\n\n\n\n\nSubtracting two datetime objects produces a timedelta object.\nAdding a timedelta to a datetime produces a new, shifted datetime.\n\n\ndt2 = datetime(2011, 11, 15, 22, 30)\ndelta = dt2 - dt\nprint(delta)\nprint(type(delta))\nprint(dt + delta)\n\n17 days, 1:59:39\n&lt;class 'datetime.timedelta'&gt;\n2011-11-15 22:30:00\n\n\n\n\n\n\nif statements execute a block of code if a condition is true.\nelif (else if) provides additional conditions.\nelse is a catchall block.\n\n\nx = -5\nif x &lt; 0:\n    print(\"It's negative\")\nelif x == 0:\n    print(\"Equal to zero\")\nelif 0 &lt; x &lt; 5:\n    print(\"Positive but smaller than 5\")\nelse:\n    print(\"Positive and larger than or equal to 5\")\n\nIt's negative\n\n\n\nConditions with and and or are evaluated left to right and short-circuit.\n\n\n\n\n\nIterate over a collection (list, tuple, etc.) or an iterator.\n\n\nfor value in collection:\n    # do something with value\n\n\ncontinue skips the rest of the current iteration.\nbreak exits the loop entirely.\n\n\n\n\n\nsequence = [1, 2, None, 4, None, 5]\ntotal = 0\nfor value in sequence:\n    if value is None:\n        continue  # Skip None values\n    total += value\n\nsequence = [1, 2, 0, 4, 6, 5, 2, 1]\ntotal_until_5 = 0\nfor value in sequence:\n    if value == 5:\n        break  # Exit loop when we reach 5\n    total_until_5 += value\n\n\n\n\n\nfor i in range(4):\n    for j in range(4):\n        if j &gt; i:\n            break  # Only breaks out of the inner loop\n        print((i, j))\n\n(0, 0)\n(1, 0)\n(1, 1)\n(2, 0)\n(2, 1)\n(2, 2)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n\n\n\n\n\n\nExecute a block of code repeatedly as long as a condition is true.\n\n\nx = 256\ntotal = 0\nwhile x &gt; 0:\n    if total &gt; 500:\n        break  # Exit loop if total exceeds 500\n    total += x\n    x = x // 2\n\n\n\n\n\npass is a “no-op” statement. It does nothing. It’s used where a statement is syntactically required but you don’t want to execute any code.\n\n\nif x &lt; 0:\n    print(\"negative!\")\nelif x == 0:\n    # TODO: put something smart here\n    pass\nelse:\n    print(\"positive!\")\n\npositive!\n\n\n\n\n\n\nrange() generates a sequence of evenly spaced integers.\nrange(stop): Generates integers from 0 up to (but not including) stop.\nrange(start, stop): Generates integers from start up to (but not including) stop.\nrange(start, stop, step): Generates integers with a specified step.\n\n\nprint(list(range(10)))\nprint(list(range(0, 20, 2)))\nprint(list(range(5, 0, -1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n[5, 4, 3, 2, 1]\n\n\n\n\n\n\nseq = [1, 2, 3, 4]\nfor i in range(len(seq)):\n    print(f\"element {i}: {seq[i]}\")\n\nelement 0: 1\nelement 1: 2\nelement 2: 3\nelement 3: 4\n\n\n\nA common use of range is for iterating through sequences by index.\n\n\n\n\n\nWe’ve covered the core building blocks of Python: data types, operators, control flow, and basic usage of IPython and Jupyter Notebooks.\nThese concepts form the foundation for everything else we’ll do in data analysis with Python.\nRemember to practice and experiment!\n\n\n\n\n\nHow does Python’s “everything is an object” philosophy compare to other programming languages you know?\nWhat are the advantages of using Jupyter Notebooks for data analysis compared to writing scripts in a text editor?\nCan you think of situations where duck typing would be particularly useful?\nHow might you use the datetime module in a real-world data analysis project?\nWhat are the differences between mutable and immutable objects? What are their pros and cons respectively?"
  },
  {
    "objectID": "qmd/pandas3ed2.html#introduction",
    "href": "qmd/pandas3ed2.html#introduction",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "This chapter introduces the fundamental concepts of Python, IPython, and Jupyter Notebooks, which are essential tools for data analysis. We’ll cover:\n\nPython Language Basics: Core syntax and semantics.\nIPython: An enhanced interactive Python shell.\nJupyter Notebooks: Web-based interactive computing environments.\n\nThe evolution of Python’s data analysis capabilities is akin to a “chicken-and-egg” scenario. Initially, libraries like pandas, scikit-learn, and statsmodels were less developed. Today, these libraries are mature, forming a robust ecosystem for data science, machine learning, and statistical computing. This makes Python a great tool for anyone who is interested in working with data."
  },
  {
    "objectID": "qmd/pandas3ed2.html#why-python-for-data-analysis",
    "href": "qmd/pandas3ed2.html#why-python-for-data-analysis",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Ideal for Data Wrangling: Python excels at transforming messy, unstructured data into a clean, tabular format. This is crucial for preparing datasets for analysis.\nRich Ecosystem of Libraries: Libraries like pandas, NumPy, scikit-learn, and Matplotlib provide powerful tools for data manipulation, analysis, and visualization.\nExpressive and Readable Syntax: The readability makes Python easy to learn and use, especially for beginners in programming."
  },
  {
    "objectID": "qmd/pandas3ed2.html#getting-started-live-coding",
    "href": "qmd/pandas3ed2.html#getting-started-live-coding",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "The best way to learn is by doing! We’ll explore many of these concepts through live IPython or Jupyter sessions. Follow along with the examples to maximize your learning experience.\n\nFamiliarity with the commands of the keyboard-driven, console-like development environment is also part of the learning process."
  },
  {
    "objectID": "qmd/pandas3ed2.html#the-python-interpreter",
    "href": "qmd/pandas3ed2.html#the-python-interpreter",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Python is an interpreted language. The interpreter executes code line by line.\nLaunch the standard interpreter with the python command.\n\n$ python\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\n[GCC 10.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; a = 5\n&gt;&gt;&gt; print(a)\n5\n\n&gt;&gt;&gt; is the prompt where you type your code.\nExit with exit() or Ctrl-D (Linux/macOS)."
  },
  {
    "objectID": "qmd/pandas3ed2.html#running-python-programs",
    "href": "qmd/pandas3ed2.html#running-python-programs",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Create a .py file (e.g., hello_world.py).\nRun it from the terminal: python hello_world.py. Make sure the file is in your current working directory.\n\n\n# hello_world.py\nprint(\"Hello world\")\n\nHello world\n\n\n$ python hello_world.py\nHello world"
  },
  {
    "objectID": "qmd/pandas3ed2.html#ipython-basics",
    "href": "qmd/pandas3ed2.html#ipython-basics",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "IPython is an enhanced Python interpreter. It’s designed for interactive data analysis.\nJupyter Notebooks are web-based environments built on top of IPython. They provide a rich, interactive experience for coding, visualization, and documentation.\nLaunch IPython with the ipython command.\n\n$ ipython\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.31.1 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]:\n\nNotice the In [1]: prompt, which is different from the standard &gt;&gt;&gt;."
  },
  {
    "objectID": "qmd/pandas3ed2.html#ipython-running-code",
    "href": "qmd/pandas3ed2.html#ipython-running-code",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Execute code by typing it and pressing Enter.\nIPython displays a string representation of objects when you type their name.\n\n\nIn [1]: a = 5\n\nIn [2]: a\nOut[2]: 5\n\nIn [3]: import numpy as np\n\nIn [4]: data = [np.random.standard_normal() for i in range(7)]\n\nIn [5]: data\nOut[5]:\n[-0.20470765948471295,\n 0.47894333805754824,\n -0.5194387150567381,\n -0.55573030434749,\n 1.9657805725027142,\n 1.3934058329729904,\n 0.09290787674371767]\n\n\nIPython’s output is often more readable than standard Python’s print()."
  },
  {
    "objectID": "qmd/pandas3ed2.html#running-the-jupyter-notebook",
    "href": "qmd/pandas3ed2.html#running-the-jupyter-notebook",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Jupyter Notebook is a powerful interactive document for code, text (with Markdown), visualizations, and more.\nLaunch with: jupyter notebook\n\n$ jupyter notebook\n[I 15:20:52.739 NotebookApp] Serving notebooks from local directory:\n/home/wesm/code/pydata-book\n...\n[I 15:20:52.740 NotebookApp] Use Control-C to stop this server and shut down\nall kernels...\n\nJupyter usually opens automatically in your web browser. If not, navigate to the address provided (e.g., http://localhost:8888)."
  },
  {
    "objectID": "qmd/pandas3ed2.html#jupyter-notebook-interface",
    "href": "qmd/pandas3ed2.html#jupyter-notebook-interface",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Landing Page: Shows files in the directory where you started Jupyter.\nNew Notebook: Click “New” -&gt; “Python 3” to create a new notebook."
  },
  {
    "objectID": "qmd/pandas3ed2.html#jupyter-notebook-cells",
    "href": "qmd/pandas3ed2.html#jupyter-notebook-cells",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Code Cells: Where you write and execute Python code. Press Shift-Enter to run a cell.\nMarkdown Cells: For text, explanations, and documentation (using Markdown syntax).\nSave the notebook, it will create a file with the extension .ipynb, which is a self-contained file format that contains all the current content of the notebook."
  },
  {
    "objectID": "qmd/pandas3ed2.html#jupyter-notebook-example-view",
    "href": "qmd/pandas3ed2.html#jupyter-notebook-example-view",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "This image displays an example of an existing Jupyter notebook containing code for data analysis, along with descriptive text. The notebook includes:\n\nTitle: “Introductory examples”.\nSection Heading: “1.usa.gov data from bit.ly”.\nCode Cells:\n\n%pwd: Displays the current working directory.\nReading and processing data from a file.\nUsing the json library to work with JSON data.\nAccessing and printing specific elements within the data.\n\nText Cell: A brief note on “Counting time zones in pure Python”."
  },
  {
    "objectID": "qmd/pandas3ed2.html#ipython-and-jupyter-tab-completion",
    "href": "qmd/pandas3ed2.html#ipython-and-jupyter-tab-completion",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Tab Completion: A huge time-saver! Press Tab while typing to:\n\nComplete variable names.\nShow available methods and attributes of objects.\nComplete file paths.\nSee function keyword arguments.\n\n\n\nIn [1]: an_apple = 27\n\nIn [2]: an_example = 42\n\nIn [3]: an&lt;Tab&gt;  # Press Tab here\nan_apple  an_example  any"
  },
  {
    "objectID": "qmd/pandas3ed2.html#tab-completion-methods-and-modules",
    "href": "qmd/pandas3ed2.html#tab-completion-methods-and-modules",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "In [3]: b = [1, 2, 3]\n\nIn [4]: b.&lt;Tab&gt; # Press Tab after the dot\nappend()  count()   insert()  reverse()\nclear()   extend()  pop()     sort()\ncopy()    index()   remove()\n\n\nIn [1]: import datetime\n\nIn [2]: datetime.&lt;Tab&gt; # Press Tab after the dot\ndate       MAXYEAR    timedelta\ndatetime   MINYEAR    timezone\ndatetime_CAPI time      tzinfo\n\n\nIPython hides methods and attributes starting with underscores by default."
  },
  {
    "objectID": "qmd/pandas3ed2.html#tab-completion-function-arguments",
    "href": "qmd/pandas3ed2.html#tab-completion-function-arguments",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Tab completion also works for function keyword arguments, including the = sign!"
  },
  {
    "objectID": "qmd/pandas3ed2.html#ipython-and-jupyter-introspection",
    "href": "qmd/pandas3ed2.html#ipython-and-jupyter-introspection",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Introspection: Get information about an object using ?.\n\n\nIn [1]: b = [1, 2, 3]\n\nIn [2]: b?\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:\nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\nUse ? after a function to see its docstring (if available).\nIntrospection also shows function or instance method and docstrings."
  },
  {
    "objectID": "qmd/pandas3ed2.html#introspection-example-with-a-function",
    "href": "qmd/pandas3ed2.html#introspection-example-with-a-function",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "def add_numbers(a, b):\n    \"\"\"\n    Add two numbers together\n\n    Returns\n    -------\n    the_sum : type of arguments\n    \"\"\"\n    return a + b\n\nIn [6]: add_numbers?\nSignature: add_numbers(a, b)\nDocstring:\nAdd two numbers together\n\nReturns\n-------\nthe_sum : type of arguments\nFile:      &lt;ipython-input-9-6a548a216e27&gt;\nType:      function\n\n\nThe ? operator displays the docstring, providing information about the function’s purpose and usage."
  },
  {
    "objectID": "qmd/pandas3ed2.html#introspection-wildcard-searching",
    "href": "qmd/pandas3ed2.html#introspection-wildcard-searching",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Use * with ? to search the IPython namespace.\n\n\nIn [9]: import numpy as np\n\nIn [10]: np.*load*?\nnp.__loader__\nnp.load\nnp.loads\nnp.loadtxt\n\n\nThis shows all names in the NumPy namespace containing “load”."
  },
  {
    "objectID": "qmd/pandas3ed2.html#python-language-basics",
    "href": "qmd/pandas3ed2.html#python-language-basics",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Now, let’s dive into the core syntax and semantics of the Python language itself.\n\n\n\nPython emphasizes readability, simplicity, and explicitness. It’s often described as “executable pseudocode.”\n\n\n\n\n\nPython uses indentation (spaces or tabs) to structure code, not curly braces {} like many other languages.\n\n\nfor x in array:\n    if x &lt; pivot:\n        less.append(x)\n    else:\n        greater.append(x)\n\n\nA colon : indicates the start of an indented block.\nConsistent indentation is crucial! Use four spaces for indentation.\n\n\n\n\n\n\n\nNote\n\n\n\nIt is highly recommended to use four spaces as the default indent and to replace tabs with four spaces. Many text editors have settings that will automatically replace tab stops with spaces."
  },
  {
    "objectID": "qmd/pandas3ed2.html#semicolons",
    "href": "qmd/pandas3ed2.html#semicolons",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Python statements generally do not need to be terminated by semicolons.\nSemicolons can separate multiple statements on a single line, but this is generally discouraged for readability.\n\n\na = 5; b = 6; c = 7  # Generally avoid this style"
  },
  {
    "objectID": "qmd/pandas3ed2.html#everything-is-an-object",
    "href": "qmd/pandas3ed2.html#everything-is-an-object",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "In Python, everything is an object: numbers, strings, lists, functions, classes, modules, etc.\nEach object has a type (e.g., int, str, list, function) and internal data.\nThis makes Python very flexible."
  },
  {
    "objectID": "qmd/pandas3ed2.html#comments",
    "href": "qmd/pandas3ed2.html#comments",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Use the hash mark # to create comments. Anything after # on a line is ignored by the interpreter.\n\n\nresults = []\nfor line in file_handle:\n    # keep the empty lines for now\n    # if len(line) == 0:\n    #     continue\n    results.append(line.replace(\"foo\", \"bar\"))\n\nprint(\"Reached this line\")  # Simple status report"
  },
  {
    "objectID": "qmd/pandas3ed2.html#function-and-object-method-calls",
    "href": "qmd/pandas3ed2.html#function-and-object-method-calls",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Call functions with parentheses () and pass arguments (if any).\nObjects often have methods (functions attached to the object) that you call using the dot . syntax.\n\n\nresult = f(x, y, z)\ng()\n\nobj.some_method(x, y, z)\n\nresult = f(a, b, c, d=5, e=\"foo\")  # Positional and keyword arguments"
  },
  {
    "objectID": "qmd/pandas3ed2.html#variables-and-argument-passing",
    "href": "qmd/pandas3ed2.html#variables-and-argument-passing",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Assigning a variable creates a reference to the object on the right-hand side of the =.\n\n\na = [1, 2, 3]\nb = a  # b now refers to the *same* list as a\na.append(4)\nprint(b)  # Output: [1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n\n\nImportant: In Python, a and b point to the same object in memory, not copies."
  },
  {
    "objectID": "qmd/pandas3ed2.html#variable-references-diagram",
    "href": "qmd/pandas3ed2.html#variable-references-diagram",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "This diagram illustrates that a and b are simply names that refer to the same list object in memory.\n\n\n\n\n\n\n\nNote\n\n\n\nAssignment is also known as binding because we are binding a name to an object. Assigned variable names are sometimes referred to as bound variables."
  },
  {
    "objectID": "qmd/pandas3ed2.html#dynamic-references-strong-types",
    "href": "qmd/pandas3ed2.html#dynamic-references-strong-types",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Variables in Python don’t have an inherent type. The type is associated with the object the variable refers to.\n\n\na = 5\nprint(type(a))  # Output: &lt;class 'int'&gt;\n\na = \"foo\"\nprint(type(a))  # Output: &lt;class 'str'&gt;\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n\n\n\nPython is strongly typed: Objects have specific types, and implicit conversions are limited.\n\n\n# \"5\" + 5  # This would cause a TypeError"
  },
  {
    "objectID": "qmd/pandas3ed2.html#strong-typing-example",
    "href": "qmd/pandas3ed2.html#strong-typing-example",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "a = 4.5\nb = 2\nprint(f\"a is {type(a)}, b is {type(b)}\")  # String formatting\nprint(a / b)\n\na is &lt;class 'float'&gt;, b is &lt;class 'int'&gt;\n2.25\n\n\n\nString formatting is f”a is {type(a)}, b is {type(b)}”\n\n\nEven though b is an integer, it’s implicitly converted to a float for the division."
  },
  {
    "objectID": "qmd/pandas3ed2.html#checking-types-with-isinstance",
    "href": "qmd/pandas3ed2.html#checking-types-with-isinstance",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Use isinstance() to check if an object is an instance of a particular type (or one of several types).\n\n\na = 5\nprint(isinstance(a, int))  # Output: True\n\nb = 4.5\nprint(isinstance(a, (int, float)))  # Output: True\nprint(isinstance(b, (int, float)))  # Output: True\n\nTrue\nTrue\nTrue"
  },
  {
    "objectID": "qmd/pandas3ed2.html#attributes-and-methods",
    "href": "qmd/pandas3ed2.html#attributes-and-methods",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Objects have attributes (data stored “inside” the object) and methods (functions associated with the object).\nAccess them using obj.attribute_name.\nWe use getattr function can get object’s attributes and methods by name.\n\n\na = \"foo\"\n# a.&lt;Press Tab&gt;  # See available attributes and methods\n\nprint(getattr(a, \"split\"))\n\n&lt;built-in method split of str object at 0x7f008a5394d0&gt;"
  },
  {
    "objectID": "qmd/pandas3ed2.html#duck-typing",
    "href": "qmd/pandas3ed2.html#duck-typing",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "“If it walks like a duck and quacks like a duck, then it’s a duck.”\nCheck for specific behavior (e.g., iterability) rather than strict type.\n\n\ndef isiterable(obj):\n    try:\n        iter(obj)\n        return True\n    except TypeError:  # not iterable\n        return False\n\nprint(isiterable(\"a string\"))  # Output: True\nprint(isiterable([1, 2, 3]))  # Output: True\nprint(isiterable(5))  # Output: False\n\nTrue\nTrue\nFalse"
  },
  {
    "objectID": "qmd/pandas3ed2.html#imports",
    "href": "qmd/pandas3ed2.html#imports",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "A module is a .py file containing Python code.\nUse import to access variables and functions from other modules.\n\n\n# some_module.py\nPI = 3.14159\n\ndef f(x):\n    return x + 2\n\ndef g(a, b):\n    return a + b\n\n\n# In another file:\nimport some_module\nresult = some_module.f(5)\npi = some_module.PI\n\n# Or:\nfrom some_module import g, PI\nresult = g(5, PI)\n\n# Or with different names:\nimport some_module as sm\nfrom some_module import PI as pi, g as gf"
  },
  {
    "objectID": "qmd/pandas3ed2.html#binary-operators-and-comparisons",
    "href": "qmd/pandas3ed2.html#binary-operators-and-comparisons",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Python uses standard mathematical syntax for binary operations and comparisons.\n\n\nprint(5 - 7)\nprint(12 + 21.5)\nprint(5 &lt;= 2)\n\n-2\n33.5\nFalse"
  },
  {
    "objectID": "qmd/pandas3ed2.html#binary-operators-table",
    "href": "qmd/pandas3ed2.html#binary-operators-table",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Operation\nDescription\n\n\n\n\na + b\nAdd a and b\n\n\na - b\nSubtract b from a\n\n\na * b\nMultiply a by b\n\n\na / b\nDivide a by b\n\n\na // b\nFloor-divide a by b, dropping any fractional remainder\n\n\na ** b\nRaise a to the b power\n\n\na & b\nTrue if both a and b are True; for integers, take the bitwise AND\n\n\na \\| b\nTrue if either a or b is True; for integers, take the bitwise OR\n\n\na ^ b\nFor Booleans, True if a or b is True, but not both; for integers, take the bitwise EXCLUSIVE-OR\n\n\na == b\nTrue if a equals b\n\n\na != b\nTrue if a is not equal to b\n\n\na &lt; b, a &lt;= b\nTrue if a is less than (less than or equal to) b\n\n\na &gt; b, a &gt;= b\nTrue if a is greater than (greater than or equal to) b\n\n\na is b\nTrue if a and b reference the same Python object\n\n\na is not b\nTrue if a and b reference different Python objects"
  },
  {
    "objectID": "qmd/pandas3ed2.html#is-and-is-not",
    "href": "qmd/pandas3ed2.html#is-and-is-not",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "is checks if two variables refer to the same object.\nis not check if two objects are not the same\n== checks for equality of value.\n\n\na = [1, 2, 3]\nb = a\nc = list(a)  # Creates a *new* list (a copy)\n\nprint(a is b)      # Output: True\nprint(a is not c)  # Output: True\nprint(a == c)      # Output: True\n\nTrue\nTrue\nTrue"
  },
  {
    "objectID": "qmd/pandas3ed2.html#mutable-and-immutable-objects",
    "href": "qmd/pandas3ed2.html#mutable-and-immutable-objects",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Mutable objects (lists, dicts, NumPy arrays, etc.) can be modified in place.\nImmutable objects (strings, tuples) cannot be changed after creation.\n\n\na_list = [\"foo\", 2, [4, 5]]\na_list[2] = (3, 4)\nprint(a_list)  # Output: ['foo', 2, (3, 4)]\n\n# a_tuple = (3, 5, (4, 5))\n# a_tuple[1] = \"four\"  # This would cause a TypeError\n\n['foo', 2, (3, 4)]"
  },
  {
    "objectID": "qmd/pandas3ed2.html#scalar-types",
    "href": "qmd/pandas3ed2.html#scalar-types",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Python has built-in types for handling numerical data, strings, Booleans, and dates/times. These are called scalar types.\n\n\n\n\nType\nDescription\n\n\n\n\nNone\nThe Python “null” value\n\n\nstr\nString type; holds Unicode strings\n\n\nbytes\nRaw binary data\n\n\nfloat\nDouble-precision floating-point number\n\n\nbool\nA Boolean True or False value\n\n\nint\nArbitrary precision integer"
  },
  {
    "objectID": "qmd/pandas3ed2.html#numeric-types-int-and-float",
    "href": "qmd/pandas3ed2.html#numeric-types-int-and-float",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "int: Can store arbitrarily large integers.\nfloat: Represents double-precision floating-point numbers (like double in C/C++).\n\n\nival = 17239871\nprint(ival ** 6)\n\nfval = 7.243\nfval2 = 6.78e-5  # Scientific notation\n\n26254519291092456596965462913230729701102721\n\n\n\nInteger division resulting in a non-whole number always yields a float. Use // for floor division."
  },
  {
    "objectID": "qmd/pandas3ed2.html#strings",
    "href": "qmd/pandas3ed2.html#strings",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Use single quotes '...' or double quotes \"...\" to create string literals.\nTriple quotes '''...''' or \"\"\"...\"\"\" for multiline strings.\n\n\na = 'one way of writing a string'\nb = \"another way\"\nc = \"\"\"\nThis is a longer string that\nspans multiple lines\n\"\"\"\n\n\nPython strings are immutable."
  },
  {
    "objectID": "qmd/pandas3ed2.html#string-operations",
    "href": "qmd/pandas3ed2.html#string-operations",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Many built-in string methods are available (e.g., count(), replace(), split()).\n\n\na = \"this is a string\"\n# a[10] = 'f'  # TypeError: 'str' object does not support item assignment\n\nb = a.replace(\"string\", \"longer string\")\nprint(b)\nprint(a)\n\nthis is a longer string\nthis is a string\n\n\n\nConvert other objects to strings using str()."
  },
  {
    "objectID": "qmd/pandas3ed2.html#string-slicing-and-raw-strings",
    "href": "qmd/pandas3ed2.html#string-slicing-and-raw-strings",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Strings are sequences of Unicode characters and can be treated like lists/tuples.\n\n\ns = \"python\"\nprint(list(s))\nprint(s[:3])\n\n['p', 'y', 't', 'h', 'o', 'n']\npyt\n\n\n\nBackslash \\ is an escape character. Use raw strings (prefix with r) to avoid escaping.\n\n\ns = \"12\\\\\\\\34\"  # String with two backslashes\nprint(s)\n\nraw_string = r\"this\\has\\no\\special\\characters\"\nprint(raw_string)\n\n12\\\\34\nthis\\has\\no\\special\\characters"
  },
  {
    "objectID": "qmd/pandas3ed2.html#string-concatenation-and-formatting",
    "href": "qmd/pandas3ed2.html#string-concatenation-and-formatting",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Adding strings together concatenates them.\n\n\na = \"this is the first half \"\nb = \"and this is the second half\"\nprint(a + b)\n\nthis is the first half and this is the second half\n\n\n\nUse string formatting (the format() method or f-strings) for more complex string construction."
  },
  {
    "objectID": "qmd/pandas3ed2.html#string-formatting-f-strings",
    "href": "qmd/pandas3ed2.html#string-formatting-f-strings",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "amount = 10\nrate = 88.46\ncurrency = \"Pesos\"\nresult = f\"{amount} {currency} is worth US${amount / rate:.2f}\"\nprint(result)\n\n10 Pesos is worth US$0.11\n\n\n\nf-strings (formatted string literals) are a concise way to embed expressions inside strings."
  },
  {
    "objectID": "qmd/pandas3ed2.html#bytes-and-unicode",
    "href": "qmd/pandas3ed2.html#bytes-and-unicode",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "In Python 3, Unicode is the first-class string type.\nencode() converts a Unicode string to bytes (e.g., UTF-8).\ndecode() converts bytes back to a Unicode string.\n\n\nval = \"español\"\nval_utf8 = val.encode(\"utf-8\")\nprint(val_utf8)\nprint(type(val_utf8))\n\nprint(val_utf8.decode(\"utf-8\"))\n\nb'espa\\xc3\\xb1ol'\n&lt;class 'bytes'&gt;\nespañol"
  },
  {
    "objectID": "qmd/pandas3ed2.html#booleans",
    "href": "qmd/pandas3ed2.html#booleans",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "True and False are the Boolean values.\nComparisons and conditional expressions evaluate to True or False.\nCombine with and, or, and not.\n\n\nprint(True and True)\nprint(False or True)\n\nprint(int(False))  # Output: 0\nprint(int(True))   # Output: 1\n\nTrue\nTrue\n0\n1"
  },
  {
    "objectID": "qmd/pandas3ed2.html#type-casting",
    "href": "qmd/pandas3ed2.html#type-casting",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "str(), bool(), int(), and float() can be used to cast values to different types.\n\n\ns = \"3.14159\"\nfval = float(s)\nprint(type(fval))\nprint(int(fval))\nprint(bool(fval))\nprint(bool(0))  # 0 casts to False, other numbers to True\n\n&lt;class 'float'&gt;\n3\nTrue\nFalse"
  },
  {
    "objectID": "qmd/pandas3ed2.html#none",
    "href": "qmd/pandas3ed2.html#none",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "None is the Python null value type. It represents the absence of a value.\nIt is also the default return value of a function if there isn’t return statement in the function.\n\n\na = None\nprint(a is None)  # Output: True\n\nb = 5\nprint(b is not None)  # Output: True\n\nTrue\nTrue\n\n\n\nNone is often used as a default value for function arguments."
  },
  {
    "objectID": "qmd/pandas3ed2.html#dates-and-times",
    "href": "qmd/pandas3ed2.html#dates-and-times",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "The datetime module provides datetime, date, and time types.\n\n\nfrom datetime import datetime, date, time\n\ndt = datetime(2011, 10, 29, 20, 30, 21)\nprint(dt.day)\nprint(dt.minute)\nprint(dt.date())\nprint(dt.time())\n\n29\n30\n2011-10-29\n20:30:21"
  },
  {
    "objectID": "qmd/pandas3ed2.html#formatting-dates-and-times",
    "href": "qmd/pandas3ed2.html#formatting-dates-and-times",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "strftime() formats a datetime object as a string.\nstrptime() parses a string into a datetime object.\n\n\nprint(dt.strftime(\"%Y-%m-%d %H:%M\"))\n\ndt2 = datetime.strptime(\"20091031\", \"%Y%m%d\")\nprint(dt2)\n\n2011-10-29 20:30\n2009-10-31 00:00:00\n\n\n\nRefer to Python’s documentation for a complete list of format codes.\nSince datetime.datetime is an immutable type, methods like strftime and strptime will always produce new objects."
  },
  {
    "objectID": "qmd/pandas3ed2.html#datetime-arithmetic",
    "href": "qmd/pandas3ed2.html#datetime-arithmetic",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Subtracting two datetime objects produces a timedelta object.\nAdding a timedelta to a datetime produces a new, shifted datetime.\n\n\ndt2 = datetime(2011, 11, 15, 22, 30)\ndelta = dt2 - dt\nprint(delta)\nprint(type(delta))\nprint(dt + delta)\n\n17 days, 1:59:39\n&lt;class 'datetime.timedelta'&gt;\n2011-11-15 22:30:00"
  },
  {
    "objectID": "qmd/pandas3ed2.html#control-flow-if-elif-else",
    "href": "qmd/pandas3ed2.html#control-flow-if-elif-else",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "if statements execute a block of code if a condition is true.\nelif (else if) provides additional conditions.\nelse is a catchall block.\n\n\nx = -5\nif x &lt; 0:\n    print(\"It's negative\")\nelif x == 0:\n    print(\"Equal to zero\")\nelif 0 &lt; x &lt; 5:\n    print(\"Positive but smaller than 5\")\nelse:\n    print(\"Positive and larger than or equal to 5\")\n\nIt's negative\n\n\n\nConditions with and and or are evaluated left to right and short-circuit."
  },
  {
    "objectID": "qmd/pandas3ed2.html#for-loops",
    "href": "qmd/pandas3ed2.html#for-loops",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Iterate over a collection (list, tuple, etc.) or an iterator.\n\n\nfor value in collection:\n    # do something with value\n\n\ncontinue skips the rest of the current iteration.\nbreak exits the loop entirely."
  },
  {
    "objectID": "qmd/pandas3ed2.html#for-loop-examples",
    "href": "qmd/pandas3ed2.html#for-loop-examples",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "sequence = [1, 2, None, 4, None, 5]\ntotal = 0\nfor value in sequence:\n    if value is None:\n        continue  # Skip None values\n    total += value\n\nsequence = [1, 2, 0, 4, 6, 5, 2, 1]\ntotal_until_5 = 0\nfor value in sequence:\n    if value == 5:\n        break  # Exit loop when we reach 5\n    total_until_5 += value"
  },
  {
    "objectID": "qmd/pandas3ed2.html#nested-for-loops",
    "href": "qmd/pandas3ed2.html#nested-for-loops",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "for i in range(4):\n    for j in range(4):\n        if j &gt; i:\n            break  # Only breaks out of the inner loop\n        print((i, j))\n\n(0, 0)\n(1, 0)\n(1, 1)\n(2, 0)\n(2, 1)\n(2, 2)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)"
  },
  {
    "objectID": "qmd/pandas3ed2.html#while-loops",
    "href": "qmd/pandas3ed2.html#while-loops",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "Execute a block of code repeatedly as long as a condition is true.\n\n\nx = 256\ntotal = 0\nwhile x &gt; 0:\n    if total &gt; 500:\n        break  # Exit loop if total exceeds 500\n    total += x\n    x = x // 2"
  },
  {
    "objectID": "qmd/pandas3ed2.html#pass",
    "href": "qmd/pandas3ed2.html#pass",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "pass is a “no-op” statement. It does nothing. It’s used where a statement is syntactically required but you don’t want to execute any code.\n\n\nif x &lt; 0:\n    print(\"negative!\")\nelif x == 0:\n    # TODO: put something smart here\n    pass\nelse:\n    print(\"positive!\")\n\npositive!"
  },
  {
    "objectID": "qmd/pandas3ed2.html#range",
    "href": "qmd/pandas3ed2.html#range",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "range() generates a sequence of evenly spaced integers.\nrange(stop): Generates integers from 0 up to (but not including) stop.\nrange(start, stop): Generates integers from start up to (but not including) stop.\nrange(start, stop, step): Generates integers with a specified step.\n\n\nprint(list(range(10)))\nprint(list(range(0, 20, 2)))\nprint(list(range(5, 0, -1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n[5, 4, 3, 2, 1]"
  },
  {
    "objectID": "qmd/pandas3ed2.html#range-example",
    "href": "qmd/pandas3ed2.html#range-example",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "seq = [1, 2, 3, 4]\nfor i in range(len(seq)):\n    print(f\"element {i}: {seq[i]}\")\n\nelement 0: 1\nelement 1: 2\nelement 2: 3\nelement 3: 4\n\n\n\nA common use of range is for iterating through sequences by index."
  },
  {
    "objectID": "qmd/pandas3ed2.html#summary",
    "href": "qmd/pandas3ed2.html#summary",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "We’ve covered the core building blocks of Python: data types, operators, control flow, and basic usage of IPython and Jupyter Notebooks.\nThese concepts form the foundation for everything else we’ll do in data analysis with Python.\nRemember to practice and experiment!"
  },
  {
    "objectID": "qmd/pandas3ed2.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed2.html#thoughts-and-discussion",
    "title": "Chapter 2 Python Language Basics",
    "section": "",
    "text": "How does Python’s “everything is an object” philosophy compare to other programming languages you know?\nWhat are the advantages of using Jupyter Notebooks for data analysis compared to writing scripts in a text editor?\nCan you think of situations where duck typing would be particularly useful?\nHow might you use the datetime module in a real-world data analysis project?\nWhat are the differences between mutable and immutable objects? What are their pros and cons respectively?"
  },
  {
    "objectID": "qmd/pandas3ed11.html",
    "href": "qmd/pandas3ed11.html",
    "title": "",
    "section": "",
    "text": "---\ntitle: \"Chapter 11: Time Series\"\nauthor: \"Your Name\"\nformat:\n  revealjs:\n    theme: sky\n    slide-number: true\n    show-slide-number: all\n    preview-links: auto\n---\n\n## Introduction to Time Series Data\n\nTime series data is a sequence of data points collected over time intervals. ⏱️ It's a crucial data type in various fields:\n\n-   **Finance:** Stock prices, trading volume, interest rates 💰\n-   **Economics:** GDP, inflation, unemployment rates 📈\n-   **Ecology:** Population sizes, temperature changes 🌡️\n-   **Neuroscience:** Brainwave activity, neural signals 🧠\n-   **Physics:** Motion, velocity, acceleration 🚀\n\nEssentially, anything recorded repeatedly over time forms a time series.\n\n## Types of Time Series Data\n\nTime series data can be categorized based on how data points are measured concerning time:\n\n1.  **Timestamps:** Specific instants in time (e.g., 2024-10-27 09:30:00).\n2.  **Fixed Periods:**  Represent entire durations (e.g., January 2017, the year 2020).\n3.  **Intervals of Time:** Indicated by a start and end timestamp (e.g., a user session from 2:00 PM to 2:30 PM).\n4.  **Experiment or Elapsed Time:** Time relative to a starting point (e.g., seconds since a cookie was placed in the oven).\n\n::: {.callout-note}\nThis chapter focuses primarily on the first three categories (timestamps, fixed periods, and intervals).\n:::\n\n## Time Series: Regular vs. Irregular\n\nTime series can also be:\n\n-   **Fixed Frequency (Regular):** Data points occur at regular intervals (e.g., every 15 seconds, every 5 minutes, monthly).\n-   **Irregular:** Data points don't follow a fixed time unit (e.g., timestamps of website visits).\n\nThe choice of representation depends on the specific application.\n\n## Time Series in pandas\n\n`pandas` is a powerful Python library that offers extensive tools for time series analysis. It allows you to:\n\n-   Work with large time series efficiently.\n-   Slice, dice, and aggregate data.\n-   Resample both irregular and fixed-frequency time series.\n-   Handle missing data.\n\nThese capabilities are vital for financial and economic applications, but they are equally applicable to analyzing diverse datasets like server logs.\n\n## Importing Necessary Libraries\n\nBefore diving into time series manipulations, let's import the essential libraries: `NumPy` for numerical operations and `pandas` for data analysis.\n\n```python\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "qmd/pandas3ed11.html#date-and-time-data-types-and-tools",
    "href": "qmd/pandas3ed11.html#date-and-time-data-types-and-tools",
    "title": "",
    "section": "Date and Time Data Types and Tools",
    "text": "Date and Time Data Types and Tools\nPython’s standard library provides modules for handling dates and times:\n\ndatetime: Provides classes for manipulating dates and times (e.g., datetime, date, time, timedelta).\ntime: Provides time-related functions.\ncalendar: Functions related to calendars.\n\nThe datetime.datetime type (or simply datetime) is commonly used."
  },
  {
    "objectID": "qmd/pandas3ed11.html#the-datetime-object",
    "href": "qmd/pandas3ed11.html#the-datetime-object",
    "title": "",
    "section": "The datetime Object",
    "text": "The datetime Object\nLet’s create a datetime object representing the current time:\nfrom datetime import datetime\n\nnow = datetime.now()\nprint(now)\nThis code snippet retrieves the current date and time, including year, month, day, hour, minute, second, and microsecond. We can also manually construct a datetime object:\nmy_date = datetime(2024, 10, 27, 10, 30, 0) # Year, Month, Day, Hour, Minute, Second\nprint(my_date)\nAccess individual components:\nprint(f\"Year: {now.year}, Month: {now.month}, Day: {now.day}\")"
  },
  {
    "objectID": "qmd/pandas3ed11.html#the-timedelta-object",
    "href": "qmd/pandas3ed11.html#the-timedelta-object",
    "title": "",
    "section": "The timedelta Object",
    "text": "The timedelta Object\nA timedelta object represents the difference between two datetime objects:\ndelta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)\nprint(delta)\nprint(f\"Days: {delta.days}, Seconds: {delta.seconds}\")\n\ndelta.days: Returns the difference in days.\ndelta.seconds: Returns the difference in seconds (within the last day). It does not include the seconds contained within the days difference.\n\nYou can add or subtract timedelta objects to/from datetime objects:\nfrom datetime import timedelta\n\nstart = datetime(2011, 1, 7)\nprint(start + timedelta(12))  # Add 12 days\nprint(start - 2 * timedelta(12))  # Subtract 24 days"
  },
  {
    "objectID": "qmd/pandas3ed11.html#types-in-the-datetime-module",
    "href": "qmd/pandas3ed11.html#types-in-the-datetime-module",
    "title": "",
    "section": "Types in the datetime Module",
    "text": "Types in the datetime Module\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ndate\nStores the calendar date (year, month, day) using the Gregorian calendar.\n\n\ntime\nStores the time of day (hours, minutes, seconds, microseconds).\n\n\ndatetime\nStores both date and time.\n\n\ntimedelta\nRepresents the difference between two datetime values.\n\n\ntzinfo\nBase type for storing time zone information."
  },
  {
    "objectID": "qmd/pandas3ed11.html#converting-between-string-and-datetime",
    "href": "qmd/pandas3ed11.html#converting-between-string-and-datetime",
    "title": "",
    "section": "Converting Between String and Datetime",
    "text": "Converting Between String and Datetime\n\nstrftime(): Formats a datetime object into a string.\nstrptime(): Parses a string into a datetime object.\npd.to_datetime(): convert string to DatetimeIndex in pandas.\n\nstamp = datetime(2011, 1, 3)\n\n# datetime to string\nprint(str(stamp))  # Using str()\nprint(stamp.strftime('%Y-%m-%d'))  # Using strftime()\n\n# string to datetime\nvalue = '2011-01-03'\nprint(datetime.strptime(value, '%Y-%m-%d'))\n\ndatestrs = ['7/6/2011', '8/6/2011']\ndt_list = [datetime.strptime(x, '%m/%d/%Y') for x in datestrs]\nprint(dt_list)\n\n%Y: 4-digit year\n%y: 2-digit year\n%m: 2-digit month [01, 12]\n%d: 2-digit day [01, 31]\n%H: Hour (24-hour clock) [00, 23]\n%I: Hour (12-hour clock) [01, 12]\n%M: 2-digit minute [00, 59]\n%S: Second [00, 61] (60 and 61 are for leap seconds) -%f: Microsecond as an integer, zero-padded (from 000000 to 999999) -%j Day of the year as a zero-padded integer (from 001 to 336) -%w Weekday as an integer [0 (Sunday), 6] -%u Weekday as an integer starting from 1, where 1 is Monday. -%U Week number of the year [00, 53]; Sunday is considered the first day of the week, and days before the first Sunday of the year are “week 0”. -%W Week number of the year [00, 53]; Monday is considered the first day of the week, and days before the first Monday of the year are “week 0”. -%z UTC time zone offset as +HHMM or -HHMM; empty if time zone naive -%Z Time zone name as a string, or empty string if no time zone -%F Shortcut for %Y-%m-%d (e.g., 2012-4-18) -%D Shortcut for %m/%d/%y (e.g., 04/18/12)"
  },
  {
    "objectID": "qmd/pandas3ed11.html#pd.to_datetime-in-pandas",
    "href": "qmd/pandas3ed11.html#pd.to_datetime-in-pandas",
    "title": "",
    "section": "pd.to_datetime() in pandas",
    "text": "pd.to_datetime() in pandas\npandas is designed for working with arrays of dates. The pd.to_datetime() method is highly versatile:\ndatestrs = ['2011-07-06 12:00:00', '2011-08-06 00:00:00']\ndt_index = pd.to_datetime(datestrs)\nprint(dt_index)\nIt automatically handles various date formats and can also identify missing values:\nidx = pd.to_datetime(datestrs + [None])\nprint(idx)\nprint(idx[2])  # NaT (Not a Time)\nprint(pd.isna(idx))\nNaT is pandas’s representation of a null timestamp."
  },
  {
    "objectID": "qmd/pandas3ed11.html#locale-specific-date-formatting",
    "href": "qmd/pandas3ed11.html#locale-specific-date-formatting",
    "title": "",
    "section": "Locale-Specific Date Formatting",
    "text": "Locale-Specific Date Formatting\ndatetime objects have locale-specific formatting options.\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n%a\nAbbreviated weekday name.\n\n\n%A\nFull weekday name.\n\n\n%b\nAbbreviated month name.\n\n\n%B\nFull month name.\n\n\n%c\nFull date and time (e.g., ‘Tue 01 May 2012 04:20:57 PM’).\n\n\n%p\nLocale equivalent of AM or PM.\n\n\n%x\nLocale-appropriate formatted date (e.g., in the US, May 1, 2012 yields ‘05/01/2012’).\n\n\n%X\nLocale-appropriate time (e.g., ‘04:24:12 PM’)."
  },
  {
    "objectID": "qmd/pandas3ed11.html#time-series-basics-in-pandas",
    "href": "qmd/pandas3ed11.html#time-series-basics-in-pandas",
    "title": "",
    "section": "Time Series Basics in pandas",
    "text": "Time Series Basics in pandas\nA fundamental time series object in pandas is a Series indexed by timestamps:\ndates = [datetime(2011, 1, 2), datetime(2011, 1, 5),\n         datetime(2011, 1, 7), datetime(2011, 1, 8),\n         datetime(2011, 1, 10), datetime(2011, 1, 12)]\nts = pd.Series(np.random.randn(6), index=dates) # Standard normal distribution\nprint(ts)\nprint(type(ts))\n\nThe index is a DatetimeIndex.\nArithmetic operations between differently-indexed time series automatically align on the dates.\n\nprint(ts.index)\nprint(ts + ts[::2]) # [::2] selects every second element.  Note the NaN values."
  },
  {
    "objectID": "qmd/pandas3ed11.html#timestamp-objects",
    "href": "qmd/pandas3ed11.html#timestamp-objects",
    "title": "",
    "section": "Timestamp Objects",
    "text": "Timestamp Objects\nScalar values within a DatetimeIndex is pandas Timestamp objects:\nstamp = ts.index[0]\nprint(stamp)\nprint(type(stamp))\nA pandas.Timestamp can be substituted most places where you would use a datetime object."
  },
  {
    "objectID": "qmd/pandas3ed11.html#indexing-selection-and-subsetting",
    "href": "qmd/pandas3ed11.html#indexing-selection-and-subsetting",
    "title": "",
    "section": "Indexing, Selection, and Subsetting",
    "text": "Indexing, Selection, and Subsetting\nYou can index time series using the labels (dates) in various ways:\nstamp = ts.index[2]\nprint(ts[stamp])\nprint(ts['2011-01-10']) # String interpretable as date.\nFor longer time series, you can select slices using years or year-months:\nlonger_ts = pd.Series(np.random.randn(1000),\n                      index=pd.date_range('1/1/2000', periods=1000))  # Daily frequency\nprint(longer_ts['2001'])  # Select all of 2001\nprint(longer_ts['2001-05'])  # Select May 2001\nSlicing with datetime objects also works, including range queries:\nprint(ts[datetime(2011, 1, 7):])\nprint(ts['2011-01-06':'2011-01-11'])  # Range query (inclusive on both ends)\nThe truncate() method slices a Series between two dates:\nprint(ts.truncate(after='2011-01-09'))\nAll of these slicing operations also apply to DataFrame, indexing on its rows (assuming the index is a DatetimeIndex):\ndates = pd.date_range('1/1/2000', periods=100, freq='W-WED')\nlong_df = pd.DataFrame(np.random.randn(100, 4),\n                       index=dates,\n                       columns=['Colorado', 'Texas', 'New York', 'Ohio'])\nprint(long_df.loc['2001-05'])"
  },
  {
    "objectID": "qmd/pandas3ed11.html#time-series-with-duplicate-indices",
    "href": "qmd/pandas3ed11.html#time-series-with-duplicate-indices",
    "title": "",
    "section": "Time Series with Duplicate Indices",
    "text": "Time Series with Duplicate Indices\nIt’s possible to have multiple data observations for the same timestamp:\ndates = pd.DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000', '1/2/2000',\n                        '1/3/2000'])\ndup_ts = pd.Series(np.arange(5), index=dates)\nprint(dup_ts)\nprint(dup_ts.index.is_unique)  # Check for uniqueness\nIndexing will now produce either scalar values (if the timestamp is unique) or slices (if duplicated):\nprint(dup_ts['1/3/2000'])  # Not duplicated\nprint(dup_ts['1/2/2000'])  # Duplicated\nTo aggregate data with non-unique timestamps, use groupby with level=0:\ngrouped = dup_ts.groupby(level=0)\nprint(grouped.mean())\nprint(grouped.count())"
  },
  {
    "objectID": "qmd/pandas3ed11.html#date-ranges-frequencies-and-shifting",
    "href": "qmd/pandas3ed11.html#date-ranges-frequencies-and-shifting",
    "title": "",
    "section": "Date Ranges, Frequencies, and Shifting",
    "text": "Date Ranges, Frequencies, and Shifting\n\nGenerating Date Ranges\npandas.date_range() is used to generate a DatetimeIndex with a specific length and frequency:\nindex = pd.date_range('2012-04-01', '2012-06-01')\nprint(index)\nBy default, date_range generates daily timestamps. You can specify a start or end date and the number of periods:\nprint(pd.date_range(start='2012-04-01', periods=20))\nprint(pd.date_range(end='2012-06-01', periods=20))\nYou can also specify frequencies. For example, to get the last business day of each month:\nprint(pd.date_range('2000-01-01', '2000-12-01', freq='BM'))  # 'BM' = Business Month end\n\n\nFrequencies and Date Offsets\nFrequencies in pandas are composed of a base frequency and a multiplier. Base frequencies are typically string aliases (e.g., ‘M’ for monthly, ‘H’ for hourly).\n\n\n\n\n\n\n\n\nAlias\nOffset Type\nDescription\n\n\n\n\nD\nDay\nCalendar daily\n\n\nB\nBusinessDay\nBusiness daily\n\n\nH\nHour\nHourly\n\n\nT or min\nMinute\nOnce a minute\n\n\nS\nSecond\nOnce a second\n\n\nL or ms\nMilli\nMillisecond (1/1,000 of 1 second)\n\n\nU\nMicro\nMicrosecond (1/1,000,000 of 1 second)\n\n\nM\nMonthEnd\nLast calendar day of month\n\n\nBM\nBusinessMonthEnd\nLast business day (weekday) of month\n\n\nMS\nMonthBegin\nFirst calendar day of month\n\n\nBMS\nBusinessMonthBegin\nFirst weekday of month\n\n\nW-MON, W-TUE, …\nWeek\nWeekly on given day of week (MON, TUE, WED, THU,FRI, SAT, or SUN)\n\n\nWOM-1MON, WOM-2MON, …\nWeekOfMonth\nGenerate weekly dates in the first, second, third, or fourth week of the month (e.g., WOM-3FRI for thethird Friday of each month)\n\n\nQ-JAN, Q-FEB, …\nQuarterEnd\nQuarterly dates anchored on last calendar day of each month, for year ending in indicated month (JAN, FEB,MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC)\n\n\nBQ-JAN, BQ-FEB, …\nBusinessQuarterEnd\nQuarterly dates anchored on last weekday day of each month, for year ending in indicated month\n\n\nQS-JAN, QS-FEB, …\nQuarterBegin\nQuarterly dates anchored on first calendar day of each month, for year ending in indicated month\n\n\nBQS-JAN, BQS-FEB, …\nBusinessQuarterBegin\nQuarterly dates anchored on first weekday day of each month, for year ending in indicated month\n\n\nA-JAN, A-FEB, …\nYearEnd\nAnnual dates anchored on last calendar day of given month (JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP,OCT, NOV, or DEC)\n\n\nBA-JAN, BA-FEB, …\nBusinessYearEnd\nAnnual dates anchored on last weekday of given month\n\n\nAS-JAN, AS-FEB, …\nYearBegin\nAnnual dates anchored on first day of given month\n\n\nBAS-JAN, BAS-FEB, …\nBusinessYearBegin\nAnnual dates anchored on first weekday of given month\n\n\n\nExamples:\nfrom pandas.tseries.offsets import Hour, Minute\nprint(Hour())\nprint(Hour(4))  # Four-hour intervals\nprint(pd.date_range('2000-01-01', '2000-01-03 23:59', freq='4H'))\nprint(Hour(2) + Minute(30))\nprint(pd.date_range('2000-01-01', periods=10, freq='1h30min'))\n“Week of month” dates (e.g., the third Friday of each month):\nrng = pd.date_range('2012-01-01', '2012-09-01', freq='WOM-3FRI')\nprint(list(rng))\n\n\nShifting (Leading and Lagging) Data\nShifting moves data backward or forward through time. The shift() method is used for this:\nts = pd.Series(np.random.randn(4),\n               index=pd.date_range('1/1/2000', periods=4, freq='M'))\nprint(ts)\nprint(ts.shift(2))  # Shift forward by 2 periods\nprint(ts.shift(-2)) # Shift backward by 2 periods\nA common use is to compute percentage changes:\nprint(ts / ts.shift(1) - 1)\nYou can also shift the timestamps themselves, leaving the data unchanged, by passing a frequency to shift:\nprint(ts.shift(2, freq='M'))  # Shift the index by 2 months\nprint(ts.shift(3, freq='D'))\nprint(ts.shift(1, freq='90T'))  # Shift by 90 minutes\n\n\nShifting dates with offsets\npandas date offsets can be used with datetime or Timestamp objects:\nfrom pandas.tseries.offsets import Day, MonthEnd\nnow = datetime(2011, 11, 17)\nprint(now + 3 * Day())\nprint(now + MonthEnd()) # roll forward to the month end.\nprint(now + MonthEnd(2))\n\noffset = MonthEnd()\nprint(offset.rollforward(now)) # Explicit forward roll\nprint(offset.rollback(now)) # Explicit backward roll\nA clever use of date offsets with groupby is to “roll” dates to a specific frequency:\nts = pd.Series(np.random.randn(20),\n                index=pd.date_range('1/15/2000', periods=20, freq='4D'))\nprint(ts.groupby(MonthEnd().rollforward).mean()) #mean value of each month.\nprint(ts.resample('M').mean()) # Equivalent, and faster"
  },
  {
    "objectID": "qmd/pandas3ed11.html#time-zone-handling",
    "href": "qmd/pandas3ed11.html#time-zone-handling",
    "title": "",
    "section": "Time Zone Handling",
    "text": "Time Zone Handling\nWorking with time zones can be complex. pandas uses the pytz library to handle time zone conversions. By default, time series in pandas are time zone naive.\nimport pytz\nprint(pytz.common_timezones[-5:])\ntz = pytz.timezone('America/New_York')\nprint(tz)\n\nTime Zone Localization and Conversion\ndates = pd.date_range('3/9/2012 9:30', periods=6, freq='D')\nts = pd.Series(np.random.randn(len(dates)), index=dates)\nprint(ts)\nprint(ts.index.tz) # Time zone naive (None)\n\n#Generate a date range with a timezone\ndate_rng = pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC')\nprint(date_rng.tz)\n\n# Localize to a timezone.\nts_utc = ts.tz_localize('UTC') # Localize to a specific time zone\nprint(ts_utc)\nprint(ts_utc.index)\n\n# Convert to another time zone.\nts_eastern = ts_utc.tz_convert('America/New_York')\nprint(ts_eastern)\n\n\nOperations with Time Zone-Aware Timestamp Objects\nTimestamp objects also support time zone localization and conversion:\nstamp = pd.Timestamp('2011-03-12 04:00')\nstamp_utc = stamp.tz_localize('utc')\nprint(stamp_utc.tz_convert('America/New_York'))\nWhen performing operations between different time zones, the result will be in UTC.\ndates = pd.date_range('3/7/2012 9:30', periods=10, freq='B')\nts = pd.Series(np.random.randn(len(dates)), index=dates)\nts1 = ts[:7].tz_localize('Europe/London')\nts2 = ts1[2:].tz_convert('Europe/Moscow')\nresult = ts1 + ts2\nprint(result.index)  # UTC"
  },
  {
    "objectID": "qmd/pandas3ed11.html#periods-and-period-arithmetic",
    "href": "qmd/pandas3ed11.html#periods-and-period-arithmetic",
    "title": "",
    "section": "Periods and Period Arithmetic",
    "text": "Periods and Period Arithmetic\nPeriods represent time spans (e.g., days, months, quarters, years). The Period class is used for this:\np = pd.Period(2011, freq='A-DEC')  # Annual period, ending in December\nprint(p)\nprint(p + 5)\nprint(p - 2)\nprint(pd.Period('2014', freq='A-DEC') - p) # difference between periods.\nperiod_range creates regular ranges of periods:\nrng = pd.period_range('2000-01-01', '2000-06-30', freq='M')\nprint(rng)\nprint(pd.Series(np.random.randn(6), index=rng))\n\nvalues = ['2001Q3', '2002Q2', '2003Q1']\nindex = pd.PeriodIndex(values, freq='Q-DEC') # create periods from string\nprint(index)\n\nPeriod Frequency Conversion\nPeriods and PeriodIndex objects can be converted to another frequency using asfreq:\np = pd.Period('2011', freq='A-DEC')\nprint(p.asfreq('M', how='start'))  # Get the first month\nprint(p.asfreq('M', how='end'))    # Get the last month\n\np = pd.Period('Aug-2011', 'M')\nprint(p.asfreq('A-JUN'))\n# convert period range\nperiods = pd.period_range('2006', '2009', freq='A-DEC')\nts = pd.Series(np.random.randn(len(periods)), index=periods)\nprint(ts.asfreq('M', how='start'))\nprint(ts.asfreq('B', how='end'))\n\n\nQuarterly Period Frequencies\nQuarterly data is common in finance. pandas supports quarterly frequencies (Q-JAN through Q-DEC):\np = pd.Period('2012Q4', freq='Q-JAN')#In the case of a fiscal year ending in January, 2012Q4 runs from November 2011through January 2012\nprint(p)\nprint(p.asfreq('D', how='start'))\nprint(p.asfreq('D', how='end'))\nGet the timestamp at 4 P.M. on the second-to-last business day of the quarter\np4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60\nprint(p4pm)\nprint(p4pm.to_timestamp())\nGenerate quarterly ranges using pandas.period_range\nperiods = pd.period_range('2011Q3', '2012Q4', freq='Q-JAN')\nts = pd.Series(np.arange(len(periods)), index=periods)\nprint(ts)\nnew_periods = (periods.asfreq('B', 'e') - 1).asfreq('H', 's') + 16\nts.index = new_periods.to_timestamp()\nprint(ts)\n\n\nConverting Timestamps to Periods (and Back)\nto_period() converts timestamps to periods:\ndates = pd.date_range('1/1/2000', periods=3, freq='M')\nts = pd.Series(np.random.randn(3), index=dates)\npts = ts.to_period()\nprint(ts)\nprint(pts)\ndates = pd.date_range('1/29/2000', periods=6, freq='D')\nts2 = pd.Series(np.random.randn(6), index=dates)\nprint(ts2.to_period('M'))\nprint(ts2.to_period('M').to_timestamp(how='end'))#back to Timestamps\n\n\nCreating a PeriodIndex from Arrays\nYou can combine year and quarter columns to create a PeriodIndex:\ndata = pd.read_csv('examples/macrodata.csv')\nprint(data.head(5))\nindex = pd.PeriodIndex(year=data['year'], quarter=data['quarter'],freq='Q-DEC')\ndata.index = index\nprint(data['infl'].head())"
  },
  {
    "objectID": "qmd/pandas3ed11.html#resampling-and-frequency-conversion",
    "href": "qmd/pandas3ed11.html#resampling-and-frequency-conversion",
    "title": "",
    "section": "Resampling and Frequency Conversion",
    "text": "Resampling and Frequency Conversion\nResampling converts a time series from one frequency to another.\n\nDownsampling: Aggregating higher frequency data to a lower frequency (e.g., daily to monthly).\nUpsampling: Converting lower frequency data to a higher frequency (e.g., daily to hourly).\n\nThe resample() method is used for this. It’s similar to groupby.\ndates = pd.date_range('1/1/2000', periods=100, freq='D')\nts = pd.Series(np.random.randn(len(dates)), index=dates)\nprint(ts.resample('M').mean()) # Monthly means (downsampling)\nprint(ts.resample('M', kind='period').mean()) # Monthly means, using periods\n\nResample Method Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nrule\nString, DateOffset, or timedelta indicating the desired resampled frequency (for example, ‘M’, ‘5min’, or Second(15))\n\n\naxis\nAxis to resample on; default axis=0\n\n\nfill_method\nHow to interpolate when upsampling, as in “ffill” or “bfill”; by default does no interpolation\n\n\nclosed\nIn downsampling, which end of each interval is closed (inclusive), “right” or “left”\n\n\nlabel\nIn downsampling, how to label the aggregated result, with the “right” or “left” bin edge (e.g., the9:30 to 9:35 five-minute interval could be labeled 9:30 or 9:35)\n\n\nlimit\nWhen forward or backward filling, the maximum number of periods to fill\n\n\nkind\nAggregate to periods (“period”) or timestamps (“timestamp”); defaults to the type of index thetime series has\n\n\nconvention\nWhen resampling periods, the convention (“start” or “end”) for converting the low-frequency periodto high frequency; defaults to “start”\n\n\norigin\nThe “base” timestamp from which to determine the resampling bin edges; can also be one of “epoch”,“start”, “start_day”, “end”, or “end_day”; see the resample docstring for full details\n\n\noffset\nAn offset timedelta added to the origin; defaults to None\n\n\n\n\n\nDownsampling\ndates = pd.date_range('1/1/2000', periods=12, freq='T') # minutely data\nts = pd.Series(np.arange(12), index=dates)\nprint(ts)\n# closed='left'(default),label='left'(default)\nprint(ts.resample('5min').sum())\n\n# closed='right', label='left'\nprint(ts.resample('5min', closed='right').sum())\n\n# closed='right', label='right'\nprint(ts.resample('5min', closed='right', label='right').sum())\n\n#shift the result index\nfrom pandas.tseries.frequencies import to_offset\nresult = ts.resample('5min', closed='right', label='right').sum()\nresult.index = result.index + to_offset(\"-1s\")\nprint(result)\n\nclosed='right': The right bin edge is inclusive.\nlabel='right': Label the result with the right bin edge.\n\n\nOpen-High-Low-Close (OHLC) Resampling\nfinance data resampling\nprint(ts.resample('5min').ohlc())\n\n\n\nUpsampling and Interpolation\nframe = pd.DataFrame(np.random.randn(2, 4),\n                    index=pd.date_range('1/1/2000', periods=2, freq='W-WED'),\n                    columns=['Colorado', 'Texas', 'New York', 'Ohio'])\nprint(frame)\ndf_daily = frame.resample('D').asfreq()\nprint(df_daily)\nprint(frame.resample('D').ffill()) # forward fill\nprint(frame.resample('D').ffill(limit=2))\nprint(frame.resample('W-THU').ffill())\n\n\nResampling with Periods\nResampling period-indexed data is similar:\nframe = pd.DataFrame(np.random.randn(24, 4),\n                     index=pd.period_range('1-2000', '12-2001', freq='M'),\n                     columns=['Colorado', 'Texas', 'New York', 'Ohio'])\nprint(frame.head())\n\nannual_frame = frame.resample('A-DEC').mean()\nprint(annual_frame)\n\n# Q-DEC: Quarterly, year ending in December\nprint(annual_frame.resample('Q-DEC').ffill())\nprint(annual_frame.resample('Q-DEC', convention='end').asfreq())\nprint(annual_frame.resample('Q-MAR').ffill())"
  },
  {
    "objectID": "qmd/pandas3ed11.html#grouped-time-resampling",
    "href": "qmd/pandas3ed11.html#grouped-time-resampling",
    "title": "",
    "section": "Grouped Time Resampling",
    "text": "Grouped Time Resampling\nN = 15\ntimes = pd.date_range('2017-05-20 00:00', freq='1min', periods=N)\ndf = pd.DataFrame({'time': times, 'value': np.arange(N)})\nprint(df)\nprint(df.set_index('time').resample('5min').count())\ndf2 = pd.DataFrame({'time': times.repeat(3),\n                    'key': np.tile(['a', 'b', 'c'], N),\n                    'value': np.arange(N * 3.)})\nprint(df2.head(7))\ntime_key = pd.Grouper(freq='5min')\nresampled = (df2.set_index('time')\n             .groupby(['key', time_key])\n             .sum())\nprint(resampled)"
  },
  {
    "objectID": "qmd/pandas3ed11.html#moving-window-functions",
    "href": "qmd/pandas3ed11.html#moving-window-functions",
    "title": "",
    "section": "Moving Window Functions",
    "text": "Moving Window Functions\nMoving window functions (also called rolling window functions) operate on a sliding window of data. They are commonly used for smoothing noisy time series.\nclose_px_all = pd.read_csv('examples/stock_px.csv',parse_dates=True, index_col=0)\nclose_px = close_px_all[['AAPL', 'MSFT', 'XOM']]\nclose_px = close_px.resample('B').ffill()#business day frequency\nclose_px['AAPL'].plot()\nclose_px['AAPL'].rolling(250).mean().plot() # rolling 250 days mean\nstd250 = close_px['AAPL'].pct_change().rolling(250, min_periods=10).std()\nprint(std250[5:12])\nstd250.plot()\nexpanding_mean = std250.expanding().mean()\nplt.style.use('grayscale')\nclose_px.rolling(60).mean().plot(logy=True)\nprint(close_px.rolling('20D').mean())\n\nExponentially Weighted Functions\naapl_px = close_px['AAPL']['2006':'2007']\n\n```qmd\nma30 = aapl_px.rolling(30, min_periods=20).mean()\newma30 = aapl_px.ewm(span=30).mean()\n\naapl_px.plot(style='k-', label='Price')\nma30.plot(style='k--', label='Simple Moving Avg')\newma30.plot(style='k-', label='EW MA')  # Use 'k-' for solid black\nplt.legend()\n\n\nBinary Moving Window Functions\nspx_px = close_px_all['SPX']\nspx_rets = spx_px.pct_change()\nreturns = close_px.pct_change()\n\n# Correlation of AAPL returns with S&P 500 returns\ncorr = returns['AAPL'].rolling(125, min_periods=100).corr(spx_rets)\ncorr.plot()\n# Correlation of all stock returns with S&P 500\ncorr = returns.rolling(125, min_periods=100).corr(spx_rets)\ncorr.plot()\n\n\nUser-Defined Moving Window Functions\nThe apply method allows you to apply custom functions to a rolling window:\nfrom scipy.stats import percentileofscore\n\ndef score_at_2percent(x):\n    return percentileofscore(x, 0.02)\n\nresult = returns['AAPL'].rolling(250).apply(score_at_2percent)\nresult.plot()"
  },
  {
    "objectID": "qmd/pandas3ed11.html#conclusion",
    "href": "qmd/pandas3ed11.html#conclusion",
    "title": "",
    "section": "Conclusion",
    "text": "Conclusion\nThis chapter covered essential techniques for working with time series data in pandas, including:\n\nDate and time data types.\nTime series indexing, selection, and subsetting.\nGenerating date ranges and frequencies.\nShifting data.\nTime zone handling.\nPeriods and period arithmetic.\nResampling (downsampling and upsampling).\nMoving window functions.\n\nThese tools are fundamental for analyzing time-based data in various domains. The next step will involve the use of these skills with modeling libraries like statsmodels and scikit-learn."
  },
  {
    "objectID": "qmd/pandas3ed11.html#summary",
    "href": "qmd/pandas3ed11.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\n\nTime Series Data: Sequences of data points indexed in time order, crucial for analyzing trends and patterns over time.\npandas Functionality: pandas provides robust tools for manipulating, analyzing, and visualizing time series data.\nKey Operations: Learned to handle date/time types, resample, shift, and apply rolling/expanding window functions.\nApplications: These techniques are applicable in finance, economics, ecology, and numerous other fields.\nBuilding Blocks: Foundation for advanced time series modeling and forecasting."
  },
  {
    "objectID": "qmd/pandas3ed11.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed11.html#thoughts-and-discussion",
    "title": "",
    "section": "Thoughts and Discussion",
    "text": "Thoughts and Discussion\n\nData Frequency Choice: How does the choice of data frequency (e.g., daily, monthly, annually) impact the insights you can draw from a time series? Consider both practical and theoretical implications.\nMissing Data Strategies: Discuss different strategies for handling missing data in time series. When is it appropriate to forward-fill, backward-fill, or interpolate? What are the potential drawbacks of each method?\nMoving Window Function Selection: What are the trade-offs between using a simple moving average, an exponentially weighted moving average, and a custom moving window function? Give examples of situations where each would be most appropriate.\nTime Zone Awareness: Why is time zone awareness crucial in financial data analysis? Provide a real-world scenario where neglecting time zones could lead to incorrect conclusions.\nResampling Applications: Beyond the examples given, think of other applications where resampling time series data would be necessary or beneficial. Describe the specific resampling operation (upsampling or downsampling) and the desired outcome.\nPeriod vs. Timestamp: When would you choose to represent time using Periods instead of Timestamps, and vice-versa? What are the advantages and disadvantages of each representation?\nReal-World Data Challenges: What are some common challenges you might encounter when working with real-world time series data, and how would you address them using pandas? (e.g., irregular frequencies, data gaps, outliers).\nBeyond pandas: What other Python libraries or tools are useful for more advanced time series analysis (e.g., forecasting, anomaly detection)?\nEthical Considerations: Are there any ethical considerations when analyzing time series data, particularly in areas like finance or economics? (e.g., potential for misinterpretation, bias in data).\nProject Ideas: Propose a small project idea that utilizes the time series techniques covered in this chapter. Describe the dataset you would use, the questions you would investigate, and the pandas methods you would employ."
  },
  {
    "objectID": "qmd/pandas3ed7.html",
    "href": "qmd/pandas3ed7.html",
    "title": "```qmd",
    "section": "",
    "text": "title: “Chapter 7: Data Cleaning and Preparation” author: “Your Name” format: revealjs: theme: sky slide-number: true show-slide-number: all preview-links: auto"
  },
  {
    "objectID": "qmd/pandas3ed7.html#introduction-why-data-cleaning-matters",
    "href": "qmd/pandas3ed7.html#introduction-why-data-cleaning-matters",
    "title": "```qmd",
    "section": "Introduction: Why Data Cleaning Matters",
    "text": "Introduction: Why Data Cleaning Matters\n\n\nData analysis and modeling require significant data preparation.\nLoading, cleaning, transforming, and rearranging data consumes a large portion of an analyst’s time (often 80% or more! 😮).\nData isn’t always in the right format. Real-world data is messy!\nPandas, combined with Python’s built-in features, offers powerful tools for data manipulation."
  },
  {
    "objectID": "qmd/pandas3ed7.html#introduction-pandas-for-data-manipulation",
    "href": "qmd/pandas3ed7.html#introduction-pandas-for-data-manipulation",
    "title": "```qmd",
    "section": "Introduction: Pandas for Data Manipulation",
    "text": "Introduction: Pandas for Data Manipulation\n\nPandas provides high-level, flexible, and fast tools for data manipulation.\nIt’s designed to handle real-world data challenges effectively.\nThis chapter covers tools for:\n\nHandling missing data.\nDealing with duplicate data.\nString manipulation.\nOther analytical data transformations."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data",
    "href": "qmd/pandas3ed7.html#handling-missing-data",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data",
    "text": "7.1 Handling Missing Data\n\nMissing data is common in data analysis.\nPandas aims to make working with missing data as easy as possible.\nDescriptive statistics in pandas exclude missing data by default.\nPandas uses NaN (Not a Number), a floating-point value, to represent missing data,especially for float64 type."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-the-nan-sentinel",
    "href": "qmd/pandas3ed7.html#handling-missing-data-the-nan-sentinel",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: The NaN Sentinel",
    "text": "7.1 Handling Missing Data: The NaN Sentinel\n\nimport numpy as np\nimport pandas as pd\n\nfloat_data = pd.Series([1.2, -3.5, np.nan, 0])\nfloat_data\n\n0    1.2\n1   -3.5\n2    NaN\n3    0.0\ndtype: float64\n\n\n\nnp.nan is a special floating-point value indicating missing data.\nIt’s a sentinel value – its presence signals a missing or null value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-detecting-with-.isna",
    "href": "qmd/pandas3ed7.html#handling-missing-data-detecting-with-.isna",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: Detecting with .isna()",
    "text": "7.1 Handling Missing Data: Detecting with .isna()\n\nfloat_data.isna()\n\n0    False\n1    False\n2     True\n3    False\ndtype: bool\n\n\n\nThe .isna() method returns a Boolean Series.\nTrue indicates a missing value (NaN), and False indicates a non-missing value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-na-convention",
    "href": "qmd/pandas3ed7.html#handling-missing-data-na-convention",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: NA Convention",
    "text": "7.1 Handling Missing Data: NA Convention\n\nPandas adopts the R convention: missing data is referred to as NA (not available).\nNA can mean:\n\nData doesn’t exist.\nData exists but wasn’t observed (e.g., data collection issues).\n\nAnalyzing missing data itself can reveal data collection problems or potential biases. 🤔"
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-none-is-also-na",
    "href": "qmd/pandas3ed7.html#handling-missing-data-none-is-also-na",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: None is also NA",
    "text": "7.1 Handling Missing Data: None is also NA\n\nstring_data = pd.Series([\"aardvark\", np.nan, None, \"avocado\"])\nstring_data\n\n0    aardvark\n1         NaN\n2        None\n3     avocado\ndtype: object\n\n\n\nstring_data.isna()\n\n0    False\n1     True\n2     True\n3    False\ndtype: bool\n\n\n\nPython’s built-in None value is also treated as NA in pandas.\nBoth string and numeric Series can hold None and NaN as NA."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-consistent-handling",
    "href": "qmd/pandas3ed7.html#handling-missing-data-consistent-handling",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: Consistent Handling",
    "text": "7.1 Handling Missing Data: Consistent Handling\n\nfloat_data = pd.Series([1, 2, None], dtype='float64')\nfloat_data\n\n0    1.0\n1    2.0\n2    NaN\ndtype: float64\n\n\n\nfloat_data.isna()\n\n0    False\n1    False\n2     True\ndtype: bool\n\n\n\nPandas strives for consistent missing data handling across data types.\nfloat_data use NaN represents missing value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-na-handling-methods",
    "href": "qmd/pandas3ed7.html#handling-missing-data-na-handling-methods",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: NA Handling Methods",
    "text": "7.1 Handling Missing Data: NA Handling Methods\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ndropna\nFilters out axis labels (rows/columns) based on missing values, with options for thresholds.\n\n\nfillna\nFills in missing data with a specified value or using interpolation methods (e.g., “ffill”, “bfill”).\n\n\nisna\nReturns a Boolean array/Series indicating which values are missing/NA.\n\n\nnotna\nThe negation of isna: returns True for non-NA values, False for NA values.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThese methods provide the foundation for handling missing data in pandas."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-dropna-on-series",
    "href": "qmd/pandas3ed7.html#handling-missing-data-dropna-on-series",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: dropna on Series",
    "text": "7.1 Handling Missing Data: dropna on Series\n\ndata = pd.Series([1, np.nan, 3.5, np.nan, 7])\ndata.dropna()\n\n0    1.0\n2    3.5\n4    7.0\ndtype: float64\n\n\n\ndropna() on a Series returns a new Series with only non-null data and index labels.\nEquivalent to Boolean indexing: data[data.notna()]."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-dropna-on-dataframes",
    "href": "qmd/pandas3ed7.html#handling-missing-data-dropna-on-dataframes",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: dropna on DataFrames",
    "text": "7.1 Handling Missing Data: dropna on DataFrames\n\ndata = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan],\n                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\ndata\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n1\n1.0\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\n\n\n\n\n\n\n\n\ndata.dropna()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n\n\n\n\n\n\nBy default, dropna() drops any row containing any NA value.\nThis can be very strict."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-dropna-with-howall",
    "href": "qmd/pandas3ed7.html#handling-missing-data-dropna-with-howall",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: dropna with how='all'",
    "text": "7.1 Handling Missing Data: dropna with how='all'\n\ndata.dropna(how=\"all\")\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n1\n1.0\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\n\n\n\n\n\n\n\n\nhow=\"all\" drops only rows that are all NA.\nMore lenient than the default behavior."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-dropping-columns",
    "href": "qmd/pandas3ed7.html#handling-missing-data-dropping-columns",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: Dropping Columns",
    "text": "7.1 Handling Missing Data: Dropping Columns\n\ndata[4] = np.nan\ndata\n\n\n\n\n\n\n\n\n0\n1\n2\n4\n\n\n\n\n0\n1.0\n6.5\n3.0\nNaN\n\n\n1\n1.0\nNaN\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\nNaN\n\n\n\n\n\n\n\n\ndata.dropna(axis=\"columns\", how=\"all\")\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n6.5\n3.0\n\n\n1\n1.0\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\n\n\n3\nNaN\n6.5\n3.0\n\n\n\n\n\n\n\n\nTo drop columns, use axis=\"columns\" (or axis=1).\nhow=\"all\" with axis=\"columns\" drops columns that are all NA."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-dropna-with-thresh",
    "href": "qmd/pandas3ed7.html#handling-missing-data-dropna-with-thresh",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: dropna with thresh",
    "text": "7.1 Handling Missing Data: dropna with thresh\n\ndf = pd.DataFrame(np.random.standard_normal((7, 3)))\ndf.iloc[:4, 1] = np.nan\ndf.iloc[:2, 2] = np.nan\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n-0.172337\nNaN\nNaN\n\n\n1\n-1.126801\nNaN\nNaN\n\n\n2\n-1.226928\nNaN\n-0.835414\n\n\n3\n-1.147772\nNaN\n0.258556\n\n\n4\n-0.473312\n-0.807942\n0.149569\n\n\n5\n0.783235\n-1.270142\n1.006268\n\n\n6\n2.002823\n2.249397\n-1.036528\n\n\n\n\n\n\n\n\ndf.dropna()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n4\n-0.473312\n-0.807942\n0.149569\n\n\n5\n0.783235\n-1.270142\n1.006268\n\n\n6\n2.002823\n2.249397\n-1.036528\n\n\n\n\n\n\n\n\ndf.dropna(thresh=2)\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n2\n-1.226928\nNaN\n-0.835414\n\n\n3\n-1.147772\nNaN\n0.258556\n\n\n4\n-0.473312\n-0.807942\n0.149569\n\n\n5\n0.783235\n-1.270142\n1.006268\n\n\n6\n2.002823\n2.249397\n-1.036528\n\n\n\n\n\n\n\n\nThe thresh argument keeps rows with at least thresh non-NA values.\nFine-grained control over which rows to keep."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-filling-with-fillna",
    "href": "qmd/pandas3ed7.html#handling-missing-data-filling-with-fillna",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: Filling with fillna",
    "text": "7.1 Handling Missing Data: Filling with fillna\n\ndf.fillna(0)\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n-0.172337\n0.000000\n0.000000\n\n\n1\n-1.126801\n0.000000\n0.000000\n\n\n2\n-1.226928\n0.000000\n-0.835414\n\n\n3\n-1.147772\n0.000000\n0.258556\n\n\n4\n-0.473312\n-0.807942\n0.149569\n\n\n5\n0.783235\n-1.270142\n1.006268\n\n\n6\n2.002823\n2.249397\n-1.036528\n\n\n\n\n\n\n\n\nfillna(value) replaces all NA values with the specified value.\nA common choice is 0, but this depends on the context."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-fillna-with-a-dictionary",
    "href": "qmd/pandas3ed7.html#handling-missing-data-fillna-with-a-dictionary",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: fillna with a Dictionary",
    "text": "7.1 Handling Missing Data: fillna with a Dictionary\n\ndf.fillna({1: 0.5, 2: 0})\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n-0.172337\n0.500000\n0.000000\n\n\n1\n-1.126801\n0.500000\n0.000000\n\n\n2\n-1.226928\n0.500000\n-0.835414\n\n\n3\n-1.147772\n0.500000\n0.258556\n\n\n4\n-0.473312\n-0.807942\n0.149569\n\n\n5\n0.783235\n-1.270142\n1.006268\n\n\n6\n2.002823\n2.249397\n-1.036528\n\n\n\n\n\n\n\n\nUse a dictionary to specify different fill values for each column.\nThe dictionary keys are column labels; values are the fill values."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-interpolation-with-fillna",
    "href": "qmd/pandas3ed7.html#handling-missing-data-interpolation-with-fillna",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: Interpolation with fillna",
    "text": "7.1 Handling Missing Data: Interpolation with fillna\n\ndf = pd.DataFrame(np.random.standard_normal((6, 3)))\ndf.iloc[2:, 1] = np.nan\ndf.iloc[4:, 2] = np.nan\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.747697\n-1.094361\n-0.150607\n\n\n1\n0.229561\n0.806236\n-0.739724\n\n\n2\n-1.112941\nNaN\n-0.936409\n\n\n3\n0.294874\nNaN\n-1.449678\n\n\n4\n0.860861\nNaN\nNaN\n\n\n5\n-0.040511\nNaN\nNaN\n\n\n\n\n\n\n\n\ndf.fillna(method=\"ffill\") # Forward fill\n\n/tmp/ipykernel_2635/64151187.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df.fillna(method=\"ffill\") # Forward fill\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.747697\n-1.094361\n-0.150607\n\n\n1\n0.229561\n0.806236\n-0.739724\n\n\n2\n-1.112941\n0.806236\n-0.936409\n\n\n3\n0.294874\n0.806236\n-1.449678\n\n\n4\n0.860861\n0.806236\n-1.449678\n\n\n5\n-0.040511\n0.806236\n-1.449678\n\n\n\n\n\n\n\n\nmethod=\"ffill\" (forward fill) propagates the last valid observation forward.\nmethod=\"bfill\" (backward fill) uses the next valid observation to fill the gap.\nSuitable for time series or ordered data."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-fillna-with-limit",
    "href": "qmd/pandas3ed7.html#handling-missing-data-fillna-with-limit",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: fillna with limit",
    "text": "7.1 Handling Missing Data: fillna with limit\n\ndf.fillna(method=\"ffill\", limit=2)\n\n/tmp/ipykernel_2635/1627181726.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df.fillna(method=\"ffill\", limit=2)\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.747697\n-1.094361\n-0.150607\n\n\n1\n0.229561\n0.806236\n-0.739724\n\n\n2\n-1.112941\n0.806236\n-0.936409\n\n\n3\n0.294874\n0.806236\n-1.449678\n\n\n4\n0.860861\nNaN\n-1.449678\n\n\n5\n-0.040511\nNaN\n-1.449678\n\n\n\n\n\n\n\n\nlimit restricts the number of consecutive NA values filled by ffill or bfill."
  },
  {
    "objectID": "qmd/pandas3ed7.html#handling-missing-data-imputation-with-fillna",
    "href": "qmd/pandas3ed7.html#handling-missing-data-imputation-with-fillna",
    "title": "```qmd",
    "section": "7.1 Handling Missing Data: Imputation with fillna",
    "text": "7.1 Handling Missing Data: Imputation with fillna\n\ndata = pd.Series([1., np.nan, 3.5, np.nan, 7])\ndata.fillna(data.mean())\n\n0    1.000000\n1    3.833333\n2    3.500000\n3    3.833333\n4    7.000000\ndtype: float64\n\n\n\nReplace missing values with the mean, median, or other statistics.\nThis is a simple form of imputation."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation",
    "href": "qmd/pandas3ed7.html#data-transformation",
    "title": "```qmd",
    "section": "7.2 Data Transformation",
    "text": "7.2 Data Transformation\n\nFiltering and cleaning are essential, but data often needs further transformation.\nThis section covers:\n\nRemoving duplicates.\nTransforming data using functions or mappings.\nReplacing values.\nRenaming axis indexes.\nDiscretization and binning.\nDetecting and filtering outliers.\nPermutation and random sampling.\nComputing indicator/dummy variables."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-removing-duplicates",
    "href": "qmd/pandas3ed7.html#data-transformation-removing-duplicates",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Removing Duplicates",
    "text": "7.2 Data Transformation: Removing Duplicates\n\ndata = pd.DataFrame({\"k1\": [\"one\", \"two\"] * 3 + [\"two\"],\n                     \"k2\": [1, 1, 2, 3, 3, 4, 4]})\ndata\n\n\n\n\n\n\n\n\nk1\nk2\n\n\n\n\n0\none\n1\n\n\n1\ntwo\n1\n\n\n2\none\n2\n\n\n3\ntwo\n3\n\n\n4\none\n3\n\n\n5\ntwo\n4\n\n\n6\ntwo\n4\n\n\n\n\n\n\n\n\nDuplicate rows can occur for various reasons."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-identifying-duplicates-with-duplicated",
    "href": "qmd/pandas3ed7.html#data-transformation-identifying-duplicates-with-duplicated",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Identifying Duplicates with duplicated()",
    "text": "7.2 Data Transformation: Identifying Duplicates with duplicated()\n\ndata.duplicated()\n\n0    False\n1    False\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n\n\n\nduplicated() returns a Boolean Series indicating whether each row is a duplicate (has appeared earlier)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-removing-duplicates-with-drop_duplicates",
    "href": "qmd/pandas3ed7.html#data-transformation-removing-duplicates-with-drop_duplicates",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Removing Duplicates with drop_duplicates()",
    "text": "7.2 Data Transformation: Removing Duplicates with drop_duplicates()\n\ndata.drop_duplicates()\n\n\n\n\n\n\n\n\nk1\nk2\n\n\n\n\n0\none\n1\n\n\n1\ntwo\n1\n\n\n2\none\n2\n\n\n3\ntwo\n3\n\n\n4\none\n3\n\n\n5\ntwo\n4\n\n\n\n\n\n\n\n\ndrop_duplicates() returns a DataFrame with duplicate rows removed.\nKeeps the first occurrence of each unique row."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-drop_duplicates-on-a-subset-of-columns",
    "href": "qmd/pandas3ed7.html#data-transformation-drop_duplicates-on-a-subset-of-columns",
    "title": "```qmd",
    "section": "7.2 Data Transformation: drop_duplicates() on a Subset of Columns",
    "text": "7.2 Data Transformation: drop_duplicates() on a Subset of Columns\n\ndata[\"v1\"] = range(7)\ndata\n\n\n\n\n\n\n\n\nk1\nk2\nv1\n\n\n\n\n0\none\n1\n0\n\n\n1\ntwo\n1\n1\n\n\n2\none\n2\n2\n\n\n3\ntwo\n3\n3\n\n\n4\none\n3\n4\n\n\n5\ntwo\n4\n5\n\n\n6\ntwo\n4\n6\n\n\n\n\n\n\n\n\ndata.drop_duplicates(subset=[\"k1\"])\n\n\n\n\n\n\n\n\nk1\nk2\nv1\n\n\n\n\n0\none\n1\n0\n\n\n1\ntwo\n1\n1\n\n\n\n\n\n\n\n\nSpecify a subset of columns to check for duplicates using the subset argument.\nHere, only the \"k1\" column is considered."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-drop_duplicates-with-keeplast",
    "href": "qmd/pandas3ed7.html#data-transformation-drop_duplicates-with-keeplast",
    "title": "```qmd",
    "section": "7.2 Data Transformation: drop_duplicates() with keep='last'",
    "text": "7.2 Data Transformation: drop_duplicates() with keep='last'\n\ndata.drop_duplicates([\"k1\", \"k2\"], keep=\"last\")\n\n\n\n\n\n\n\n\nk1\nk2\nv1\n\n\n\n\n0\none\n1\n0\n\n\n1\ntwo\n1\n1\n\n\n2\none\n2\n2\n\n\n3\ntwo\n3\n3\n\n\n4\none\n3\n4\n\n\n6\ntwo\n4\n6\n\n\n\n\n\n\n\n\nkeep=\"last\" keeps the last occurrence of each unique row (or combination of columns).\nThe default is keep=\"first\"."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-transforming-data-using-a-function-or-mapping",
    "href": "qmd/pandas3ed7.html#data-transformation-transforming-data-using-a-function-or-mapping",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Transforming Data Using a Function or Mapping",
    "text": "7.2 Data Transformation: Transforming Data Using a Function or Mapping\n\ndata = pd.DataFrame({\"food\": [\"bacon\", \"pulled pork\", \"bacon\",\n                              \"pastrami\", \"corned beef\", \"bacon\",\n                              \"pastrami\", \"honey ham\", \"nova lox\"],\n                     \"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\ndata\n\n\n\n\n\n\n\n\nfood\nounces\n\n\n\n\n0\nbacon\n4.0\n\n\n1\npulled pork\n3.0\n\n\n2\nbacon\n12.0\n\n\n3\npastrami\n6.0\n\n\n4\ncorned beef\n7.5\n\n\n5\nbacon\n8.0\n\n\n6\npastrami\n3.0\n\n\n7\nhoney ham\n5.0\n\n\n8\nnova lox\n6.0\n\n\n\n\n\n\n\n\nSuppose we want to add a column indicating the animal type for each food."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-using-a-mapping-dictionary",
    "href": "qmd/pandas3ed7.html#data-transformation-using-a-mapping-dictionary",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Using a Mapping Dictionary",
    "text": "7.2 Data Transformation: Using a Mapping Dictionary\n\nmeat_to_animal = {\n  \"bacon\": \"pig\",\n  \"pulled pork\": \"pig\",\n  \"pastrami\": \"cow\",\n  \"corned beef\": \"cow\",\n  \"honey ham\": \"pig\",\n  \"nova lox\": \"salmon\"\n}\n\n\nCreate a dictionary mapping each food to its corresponding animal."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-using-.map",
    "href": "qmd/pandas3ed7.html#data-transformation-using-.map",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Using .map()",
    "text": "7.2 Data Transformation: Using .map()\n\ndata[\"animal\"] = data[\"food\"].map(meat_to_animal)\ndata\n\n\n\n\n\n\n\n\nfood\nounces\nanimal\n\n\n\n\n0\nbacon\n4.0\npig\n\n\n1\npulled pork\n3.0\npig\n\n\n2\nbacon\n12.0\npig\n\n\n3\npastrami\n6.0\ncow\n\n\n4\ncorned beef\n7.5\ncow\n\n\n5\nbacon\n8.0\npig\n\n\n6\npastrami\n3.0\ncow\n\n\n7\nhoney ham\n5.0\npig\n\n\n8\nnova lox\n6.0\nsalmon\n\n\n\n\n\n\n\n\nThe .map() method of a Series accepts a function or a dictionary-like object (like our mapping).\nIt applies the mapping to each element of the Series."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-using-a-function-with-.map",
    "href": "qmd/pandas3ed7.html#data-transformation-using-a-function-with-.map",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Using a Function with .map()",
    "text": "7.2 Data Transformation: Using a Function with .map()\n\ndef get_animal(x):\n    return meat_to_animal[x]\n\ndata[\"food\"].map(get_animal)\n\n0       pig\n1       pig\n2       pig\n3       cow\n4       cow\n5       pig\n6       cow\n7       pig\n8    salmon\nName: food, dtype: object\n\n\n\nWe could also use a function with .map().\nThe function takes a single element from the Series as input and returns the transformed value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-replacing-values",
    "href": "qmd/pandas3ed7.html#data-transformation-replacing-values",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Replacing Values",
    "text": "7.2 Data Transformation: Replacing Values\n\ndata = pd.Series([1., -999., 2., -999., -1000., 3.])\ndata\n\n0       1.0\n1    -999.0\n2       2.0\n3    -999.0\n4   -1000.0\n5       3.0\ndtype: float64\n\n\n\nSuppose -999 and -1000 are sentinel values for missing data."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-replace-for-single-value",
    "href": "qmd/pandas3ed7.html#data-transformation-replace-for-single-value",
    "title": "```qmd",
    "section": "7.2 Data Transformation: replace() for Single Value",
    "text": "7.2 Data Transformation: replace() for Single Value\n\ndata.replace(-999, np.nan)\n\n0       1.0\n1       NaN\n2       2.0\n3       NaN\n4   -1000.0\n5       3.0\ndtype: float64\n\n\n\nreplace(old_value, new_value) replaces occurrences of old_value with new_value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-replace-for-multiple-values",
    "href": "qmd/pandas3ed7.html#data-transformation-replace-for-multiple-values",
    "title": "```qmd",
    "section": "7.2 Data Transformation: replace() for Multiple Values",
    "text": "7.2 Data Transformation: replace() for Multiple Values\n\ndata.replace([-999, -1000], np.nan)\n\n0    1.0\n1    NaN\n2    2.0\n3    NaN\n4    NaN\n5    3.0\ndtype: float64\n\n\n\nPass a list of old values to replace multiple values at once."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-different-replacements-for-each-value",
    "href": "qmd/pandas3ed7.html#data-transformation-different-replacements-for-each-value",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Different Replacements for Each Value",
    "text": "7.2 Data Transformation: Different Replacements for Each Value\n\ndata.replace([-999, -1000], [np.nan, 0])\n\n0    1.0\n1    NaN\n2    2.0\n3    NaN\n4    0.0\n5    3.0\ndtype: float64\n\n\n\nProvide a list of replacement values corresponding to the list of old values."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-using-a-dictionary-with-replace",
    "href": "qmd/pandas3ed7.html#data-transformation-using-a-dictionary-with-replace",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Using a Dictionary with replace()",
    "text": "7.2 Data Transformation: Using a Dictionary with replace()\n\ndata.replace({-999: np.nan, -1000: 0})\n\n0    1.0\n1    NaN\n2    2.0\n3    NaN\n4    0.0\n5    3.0\ndtype: float64\n\n\n\nA dictionary can also be used with replace().\nKeys are old values; values are new values."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-renaming-axis-indexes",
    "href": "qmd/pandas3ed7.html#data-transformation-renaming-axis-indexes",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Renaming Axis Indexes",
    "text": "7.2 Data Transformation: Renaming Axis Indexes\n\ndata = pd.DataFrame(np.arange(12).reshape((3, 4)),\n                    index=[\"Ohio\", \"Colorado\", \"New York\"],\n                    columns=[\"one\", \"two\", \"three\", \"four\"])\ndata\n\n\n\n\n\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\nOhio\n0\n1\n2\n3\n\n\nColorado\n4\n5\n6\n7\n\n\nNew York\n8\n9\n10\n11\n\n\n\n\n\n\n\n\nAxis labels (row and column indexes) can also be transformed."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-modifying-indexes-with-.map",
    "href": "qmd/pandas3ed7.html#data-transformation-modifying-indexes-with-.map",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Modifying Indexes with .map()",
    "text": "7.2 Data Transformation: Modifying Indexes with .map()\n\ndef transform(x):\n    return x[:4].upper()\n\ndata.index.map(transform)\n\nIndex(['OHIO', 'COLO', 'NEW '], dtype='object')\n\n\n\ndata.index = data.index.map(transform)\ndata\n\n\n\n\n\n\n\n\none\ntwo\nthree\nfour\n\n\n\n\nOHIO\n0\n1\n2\n3\n\n\nCOLO\n4\n5\n6\n7\n\n\nNEW\n8\n9\n10\n11\n\n\n\n\n\n\n\n\nLike Series, axis indexes have a .map() method.\nWe apply a function to transform each index label.\nAssigning to data.index modifies the DataFrame in place."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-rename-for-creating-a-transformed-copy",
    "href": "qmd/pandas3ed7.html#data-transformation-rename-for-creating-a-transformed-copy",
    "title": "```qmd",
    "section": "7.2 Data Transformation: rename() for Creating a Transformed Copy",
    "text": "7.2 Data Transformation: rename() for Creating a Transformed Copy\n\ndata.rename(index=str.title, columns=str.upper)\n\n\n\n\n\n\n\n\nONE\nTWO\nTHREE\nFOUR\n\n\n\n\nOhio\n0\n1\n2\n3\n\n\nColo\n4\n5\n6\n7\n\n\nNew\n8\n9\n10\n11\n\n\n\n\n\n\n\n\nrename() creates a transformed copy without modifying the original DataFrame.\nindex and columns arguments can take functions, dictionaries, or Series."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-rename-with-a-dictionary",
    "href": "qmd/pandas3ed7.html#data-transformation-rename-with-a-dictionary",
    "title": "```qmd",
    "section": "7.2 Data Transformation: rename() with a Dictionary",
    "text": "7.2 Data Transformation: rename() with a Dictionary\n\ndata.rename(index={\"OHIO\": \"INDIANA\"},\n            columns={\"three\": \"peekaboo\"})\n\n\n\n\n\n\n\n\none\ntwo\npeekaboo\nfour\n\n\n\n\nINDIANA\n0\n1\n2\n3\n\n\nCOLO\n4\n5\n6\n7\n\n\nNEW\n8\n9\n10\n11\n\n\n\n\n\n\n\n\nUse dictionaries with rename() to modify a subset of axis labels."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-discretization-and-binning",
    "href": "qmd/pandas3ed7.html#data-transformation-discretization-and-binning",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Discretization and Binning",
    "text": "7.2 Data Transformation: Discretization and Binning\n\nContinuous data is often discretized or binned for analysis.\nExample: Grouping ages into age ranges.\n\n\nages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\nbins = [18, 25, 35, 60, 100]  # Define bin edges\nage_categories = pd.cut(ages, bins)\nage_categories\n\n[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]\nLength: 12\nCategories (4, interval[int64, right]): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100]]\n\n\n\npd.cut(data, bins) divides the data into bins based on the specified bins edges.\nReturns a special Categorical object."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-understanding-the-categorical-object",
    "href": "qmd/pandas3ed7.html#data-transformation-understanding-the-categorical-object",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Understanding the Categorical Object",
    "text": "7.2 Data Transformation: Understanding the Categorical Object\n\nage_categories.codes\n\narray([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)\n\n\n\nage_categories.categories\n\nIntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]], dtype='interval[int64, right]')\n\n\n\nage_categories.categories[0]\n\nInterval(18, 25, closed='right')\n\n\n\ncodes: An array of integers representing the bin each value belongs to (starting from 0).\ncategories: An IntervalIndex object holding the bin intervals."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-value_counts-on-categorical",
    "href": "qmd/pandas3ed7.html#data-transformation-value_counts-on-categorical",
    "title": "```qmd",
    "section": "7.2 Data Transformation: value_counts() on Categorical",
    "text": "7.2 Data Transformation: value_counts() on Categorical\n\npd.value_counts(age_categories)\n\n/tmp/ipykernel_2635/3010498523.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n  pd.value_counts(age_categories)\n\n\n(18, 25]     5\n(25, 35]     3\n(35, 60]     3\n(60, 100]    1\nName: count, dtype: int64\n\n\n\npd.value_counts(categorical) gives the bin counts for the result of pd.cut()."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-open-vs.-closed-intervals",
    "href": "qmd/pandas3ed7.html#data-transformation-open-vs.-closed-intervals",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Open vs. Closed Intervals",
    "text": "7.2 Data Transformation: Open vs. Closed Intervals\n\nParentheses () mean the side is open (exclusive).\nSquare brackets [] mean the side is closed (inclusive).\n(18, 25] means “greater than 18, up to and including 25.”\n\n\npd.cut(ages, bins, right=False) # Change which side is closed\n\n[[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [25, 35), [60, 100), [35, 60), [35, 60), [25, 35)]\nLength: 12\nCategories (4, interval[int64, left]): [[18, 25) &lt; [25, 35) &lt; [35, 60) &lt; [60, 100)]\n\n\n\nright=False changes the closed side of the interval."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-labeling-bins",
    "href": "qmd/pandas3ed7.html#data-transformation-labeling-bins",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Labeling Bins",
    "text": "7.2 Data Transformation: Labeling Bins\n\ngroup_names = [\"Youth\", \"YoungAdult\", \"MiddleAged\", \"Senior\"]\npd.cut(ages, bins, labels=group_names)\n\n['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', 'MiddleAged', 'MiddleAged', 'YoungAdult']\nLength: 12\nCategories (4, object): ['Youth' &lt; 'YoungAdult' &lt; 'MiddleAged' &lt; 'Senior']\n\n\n\nlabels argument assigns custom names to the bins.\nMore informative than the default interval labels."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-pd.cut-with-number-of-bins",
    "href": "qmd/pandas3ed7.html#data-transformation-pd.cut-with-number-of-bins",
    "title": "```qmd",
    "section": "7.2 Data Transformation: pd.cut() with Number of Bins",
    "text": "7.2 Data Transformation: pd.cut() with Number of Bins\n\ndata = np.random.uniform(size=20)\npd.cut(data, 4, precision=2) # Cut into 4 equal-length bins\n\n[(0.45, 0.68], (0.68, 0.9], (0.68, 0.9], (0.005, 0.23], (0.68, 0.9], ..., (0.45, 0.68], (0.45, 0.68], (0.45, 0.68], (0.45, 0.68], (0.68, 0.9]]\nLength: 20\nCategories (4, interval[float64, right]): [(0.005, 0.23] &lt; (0.23, 0.45] &lt; (0.45, 0.68] &lt; (0.68, 0.9]]\n\n\n\nPass an integer number of bins to pd.cut() to compute equal-length bins based on min/max values.\nprecision limits the decimal precision of the bin labels."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-pd.qcut-for-quantile-binning",
    "href": "qmd/pandas3ed7.html#data-transformation-pd.qcut-for-quantile-binning",
    "title": "```qmd",
    "section": "7.2 Data Transformation: pd.qcut() for Quantile Binning",
    "text": "7.2 Data Transformation: pd.qcut() for Quantile Binning\n\ndata = np.random.standard_normal(1000)\nquartiles = pd.qcut(data, 4, precision=2)  # Cut into quartiles\nquartiles\n\n[(-0.031, 0.66], (-0.77, -0.031], (-2.8899999999999997, -0.77], (-2.8899999999999997, -0.77], (-2.8899999999999997, -0.77], ..., (-0.77, -0.031], (-0.77, -0.031], (0.66, 3.92], (-2.8899999999999997, -0.77], (-2.8899999999999997, -0.77]]\nLength: 1000\nCategories (4, interval[float64, right]): [(-2.8899999999999997, -0.77] &lt; (-0.77, -0.031] &lt; (-0.031, 0.66] &lt; (0.66, 3.92]]\n\n\n\npd.qcut() bins data based on sample quantiles.\nAims for (roughly) equal-sized bins.\nUseful for dividing data into percentiles."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-pd.qcut-with-custom-quantiles",
    "href": "qmd/pandas3ed7.html#data-transformation-pd.qcut-with-custom-quantiles",
    "title": "```qmd",
    "section": "7.2 Data Transformation: pd.qcut() with Custom Quantiles",
    "text": "7.2 Data Transformation: pd.qcut() with Custom Quantiles\n\npd.qcut(data, [0, 0.1, 0.5, 0.9, 1.]).value_counts()\n\n(-2.8819999999999997, -1.276]    100\n(-1.276, -0.0312]                400\n(-0.0312, 1.294]                 400\n(1.294, 3.916]                   100\nName: count, dtype: int64\n\n\n\nPass custom quantiles (values between 0 and 1) to pd.qcut().\nExample: Dividing into deciles (0.1, 0.2, …, 0.9)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-detecting-and-filtering-outliers",
    "href": "qmd/pandas3ed7.html#data-transformation-detecting-and-filtering-outliers",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Detecting and Filtering Outliers",
    "text": "7.2 Data Transformation: Detecting and Filtering Outliers\n\nOutlier filtering/transformation is often an array operation.\n\n\ndata = pd.DataFrame(np.random.standard_normal((1000, 4)))\ndata.describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n0.033010\n0.056401\n-0.052707\n-0.049544\n\n\nstd\n0.954727\n1.017465\n0.985551\n0.994715\n\n\nmin\n-2.808208\n-3.087440\n-2.873478\n-3.123682\n\n\n25%\n-0.585381\n-0.645806\n-0.749786\n-0.737607\n\n\n50%\n-0.020575\n0.061019\n-0.033416\n-0.036930\n\n\n75%\n0.631171\n0.750258\n0.615955\n0.642344\n\n\nmax\n3.037782\n3.009782\n2.775777\n3.235134\n\n\n\n\n\n\n\n\nExample DataFrame with normally distributed data."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-finding-values-exceeding-a-threshold",
    "href": "qmd/pandas3ed7.html#data-transformation-finding-values-exceeding-a-threshold",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Finding Values Exceeding a Threshold",
    "text": "7.2 Data Transformation: Finding Values Exceeding a Threshold\n\ncol = data[2]\ncol[col.abs() &gt; 3]\n\nSeries([], Name: 2, dtype: float64)\n\n\n\nFind values in column 2 with an absolute value greater than 3."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-selecting-rows-based-on-outliers",
    "href": "qmd/pandas3ed7.html#data-transformation-selecting-rows-based-on-outliers",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Selecting Rows Based on Outliers",
    "text": "7.2 Data Transformation: Selecting Rows Based on Outliers\n\ndata[(data.abs() &gt; 3).any(axis=\"columns\")]\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n271\n-0.756527\n-3.087440\n-0.113955\n1.595461\n\n\n335\n0.245135\n3.009782\n0.421811\n-1.247871\n\n\n428\n-0.655529\n2.288183\n0.948956\n-3.123682\n\n\n455\n3.037782\n-1.050033\n1.124002\n0.042943\n\n\n480\n-0.911604\n-0.695740\n0.096534\n3.064375\n\n\n523\n0.295908\n0.908946\n0.040304\n3.023940\n\n\n614\n-0.176705\n-3.017098\n0.785747\n-1.239167\n\n\n667\n2.169624\n-1.567369\n0.204976\n3.235134\n\n\n\n\n\n\n\n\ndata.abs() &gt; 3: Boolean DataFrame indicating values exceeding 3 or -3.\nany(axis=\"columns\"): Checks if any value in a row is True.\nSelects all rows containing at least one outlier value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-capping-values",
    "href": "qmd/pandas3ed7.html#data-transformation-capping-values",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Capping Values",
    "text": "7.2 Data Transformation: Capping Values\n\ndata[data.abs() &gt; 3] = np.sign(data) * 3\ndata.describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n0.032972\n0.056496\n-0.052707\n-0.049744\n\n\nstd\n0.954609\n1.017118\n0.985551\n0.993316\n\n\nmin\n-2.808208\n-3.000000\n-2.873478\n-3.000000\n\n\n25%\n-0.585381\n-0.645806\n-0.749786\n-0.737607\n\n\n50%\n-0.020575\n0.061019\n-0.033416\n-0.036930\n\n\n75%\n0.631171\n0.750258\n0.615955\n0.642344\n\n\nmax\n3.000000\n3.000000\n2.775777\n3.000000\n\n\n\n\n\n\n\n\nnp.sign(data): Returns -1 for negative values, 1 for positive values.\nCap values outside the interval [-3, 3] to -3 and 3."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-permutation-and-random-sampling",
    "href": "qmd/pandas3ed7.html#data-transformation-permutation-and-random-sampling",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Permutation and Random Sampling",
    "text": "7.2 Data Transformation: Permutation and Random Sampling\n\nPermuting (randomly reordering) rows or columns.\nSelecting a random subset of data.\n\n\ndf = pd.DataFrame(np.arange(5 * 7).reshape((5, 7)))\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n7\n8\n9\n10\n11\n12\n13\n\n\n2\n14\n15\n16\n17\n18\n19\n20\n\n\n3\n21\n22\n23\n24\n25\n26\n27\n\n\n4\n28\n29\n30\n31\n32\n33\n34\n\n\n\n\n\n\n\n\nCreate a sample DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-permuting-rows-with-permutation",
    "href": "qmd/pandas3ed7.html#data-transformation-permuting-rows-with-permutation",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Permuting Rows with permutation()",
    "text": "7.2 Data Transformation: Permuting Rows with permutation()\n\nsampler = np.random.permutation(5) # Random permutation of integers 0-4\nsampler\n\narray([4, 2, 1, 3, 0])\n\n\n\ndf.take(sampler)  # or df.iloc[sampler]\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\n4\n28\n29\n30\n31\n32\n33\n34\n\n\n2\n14\n15\n16\n17\n18\n19\n20\n\n\n1\n7\n8\n9\n10\n11\n12\n13\n\n\n3\n21\n22\n23\n24\n25\n26\n27\n\n\n0\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\n\n\n\n\nnp.random.permutation(n) generates a random permutation of integers 0 to n-1.\ntake() or iloc[] can be used with the permutation to reorder rows."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-permuting-columns",
    "href": "qmd/pandas3ed7.html#data-transformation-permuting-columns",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Permuting Columns",
    "text": "7.2 Data Transformation: Permuting Columns\n\ncolumn_sampler = np.random.permutation(7)\ncolumn_sampler\n\narray([4, 3, 2, 6, 1, 0, 5])\n\n\n\ndf.take(column_sampler, axis=\"columns\")\n\n\n\n\n\n\n\n\n4\n3\n2\n6\n1\n0\n5\n\n\n\n\n0\n4\n3\n2\n6\n1\n0\n5\n\n\n1\n11\n10\n9\n13\n8\n7\n12\n\n\n2\n18\n17\n16\n20\n15\n14\n19\n\n\n3\n25\n24\n23\n27\n22\n21\n26\n\n\n4\n32\n31\n30\n34\n29\n28\n33\n\n\n\n\n\n\n\n\nPermute columns similarly, using axis=\"columns\" with take()."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-random-sampling-without-replacement",
    "href": "qmd/pandas3ed7.html#data-transformation-random-sampling-without-replacement",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Random Sampling without Replacement",
    "text": "7.2 Data Transformation: Random Sampling without Replacement\n\ndf.sample(n=3)  # Select 3 random rows\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\n1\n7\n8\n9\n10\n11\n12\n13\n\n\n4\n28\n29\n30\n31\n32\n33\n34\n\n\n3\n21\n22\n23\n24\n25\n26\n27\n\n\n\n\n\n\n\n\nsample(n=k) selects k random rows without replacement."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-random-sampling-with-replacement",
    "href": "qmd/pandas3ed7.html#data-transformation-random-sampling-with-replacement",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Random Sampling with Replacement",
    "text": "7.2 Data Transformation: Random Sampling with Replacement\n\nchoices = pd.Series([5, 7, -1, 6, 4])\nchoices.sample(n=10, replace=True) # Sample with replacement\n\n4    4\n2   -1\n1    7\n1    7\n2   -1\n1    7\n4    4\n2   -1\n2   -1\n2   -1\ndtype: int64\n\n\n\nreplace=True allows sampling with replacement (the same row can be chosen multiple times)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-computing-indicatordummy-variables",
    "href": "qmd/pandas3ed7.html#data-transformation-computing-indicatordummy-variables",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Computing Indicator/Dummy Variables",
    "text": "7.2 Data Transformation: Computing Indicator/Dummy Variables\n\nConverting a categorical variable into a “dummy” or “indicator” matrix.\nUsed in statistical modeling and machine learning.\n\n\ndf = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"],\n                   \"data1\": range(6)})\ndf\n\n\n\n\n\n\n\n\nkey\ndata1\n\n\n\n\n0\nb\n0\n\n\n1\nb\n1\n\n\n2\na\n2\n\n\n3\nc\n3\n\n\n4\na\n4\n\n\n5\nb\n5\n\n\n\n\n\n\n\n\nExample DataFrame with a categorical column “key”."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-get_dummies",
    "href": "qmd/pandas3ed7.html#data-transformation-get_dummies",
    "title": "```qmd",
    "section": "7.2 Data Transformation: get_dummies()",
    "text": "7.2 Data Transformation: get_dummies()\n\npd.get_dummies(df[\"key\"])\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\nFalse\nTrue\nFalse\n\n\n1\nFalse\nTrue\nFalse\n\n\n2\nTrue\nFalse\nFalse\n\n\n3\nFalse\nFalse\nTrue\n\n\n4\nTrue\nFalse\nFalse\n\n\n5\nFalse\nTrue\nFalse\n\n\n\n\n\n\n\n\npd.get_dummies(categorical_column) creates a DataFrame where:\n\nEach unique value in the original column becomes a new column.\nValues are 1 if the original row had that category, 0 otherwise."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-adding-a-prefix-to-dummy-variables",
    "href": "qmd/pandas3ed7.html#data-transformation-adding-a-prefix-to-dummy-variables",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Adding a Prefix to Dummy Variables",
    "text": "7.2 Data Transformation: Adding a Prefix to Dummy Variables\n\ndummies = pd.get_dummies(df[\"key\"], prefix=\"key\")\ndf_with_dummy = df[[\"data1\"]].join(dummies)\ndf_with_dummy\n\n\n\n\n\n\n\n\ndata1\nkey_a\nkey_b\nkey_c\n\n\n\n\n0\n0\nFalse\nTrue\nFalse\n\n\n1\n1\nFalse\nTrue\nFalse\n\n\n2\n2\nTrue\nFalse\nFalse\n\n\n3\n3\nFalse\nFalse\nTrue\n\n\n4\n4\nTrue\nFalse\nFalse\n\n\n5\n5\nFalse\nTrue\nFalse\n\n\n\n\n\n\n\n\nprefix argument adds a prefix to the dummy variable column names.\nUseful when joining with the original DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-handling-multiple-categories-movielens-example",
    "href": "qmd/pandas3ed7.html#data-transformation-handling-multiple-categories-movielens-example",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Handling Multiple Categories (MovieLens Example)",
    "text": "7.2 Data Transformation: Handling Multiple Categories (MovieLens Example)\n\nmnames = [\"movie_id\", \"title\", \"genres\"]\nmovies = pd.read_table(\"https://raw.githubusercontent.com/wesm/pydata-book/3rd-edition/datasets/movielens/movies.dat\", sep=\"::\",\n                       header=None, names=mnames, engine=\"python\")\nmovies[:10]\n\n\n\n\n\n\n\n\nmovie_id\ntitle\ngenres\n\n\n\n\n0\n1\nToy Story (1995)\nAnimation|Children's|Comedy\n\n\n1\n2\nJumanji (1995)\nAdventure|Children's|Fantasy\n\n\n2\n3\nGrumpier Old Men (1995)\nComedy|Romance\n\n\n3\n4\nWaiting to Exhale (1995)\nComedy|Drama\n\n\n4\n5\nFather of the Bride Part II (1995)\nComedy\n\n\n5\n6\nHeat (1995)\nAction|Crime|Thriller\n\n\n6\n7\nSabrina (1995)\nComedy|Romance\n\n\n7\n8\nTom and Huck (1995)\nAdventure|Children's\n\n\n8\n9\nSudden Death (1995)\nAction\n\n\n9\n10\nGoldenEye (1995)\nAction|Adventure|Thriller\n\n\n\n\n\n\n\n\nMovieLens dataset: “genres” column contains pipe-separated (|) genre strings.\nA movie can belong to multiple genres."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-str.get_dummies-for-multiple-categories",
    "href": "qmd/pandas3ed7.html#data-transformation-str.get_dummies-for-multiple-categories",
    "title": "```qmd",
    "section": "7.2 Data Transformation: str.get_dummies() for Multiple Categories",
    "text": "7.2 Data Transformation: str.get_dummies() for Multiple Categories\n\ndummies = movies[\"genres\"].str.get_dummies(\"|\")\ndummies.iloc[:10, :6]  # Show first 10 rows and 6 columns\n\n\n\n\n\n\n\n\nAction\nAdventure\nAnimation\nChildren's\nComedy\nCrime\n\n\n\n\n0\n0\n0\n1\n1\n1\n0\n\n\n1\n0\n1\n0\n1\n0\n0\n\n\n2\n0\n0\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n\n\n4\n0\n0\n0\n0\n1\n0\n\n\n5\n1\n0\n0\n0\n0\n1\n\n\n6\n0\n0\n0\n0\n1\n0\n\n\n7\n0\n1\n0\n1\n0\n0\n\n\n8\n1\n0\n0\n0\n0\n0\n\n\n9\n1\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nstr.get_dummies(separator) handles multiple categories separated by a delimiter."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-combining-with-the-original-dataframe",
    "href": "qmd/pandas3ed7.html#data-transformation-combining-with-the-original-dataframe",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Combining with the Original DataFrame",
    "text": "7.2 Data Transformation: Combining with the Original DataFrame\n\nmovies_windic = movies.join(dummies.add_prefix(\"Genre_\"))\nmovies_windic.iloc[0]\n\nmovie_id                                       1\ntitle                           Toy Story (1995)\ngenres               Animation|Children's|Comedy\nGenre_Action                                   0\nGenre_Adventure                                0\nGenre_Animation                                1\nGenre_Children's                               1\nGenre_Comedy                                   1\nGenre_Crime                                    0\nGenre_Documentary                              0\nGenre_Drama                                    0\nGenre_Fantasy                                  0\nGenre_Film-Noir                                0\nGenre_Horror                                   0\nGenre_Musical                                  0\nGenre_Mystery                                  0\nGenre_Romance                                  0\nGenre_Sci-Fi                                   0\nGenre_Thriller                                 0\nGenre_War                                      0\nGenre_Western                                  0\nName: 0, dtype: object\n\n\n\nadd_prefix() adds a prefix to the dummy variable columns.\njoin() combines the dummy variables with the original DataFrame."
  },
  {
    "objectID": "qmd/pandas3ed7.html#data-transformation-combining-get_dummies-and-cut",
    "href": "qmd/pandas3ed7.html#data-transformation-combining-get_dummies-and-cut",
    "title": "```qmd",
    "section": "7.2 Data Transformation: Combining get_dummies() and cut()",
    "text": "7.2 Data Transformation: Combining get_dummies() and cut()\n\nnp.random.seed(12345)\nvalues = np.random.uniform(size=10)\nvalues\n\narray([0.92961609, 0.31637555, 0.18391881, 0.20456028, 0.56772503,\n       0.5955447 , 0.96451452, 0.6531771 , 0.74890664, 0.65356987])\n\n\n\nbins = [0, 0.2, 0.4, 0.6, 0.8, 1]\npd.get_dummies(pd.cut(values, bins))\n\n\n\n\n\n\n\n\n(0.0, 0.2]\n(0.2, 0.4]\n(0.4, 0.6]\n(0.6, 0.8]\n(0.8, 1.0]\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n5\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n6\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n7\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n8\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n9\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n\n\n\n\nA recipe for statistical applications: Combine get_dummies() with discretization functions like cut().\nCreates indicator variables for each bin."
  },
  {
    "objectID": "qmd/pandas3ed7.html#extension-data-types",
    "href": "qmd/pandas3ed7.html#extension-data-types",
    "title": "```qmd",
    "section": "7.3 Extension Data Types",
    "text": "7.3 Extension Data Types\n\nPandas’ original reliance on NumPy had limitations:\n\nIncomplete missing data handling for integers and Booleans.\nString data was computationally expensive.\nSome data types (time intervals, timedeltas) weren’t efficiently supported.\n\nPandas now has an extension type system.\n\nAllows adding new data types not natively supported by NumPy.\nTreats these types as first-class citizens."
  },
  {
    "objectID": "qmd/pandas3ed7.html#extension-data-types-integer-example",
    "href": "qmd/pandas3ed7.html#extension-data-types-integer-example",
    "title": "```qmd",
    "section": "7.3 Extension Data Types: Integer Example",
    "text": "7.3 Extension Data Types: Integer Example\n\ns = pd.Series([1, 2, 3, None])\ns\n\n0    1.0\n1    2.0\n2    3.0\n3    NaN\ndtype: float64\n\n\n\ns.dtype\n\ndtype('float64')\n\n\n\nTraditional behavior: Integer Series with missing values becomes float64."
  },
  {
    "objectID": "qmd/pandas3ed7.html#extension-data-types-int64dtype",
    "href": "qmd/pandas3ed7.html#extension-data-types-int64dtype",
    "title": "```qmd",
    "section": "7.3 Extension Data Types: Int64Dtype",
    "text": "7.3 Extension Data Types: Int64Dtype\n\ns = pd.Series([1, 2, 3, None], dtype=pd.Int64Dtype())\ns\n\n0       1\n1       2\n2       3\n3    &lt;NA&gt;\ndtype: Int64\n\n\n\ns.isna()\n\n0    False\n1    False\n2    False\n3     True\ndtype: bool\n\n\n\ns.dtype\n\nInt64Dtype()\n\n\n\npd.Int64Dtype() (or \"Int64\") creates an integer Series with proper NA handling.\nUses &lt;NA&gt; to indicate missing values (pandas.NA sentinel value)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#extension-data-types-string-example",
    "href": "qmd/pandas3ed7.html#extension-data-types-string-example",
    "title": "```qmd",
    "section": "7.3 Extension Data Types: String Example",
    "text": "7.3 Extension Data Types: String Example\n\ns = pd.Series(['one', 'two', None, 'three'], dtype=pd.StringDtype())\ns\n\n0      one\n1      two\n2     &lt;NA&gt;\n3    three\ndtype: string\n\n\n\ns.dtype\n\nstring[python]\n\n\n\npd.StringDtype() creates a specialized string data type.\nMore memory-efficient and computationally efficient for large datasets.\nRequires the pyarrow library."
  },
  {
    "objectID": "qmd/pandas3ed7.html#extension-data-types-astype",
    "href": "qmd/pandas3ed7.html#extension-data-types-astype",
    "title": "```qmd",
    "section": "7.3 Extension Data Types: astype()",
    "text": "7.3 Extension Data Types: astype()\n\ndf = pd.DataFrame({\"A\": [1, 2, None, 4],\n                    \"B\": [\"one\", \"two\", \"three\", None],\n                   \"C\": [False, None, False, True]})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1.0\none\nFalse\n\n\n1\n2.0\ntwo\nNone\n\n\n2\nNaN\nthree\nFalse\n\n\n3\n4.0\nNone\nTrue\n\n\n\n\n\n\n\n\ndf[\"A\"] = df[\"A\"].astype(\"Int64\")\ndf[\"B\"] = df[\"B\"].astype(\"string\")\ndf[\"C\"] = df[\"C\"].astype(\"boolean\")\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\none\nFalse\n\n\n1\n2\ntwo\n&lt;NA&gt;\n\n\n2\n&lt;NA&gt;\nthree\nFalse\n\n\n3\n4\n&lt;NA&gt;\nTrue\n\n\n\n\n\n\n\n\nExtension types are well-integrated with existing tools. You can use astype() method to convert different types."
  },
  {
    "objectID": "qmd/pandas3ed7.html#extension-data-types-1",
    "href": "qmd/pandas3ed7.html#extension-data-types-1",
    "title": "```qmd",
    "section": "7.3 Extension Data Types",
    "text": "7.3 Extension Data Types\n\n\n\n\n\n\n\nExtension type\nDescription\n\n\n\n\nBooleanDtype\nNullable Boolean data, use \"boolean\" when passing as string\n\n\nCategoricalDtype\nCategorical data type, use \"category\" when passing as string\n\n\nDatetimeTZDtype\nDatetime with time zone\n\n\nFloat32Dtype\n32-bit nullable floating point, use \"Float32\" when passing as string\n\n\nFloat64Dtype\n64-bit nullable floating point, use \"Float64\" when passing as string\n\n\nInt8Dtype\n8-bit nullable signed integer, use \"Int8\" when passing as string\n\n\nInt16Dtype\n16-bit nullable signed integer, use \"Int16\" when passing as string\n\n\nInt32Dtype\n32-bit nullable signed integer, use \"Int32\" when passing as string\n\n\nInt64Dtype\n64-bit nullable signed integer, use \"Int64\" when passing as string\n\n\nUInt8Dtype\n8-bit nullable unsigned integer, use \"UInt8\" when passing as string\n\n\nUInt16Dtype\n16-bit nullable unsigned integer, use \"UInt16\" when passing as string\n\n\nUInt32Dtype\n32-bit nullable unsigned integer, use \"UInt32\" when passing as string\n\n\nUInt64Dtype\n64-bit nullable unsigned integer, use \"UInt64\" when passing as string\n\n\n\n\nA reasonably complete list of extension types available."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation",
    "href": "qmd/pandas3ed7.html#string-manipulation",
    "title": "```qmd",
    "section": "7.4 String Manipulation",
    "text": "7.4 String Manipulation\n\nPython is popular for string/text processing.\nString object methods are often sufficient.\nRegular expressions (regex) provide more power.\nPandas combines these, handling missing data gracefully."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-python-built-in-string-methods",
    "href": "qmd/pandas3ed7.html#string-manipulation-python-built-in-string-methods",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Python Built-In String Methods",
    "text": "7.4 String Manipulation: Python Built-In String Methods\n\nval = \"a,b,  guido\"\nval.split(\",\")\n\n['a', 'b', '  guido']\n\n\n\nsplit(): Breaks a string into a list of substrings based on a delimiter.\n\n\npieces = [x.strip() for x in val.split(\",\")]\npieces\n\n['a', 'b', 'guido']\n\n\n\nstrip(): Removes leading/trailing whitespace. Often used with split()."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-string-concatenation",
    "href": "qmd/pandas3ed7.html#string-manipulation-string-concatenation",
    "title": "```qmd",
    "section": "7.4 String Manipulation: String Concatenation",
    "text": "7.4 String Manipulation: String Concatenation\n\nfirst, second, third = pieces\nfirst + \"::\" + second + \"::\" + third  # Using + operator\n\n'a::b::guido'\n\n\n\n\"::\".join(pieces) # More Pythonic way,using join()\n\n'a::b::guido'\n\n\n\njoin(): A more Pythonic way to concatenate strings with a delimiter."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-substring-detection",
    "href": "qmd/pandas3ed7.html#string-manipulation-substring-detection",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Substring Detection",
    "text": "7.4 String Manipulation: Substring Detection\n\n\"guido\" in val\n\nTrue\n\n\n\nval.index(\",\")  # Raises ValueError if not found\n\n1\n\n\n\nval.find(\":\")   # Returns -1 if not found\n\n-1\n\n\n\nin: The best way to check if a substring exists.\nindex(): Finds the first occurrence of a substring; raises an error if not found.\nfind(): Similar to index(), but returns -1 if not found."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-count-and-replace",
    "href": "qmd/pandas3ed7.html#string-manipulation-count-and-replace",
    "title": "```qmd",
    "section": "7.4 String Manipulation: count() and replace()",
    "text": "7.4 String Manipulation: count() and replace()\n\nval.count(\",\") # Counts occurrences of a substring\n\n2\n\n\n\nval.replace(\",\", \"::\")\n\n'a::b::  guido'\n\n\n\nval.replace(\",\", \"\")  # Delete occurrences by replacing with empty string\n\n'ab  guido'\n\n\n\ncount(): Counts the number of occurrences of a substring.\nreplace(): Substitutes occurrences of one pattern with another."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-python-built-in-string-methods-1",
    "href": "qmd/pandas3ed7.html#string-manipulation-python-built-in-string-methods-1",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Python Built-in string methods",
    "text": "7.4 String Manipulation: Python Built-in string methods\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nReturn the number of nonoverlapping occurrences of substring in the string\n\n\nendswith\nReturn True if string ends with suffix\n\n\nstartswith\nReturn True if string starts with prefix\n\n\njoin\nUse string as delimiter for concatenating a sequence of other strings\n\n\nindex\nReturn starting index of the first occurrence of passed substring if found in the string; otherwise, raises ValueError if not found\n\n\nfind\nReturn position of first character of first occurrence of substring in the string; like index, but returns -1 if not found\n\n\nrfind\nReturn position of first character of last occurrence of substring in the string; returns -1 if not found\n\n\nreplace\nReplace occurrences of string with another string\n\n\nstrip\nTrim whitespace, including newlines on both sides\n\n\nrstrip\nTrim whitespace on right side\n\n\nlstrip\nTrim whitespace on left side\n\n\nsplit\nBreak string into list of substrings using passed delimiter\n\n\nlower\nConvert alphabet characters to lowercase\n\n\nupper\nConvert alphabet characters to uppercase\n\n\ncasefold\nConvert characters to lowercase, handling region-specific variations\n\n\nljust\nLeft justify; pad right side with spaces (or other fill character)\n\n\nrjust\nRight justify; pad left side with spaces (or other fill character)"
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-regular-expressions",
    "href": "qmd/pandas3ed7.html#string-manipulation-regular-expressions",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Regular Expressions",
    "text": "7.4 String Manipulation: Regular Expressions\n\nRegular expressions (regex) provide a powerful way to search, match, and manipulate text patterns.\nPython’s built-in re module handles regular expressions.\nRegex functions fall into three categories:\n\nPattern matching.\nSubstitution.\nSplitting."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-regex-example---splitting",
    "href": "qmd/pandas3ed7.html#string-manipulation-regex-example---splitting",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Regex Example - Splitting",
    "text": "7.4 String Manipulation: Regex Example - Splitting\n\nimport re\ntext = \"foo    bar\\t baz  \\tqux\"\nre.split(r\"\\s+\", text)  # Split on one or more whitespace characters\n\n['foo', 'bar', 'baz', 'qux']\n\n\n\\s+: Regex for one or more whitespace characters. - re.split(pattern, text): Splits the text based on the regex pattern."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-compiling-regex-objects",
    "href": "qmd/pandas3ed7.html#string-manipulation-compiling-regex-objects",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Compiling Regex Objects",
    "text": "7.4 String Manipulation: Compiling Regex Objects\n\nregex = re.compile(r\"\\s+\")  # Compile the regex\nregex.split(text)\n\n['foo', 'bar', 'baz', 'qux']\n\n\n\nre.compile(pattern): Compiles a regex into a reusable regex object.\nRecommended if you’ll apply the same regex to multiple strings (saves CPU cycles)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-findall",
    "href": "qmd/pandas3ed7.html#string-manipulation-findall",
    "title": "```qmd",
    "section": "7.4 String Manipulation: findall()",
    "text": "7.4 String Manipulation: findall()\n\nregex.findall(text)\n\n['    ', '\\t ', '  \\t']\n\n\n\nfindall(): Returns a list of all non-overlapping matches of the pattern in the string."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-regex-example---email-matching",
    "href": "qmd/pandas3ed7.html#string-manipulation-regex-example---email-matching",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Regex Example - Email Matching",
    "text": "7.4 String Manipulation: Regex Example - Email Matching\n\ntext = \"\"\"Dave dave@google.com\nSteve steve@gmail.com\nRob rob@gmail.com\nRyan ryan@yahoo.com\"\"\"\n\npattern = r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\"  # Basic email regex\n\n# re.IGNORECASE makes the regex case-insensitive\nregex = re.compile(pattern, flags=re.IGNORECASE)\n\n\nA more complex regex to match email addresses.\nre.IGNORECASE flag makes the match case-insensitive."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-findall-with-email-regex",
    "href": "qmd/pandas3ed7.html#string-manipulation-findall-with-email-regex",
    "title": "```qmd",
    "section": "7.4 String Manipulation: findall() with Email Regex",
    "text": "7.4 String Manipulation: findall() with Email Regex\n\nregex.findall(text)\n\n['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com']\n\n\n\nfindall() returns a list of all matched email addresses."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-search",
    "href": "qmd/pandas3ed7.html#string-manipulation-search",
    "title": "```qmd",
    "section": "7.4 String Manipulation: search()",
    "text": "7.4 String Manipulation: search()\n\nm = regex.search(text)\nm\n\n&lt;re.Match object; span=(5, 20), match='dave@google.com'&gt;\n\n\n\ntext[m.start():m.end()]\n\n'dave@google.com'\n\n\n\nsearch(): Returns a match object for the first match in the string.\nThe match object gives the start and end positions of the match.\nregex.match() Returns None."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-sub",
    "href": "qmd/pandas3ed7.html#string-manipulation-sub",
    "title": "```qmd",
    "section": "7.4 String Manipulation: sub()",
    "text": "7.4 String Manipulation: sub()\n\nprint(regex.sub(\"REDACTED\", text))\n\nDave REDACTED\nSteve REDACTED\nRob REDACTED\nRyan REDACTED\n\n\n\nsub(replacement, text): Returns a new string with occurrences of the pattern replaced by the replacement string."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-regex-groups",
    "href": "qmd/pandas3ed7.html#string-manipulation-regex-groups",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Regex Groups",
    "text": "7.4 String Manipulation: Regex Groups\n\npattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"  # Regex with groups\nregex = re.compile(pattern, flags=re.IGNORECASE)\n\nm = regex.match(\"wesm@bright.net\")\nm.groups()\n\n('wesm', 'bright', 'net')\n\n\n\nParentheses () in a regex define capture groups.\ngroups() method of a match object returns a tuple of the captured group contents."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-findall-with-groups",
    "href": "qmd/pandas3ed7.html#string-manipulation-findall-with-groups",
    "title": "```qmd",
    "section": "7.4 String Manipulation: findall() with Groups",
    "text": "7.4 String Manipulation: findall() with Groups\n\nregex.findall(text)\n\n[('dave', 'google', 'com'),\n ('steve', 'gmail', 'com'),\n ('rob', 'gmail', 'com'),\n ('ryan', 'yahoo', 'com')]\n\n\n\nWhen a regex has groups, findall() returns a list of tuples, where each tuple contains the captured groups."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-sub-with-group-references",
    "href": "qmd/pandas3ed7.html#string-manipulation-sub-with-group-references",
    "title": "```qmd",
    "section": "7.4 String Manipulation: sub() with Group References",
    "text": "7.4 String Manipulation: sub() with Group References\n\nprint(regex.sub(r\"Username: \\1, Domain: \\2, Suffix: \\3\", text))\n\nDave Username: dave, Domain: google, Suffix: com\nSteve Username: steve, Domain: gmail, Suffix: com\nRob Username: rob, Domain: gmail, Suffix: com\nRyan Username: ryan, Domain: yahoo, Suffix: com\n\n\n\nIn sub(), \\1, \\2, etc., refer to the captured groups (backreferences)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-regular-expression-methods",
    "href": "qmd/pandas3ed7.html#string-manipulation-regular-expression-methods",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Regular expression methods",
    "text": "7.4 String Manipulation: Regular expression methods\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nfindall\nReturn all nonoverlapping matching patterns in a string as a list\n\n\nfinditer\nLike findall, but returns an iterator\n\n\nmatch\nMatch pattern at start of string and optionally segment pattern components into groups; if the pattern matches, return a match object, and otherwise None\n\n\nsearch\nScan string for match to pattern, returning a match object if so; unlike match, the match can be anywhere in the string\n\n\nsplit\nBreak string into pieces at each occurrence of pattern\n\n\nsub, subn\nReplace all (sub) or first n occurrences (subn) of pattern in string with replacement expression; use symbols \\1, \\2, …"
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-string-functions-in-pandas",
    "href": "qmd/pandas3ed7.html#string-manipulation-string-functions-in-pandas",
    "title": "```qmd",
    "section": "7.4 String Manipulation: String Functions in pandas",
    "text": "7.4 String Manipulation: String Functions in pandas\n\nPandas extends string manipulation to Series and DataFrames.\nHandles missing data gracefully.\n\n\ndata = {\"Dave\": \"dave@google.com\", \"Steve\": \"steve@gmail.com\",\n        \"Rob\": \"rob@gmail.com\", \"Wes\": np.nan}\ndata = pd.Series(data)\ndata\n\nDave     dave@google.com\nSteve    steve@gmail.com\nRob        rob@gmail.com\nWes                  NaN\ndtype: object\n\n\n\ndata.isna()\n\nDave     False\nSteve    False\nRob      False\nWes       True\ndtype: bool\n\n\n\nExample Series with string data and a missing value."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-str-accessor",
    "href": "qmd/pandas3ed7.html#string-manipulation-str-accessor",
    "title": "```qmd",
    "section": "7.4 String Manipulation: str Accessor",
    "text": "7.4 String Manipulation: str Accessor\n\ndata.str.contains(\"gmail\")\n\nDave     False\nSteve     True\nRob       True\nWes        NaN\ndtype: object\n\n\n\nSeries has a str attribute that provides access to string methods.\nThese methods skip over and propagate NA values."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-str.contains",
    "href": "qmd/pandas3ed7.html#string-manipulation-str.contains",
    "title": "```qmd",
    "section": "7.4 String Manipulation: str.contains()",
    "text": "7.4 String Manipulation: str.contains()\n\nstr.contains(substring): Checks if each string contains the given substring.\nReturns a Boolean Series."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-using-regex-with-str-methods",
    "href": "qmd/pandas3ed7.html#string-manipulation-using-regex-with-str-methods",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Using Regex with str Methods",
    "text": "7.4 String Manipulation: Using Regex with str Methods\n\npattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\ndata.str.findall(pattern, flags=re.IGNORECASE)\n\nDave     [(dave, google, com)]\nSteve    [(steve, gmail, com)]\nRob        [(rob, gmail, com)]\nWes                        NaN\ndtype: object\n\n\n\nRegular expressions can be used with str methods.\nflags (like re.IGNORECASE) can be passed."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-vectorized-element-retrieval",
    "href": "qmd/pandas3ed7.html#string-manipulation-vectorized-element-retrieval",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Vectorized Element Retrieval",
    "text": "7.4 String Manipulation: Vectorized Element Retrieval\n\nmatches = data.str.findall(pattern, flags=re.IGNORECASE).str[0]\nmatches\n\nDave     (dave, google, com)\nSteve    (steve, gmail, com)\nRob        (rob, gmail, com)\nWes                      NaN\ndtype: object\n\n\n\nmatches.str.get(1) # Accessing the group\n\nDave     google\nSteve     gmail\nRob       gmail\nWes         NaN\ndtype: object\n\n\n\ndata.str[:5]  # String slicing\n\nDave     dave@\nSteve    steve\nRob      rob@g\nWes        NaN\ndtype: object\n\n\n\nVectorized element retrieval: Use str.get(i) or index into the str attribute (str[i])."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-str.extract",
    "href": "qmd/pandas3ed7.html#string-manipulation-str.extract",
    "title": "```qmd",
    "section": "7.4 String Manipulation: str.extract()",
    "text": "7.4 String Manipulation: str.extract()\n\ndata.str.extract(pattern, flags=re.IGNORECASE)\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\nDave\ndave\ngoogle\ncom\n\n\nSteve\nsteve\ngmail\ncom\n\n\nRob\nrob\ngmail\ncom\n\n\nWes\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nstr.extract(pattern): Returns a DataFrame where each captured group in the regex becomes a column."
  },
  {
    "objectID": "qmd/pandas3ed7.html#string-manipulation-partial-listing-of-series-string-methods",
    "href": "qmd/pandas3ed7.html#string-manipulation-partial-listing-of-series-string-methods",
    "title": "```qmd",
    "section": "7.4 String Manipulation: Partial listing of Series string methods",
    "text": "7.4 String Manipulation: Partial listing of Series string methods\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncat\nConcatenate strings element-wise with optional delimiter\n\n\ncontains\nReturn Boolean array if each string contains pattern/regex\n\n\ncount\nCount occurrences of pattern\n\n\nextract\nUse a regular expression with groups to extract one or more strings from a Series of strings; the result will be a DataFrame with one column per group\n\n\nendswith\nEquivalent to x.endswith(pattern) for each element\n\n\nstartswith\nEquivalent to x.startswith(pattern) for each element\n\n\nfindall\nCompute list of all occurrences of pattern/regex for each string\n\n\nget\nIndex into each element (retrieve i-th element)\n\n\nisalnum\nEquivalent to built-in str.isalnum\n\n\nisalpha\nEquivalent to built-in str.isalpha\n\n\nisdecimal\nEquivalent to built-in str.isdecimal\n\n\nisdigit\nEquivalent to built-in str.isdigit\n\n\nislower\nEquivalent to built-in str.islower\n\n\nisnumeric\nEquivalent to built-in str.isnumeric\n\n\nisupper\nEquivalent to built-in str.isupper\n\n\njoin\nJoin strings in each element of the Series with passed separator\n\n\nlen\nCompute length of each string\n\n\nlower, upper\nConvert cases; equivalent to x.lower() or x.upper() for each element\n\n\nmatch\nUse re.match with the passed regular expression on each element, returning True or False whether it matches\n\n\npad\nAdd whitespace to left, right, or both sides of strings\n\n\ncenter\nEquivalent to pad(side=\"both\")\n\n\nrepeat\nDuplicate values (e.g., s.str.repeat(3) is equivalent to x * 3 for each string)\n\n\nreplace\nReplace occurrences of pattern/regex with some other string\n\n\nslice\nSlice each string in the Series\n\n\nsplit\nSplit strings on delimiter or regular expression\n\n\nstrip\nTrim whitespace from both sides, including newlines\n\n\nrstrip\nTrim whitespace on right side\n\n\nlstrip\nTrim whitespace on left side"
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data",
    "href": "qmd/pandas3ed7.html#categorical-data",
    "title": "```qmd",
    "section": "7.5 Categorical Data",
    "text": "7.5 Categorical Data\n\nIntroduces the pandas Categorical type.\nImproves performance and memory use in some pandas operations.\nUseful for statistical and machine learning applications."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-background-and-motivation",
    "href": "qmd/pandas3ed7.html#categorical-data-background-and-motivation",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Background and Motivation",
    "text": "7.5 Categorical Data: Background and Motivation\n\nColumns often contain repeated instances of a smaller set of distinct values.\nDimension tables are a common technique in data warehousing.\n\nDistinct values are stored in the dimension table.\nPrimary observations are stored as integer keys referencing the dimension table.\n\nMore efficient storage and computation.\n\n\nvalues = pd.Series(['apple', 'orange', 'apple',\n                    'apple'] * 2)\nvalues\n\n0     apple\n1    orange\n2     apple\n3     apple\n4     apple\n5    orange\n6     apple\n7     apple\ndtype: object\n\n\n\npd.unique(values)\n\narray(['apple', 'orange'], dtype=object)\n\n\n\npd.value_counts(values)\n\n/tmp/ipykernel_2635/3297668723.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n  pd.value_counts(values)\n\n\napple     6\norange    2\nName: count, dtype: int64"
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-dimension-table-representation",
    "href": "qmd/pandas3ed7.html#categorical-data-dimension-table-representation",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Dimension Table Representation",
    "text": "7.5 Categorical Data: Dimension Table Representation\n\nvalues = pd.Series([0, 1, 0, 0] * 2)\ndim = pd.Series(['apple', 'orange'])\nvalues\n\n0    0\n1    1\n2    0\n3    0\n4    0\n5    1\n6    0\n7    0\ndtype: int64\n\n\n\ndim\n\n0     apple\n1    orange\ndtype: object\n\n\n\nvalues: Integer keys referencing the dimension table.\ndim: Dimension table containing the distinct values."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-restoring-original-data-with-take",
    "href": "qmd/pandas3ed7.html#categorical-data-restoring-original-data-with-take",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Restoring Original Data with take()",
    "text": "7.5 Categorical Data: Restoring Original Data with take()\n\ndim.take(values)\n\n0     apple\n1    orange\n0     apple\n0     apple\n0     apple\n1    orange\n0     apple\n0     apple\ndtype: object\n\n\n\ntake() method can be used to restore the original Series of strings."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-terminology",
    "href": "qmd/pandas3ed7.html#categorical-data-terminology",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Terminology",
    "text": "7.5 Categorical Data: Terminology\n\nCategorical or dictionary-encoded representation: Representing data with repeated values as integers.\nCategories, dictionary, or levels: The array of distinct values.\nCategory codes or codes: The integer values referencing the categories."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-benefits",
    "href": "qmd/pandas3ed7.html#categorical-data-benefits",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Benefits",
    "text": "7.5 Categorical Data: Benefits\n\nSignificant performance improvements in analytics.\nTransformations on categories while leaving codes unmodified.\n\nRenaming categories.\nAppending new categories."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-categorical-extension-type-in-pandas",
    "href": "qmd/pandas3ed7.html#categorical-data-categorical-extension-type-in-pandas",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Categorical Extension Type in pandas",
    "text": "7.5 Categorical Data: Categorical Extension Type in pandas\n\nfruits = ['apple', 'orange', 'apple', 'apple'] * 2\nN = len(fruits)\nrng = np.random.default_rng(seed=12345)\ndf = pd.DataFrame({'fruit': fruits,\n                   'basket_id': np.arange(N),\n                   'count': rng.integers(3, 15, size=N),\n                   'weight': rng.uniform(0, 4, size=N)},\n                  columns=['basket_id', 'fruit', 'count', 'weight'])\ndf\n\n\n\n\n\n\n\n\nbasket_id\nfruit\ncount\nweight\n\n\n\n\n0\n0\napple\n11\n1.564438\n\n\n1\n1\norange\n5\n1.331256\n\n\n2\n2\napple\n12\n2.393235\n\n\n3\n3\napple\n6\n0.746937\n\n\n4\n4\napple\n5\n2.691024\n\n\n5\n5\norange\n12\n3.767211\n\n\n6\n6\napple\n10\n0.992983\n\n\n7\n7\napple\n11\n3.795525\n\n\n\n\n\n\n\n\nExample DataFrame with a “fruit” column (string objects)."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-converting-to-categorical",
    "href": "qmd/pandas3ed7.html#categorical-data-converting-to-categorical",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Converting to Categorical",
    "text": "7.5 Categorical Data: Converting to Categorical\n\nfruit_cat = df['fruit'].astype('category')\nfruit_cat\n\n0     apple\n1    orange\n2     apple\n3     apple\n4     apple\n5    orange\n6     apple\n7     apple\nName: fruit, dtype: category\nCategories (2, object): ['apple', 'orange']\n\n\n\nastype('category'): Converts a column to the Categorical type."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-accessing-the-categorical-object",
    "href": "qmd/pandas3ed7.html#categorical-data-accessing-the-categorical-object",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Accessing the Categorical Object",
    "text": "7.5 Categorical Data: Accessing the Categorical Object\n\nc = fruit_cat.array\ntype(c)\n\npandas.core.arrays.categorical.Categorical\n\n\n\nThe .array attribute accesses the underlying Categorical object."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-categories-and-codes-attributes",
    "href": "qmd/pandas3ed7.html#categorical-data-categories-and-codes-attributes",
    "title": "```qmd",
    "section": "7.5 Categorical Data: categories and codes Attributes",
    "text": "7.5 Categorical Data: categories and codes Attributes\n\nc.categories\n\nIndex(['apple', 'orange'], dtype='object')\n\n\n\nc.codes\n\narray([0, 1, 0, 0, 0, 1, 0, 0], dtype=int8)\n\n\n\ncategories: The distinct values.\ncodes: Integer codes representing each value’s category."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-converting-a-dataframe-column",
    "href": "qmd/pandas3ed7.html#categorical-data-converting-a-dataframe-column",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Converting a DataFrame Column",
    "text": "7.5 Categorical Data: Converting a DataFrame Column\n\ndf['fruit'] = df['fruit'].astype('category')\ndf[\"fruit\"]\n\n0     apple\n1    orange\n2     apple\n3     apple\n4     apple\n5    orange\n6     apple\n7     apple\nName: fruit, dtype: category\nCategories (2, object): ['apple', 'orange']\n\n\n\nConvert a DataFrame column to categorical by assigning the result of astype('category')."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-creating-categorical-directly",
    "href": "qmd/pandas3ed7.html#categorical-data-creating-categorical-directly",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Creating Categorical Directly",
    "text": "7.5 Categorical Data: Creating Categorical Directly\n\nmy_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar'])\nmy_categories\n\n['foo', 'bar', 'baz', 'foo', 'bar']\nCategories (3, object): ['bar', 'baz', 'foo']\n\n\n\nCreate Categorical objects directly from Python sequences."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-from_codes-constructor",
    "href": "qmd/pandas3ed7.html#categorical-data-from_codes-constructor",
    "title": "```qmd",
    "section": "7.5 Categorical Data: from_codes() Constructor",
    "text": "7.5 Categorical Data: from_codes() Constructor\n\ncategories = ['foo', 'bar', 'baz']\ncodes = [0, 1, 2, 0, 0, 1]\nmy_cats_2 = pd.Categorical.from_codes(codes, categories)\nmy_cats_2\n\n['foo', 'bar', 'baz', 'foo', 'foo', 'bar']\nCategories (3, object): ['foo', 'bar', 'baz']\n\n\n\nfrom_codes(codes, categories): Creates a Categorical from existing codes and categories."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-ordered-categories",
    "href": "qmd/pandas3ed7.html#categorical-data-ordered-categories",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Ordered Categories",
    "text": "7.5 Categorical Data: Ordered Categories\n\nordered_cat = pd.Categorical.from_codes(codes, categories,\n                                        ordered=True)\nordered_cat\n\n['foo', 'bar', 'baz', 'foo', 'foo', 'bar']\nCategories (3, object): ['foo' &lt; 'bar' &lt; 'baz']\n\n\n\nmy_cats_2.as_ordered() # unordered categorical instance can be made ordered\n\n['foo', 'bar', 'baz', 'foo', 'foo', 'bar']\nCategories (3, object): ['foo' &lt; 'bar' &lt; 'baz']\n\n\n\nordered=True: Indicates that the categories have a meaningful order.\nBy default, categories are unordered."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-computations-with-categoricals",
    "href": "qmd/pandas3ed7.html#categorical-data-computations-with-categoricals",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Computations with Categoricals",
    "text": "7.5 Categorical Data: Computations with Categoricals\n\nUsing Categorical generally behaves the same as the non-encoded version (e.g., string array).\nSome pandas functions (like groupby) perform better with categoricals.\n\n\nrng = np.random.default_rng(seed=12345)\ndraws = rng.standard_normal(1000)\ndraws[:5]\n\narray([-1.42382504,  1.26372846, -0.87066174, -0.25917323, -0.07534331])"
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-qcut-and-categoricals",
    "href": "qmd/pandas3ed7.html#categorical-data-qcut-and-categoricals",
    "title": "```qmd",
    "section": "7.5 Categorical Data: qcut() and Categoricals",
    "text": "7.5 Categorical Data: qcut() and Categoricals\n\nbins = pd.qcut(draws, 4) # quartile binning\nbins\n\n[(-3.121, -0.675], (0.687, 3.211], (-3.121, -0.675], (-0.675, 0.0134], (-0.675, 0.0134], ..., (0.0134, 0.687], (0.0134, 0.687], (-0.675, 0.0134], (0.0134, 0.687], (-0.675, 0.0134]]\nLength: 1000\nCategories (4, interval[float64, right]): [(-3.121, -0.675] &lt; (-0.675, 0.0134] &lt; (0.0134, 0.687] &lt; (0.687, 3.211]]\n\n\n\nbins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\nbins\n\n['Q1', 'Q4', 'Q1', 'Q2', 'Q2', ..., 'Q3', 'Q3', 'Q2', 'Q3', 'Q2']\nLength: 1000\nCategories (4, object): ['Q1' &lt; 'Q2' &lt; 'Q3' &lt; 'Q4']\n\n\n\nbins.codes[:10]\n\narray([0, 3, 0, 1, 1, 0, 0, 2, 2, 0], dtype=int8)\n\n\n\npd.qcut() returns a Categorical object.\nlabels argument to give names."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-groupby-with-categoricals",
    "href": "qmd/pandas3ed7.html#categorical-data-groupby-with-categoricals",
    "title": "```qmd",
    "section": "7.5 Categorical Data: groupby() with Categoricals",
    "text": "7.5 Categorical Data: groupby() with Categoricals\n\nbins = pd.Series(bins, name='quartile')\nresults = (pd.Series(draws)\n           .groupby(bins)\n           .agg(['count', 'min', 'max'])\n           .reset_index())\nresults\n\n/tmp/ipykernel_2635/2483392743.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby(bins)\n\n\n\n\n\n\n\n\n\nquartile\ncount\nmin\nmax\n\n\n\n\n0\nQ1\n250\n-3.119609\n-0.678494\n\n\n1\nQ2\n250\n-0.673305\n0.008009\n\n\n2\nQ3\n250\n0.018753\n0.686183\n\n\n3\nQ4\n250\n0.688282\n3.211418\n\n\n\n\n\n\n\n\nresults['quartile']\n\n0    Q1\n1    Q2\n2    Q3\n3    Q4\nName: quartile, dtype: category\nCategories (4, object): ['Q1' &lt; 'Q2' &lt; 'Q3' &lt; 'Q4']\n\n\n\nThe ‘quartile’ column in the result retains the original categorical information."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-performance-benefits",
    "href": "qmd/pandas3ed7.html#categorical-data-performance-benefits",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Performance Benefits",
    "text": "7.5 Categorical Data: Performance Benefits\n\nN = 10_000_000\nlabels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4))\ncategories = labels.astype('category')\n\n\nlabels.memory_usage(deep=True)\n\n520000132\n\n\n\ncategories.memory_usage(deep=True)\n\n10000512\n\n\n\nCategoricals use significantly less memory than strings."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-categorical-methods",
    "href": "qmd/pandas3ed7.html#categorical-data-categorical-methods",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Categorical Methods",
    "text": "7.5 Categorical Data: Categorical Methods\n\nSeries containing categorical data have special methods (similar to Series.str).\nAccessed via the cat accessor.\n\n\ns = pd.Series(['a', 'b', 'c', 'd'] * 2)\ncat_s = s.astype('category')\ncat_s\n\n0    a\n1    b\n2    c\n3    d\n4    a\n5    b\n6    c\n7    d\ndtype: category\nCategories (4, object): ['a', 'b', 'c', 'd']"
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-cat-accessor",
    "href": "qmd/pandas3ed7.html#categorical-data-cat-accessor",
    "title": "```qmd",
    "section": "7.5 Categorical Data: cat Accessor",
    "text": "7.5 Categorical Data: cat Accessor\n\ncat_s.cat.codes\n\n0    0\n1    1\n2    2\n3    3\n4    0\n5    1\n6    2\n7    3\ndtype: int8\n\n\n\ncat_s.cat.categories\n\nIndex(['a', 'b', 'c', 'd'], dtype='object')\n\n\n\nThe cat accessor provides access to categorical methods and attributes."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-set_categories",
    "href": "qmd/pandas3ed7.html#categorical-data-set_categories",
    "title": "```qmd",
    "section": "7.5 Categorical Data: set_categories()",
    "text": "7.5 Categorical Data: set_categories()\n\nactual_categories = ['a', 'b', 'c', 'd', 'e']\ncat_s2 = cat_s.cat.set_categories(actual_categories)\ncat_s2\n\n0    a\n1    b\n2    c\n3    d\n4    a\n5    b\n6    c\n7    d\ndtype: category\nCategories (5, object): ['a', 'b', 'c', 'd', 'e']\n\n\n\nset_categories(): Changes the set of categories.\nUseful when the data doesn’t include all possible categories."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-value_counts-with-set_categories",
    "href": "qmd/pandas3ed7.html#categorical-data-value_counts-with-set_categories",
    "title": "```qmd",
    "section": "7.5 Categorical Data: value_counts() with set_categories()",
    "text": "7.5 Categorical Data: value_counts() with set_categories()\n\ncat_s.value_counts()\n\na    2\nb    2\nc    2\nd    2\nName: count, dtype: int64\n\n\n\ncat_s2.value_counts()\n\na    2\nb    2\nc    2\nd    2\ne    0\nName: count, dtype: int64\n\n\n\nvalue_counts() respects the categories defined, even if some aren’t present in the data."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-remove_unused_categories",
    "href": "qmd/pandas3ed7.html#categorical-data-remove_unused_categories",
    "title": "```qmd",
    "section": "7.5 Categorical Data: remove_unused_categories()",
    "text": "7.5 Categorical Data: remove_unused_categories()\n\ncat_s3 = cat_s[cat_s.isin(['a', 'b'])]\ncat_s3\n\n0    a\n1    b\n4    a\n5    b\ndtype: category\nCategories (4, object): ['a', 'b', 'c', 'd']\n\n\n\ncat_s3.cat.remove_unused_categories()\n\n0    a\n1    b\n4    a\n5    b\ndtype: category\nCategories (2, object): ['a', 'b']\n\n\n\nremove_unused_categories(): Removes categories that don’t appear in the data.\nUseful for memory savings after filtering."
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-categorical-methods-for-series-in-pandas",
    "href": "qmd/pandas3ed7.html#categorical-data-categorical-methods-for-series-in-pandas",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Categorical methods for Series in pandas",
    "text": "7.5 Categorical Data: Categorical methods for Series in pandas\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nadd_categories\nAppend new (unused) categories at end of existing categories\n\n\nas_ordered\nMake categories ordered\n\n\nas_unordered\nMake categories unordered\n\n\nremove_categories\nRemove categories, setting any removed values to null\n\n\nremove_unused_categories\nRemove any category values that do not appear in the data\n\n\nrename_categories\nReplace categories with indicated set of new category names; cannot change the number of categories\n\n\nreorder_categories\nBehaves like rename_categories, but can also change the result to have ordered categories\n\n\nset_categories\nReplace the categories with the indicated set of new categories; can add or remove categories"
  },
  {
    "objectID": "qmd/pandas3ed7.html#categorical-data-creating-dummy-variables",
    "href": "qmd/pandas3ed7.html#categorical-data-creating-dummy-variables",
    "title": "```qmd",
    "section": "7.5 Categorical Data: Creating Dummy Variables",
    "text": "7.5 Categorical Data: Creating Dummy Variables\n\nConverting categorical data into dummy variables (one-hot encoding).\nUsed in statistics and machine learning.\n\n\ncat_s = pd.Series(['a', 'b', 'c', 'd'] * 2, dtype='category')\npd.get_dummies(cat_s)\n\n\n\n\n\n\n\n\na\nb\nc\nd\n\n\n\n\n0\nTrue\nFalse\nFalse\nFalse\n\n\n1\nFalse\nTrue\nFalse\nFalse\n\n\n2\nFalse\nFalse\nTrue\nFalse\n\n\n3\nFalse\nFalse\nFalse\nTrue\n\n\n4\nTrue\nFalse\nFalse\nFalse\n\n\n5\nFalse\nTrue\nFalse\nFalse\n\n\n6\nFalse\nFalse\nTrue\nFalse\n\n\n7\nFalse\nFalse\nFalse\nTrue\n\n\n\n\n\n\n\n\npd.get_dummies(categorical_series) creates a DataFrame with dummy variables."
  },
  {
    "objectID": "qmd/pandas3ed7.html#conclusion",
    "href": "qmd/pandas3ed7.html#conclusion",
    "title": "```qmd",
    "section": "7.6 Conclusion",
    "text": "7.6 Conclusion\n\nEffective data preparation is crucial for efficient data analysis.\nThis chapter covered many data cleaning and transformation techniques.\nThe next chapter explores joining and grouping functionality in pandas."
  },
  {
    "objectID": "qmd/pandas3ed7.html#summary",
    "href": "qmd/pandas3ed7.html#summary",
    "title": "```qmd",
    "section": "Summary",
    "text": "Summary\n\nData cleaning is a significant part of data analysis, often taking up 80% or more of an analyst’s time.\nPandas provides powerful tools for handling missing data (NaN, None), including dropna, fillna, isna, and notna.\nData transformation operations include removing duplicates (duplicated, drop_duplicates), mapping values (map), replacing values (replace), renaming indexes (rename), binning (cut, qcut), outlier detection, permutation, sampling (sample), and creating dummy variables (get_dummies).\nExtension data types (Int64Dtype, StringDtype, CategoricalDtype, etc.) offer improved handling of specific data types and missing values.\nString manipulation can be done efficiently with Python’s built-in string methods, regular expressions (re module), and pandas’ str accessor.\nThe Categorical type provides memory and performance benefits for data with repeated values, offering methods like cat.codes, cat.categories, set_categories, and remove_unused_categories."
  },
  {
    "objectID": "qmd/pandas3ed7.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed7.html#thoughts-and-discussion",
    "title": "```qmd",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\nReflect on a time you encountered messy data. Which of the techniques discussed in this chapter would have been most helpful?\nWhy is it important to handle missing data appropriately? What are the potential consequences of ignoring or mishandling it?\nHow does the Categorical type improve efficiency compared to storing data as strings? When would you choose to use Categorical data?\nCan you think of situations where you might not want to drop duplicate data?\nExplore the documentation for the re module and pandas’ str accessor. What other useful functions can you find?\nConsider the tradeoffs between cut() and qcut(). When would you use one versus the other?\nDiscuss scenarios for using ordered vs. unordered categorical.\nWhy might you want to cap outlier to a certain range instead of simply remove all outliers?"
  },
  {
    "objectID": "qmd/pandas3edA1.html",
    "href": "qmd/pandas3edA1.html",
    "title": "",
    "section": "",
    "text": "---\ntitle: \"Advanced NumPy\"\nformat:\n  revealjs:\n    theme: sky\n    footer: \"Python for Data Analysis\"\n    multiplex: true\n---\n\n## Introduction to Advanced NumPy\n\n::: {layout-ncol=2}\n-   So far, we've learned about the basics of NumPy.\n-   In this lecture, we will go *deeper* into NumPy.\n    -   Internal details of the `ndarray` type.\n    -   Advanced array manipulations and algorithms.\n\n-   This will include topics like:\n\n    -   `ndarray` Object Internals\n    -   Data Type Hierarchy\n    -   Array Manipulation\n    -   Broadcasting\n    -   Advanced `ufunc` Usage\n    -   Structured Arrays\n    -   Sorting\n    -   Writing Fast NumPy Functions with Numba\n\n![](page1_1.png){.absolute top=0 right=0 width=\"400\"}\n:::\n\n##  `ndarray` Object Internals\n\n-   The NumPy `ndarray` provides a way to interpret a block of **homogeneously typed data** as a multidimensional array object.\n\n    -   *Homogeneously typed data*: All elements in the array have the **same data type**.\n    -   It can be *contiguous* or *strided*.\n\n-   **Data Type (`dtype`)**: Determines how the data is interpreted (e.g., floating point, integer, boolean).\n\n-   **Strided View**: Every array object is a *strided view* on a block of data, enabling operations like `arr[::2, ::-1]` **without copying data**.\n\n## `ndarray` Object Internals (Cont'd)\n\n- An `ndarray` internally consists of:\n\n    1.  **A pointer to data**: A block of data in RAM or in a memory-mapped file.\n    2.  **The data type (`dtype`)**: Describes fixed-size value cells in the array.\n    3.  **A tuple indicating the array's shape**:  E.g., `(10, 5)` for a 10x5 array.\n    4.  **A tuple of strides**: Integers indicating the number of bytes to \"step\" in order to advance one element along a dimension.\n\n::: {layout-ncol=2}\n```python\nimport numpy as np\nrng = np.random.default_rng(seed=12345)\n:::"
  },
  {
    "objectID": "qmd/pandas3edA1.html#visualizing-ndarray",
    "href": "qmd/pandas3edA1.html#visualizing-ndarray",
    "title": "",
    "section": "Visualizing ndarray",
    "text": "Visualizing ndarray\n\n\nData: The actual data stored in the array.\ndtype: Information about the data type (e.g., float64, int32).\nShape: Dimensions of the array (e.g., (3, 4, 5)).\nStrides: Number of bytes to jump to get to the next element in each dimension."
  },
  {
    "objectID": "qmd/pandas3edA1.html#example-shape-and-strides",
    "href": "qmd/pandas3edA1.html#example-shape-and-strides",
    "title": "",
    "section": "Example: Shape and Strides",
    "text": "Example: Shape and Strides\n\nA 10 x 5 array would have the shape (10, 5):\n\narr_2d = np.ones((10, 5))\narr_2d.shape\n\nOutput:\n\n(10, 5)\n\nA typical (C order) 3 x 4 x 5 array of float64 (8-byte) values has the strides (160, 40, 8):\n\narr_3d = np.ones((3, 4, 5), dtype=np.float64)\narr_3d.strides\n\nOutput:\n\n(160, 40, 8)"
  },
  {
    "objectID": "qmd/pandas3edA1.html#understanding-strides",
    "href": "qmd/pandas3edA1.html#understanding-strides",
    "title": "",
    "section": "Understanding Strides",
    "text": "Understanding Strides\n\nStrides indicate how many bytes we need to move in memory to get to the next element along each dimension.\nExample:\n\narr_3d.strides is (160, 40, 8).\nTo get to the next element in the first dimension (rows), move 160 bytes.\nTo get to the next element in the second dimension (columns), move 40 bytes.\nTo get to the next element in the third dimension, move 8 bytes (size of float64).\n\nLarger strides on a particular axis generally mean computation along that axis is more costly.\nStrides can even be negative."
  },
  {
    "objectID": "qmd/pandas3edA1.html#numpy-data-type-hierarchy",
    "href": "qmd/pandas3edA1.html#numpy-data-type-hierarchy",
    "title": "",
    "section": "NumPy Data Type Hierarchy",
    "text": "NumPy Data Type Hierarchy\n\n\n\n\n\n\n\nNumPy has a rich hierarchy of data types.\nSometimes, you need to check if an array contains, integers, floating-point numbers, strings, etc..\nInstead of checking against a long list of types, you can use superclasses like np.integer and np.floating with the np.issubdtype function.\n\n\n\nints = np.ones(10, dtype=np.uint16)\nfloats = np.ones(10, dtype=np.float32)\nnp.issubdtype(ints.dtype, np.integer)\n\n\n\n\nOutput:\n\n\nTrue\n\n\n\n\nnp.issubdtype(floats.dtype, np.floating)\n\n\nOutput:\n\n\n\n\nTrue"
  },
  {
    "objectID": "qmd/pandas3edA1.html#numpy-data-type-hierarchy-contd",
    "href": "qmd/pandas3edA1.html#numpy-data-type-hierarchy-contd",
    "title": "",
    "section": "NumPy Data Type Hierarchy (Cont’d)",
    "text": "NumPy Data Type Hierarchy (Cont’d)\n\nYou can see all parent classes of a specific data type using the .mro() method (Method Resolution Order).\n\nnp.float64.mro()\n\nOutput:\n\n[numpy.float64,\n numpy.floating,\n numpy.inexact,\n numpy.number,\n numpy.generic,\n float,\n object]\n\nIt means np.float64 inherits from np.floating, np.inexact, …, and object."
  },
  {
    "objectID": "qmd/pandas3edA1.html#visualizing-numpy-data-type-hierarchy",
    "href": "qmd/pandas3edA1.html#visualizing-numpy-data-type-hierarchy",
    "title": "",
    "section": "Visualizing NumPy Data Type Hierarchy",
    "text": "Visualizing NumPy Data Type Hierarchy\n\n\nThis diagram shows the relationships between different NumPy data types.\n\ngeneric is the root of the hierarchy.\nnumber, character, bool_, and object_ are direct subclasses of generic.\nnumber is further subdivided into integer, inexact, etc."
  },
  {
    "objectID": "qmd/pandas3edA1.html#advanced-array-manipulation-reshaping",
    "href": "qmd/pandas3edA1.html#advanced-array-manipulation-reshaping",
    "title": "",
    "section": "Advanced Array Manipulation: Reshaping",
    "text": "Advanced Array Manipulation: Reshaping\n\nReshaping allows you to convert an array from one shape to another without copying data.\nUse the reshape() method, passing a tuple indicating the new shape.\n\narr = np.arange(8)\narr.reshape((4, 2))\n\nOutput:\n\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#reshaping-contd",
    "href": "qmd/pandas3edA1.html#reshaping-contd",
    "title": "",
    "section": "Reshaping (Cont’d)",
    "text": "Reshaping (Cont’d)\n\nYou can also reshape multidimensional arrays:\n\narr.reshape((4, 2)).reshape((2, 4))\n\nOutput:\n\narray([[0, 1, 2, 3],\n       [4, 5, 6, 7]])\n\nOne dimension can be -1, which means the value is inferred from the data:\n\narr = np.arange(15)\narr.reshape((5, -1))\n\nOutput:\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11],\n       [12, 13, 14]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#reshaping-contd-1",
    "href": "qmd/pandas3edA1.html#reshaping-contd-1",
    "title": "",
    "section": "Reshaping (Cont’d)",
    "text": "Reshaping (Cont’d)\n\nYou can pass an array’s shape attribute directly to reshape:\n\nother_arr = np.ones((3, 5))\narr.reshape(other_arr.shape)\n\nOutput:\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#flattening-or-raveling",
    "href": "qmd/pandas3edA1.html#flattening-or-raveling",
    "title": "",
    "section": "Flattening or Raveling",
    "text": "Flattening or Raveling\n\nFlattening or raveling is the opposite of reshaping: converting a multidimensional array to a one-dimensional array.\nravel() does not copy the underlying values if the values in the result were contiguous in the original array.\n\narr = np.arange(15).reshape((5, 3))\narr.ravel()\n\nOutput:\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n\nflatten() behaves like ravel except that it always returns a copy of the data:\n\narr.flatten()"
  },
  {
    "objectID": "qmd/pandas3edA1.html#c-versus-fortran-order",
    "href": "qmd/pandas3edA1.html#c-versus-fortran-order",
    "title": "",
    "section": "C Versus FORTRAN Order",
    "text": "C Versus FORTRAN Order\n\nNumPy arrays can be created in row major (C) order or column major (FORTRAN) order.\n\nRow major (C order): Consecutive elements in a row are stored next to each other in memory.\nColumn major (FORTRAN order): Consecutive elements in a column are stored next to each other in memory.\n\nFunctions like reshape and ravel accept an order argument ('C' or 'F').\n\narr = np.arange(12).reshape((3, 4))\narr.ravel()       # Default is 'C' order\n\nOutput:\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\narr.ravel('F')  # FORTRAN order\n\nOutput:\n\narray([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#c-versus-fortran-order-contd",
    "href": "qmd/pandas3edA1.html#c-versus-fortran-order-contd",
    "title": "",
    "section": "C Versus FORTRAN Order (Cont’d)",
    "text": "C Versus FORTRAN Order (Cont’d)\n\n\n\n\n\n\n\nThe key difference between C and FORTRAN order is the way in which the dimensions are walked:\n\nC/row major order: Traverse higher dimensions first (e.g., axis 1 before advancing on axis 0).\nFORTRAN/column major order Traverse higher dimensions last (e.g., axis 0 before advancing on axis 1)."
  },
  {
    "objectID": "qmd/pandas3edA1.html#concatenating-and-splitting-arrays",
    "href": "qmd/pandas3edA1.html#concatenating-and-splitting-arrays",
    "title": "",
    "section": "Concatenating and Splitting Arrays",
    "text": "Concatenating and Splitting Arrays\n\nnumpy.concatenate: Joins a sequence of arrays along an existing axis.\n\narr1 = np.array([[1, 2, 3], [4, 5, 6]])\narr2 = np.array([[7, 8, 9], [10, 11, 12]])\nnp.concatenate([arr1, arr2], axis=0)  # Stack vertically\n\nOutput:\n\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]])\nnp.concatenate([arr1, arr2], axis=1)  # Stack horizontally\n\nOutput:\n\narray([[ 1,  2,  3,  7,  8,  9],\n       [ 4,  5,  6, 10, 11, 12]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#concatenating-and-splitting-arrays-contd",
    "href": "qmd/pandas3edA1.html#concatenating-and-splitting-arrays-contd",
    "title": "",
    "section": "Concatenating and Splitting Arrays (Cont’d)",
    "text": "Concatenating and Splitting Arrays (Cont’d)\n\nConvenience functions:\n\nvstack, row_stack: Stack arrays by rows (along axis 0).\nhstack: Stack arrays by columns (along axis 1).\ncolumn_stack: Like hstack, but converts 1D arrays to 2D column vectors first.\ndstack: Stack arrays by “depth” (along axis 2)\n\n\nnp.vstack((arr1, arr2))\n\nOutput:\n\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]])\nnp.hstack((arr1, arr2))\n\nOutput:\n\narray([[ 1,  2,  3,  7,  8,  9],\n       [ 4,  5,  6, 10, 11, 12]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#concatenating-and-splitting-arrays-contd-1",
    "href": "qmd/pandas3edA1.html#concatenating-and-splitting-arrays-contd-1",
    "title": "",
    "section": "Concatenating and Splitting Arrays (Cont’d)",
    "text": "Concatenating and Splitting Arrays (Cont’d)\n\nsplit: Slices an array into multiple arrays along an axis.\n\narr = rng.standard_normal((5, 2))\nfirst, second, third = np.split(arr, [1, 3])\n\n\n\n\n\n\nfirst\n\n\narray([[-0.2047,  0.4789]])\n\n\nsecond\n\n\n\n\narray([[-0.5194, -0.5557],\n       [ 1.9658,  1.3934]])\n\n\nthird\n\n\narray([[-0.5031, -0.6223],\n       [-0.9212, -0.9238]])\n\n\n\n\n\nhsplit/vsplit: Convenience functions for splitting on axis 0 and 1, respectively."
  },
  {
    "objectID": "qmd/pandas3edA1.html#array-concatenation-functions",
    "href": "qmd/pandas3edA1.html#array-concatenation-functions",
    "title": "",
    "section": "Array Concatenation Functions",
    "text": "Array Concatenation Functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nconcatenate\nMost general function, concatenate collection of arrays along one axis\n\n\nvstack, row_stack\nStack arrays by rows (along axis 0)\n\n\nhstack\nStack arrays by columns (along axis 1)\n\n\ncolumn_stack\nLike hstack, but convert 1D arrays to 2D column vectors first\n\n\ndstack\nStack arrays by “depth” (along axis 2)\n\n\nsplit\nSplit array at passed locations along a particular axis\n\n\nhsplit/vsplit\nConvenience functions for splitting on axis 0 and 1, respectively"
  },
  {
    "objectID": "qmd/pandas3edA1.html#stacking-helpers-r_-and-c_",
    "href": "qmd/pandas3edA1.html#stacking-helpers-r_-and-c_",
    "title": "",
    "section": "Stacking helpers: r_ and c_",
    "text": "Stacking helpers: r_ and c_\n\nr_ and c_ are objects in the NumPy namespace that make stacking arrays more concise.\n\narr = np.arange(6)\narr1 = arr.reshape((3, 2))\narr2 = rng.standard_normal((3, 2))\nnp.r_[arr1, arr2] # row_stack\n\nOutput:\n\narray([[ 0.        ,  1.        ],\n       [ 2.        ,  3.        ],\n       [ 4.        ,  5.        ],\n       [ 0.12412138,  0.30261367],\n       [ 0.52377193,  1.34380973],\n       [ 0.71354416,  0.83115413]])\nnp.c_[np.r_[arr1, arr2], arr]  # Concatenate arr as a new column\n\nOutput:\n\narray([[ 0.        ,  1.        ,  0.        ],\n       [ 2.        ,  3.        ,  1.        ],\n       [ 4.        ,  5.        ,  2.        ],\n       [ 0.12412138,  0.30261367,  3.        ],\n       [ 0.52377193,  1.34380973,  4.        ],\n       [ 0.71354416,  0.83115413,  5.        ]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#repeating-elements-tile-and-repeat",
    "href": "qmd/pandas3edA1.html#repeating-elements-tile-and-repeat",
    "title": "",
    "section": "Repeating Elements: tile and repeat",
    "text": "Repeating Elements: tile and repeat\n\nrepeat: Replicates each element in an array some number of times, producing a larger array.\n\narr = np.arange(3)\narr.repeat(3)\n\nOutput:\n\narray([0, 0, 0, 1, 1, 1, 2, 2, 2])\narr.repeat([2, 3, 4])  # Different repetition for each element\n\nOutput:\n\narray([0, 0, 1, 1, 1, 2, 2, 2, 2])\n\nWith a 2D array, you can repeat elements along a particular axis:\n\narr = rng.standard_normal((2, 2))\narr.repeat(2, axis=0)"
  },
  {
    "objectID": "qmd/pandas3edA1.html#repeating-elements-tile-and-repeat-contd",
    "href": "qmd/pandas3edA1.html#repeating-elements-tile-and-repeat-contd",
    "title": "",
    "section": "Repeating Elements: tile and repeat (Cont’d)",
    "text": "Repeating Elements: tile and repeat (Cont’d)\n\ntile: Stacks copies of an array along an axis (like “laying down tiles”).\n\narr = rng.standard_normal((2, 2))\nnp.tile(arr, 2)  # Repeat the whole array twice along rows\n\nOutput:\n\narray([[ 0.50308719, -0.62227418,  0.50308719, -0.62227418],\n       [-0.92116946, -0.92379166, -0.92116946, -0.92379166]])\nnp.tile(arr, (2, 1))  # 2 repetitions along rows, 1 along columns\n\nOutput:\n\narray([[ 0.50308719, -0.62227418],\n       [-0.92116946, -0.92379166],\n       [ 0.50308719, -0.62227418],\n       [-0.92116946, -0.92379166]])\nnp.tile(arr, (3, 2))  # 3 repetitions along rows, 2 along columns"
  },
  {
    "objectID": "qmd/pandas3edA1.html#fancy-indexing-equivalents-take-and-put",
    "href": "qmd/pandas3edA1.html#fancy-indexing-equivalents-take-and-put",
    "title": "",
    "section": "Fancy Indexing Equivalents: take and put",
    "text": "Fancy Indexing Equivalents: take and put\n\ntake: Selects elements along an axis using integer indices.\n\narr = np.arange(10) * 100\ninds = [7, 1, 2, 6]\narr.take(inds)  # Equivalent to arr[inds]\n\nOutput:\n\narray([700, 100, 200, 600])\n\nput: Assigns values to specified indices (in-place). Note: put does not accept an axis argument.\n\narr.put(inds, 42)\narr\n\nOutput:\n\narray([  0,  42,  42, 300, 400, 500,  42,  42, 800, 900])\narr.put(inds, [40, 41, 42, 43]) # assign a sequence\narr"
  },
  {
    "objectID": "qmd/pandas3edA1.html#broadcasting",
    "href": "qmd/pandas3edA1.html#broadcasting",
    "title": "",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nBroadcasting describes how operations work between arrays of different shapes.\nSimplest example: combining a scalar value with an array.\n\narr = np.arange(5)\narr * 4  # The scalar 4 is \"broadcast\" to all elements\n\nOutput:\n\narray([ 0,  4,  8, 12, 16])\n\nMore complex: demeaning each column of an array by subtracting the column means.\n\narr = rng.standard_normal((4, 3))\ndemeaned = arr - arr.mean(0)  # mean(0) computes mean of each column\ndemeaned"
  },
  {
    "objectID": "qmd/pandas3edA1.html#the-broadcasting-rule",
    "href": "qmd/pandas3edA1.html#the-broadcasting-rule",
    "title": "",
    "section": "The Broadcasting Rule",
    "text": "The Broadcasting Rule\n\n\nTwo arrays are compatible for broadcasting if for each trailing dimension (starting from the end):\n\nThe axis lengths match, OR\nEither of the lengths is 1.\n\nBroadcasting is performed over the missing or length 1 dimensions.\n\n\n\n\n\n\n\n\n\n\n\n\nThis figure shows an example of broadcasting a 1D array of shape (3,) over a 2D array of shape (4, 3) along axis 0."
  },
  {
    "objectID": "qmd/pandas3edA1.html#broadcasting-rule-example",
    "href": "qmd/pandas3edA1.html#broadcasting-rule-example",
    "title": "",
    "section": "Broadcasting Rule Example",
    "text": "Broadcasting Rule Example\n\nSuppose we want to subtract the row means from a 2D array.\n\narr = rng.standard_normal((4, 3))\nrow_means = arr.mean(1)  # Compute mean of each row\nrow_means.shape\n\nOutput:\n\n(4,)\n\nrow_means has shape (4,). To broadcast over axis 1, the smaller array must have shape (4, 1).\n\ndemeaned = arr - row_means.reshape((4, 1))\ndemeaned.mean(1)\n\nOutput:\n\narray([-2.2204e-16,  0.0000e+00,  2.2204e-16,  0.0000e+00])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#broadcasting-over-other-axes",
    "href": "qmd/pandas3edA1.html#broadcasting-over-other-axes",
    "title": "",
    "section": "Broadcasting Over Other Axes",
    "text": "Broadcasting Over Other Axes\n\nBroadcasting over axes other than axis 0 requires reshaping.\nTo add a new axis of length 1, use np.newaxis and slicing.\n\narr = np.zeros((4, 4))\narr_3d = arr[:, np.newaxis, :]  # Add a new axis in the middle\narr_3d.shape\n\nOutput:\n\n(4, 1, 4)\narr_1d = rng.standard_normal(3)\narr_1d[:, np.newaxis]  # Add a new axis at the end (column vector)\narray([[ 0.3757],\n       [ 0.3026],\n       [-0.0853]])\narr_1d[np.newaxis, :]  # Add a new axis at the beginning (row vector)\narray([[ 0.3757,  0.3026, -0.0853]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#setting-array-values-by-broadcasting",
    "href": "qmd/pandas3edA1.html#setting-array-values-by-broadcasting",
    "title": "",
    "section": "Setting Array Values by Broadcasting",
    "text": "Setting Array Values by Broadcasting\n\nThe broadcasting rule also applies to setting values via array indexing.\n\narr = np.zeros((4, 3))\narr[:] = 5  # Set all elements to 5\narr\n\nOutput:\n\narray([[5., 5., 5.],\n       [5., 5., 5.],\n       [5., 5., 5.],\n       [5., 5., 5.]])\ncol = np.array([1.28, -0.42, 0.44, 1.6])\narr[:] = col[:, np.newaxis]  # Set columns using a 1D array\narr"
  },
  {
    "objectID": "qmd/pandas3edA1.html#advanced-ufunc-usage",
    "href": "qmd/pandas3edA1.html#advanced-ufunc-usage",
    "title": "",
    "section": "Advanced ufunc Usage",
    "text": "Advanced ufunc Usage\n\nNumPy’s universal functions (ufuncs) have special methods for vectorized operations.\nreduce: Aggregates array values, optionally along an axis, by performing a sequence of binary operations.\n\narr = np.arange(10)\nnp.add.reduce(arr)  # Equivalent to arr.sum()\n\nOutput:\n\n45"
  },
  {
    "objectID": "qmd/pandas3edA1.html#ufunc-instance-methods-contd",
    "href": "qmd/pandas3edA1.html#ufunc-instance-methods-contd",
    "title": "",
    "section": "ufunc Instance Methods (Cont’d)",
    "text": "ufunc Instance Methods (Cont’d)\n\naccumulate: Produces an array of the same size with the intermediate “accumulated” values.\n\narr = np.arange(15).reshape((3, 5))\nnp.add.accumulate(arr, axis=1) # cumulative sum along rows\n\nOutput:\n\narray([[ 0,  1,  3,  6, 10],\n       [ 5, 11, 18, 26, 35],\n       [10, 21, 33, 46, 60]])\n\nouter: Performs a pair-wise cross product between two arrays.\n\narr = np.arange(3).repeat([1, 2, 2])\nnp.multiply.outer(arr, np.arange(5))\n\nOutput:\n\narray([[0, 0, 0, 0, 0],\n       [0, 1, 2, 3, 4],\n       [0, 1, 2, 3, 4],\n       [0, 2, 4, 6, 8],\n       [0, 2, 4, 6, 8]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#ufunc-instance-methods-contd-1",
    "href": "qmd/pandas3edA1.html#ufunc-instance-methods-contd-1",
    "title": "",
    "section": "ufunc Instance Methods (Cont’d)",
    "text": "ufunc Instance Methods (Cont’d)\n\nreduceat: Performs a “local reduce” (array groupby operation).\n\narr = np.arange(10)\nnp.add.reduceat(arr, [0, 5, 8])  # Reduce [0:5], [5:8], [8:]\n\nOutput:\n\narray([10, 18, 17])\narr = np.multiply.outer(np.arange(4), np.arange(5))\nnp.add.reduceat(arr, [0, 2, 4], axis=1) # Reduce along columns with bins"
  },
  {
    "objectID": "qmd/pandas3edA1.html#ufunc-methods",
    "href": "qmd/pandas3edA1.html#ufunc-methods",
    "title": "",
    "section": "ufunc Methods",
    "text": "ufunc Methods\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\naccumulate(x)\nAggregate values, preserving all partial aggregates.\n\n\nat(x, indices, b=None)\nPerforms operation in place on x at the specified indices.\n\n\nreduce(x)\nAggregate values by successive applications of the operation.\n\n\nreduceat(x, bins)\n“Local” reduce or “group by”; reduce contiguous slices of data to produce an aggregated array.\n\n\nouter(x, y)\nApply operation to all pairs of elements in x and y; the resulting array has shape x.shape + y.shape."
  },
  {
    "objectID": "qmd/pandas3edA1.html#writing-fast-numpy-functions-with-numba",
    "href": "qmd/pandas3edA1.html#writing-fast-numpy-functions-with-numba",
    "title": "",
    "section": "Writing Fast NumPy Functions with Numba",
    "text": "Writing Fast NumPy Functions with Numba\n\nNumba is an open-source project that creates fast functions for NumPy-like data using CPUs, GPUs, or other hardware.\nIt uses the LLVM Project to translate Python code into compiled machine code.\nExample: A pure Python function to compute (x - y).mean():\n\nimport numpy as np\n\ndef mean_distance(x, y):\n    nx = len(x)\n    result = 0.0\n    count = 0\n    for i in range(nx):\n        result += x[i] - y[i]\n        count += 1\n    return result / count"
  },
  {
    "objectID": "qmd/pandas3edA1.html#numba-contd",
    "href": "qmd/pandas3edA1.html#numba-contd",
    "title": "",
    "section": "Numba (Cont’d)",
    "text": "Numba (Cont’d)\n\nThis function is slow compared to NumPy’s vectorized operations.\nWe can use numba.jit to compile the function:\n\nimport numba as nb\n\nnumba_mean_distance = nb.jit(mean_distance)\n\n# OR, using a decorator:\n@nb.jit\ndef numba_mean_distance(x, y):\n    nx = len(x)\n    result = 0.0\n    count = 0\n    for i in range(nx):\n        result += x[i] - y[i]\n        count += 1\n    return result / count\n\nThe compiled function (numba_mean_distance) will be much faster than the pure Python version, and potentially even faster than the NumPy version!"
  },
  {
    "objectID": "qmd/pandas3edA1.html#creating-custom-numpy.ufunc-objects-with-numba",
    "href": "qmd/pandas3edA1.html#creating-custom-numpy.ufunc-objects-with-numba",
    "title": "",
    "section": "Creating Custom numpy.ufunc Objects with Numba",
    "text": "Creating Custom numpy.ufunc Objects with Numba\n\nThe numba.vectorize function creates compiled NumPy ufuncs, which can behave similarly to the built-in ufuncs.\n\nfrom numba import vectorize\n\n@vectorize\ndef nb_add(x, y):\n    return x + y\n\nNow, nb_add acts as a ufunc."
  },
  {
    "objectID": "qmd/pandas3edA1.html#structured-and-record-arrays",
    "href": "qmd/pandas3edA1.html#structured-and-record-arrays",
    "title": "",
    "section": "Structured and Record Arrays",
    "text": "Structured and Record Arrays\n\nndarray is usually homogeneous (all elements have the same dtype).\nStructured arrays allow each element to represent a “struct” (like in C) or a row in a SQL table with multiple named fields.\n\ndtype = [('x', np.float64), ('y', np.int32)]  # Define field names and types\nsarr = np.array([(1.5, 6), (np.pi, -2)], dtype=dtype)\nsarr\n\nOutput:\n\narray([(1.5   ,  6), (3.1416, -2)],\n      dtype=[('x', '&lt;f8'), ('y', '&lt;i4')])\n\nYou can access elements by field name like a dictionary:\n\nsarr[0]\n(1.5, 6)\nsarr[0]['y']\n6"
  },
  {
    "objectID": "qmd/pandas3edA1.html#nested-data-types-and-multidimensional-fields",
    "href": "qmd/pandas3edA1.html#nested-data-types-and-multidimensional-fields",
    "title": "",
    "section": "Nested Data Types and Multidimensional Fields",
    "text": "Nested Data Types and Multidimensional Fields\n\nYou can specify nested data types and multidimensional fields in structured arrays.\n\ndtype = [('x', np.int64, 3), ('y', np.int32)] # 'x' is an array of 3 int64\narr = np.zeros(4, dtype=dtype)\narr\n\nOutput:\n\narray([([0, 0, 0], 0), ([0, 0, 0], 0), ([0, 0, 0], 0), ([0, 0, 0], 0)],\n      dtype=[('x', '&lt;i8', (3,)), ('y', '&lt;i4')])\narr[0]['x']\n\nOutput:\n\narray([0, 0, 0])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#why-use-structured-arrays",
    "href": "qmd/pandas3edA1.html#why-use-structured-arrays",
    "title": "",
    "section": "Why Use Structured Arrays?",
    "text": "Why Use Structured Arrays?\n\nThey provide a way to interpret a block of memory as a tabular structure with nested columns.\nEfficient for writing data to and from disk (including memory maps).\nUseful for representing data serialized in C or C++ code (e.g., legacy systems).\nThey are lower level compared to pandas DataFrame."
  },
  {
    "objectID": "qmd/pandas3edA1.html#more-about-sorting",
    "href": "qmd/pandas3edA1.html#more-about-sorting",
    "title": "",
    "section": "More About Sorting",
    "text": "More About Sorting\n\nndarray.sort(): In-place sort (modifies the array).\n\narr = rng.standard_normal(6)\narr.sort()  # Sorts in ascending order\narr\n\nOutput:\n\narray([-2.3594, -0.8309, -0.1994,  0.    ,  0.3863,  1.1338])\n\nnumpy.sort(): Creates a new, sorted copy of the array.\n\narr = rng.standard_normal(5)\nnp.sort(arr)  # Returns a sorted copy\n\nBoth methods accept an axis argument to sort independently along an axis.\n\narr = rng.standard_normal((3, 5))\narr.sort(axis=1)  # Sort each row\narr"
  },
  {
    "objectID": "qmd/pandas3edA1.html#indirect-sorts-argsort-and-lexsort",
    "href": "qmd/pandas3edA1.html#indirect-sorts-argsort-and-lexsort",
    "title": "",
    "section": "Indirect Sorts: argsort and lexsort",
    "text": "Indirect Sorts: argsort and lexsort\n\nIndirect sorts return an array of integer indices that reorder the data.\nargsort(): Returns indices that would sort an array.\n\nvalues = np.array([5, 0, 1, 3, 2])\nindexer = values.argsort()\nindexer\n\nOutput:\n\narray([1, 2, 4, 3, 0])\nvalues[indexer]  # Use the indices to get the sorted array"
  },
  {
    "objectID": "qmd/pandas3edA1.html#indirect-sorts-argsort-and-lexsort-contd",
    "href": "qmd/pandas3edA1.html#indirect-sorts-argsort-and-lexsort-contd",
    "title": "",
    "section": "Indirect Sorts: argsort and lexsort (Cont’d)",
    "text": "Indirect Sorts: argsort and lexsort (Cont’d)\n\nlexsort(): Performs an indirect lexicographical sort on multiple key arrays (like sorting by last name, then first name).\nImportant: The order of keys starts with the last array passed.\n\nfirst_name = np.array(['Bob', 'Jane', 'Steve', 'Bill', 'Barbara'])\nlast_name = np.array(['Jones', 'Arnold', 'Arnold', 'Jones', 'Walters'])\nsorter = np.lexsort((first_name, last_name))  # Sort by last_name, then first_name\nlist(zip(last_name[sorter], first_name[sorter]))\n\nOutput:\n\n[('Arnold', 'Jane'),\n ('Arnold', 'Steve'),\n ('Jones', 'Bill'),\n ('Jones', 'Bob'),\n ('Walters', 'Barbara')]"
  },
  {
    "objectID": "qmd/pandas3edA1.html#alternative-sort-algorithms",
    "href": "qmd/pandas3edA1.html#alternative-sort-algorithms",
    "title": "",
    "section": "Alternative Sort Algorithms",
    "text": "Alternative Sort Algorithms\n\nNumPy offers different sorting algorithms:\n\nquicksort (default)\n`mergesort\n  -   `heapsort`\ntimsort\n\nA stable sorting algorithm preserves the relative position of equal elements. mergesort is a stable sort.\n\nvalues = np.array(['2:first', '2:second', '1:first', '1:second', '1:third'])\nkey = np.array([2, 2, 1, 1, 1])\nindexer = key.argsort(kind='mergesort') # Use mergesort for stability\nvalues.take(indexer)\n\nOutput:\n\narray(['1:first', '1:second', '1:third', '2:first', '2:second'],\n      dtype='&lt;U8')"
  },
  {
    "objectID": "qmd/pandas3edA1.html#array-sorting-methods",
    "href": "qmd/pandas3edA1.html#array-sorting-methods",
    "title": "",
    "section": "Array Sorting Methods",
    "text": "Array Sorting Methods\n\n\n\n\nKind\nSpeed\nStable\nWork space\nWorst case\n\n\n\n\n‘quicksort’\n1\nNo\n0\nO(n^2)\n\n\n‘mergesort’\n2\nYes\n~n/2\nO(n log n)\n\n\n‘heapsort’\n3\nNo\n0\nO(n log n)\n\n\n‘timsort’\n4\nYes\n~n/2\nO(n log n)\n\n\n\nNote: timsort was added after the book. It is also stable and often very efficient, particularly on partially sorted data."
  },
  {
    "objectID": "qmd/pandas3edA1.html#partially-sorting-arrays",
    "href": "qmd/pandas3edA1.html#partially-sorting-arrays",
    "title": "",
    "section": "Partially Sorting Arrays",
    "text": "Partially Sorting Arrays\n\nnumpy.partition and np.argpartition: Partition an array around the k-th smallest element.\n\nrng = np.random.default_rng(12345)\narr = rng.standard_normal(20)\nnp.partition(arr, 3)  # The first 3 elements are the smallest (unsorted)\n\nnp.argpartition returns the indices that rearrange the data:\n\nindices = np.argpartition(arr, 3)\narr.take(indices) # Equivalent to a partial sort"
  },
  {
    "objectID": "qmd/pandas3edA1.html#numpy.searchsorted-finding-elements-in-a-sorted-array",
    "href": "qmd/pandas3edA1.html#numpy.searchsorted-finding-elements-in-a-sorted-array",
    "title": "",
    "section": "numpy.searchsorted: Finding Elements in a Sorted Array",
    "text": "numpy.searchsorted: Finding Elements in a Sorted Array\n\nsearchsorted performs a binary search on a sorted array, returning the index where a value should be inserted to maintain sortedness.\n\narr = np.array([0, 1, 7, 12, 15])\narr.searchsorted(9)  # Where should 9 be inserted?\n\nOutput:\n\n3\narr.searchsorted([0, 8, 11, 16])\n\nOutput:\n\narray([0, 3, 3, 5])\n\nsearchsorted returns the index at the left side of a group of equal values by default. You can change this with side='right'."
  },
  {
    "objectID": "qmd/pandas3edA1.html#numpy.searchsorted-example-binning-data",
    "href": "qmd/pandas3edA1.html#numpy.searchsorted-example-binning-data",
    "title": "",
    "section": "numpy.searchsorted Example: Binning Data",
    "text": "numpy.searchsorted Example: Binning Data\n\nSuppose you have data between 0 and 10,000, and you want to bin it using “bucket edges”.\n\ndata = np.floor(rng.uniform(0, 10000, size=50))\nbins = np.array([0, 100, 1000, 5000, 10000])\nlabels = bins.searchsorted(data)  # Find which bin each data point belongs to\nlabels\n\nThis can be combined with pandas’s groupby to compute statistics for each bin."
  },
  {
    "objectID": "qmd/pandas3edA1.html#advanced-array-input-and-output-memory-mapped-files",
    "href": "qmd/pandas3edA1.html#advanced-array-input-and-output-memory-mapped-files",
    "title": "",
    "section": "Advanced Array Input and Output: Memory-Mapped Files",
    "text": "Advanced Array Input and Output: Memory-Mapped Files\n\nMemory-mapped files allow you to interact with binary data on disk as if it were in memory.\nNumPy’s memmap object is ndarray-like. It allows reading/writing small segments of a large file without reading the whole file into memory.\nCreate a memmap with np.memmap, specifying file path, dtype, shape, and mode.\n\nmmap = np.memmap('mymmap', dtype='float64', mode='w+',\n                 shape=(10000, 10000))\nmmap\n\nOutput:\n\nmemmap([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]])"
  },
  {
    "objectID": "qmd/pandas3edA1.html#memory-mapped-files-contd",
    "href": "qmd/pandas3edA1.html#memory-mapped-files-contd",
    "title": "",
    "section": "Memory-Mapped Files (Cont’d)",
    "text": "Memory-Mapped Files (Cont’d)\n\nSlicing a memmap returns views on the data on disk.\n\nsection = mmap[:5]  # First 5 rows\n\nAssigning to the slice buffers the changes in memory. Use flush() to synchronize changes to disk.\n\nsection[:] = rng.standard_normal((5, 10000))  # Assign random data\nmmap.flush()  # Write changes to disk\n\nWhen opening an existing memory map, you must still specify dtype and shape:\n\nmmap = np.memmap('mymmap', dtype='float64', shape=(10000, 10000))\nmmap\n\nmemmap also works with structured data types."
  },
  {
    "objectID": "qmd/pandas3edA1.html#performance-tips",
    "href": "qmd/pandas3edA1.html#performance-tips",
    "title": "",
    "section": "Performance Tips",
    "text": "Performance Tips\n\nKey Idea: Replace Python loops and conditional logic with NumPy array operations and boolean operations.\nUse broadcasting.\nUse array views (slicing) to avoid copying data.\nUtilize ufuncs and ufunc methods.\nIf NumPy alone isn’t enough, consider C, FORTRAN, or Cython (Cython is often a good choice for C-like performance)."
  },
  {
    "objectID": "qmd/pandas3edA1.html#the-importance-of-contiguous-memory",
    "href": "qmd/pandas3edA1.html#the-importance-of-contiguous-memory",
    "title": "",
    "section": "The Importance of Contiguous Memory",
    "text": "The Importance of Contiguous Memory\n\nThe memory layout of an array can significantly affect performance.\nContiguous memory: Elements are stored in memory in the order they appear in the array (C or FORTRAN order).\nOperations accessing contiguous blocks of memory are generally fastest (due to CPU cache hierarchy).\nNumPy arrays are C-contiguous by default. The transpose is Fortran-contiguous.\nCheck with the flags attribute:\n\narr_c = np.ones((100, 10000), order='C')\narr_f = np.ones((100, 10000), order='F')\narr_c.flags  # C_CONTIGUOUS: True, F_CONTIGUOUS: False\narr_f.flags  # C_CONTIGUOUS: False, F_CONTIGUOUS: True"
  },
  {
    "objectID": "qmd/pandas3edA1.html#the-importance-of-contiguous-memory-contd",
    "href": "qmd/pandas3edA1.html#the-importance-of-contiguous-memory-contd",
    "title": "",
    "section": "The Importance of Contiguous Memory (Cont’d)",
    "text": "The Importance of Contiguous Memory (Cont’d)\n\nSumming rows of a C-contiguous array is usually faster than summing rows of a FORTRAN-contiguous array.\nIf an array doesn’t have the desired memory order, use copy() with 'C' or 'F':\n\narr_f.copy('C').flags\n\nImportant: Views are not guaranteed to be contiguous. Check flags.contiguous."
  },
  {
    "objectID": "qmd/pandas3edA1.html#summary",
    "href": "qmd/pandas3edA1.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\n\nWe’ve explored the internals of NumPy’s ndarray: dtype, shape, strides.\nWe learned about advanced array manipulations: reshaping, concatenation, splitting, repeating.\nWe understood broadcasting and its rules.\nWe covered advanced ufunc methods.\nWe introduced structured arrays.\nWe discussed sorting (including indirect sorts and partial sorts).\nWe learned about memory-mapped files for large datasets.\nWe discussed performance tips, especially the importance of contiguous memory.\nWe also touched upon Numba, which offers significant speed improvements."
  },
  {
    "objectID": "qmd/pandas3edA1.html#thoughts-and-discussion",
    "href": "qmd/pandas3edA1.html#thoughts-and-discussion",
    "title": "",
    "section": "Thoughts and Discussion",
    "text": "Thoughts and Discussion\n\nHow can you apply these advanced NumPy techniques to your data analysis tasks?\nThink about scenarios where memory-mapped files would be particularly useful.\nWhen would you consider using Numba to speed up your code?\nConsider the trade-offs between using structured arrays and pandas DataFrames.\nDiscuss situations where the choice of sorting algorithm (quicksort, mergesort, etc.) might matter.\nReflect on the benefits of vectorized operations versus explicit loops in Python. How does this relate to the concept of “premature optimization”?\nExplore the Numba documentation further. What other features does it offer?"
  },
  {
    "objectID": "qmd/pandas3ed4.html",
    "href": "qmd/pandas3ed4.html",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "",
    "text": "NumPy, short for Numerical Python, is a foundational package for numerical computing in Python.\n\nWhy is it important? 🧐 Many scientific computing packages rely on NumPy’s array objects for data exchange. Think of it as the lingua franca (common language) of data analysis in Python.\nIt is designed for efficiency on large arrays of data.\nWhat will we learn? We’ll cover the basics, focusing on how NumPy enables fast, array-oriented operations, which are crucial for data analysis with libraries like pandas."
  },
  {
    "objectID": "qmd/pandas3ed4.html#introduction-to-numpy",
    "href": "qmd/pandas3ed4.html#introduction-to-numpy",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "",
    "text": "NumPy, short for Numerical Python, is a foundational package for numerical computing in Python.\n\nWhy is it important? 🧐 Many scientific computing packages rely on NumPy’s array objects for data exchange. Think of it as the lingua franca (common language) of data analysis in Python.\nIt is designed for efficiency on large arrays of data.\nWhat will we learn? We’ll cover the basics, focusing on how NumPy enables fast, array-oriented operations, which are crucial for data analysis with libraries like pandas."
  },
  {
    "objectID": "qmd/pandas3ed4.html#key-features-of-numpy",
    "href": "qmd/pandas3ed4.html#key-features-of-numpy",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Key Features of NumPy",
    "text": "Key Features of NumPy\n\nHere’s a glimpse of what NumPy offers:\n\nndarray: The heart of NumPy. A highly efficient multidimensional array. Imagine a container holding data of the same type (e.g., all numbers). It allows for fast operations and broadcasting (we’ll cover this later!).\nMathematical Functions: A rich set of functions that operate on entire arrays without explicit loops. This is called vectorization, and it’s much faster than writing loops in Python.\nData I/O: Tools to read and write array data to disk.\nLinear Algebra: Capabilities for linear algebra, random number generation, and Fourier transforms. Essential tools for many scientific and engineering tasks.\nC API: Allows seamless integration with libraries written in C, C++, or FORTRAN. This is key for leveraging high-performance legacy code."
  },
  {
    "objectID": "qmd/pandas3ed4.html#why-numpy-is-efficient",
    "href": "qmd/pandas3ed4.html#why-numpy-is-efficient",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Why NumPy is Efficient?",
    "text": "Why NumPy is Efficient?\n\nNumPy’s efficiency stems from several design choices:\n\nContiguous Memory: Unlike Python lists, NumPy arrays store data in a single, contiguous block of memory. This makes accessing and manipulating data much faster.\nC-Based Algorithms: Many NumPy operations are implemented in C, avoiding the overhead of Python’s interpreter.\nLess Memory Usage: NumPy arrays generally consume less memory than Python lists, especially for numerical data."
  },
  {
    "objectID": "qmd/pandas3ed4.html#numpy-vs.-python-lists-a-performance-showdown",
    "href": "qmd/pandas3ed4.html#numpy-vs.-python-lists-a-performance-showdown",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "NumPy vs. Python Lists: A Performance Showdown 🏃‍♂️",
    "text": "NumPy vs. Python Lists: A Performance Showdown 🏃‍♂️\n\nLet’s see NumPy’s speed advantage in action. We’ll compare multiplying a million integers by 2 using both a NumPy array and a Python list:\n\nimport numpy as np\nmy_arr = np.arange(1_000_000)  # NumPy array\nmy_list = list(range(1_000_000)) # Python list\n\nNow, the timed operations:\n\n# NumPy array operation\n# %timeit my_arr2 = my_arr * 2\n\n\n# Python list operation (using a list comprehension)\n# %timeit my_list2 = [x * 2 for x in my_list]\n\n\n\n\n\n\n\n\nNumPy-based algorithms are generally 10 to 100 times faster (or more) than their pure Python counterparts and use significantly less memory."
  },
  {
    "objectID": "qmd/pandas3ed4.html#the-numpy-ndarray-a-closer-look",
    "href": "qmd/pandas3ed4.html#the-numpy-ndarray-a-closer-look",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "The NumPy ndarray: A Closer Look",
    "text": "The NumPy ndarray: A Closer Look\n\nThe ndarray (N-dimensional array) is the core data structure in NumPy.\n\nHomogeneous Data: All elements in an ndarray must be of the same data type (e.g., all integers, all floats).\nKey Attributes:\n\nshape: A tuple indicating the size of each dimension. For a 2x3 array, the shape would be (2, 3).\ndtype: An object describing the data type of the elements (e.g., int64, float32).\n\nCreating ndarray The easiest way to create an array is to use the array function. This accepts any sequence-like object (including other arrays) and produces a new NumPy array containing the passed data."
  },
  {
    "objectID": "qmd/pandas3ed4.html#creating-ndarrays-examples",
    "href": "qmd/pandas3ed4.html#creating-ndarrays-examples",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Creating ndarrays: Examples",
    "text": "Creating ndarrays: Examples\n\nLet’s create some arrays:\n\nimport numpy as np\n\n# From a list\ndata1 = [6, 7.5, 8, 0, 1]\narr1 = np.array(data1)\nprint(arr1)\nprint(arr1.dtype)\n\n[6.  7.5 8.  0.  1. ]\nfloat64\n\n\n\n# From a nested list (creates a 2D array)\ndata2 = [[1, 2, 3, 4], [5, 6, 7, 8]]\narr2 = np.array(data2)\nprint(arr2)\nprint(arr2.ndim)  # Number of dimensions\nprint(arr2.shape)\nprint(arr2.dtype)\n\n[[1 2 3 4]\n [5 6 7 8]]\n2\n(2, 4)\nint64"
  },
  {
    "objectID": "qmd/pandas3ed4.html#array-creation-functions",
    "href": "qmd/pandas3ed4.html#array-creation-functions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Array Creation Functions",
    "text": "Array Creation Functions\n\nNumPy provides several convenient functions to create arrays:\n\n# Array of zeros\nzeros_arr = np.zeros(10)  # 1D array\nprint(zeros_arr)\n\nzeros_arr_2d = np.zeros((3, 6)) # 2D array (3x6)\nprint(zeros_arr_2d)\n\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[[0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]]\n\n\n\n# Array of ones\nones_arr = np.ones((2, 3)) # 2D array (2x3)\nprint(ones_arr)\n\n[[1. 1. 1.]\n [1. 1. 1.]]\n\n\n\n# Uninitialized array (may contain garbage values)\nempty_arr = np.empty((2, 3, 2)) # 3D array\nprint(empty_arr)\n\n[[[3.65459196e-315 0.00000000e+000]\n  [5.83300621e-317 6.94337884e-310]\n  [5.83931444e-317 5.81975339e-317]]\n\n [[5.83672949e-317 5.78951657e-317]\n  [6.94335341e-310 5.83755556e-317]\n  [6.94335290e-310 6.94332820e-310]]]\n\n\n\n#  'arange': Similar to Python's 'range', but returns an ndarray\nrange_arr = np.arange(15)\nprint(range_arr)\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#summary-of-array-creation-functions",
    "href": "qmd/pandas3ed4.html#summary-of-array-creation-functions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Summary of Array Creation Functions",
    "text": "Summary of Array Creation Functions\n\nA handy table summarizing common array creation functions:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\narray\nConverts input data (list, tuple, array, etc.) to an ndarray.\n\n\nasarray\nSimilar to array, but does not copy if the input is already an ndarray.\n\n\narange\nLike Python’s range, but returns an ndarray.\n\n\nones, ones_like\nCreates an array filled with 1s. ones_like takes another array and creates a ones array of the same shape and dtype.\n\n\nzeros, zeros_like\nSimilar to ones and ones_like, but creates arrays filled with 0s.\n\n\nempty, empty_like\nCreates an array without initializing its values. Use with caution!\n\n\nfull, full_like\nCreates an array filled with a specified value. full_like takes another array and uses its shape and dtype.\n\n\neye, identity\nCreates a square identity matrix (1s on the diagonal, 0s elsewhere)."
  },
  {
    "objectID": "qmd/pandas3ed4.html#data-types-dtypes",
    "href": "qmd/pandas3ed4.html#data-types-dtypes",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Data Types (dtypes)",
    "text": "Data Types (dtypes)\n\n\nWhat is a dtype? A special object that contains information about the data type held by an ndarray (e.g., float64, int32, bool).\nWhy are dtypes important? They give you fine-grained control over how data is stored in memory. This is crucial for performance, especially with large datasets. They also allow NumPy to interface with data from other systems (like databases or files written in C/C++).\nSpecifying dtypes:\n\n\narr1 = np.array([1, 2, 3], dtype=np.float64)  # Explicitly set dtype\narr2 = np.array([1, 2, 3], dtype=np.int32)\nprint(arr1.dtype)\nprint(arr2.dtype)\n\nfloat64\nint32"
  },
  {
    "objectID": "qmd/pandas3ed4.html#common-numpy-data-types",
    "href": "qmd/pandas3ed4.html#common-numpy-data-types",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Common NumPy Data Types",
    "text": "Common NumPy Data Types\n\n\n\n\n\n\n\n\n\nType\nType Code\nDescription\n\n\n\n\nint8, uint8\ni1, u1\nSigned and unsigned 8-bit (1 byte) integer types\n\n\nint16, uint16\ni2, u2\nSigned and unsigned 16-bit integer types\n\n\nint32, uint32\ni4, u4\nSigned and unsigned 32-bit integer types\n\n\nint64, uint64\ni8, u8\nSigned and unsigned 64-bit integer types\n\n\nfloat16\nf2\nHalf-precision floating point\n\n\nfloat32\nf4 or f\nStandard single-precision floating point; compatible with C float\n\n\nfloat64\nf8 or d\nStandard double-precision floating point; compatible with C double and Python float\n\n\nfloat128\nf16 or g\nExtended-precision floating point\n\n\ncomplex64, complex128, complex256\nc8, c16, c32\nComplex numbers represented by two 32, 64, or 128 floats, respectively\n\n\nbool\n?\nBoolean type storing True and False values\n\n\nobject\nO\nPython object type; a value can be any Python object\n\n\nstring_\nS\nFixed-length ASCII string type (1 byte per character). Use S10 for a string of length 10.\n\n\nunicode_\nU\nFixed-length Unicode type (number of bytes platform-specific)\n\n\n\n\n\n\n\n\n\n\nThere are both signed and unsigned integer types. A signed integer can represent both positive and negative integers, while an unsigned integer can only represent non-zero integers."
  },
  {
    "objectID": "qmd/pandas3ed4.html#casting-with-astype",
    "href": "qmd/pandas3ed4.html#casting-with-astype",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Casting with astype",
    "text": "Casting with astype\n\n\nWhat is casting? Converting an array from one dtype to another.\nHow to cast: Use the astype method. astype always creates a new array (a copy of the data), even if the new dtype is the same as the old dtype.\n\n\narr = np.array([1, 2, 3, 4, 5])\nprint(arr.dtype)\nfloat_arr = arr.astype(np.float64) # Integer to float\nprint(float_arr.dtype)\n\nint64\nfloat64\n\n\n\n# `np.string_` was removed in the NumPy 2.0 release. Use `np.bytes_` instead.\nnumeric_strings = np.array(['1.25', '-9.6', '42'], dtype=np.bytes_)\nfloat_arr = numeric_strings.astype(float) # String to float\nprint(float_arr)\n\n[ 1.25 -9.6  42.  ]\n\n\n\n\n\n\n\n\nBe cautious when using the numpy.string_ type, as string data in NumPy is fixed size and may truncate input without warning. pandas has more intuitive out-of-the-box behavior on non-numeric data."
  },
  {
    "objectID": "qmd/pandas3ed4.html#arithmetic-with-numpy-arrays-vectorization",
    "href": "qmd/pandas3ed4.html#arithmetic-with-numpy-arrays-vectorization",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Arithmetic with NumPy Arrays: Vectorization",
    "text": "Arithmetic with NumPy Arrays: Vectorization\n\n\nVectorization: A core concept in NumPy. It means performing operations on entire arrays without writing explicit for loops. This is much faster and more concise.\nElement-wise Operations: Arithmetic operations between equal-sized arrays are applied element-wise:\n\n\narr = np.array([[1., 2., 3.], [4., 5., 6.]])\nprint(arr * arr) # Element-wise multiplication\nprint(arr - arr) # Element-wise subtraction\n\n[[ 1.  4.  9.]\n [16. 25. 36.]]\n[[0. 0. 0.]\n [0. 0. 0.]]\n\n\n\nOperations with Scalars: Arithmetic operations with scalars propagate the scalar value to each element in the array:\n\n\nprint(1 / arr)   # Divide each element by 1\nprint(arr ** 2) # Square each element\n\n[[1.         0.5        0.33333333]\n [0.25       0.2        0.16666667]]\n[[ 1.  4.  9.]\n [16. 25. 36.]]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#broadcasting-brief-introduction",
    "href": "qmd/pandas3ed4.html#broadcasting-brief-introduction",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Broadcasting (Brief Introduction)",
    "text": "Broadcasting (Brief Introduction)\n\n\nWhat is broadcasting? A powerful mechanism that allows NumPy to perform arithmetic operations on arrays of different shapes, under certain conditions.\nExample: You can add a scalar to an array of any shape. The scalar is effectively “stretched” to match the array’s shape.\nWe’ll cover broadcasting in more detail later. For now, just be aware that it exists and is a key reason why NumPy is so flexible."
  },
  {
    "objectID": "qmd/pandas3ed4.html#basic-indexing-and-slicing",
    "href": "qmd/pandas3ed4.html#basic-indexing-and-slicing",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Basic Indexing and Slicing",
    "text": "Basic Indexing and Slicing\n\n\nSimilar to Python Lists: One-dimensional NumPy arrays can be indexed and sliced much like Python lists:\n\n\narr = np.arange(10)\nprint(arr[5])      # Access element at index 5\nprint(arr[5:8])    # Slice elements from index 5 up to (but not including) 8\narr[5:8] = 12     # Assign a value to a slice\nprint(arr)\n\n5\n[5 6 7]\n[ 0  1  2  3  4 12 12 12  8  9]\n\n\n\nViews vs. Copies: Array slices are views on the original array. This means that modifying a slice will modify the original array. This is different from Python lists, where slices create copies.\n\n\narr_slice = arr[5:8]\narr_slice[1] = 12345  # Modify the slice\nprint(arr)          # Original array is also modified!\n\n[    0     1     2     3     4    12 12345    12     8     9]\n\n\n\n\n\n\n\n\n\nIf you want a copy of a slice of an ndarray instead of a view, you will need to explicitly copy the array—for example, arr[5:8].copy()."
  },
  {
    "objectID": "qmd/pandas3ed4.html#indexing-and-slicing-higher-dimensions",
    "href": "qmd/pandas3ed4.html#indexing-and-slicing-higher-dimensions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Indexing and Slicing: Higher Dimensions",
    "text": "Indexing and Slicing: Higher Dimensions\n\n\nTwo-Dimensional Arrays: You can access elements using comma-separated indices:\n\n\narr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(arr2d[2])     # Access the third row (index 2)\nprint(arr2d[0][2])  # Access element at row 0, column 2 (two ways)\nprint(arr2d[0, 2])   # Access element at row 0, column 2\n\n[7 8 9]\n3\n3\n\n\n\nThinking about Axes:\n\nAxis 0: Rows\nAxis 1: Columns"
  },
  {
    "objectID": "qmd/pandas3ed4.html#indexing-elements-in-a-numpy-array.",
    "href": "qmd/pandas3ed4.html#indexing-elements-in-a-numpy-array.",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Indexing elements in a NumPy array.",
    "text": "Indexing elements in a NumPy array.\n\n\n\n\n\n\ngraph LR\n    subgraph \"Axis 0 (Rows)\"\n        0 --&gt; 1\n        1 --&gt; 2\n    end\n    subgraph \"Axis 1 (Columns)\"\n        0 --&gt; 0[0,0]\n        0 --&gt; 1[0,1]\n        0 --&gt; 2[0,2]\n        1 --&gt; 3[1,0]\n        1 --&gt; 4[1,1]\n        1 --&gt; 5[1,2]\n        2 --&gt; 6[2,0]\n        2 --&gt; 7[2,1]\n        2 --&gt; 8[2,2]\n    end"
  },
  {
    "objectID": "qmd/pandas3ed4.html#indexing-and-slicing-higher-dimensions-continued",
    "href": "qmd/pandas3ed4.html#indexing-and-slicing-higher-dimensions-continued",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Indexing and Slicing: Higher Dimensions (Continued)",
    "text": "Indexing and Slicing: Higher Dimensions (Continued)\n\n\nSlicing in Multiple Dimensions:\n\n\nprint(arr2d[:2])      # Select the first two rows\nprint(arr2d[:2, 1:])   # Select first two rows, columns from index 1 onwards\n\n[[1 2 3]\n [4 5 6]]\n[[2 3]\n [5 6]]\n\n\n\nMixing Integer Indexing and Slicing:\n\n\nprint(arr2d[1, :2])   # Select second row, first two columns (lower dimensional slice)\nprint(arr2d[:2, 2])    # Select first two rows, third column\n\n[4 5]\n[3 6]\n\n\n\nColon for Entire Axis:\n\n\nprint(arr2d[:, :1])   # Select all rows, but only the first column\n\n[[1]\n [4]\n [7]]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#two-dimensional-array-slicing",
    "href": "qmd/pandas3ed4.html#two-dimensional-array-slicing",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Two-dimensional array slicing",
    "text": "Two-dimensional array slicing\n\n\n\n\n\n\n\n\n\nExpression\nShape\nVisualization\n\n\n\n\narr[:2,1:]\n(2,2)\n```{python}\n\n\n#\necho: false\n\n\n\n\nimport matplotlib.pyplot as plt import numpy as np\narr = np.zeros((3,3)) arr[:2,1:] = 1 plt.imshow(arr, cmap=‘gray_r’) plt.xticks([]) plt.yticks([]) plt.show()\n| `arr[2]`          |    (3,)      |  ```{python}\n#| echo: false\narr = np.zeros((3,3))\narr[2,:] = 1\nplt.imshow(arr, cmap='gray_r')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```    |\n| `arr[2,:]`          |    (3,)      |   ```{python}\n#| echo: false\narr = np.zeros((3,3))\narr[2,:] = 1\nplt.imshow(arr, cmap='gray_r')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```   |\n| `arr[2:,:]`          |     (1,3)     |   ```{python}\n#| echo: false\narr = np.zeros((3,3))\narr[2:,:] = 1\nplt.imshow(arr, cmap='gray_r')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```   |\n| `arr[:, :2]`          |   (3,2)       |   ```{python}\n#| echo: false\narr = np.zeros((3,3))\narr[:,:2] = 1\nplt.imshow(arr, cmap='gray_r')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```   |\n| `arr[1, :2]`          |     (2,)     |   ```{python}\n#| echo: false\narr = np.zeros((3,3))\narr[1,:2] = 1\nplt.imshow(arr, cmap='gray_r')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```   |\n| `arr[1:2, :2]`          |  (1,2)        |  ```{python}\n#| echo: false\narr = np.zeros((3,3))\narr[1:2,:2] = 1\nplt.imshow(arr, cmap='gray_r')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```    |\n:::\n\n## Boolean Indexing\n\n::: {style=\"font-size: 0.8em;\"}\n- **Concept:**  Select data based on a Boolean array (an array of `True`/`False` values).  The Boolean array typically has the same shape as the array you're indexing.\n\n::: {#200036a0 .cell execution_count=21}\n``` {.python .cell-code}\nnames = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])\ndata = np.array([[4, 7], [0, 2], [-5, 6], [0, 0], [1, 2],\n                 [-12, -4], [3, 4]])\n\nprint(names == 'Bob')  # Create a Boolean array\nprint(data[names == 'Bob'])  # Select rows where names == 'Bob'\n\n[ True False False  True False False False]\n[[4 7]\n [0 0]]\n\n\n\nCombining with Slicing/Indexing:\n\n\nprint(data[names == 'Bob', 1:])  # Select rows where names == 'Bob', and columns from index 1\nprint(data[names != 'Bob'])     # Select rows where names is NOT 'Bob'\n\n[[7]\n [0]]\n[[  0   2]\n [ -5   6]\n [  1   2]\n [-12  -4]\n [  3   4]]\n\n\n\nLogical Operators:\n\n~: Negates a Boolean array (like not)\n&: Combines conditions (like and)\n|: Combines conditions (like or)\n\n\n\nmask = (names == 'Bob') | (names == 'Will')\nprint(data[mask])\n\n[[ 4  7]\n [-5  6]\n [ 0  0]\n [ 1  2]]\n\n\n\n\n\n\n\n\nThe Python keywords and and or do not work with Boolean arrays. Use & (and) and | (or) instead."
  },
  {
    "objectID": "qmd/pandas3ed4.html#fancy-indexing",
    "href": "qmd/pandas3ed4.html#fancy-indexing",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Fancy Indexing",
    "text": "Fancy Indexing\n\nConcept: Indexing using integer arrays. Allows you to select specific rows or columns, and even reorder them.\n\n\narr = np.zeros((8, 4))\nfor i in range(8):\n    arr[i] = i\nprint(arr)\nprint(arr[[4, 3, 0, 6]])  # Select rows 4, 3, 0, and 6, in that order\n\n[[0. 0. 0. 0.]\n [1. 1. 1. 1.]\n [2. 2. 2. 2.]\n [3. 3. 3. 3.]\n [4. 4. 4. 4.]\n [5. 5. 5. 5.]\n [6. 6. 6. 6.]\n [7. 7. 7. 7.]]\n[[4. 4. 4. 4.]\n [3. 3. 3. 3.]\n [0. 0. 0. 0.]\n [6. 6. 6. 6.]]\n\n\n\narr = np.arange(32).reshape((8, 4))\nprint(arr[[1, 5, 7, 2], [0, 3, 1, 2]]) # Select elements (1, 0), (5, 3), (7, 1), (2, 2)\n\n[ 4 23 29 10]\n\n\n\nSelecting a Rectangular Region:\n\n\nprint(arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]])  # Select rows 1, 5, 7, 2, and reorder columns\n\n[[ 4  7  5  6]\n [20 23 21 22]\n [28 31 29 30]\n [ 8 11  9 10]]\n\n\n\nImportant: Fancy indexing, unlike slicing, always copies the data into a new array."
  },
  {
    "objectID": "qmd/pandas3ed4.html#transposing-arrays-and-swapping-axes",
    "href": "qmd/pandas3ed4.html#transposing-arrays-and-swapping-axes",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Transposing Arrays and Swapping Axes",
    "text": "Transposing Arrays and Swapping Axes\n\n\nTransposing: Rearranging data by switching rows and columns. Use the .T attribute or the transpose method.\n\n\narr = np.arange(15).reshape((3, 5))\nprint(arr)\nprint(arr.T)  # Transpose the array\n\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]]\n[[ 0  5 10]\n [ 1  6 11]\n [ 2  7 12]\n [ 3  8 13]\n [ 4  9 14]]\n\n\n\nMatrix Multiplication: Use np.dot or the @ operator for matrix multiplication.\n\n\narr = np.array([[0, 1, 0], [1, 2, -2], [6, 3, 2], [-1, 0, -1], [1, 0, 1]])\nprint(np.dot(arr.T, arr))  # Matrix multiplication\nprint(arr.T @ arr)\n\n[[39 20 12]\n [20 14  2]\n [12  2 10]]\n[[39 20 12]\n [20 14  2]\n [12  2 10]]\n\n\n\nSwapping Axes: The swapaxes method takes a pair of axis numbers and switches the indicated axes.\n\n\nprint(arr.swapaxes(0, 1)) # swap axis 0 and axis 1\n\n[[ 0  1  6 -1  1]\n [ 1  2  3  0  0]\n [ 0 -2  2 -1  1]]\n\n\n\n\n\n\n\n\n\nTransposing and swapaxes return views on the underlying data without making a copy."
  },
  {
    "objectID": "qmd/pandas3ed4.html#pseudorandom-number-generation",
    "href": "qmd/pandas3ed4.html#pseudorandom-number-generation",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Pseudorandom Number Generation",
    "text": "Pseudorandom Number Generation\n\n\nnumpy.random Module: Provides functions to generate arrays of random numbers from various distributions.\ndefault_rng: The recommended way to create a random number generator.\n\n\nrng = np.random.default_rng(seed=12345)  # Create a generator with a seed\ndata = rng.standard_normal((2, 3))       # Generate a 2x3 array of standard normal values\nprint(data)\n\n[[-1.42382504  1.26372846 -0.87066174]\n [-0.25917323 -0.07534331 -0.74088465]]\n\n\n\nWhy use a seed? Setting a seed ensures reproducibility. You’ll get the same random numbers each time you run the code with the same seed.\nGenerator Isolation: The generator object rng is isolated from other code that might also use the numpy.random module.\nPerformance: numpy.random is much faster than Python’s built-in random module for generating large arrays."
  },
  {
    "objectID": "qmd/pandas3ed4.html#common-numpy.random-functions",
    "href": "qmd/pandas3ed4.html#common-numpy.random-functions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Common numpy.random Functions",
    "text": "Common numpy.random Functions\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\npermutation\nReturns a random permutation of a sequence, or a permuted range.\n\n\nshuffle\nRandomly permutes a sequence in place.\n\n\nuniform\nDraws samples from a uniform distribution.\n\n\nintegers\nDraws random integers from a given low-to-high range.\n\n\nstandard_normal\nDraws samples from a standard normal distribution (mean 0, standard deviation 1).\n\n\nbinomial\nDraws samples from a binomial distribution.\n\n\nnormal\nDraws samples from a normal (Gaussian) distribution.\n\n\nbeta\nDraws samples from a Beta distribution.\n\n\nchisquare\nDraws samples from a chi-square distribution.\n\n\ngamma\nDraws samples from a gamma distribution.\n\n\nuniform\nDraws samples from a uniform [0, 1) distribution."
  },
  {
    "objectID": "qmd/pandas3ed4.html#universal-functions-ufuncs",
    "href": "qmd/pandas3ed4.html#universal-functions-ufuncs",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Universal Functions (ufuncs)",
    "text": "Universal Functions (ufuncs)\n\n\nWhat are ufuncs? Functions that perform element-wise operations on ndarrays. They are fast vectorized wrappers for simple functions.\nUnary ufuncs: Take a single array as input.\n\n\narr = np.arange(10)\nprint(np.sqrt(arr))    # Square root of each element\nprint(np.exp(arr))     # Exponential of each element\n\n[0.         1.         1.41421356 1.73205081 2.         2.23606798\n 2.44948974 2.64575131 2.82842712 3.        ]\n[1.00000000e+00 2.71828183e+00 7.38905610e+00 2.00855369e+01\n 5.45981500e+01 1.48413159e+02 4.03428793e+02 1.09663316e+03\n 2.98095799e+03 8.10308393e+03]\n\n\n\nBinary ufuncs: Take two arrays as input.\n\n\nx = rng.standard_normal(8)\ny = rng.standard_normal(8)\nprint(np.maximum(x, y))  # Element-wise maximum\n\n[-0.46695317  0.6488928   0.78884434 -1.25666813  2.34740965  1.39897899\n  1.32229806  0.90219827]\n\n\n\nufuncs that return multiple arrays:\n\n\narr = rng.standard_normal(7) * 5\nremainder, whole_part = np.modf(arr)  # Returns fractional and integral parts\nprint(remainder)\nprint(whole_part)\n\n[ 0.51459671 -0.10791367 -0.7909463   0.24741966 -0.71800536 -0.40843795\n  0.62369966]\n[ 4. -8. -0.  2. -6. -0.  8.]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#some-unary-universal-functions",
    "href": "qmd/pandas3ed4.html#some-unary-universal-functions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Some Unary Universal Functions",
    "text": "Some Unary Universal Functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nabs, fabs\nComputes the absolute value element-wise. fabs is faster for non-complex data.\n\n\nsqrt\nComputes the square root of each element (equivalent to arr ** 0.5).\n\n\nsquare\nComputes the square of each element (equivalent to arr ** 2).\n\n\nexp\nComputes the exponent ex of each element.\n\n\nlog, log10, log2, log1p\nNatural logarithm (base e), log base 10, log base 2, and log(1 + x), respectively.\n\n\nsign\nComputes the sign of each element: 1 (positive), 0 (zero), or -1 (negative).\n\n\nceil\nComputes the ceiling of each element (smallest integer greater than or equal to that number).\n\n\nfloor\nComputes the floor of each element (largest integer less than or equal to each element).\n\n\nrint\nRounds elements to the nearest integer, preserving the dtype.\n\n\nmodf\nReturns fractional and integral parts of array as separate arrays.\n\n\nisnan\nReturns a Boolean array indicating whether each value is NaN (Not a Number).\n\n\nisfinite, isinf\nReturns a Boolean array indicating whether each element is finite or infinite, respectively.\n\n\ncos, cosh, sin, sinh, tan, tanh\nRegular and hyperbolic trigonometric functions.\n\n\narccos, arccosh, arcsin, arcsinh, arctan, arctanh\nInverse trigonometric functions.\n\n\nlogical_not\nComputes the truth value of not x element-wise (equivalent to ~arr)."
  },
  {
    "objectID": "qmd/pandas3ed4.html#some-binary-universal-functions",
    "href": "qmd/pandas3ed4.html#some-binary-universal-functions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Some Binary Universal Functions",
    "text": "Some Binary Universal Functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nadd\nAdds corresponding elements in arrays.\n\n\nsubtract\nSubtracts elements in second array from first array.\n\n\nmultiply\nMultiplies array elements.\n\n\ndivide, floor_divide\nDivides or floor divides (truncating the remainder).\n\n\npower\nRaises elements in first array to powers indicated in second array.\n\n\nmaximum, fmax\nElement-wise maximum. fmax ignores NaN.\n\n\nminimum, fmin\nElement-wise minimum. fmin ignores NaN.\n\n\nmod\nElement-wise modulus (remainder of division).\n\n\ncopysign\nCopies the sign of values in second argument to values in first argument.\n\n\ngreater, greater_equal, less, less_equal, equal, not_equal\nPerforms element-wise comparison, yielding a Boolean array.\n\n\nlogical_and, logical_or, logical_xor\nComputes element-wise truth value of logical operations."
  },
  {
    "objectID": "qmd/pandas3ed4.html#array-oriented-programming-example",
    "href": "qmd/pandas3ed4.html#array-oriented-programming-example",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Array-Oriented Programming: Example",
    "text": "Array-Oriented Programming: Example\n\nLet’s compute the function √(x^2 + y^2) across a grid of values:\n\npoints = np.arange(-5, 5, 0.01)  # 1000 equally spaced points\nxs, ys = np.meshgrid(points, points)  # Create coordinate matrices\nz = np.sqrt(xs ** 2 + ys ** 2)      # Compute the function\n\nNow, let’s visualize the result using Matplotlib:\n\nimport matplotlib.pyplot as plt\nplt.imshow(z, cmap=plt.cm.gray, extent=[-5, 5, -5, 5])\nplt.colorbar()\nplt.title(\"Image plot of $\\sqrt{x^2 + y^2}$ for a grid of values\")\n# plt.close('all')\nplt.show()\n\n&lt;&gt;:4: SyntaxWarning: invalid escape sequence '\\s'\n&lt;&gt;:4: SyntaxWarning: invalid escape sequence '\\s'\n/tmp/ipykernel_2711/1319111413.py:4: SyntaxWarning: invalid escape sequence '\\s'\n  plt.title(\"Image plot of $\\sqrt{x^2 + y^2}$ for a grid of values\")\n\n\n\n\n\n\n\n\n\nThis example demonstrates how concise and efficient array-oriented programming can be."
  },
  {
    "objectID": "qmd/pandas3ed4.html#expressing-conditional-logic-np.where",
    "href": "qmd/pandas3ed4.html#expressing-conditional-logic-np.where",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Expressing Conditional Logic: np.where",
    "text": "Expressing Conditional Logic: np.where\n\n\nnp.where: A vectorized version of the ternary expression x if condition else y.\n\n\nxarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])\nyarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])\ncond = np.array([True, False, True, True, False])\n\nresult = np.where(cond, xarr, yarr)  # Select from xarr if cond is True, otherwise yarr\nprint(result)\n\n[1.1 2.2 1.3 1.4 2.5]\n\n\n\nExample: Replace positive values in an array with 2, and negative values with -2:\n\n\narr = rng.standard_normal((4, 4))\nresult = np.where(arr &gt; 0, 2, -2)\nprint(result)\n\n[[ 2  2  2 -2]\n [-2 -2  2  2]\n [-2 -2  2  2]\n [-2  2 -2 -2]]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#mathematical-and-statistical-methods",
    "href": "qmd/pandas3ed4.html#mathematical-and-statistical-methods",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Mathematical and Statistical Methods",
    "text": "Mathematical and Statistical Methods\n\nNumPy provides a set of methods for computing statistics on arrays:\n\narr = rng.standard_normal((5, 4))\nprint(arr.mean())       # Mean of all elements\nprint(np.mean(arr))    # Equivalent to arr.mean()\nprint(arr.sum())        # Sum of all elements\n\n-0.08719744457434529\n-0.08719744457434529\n-1.743948891486906\n\n\n\nAxis Argument: Many methods take an optional axis argument to compute the statistic along a specific axis:\n\n\nprint(arr.mean(axis=1))  # Mean across columns (for each row)\nprint(arr.sum(axis=0))   # Sum down rows (for each column)\n\n[ 0.10899104  0.3280763   0.16502112 -0.66719934 -0.37087634]\n[-1.62923076  1.03990647 -0.33436331 -0.82026129]\n\n\n\ncumsum and cumprod: Compute cumulative sums and products:\n\n\narr = np.array([0, 1, 2, 3, 4, 5, 6, 7])\nprint(arr.cumsum())  # Cumulative sum\n\n[ 0  1  3  6 10 15 21 28]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#basic-array-statistical-methods",
    "href": "qmd/pandas3ed4.html#basic-array-statistical-methods",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Basic Array Statistical Methods",
    "text": "Basic Array Statistical Methods\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nsum\nSum of all the elements in the array or along an axis; zero-length arrays have sum 0.\n\n\nmean\nArithmetic mean; invalid (returns NaN) on zero-length arrays.\n\n\nstd, var\nStandard deviation and variance, respectively.\n\n\nmin,max\nMinimum and maximum.\n\n\nargmin, argmax\nIndices of minimum and maximum elements, respectively.\n\n\ncumsum\nCumulative sum of elements starting from 0.\n\n\ncumprod\nCumulative product of elements starting from 1."
  },
  {
    "objectID": "qmd/pandas3ed4.html#methods-for-boolean-arrays",
    "href": "qmd/pandas3ed4.html#methods-for-boolean-arrays",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Methods for Boolean Arrays",
    "text": "Methods for Boolean Arrays\n\n\nsum with Booleans: True values are treated as 1, False as 0. Useful for counting True values.\n\n\narr = rng.standard_normal(100)\nprint((arr &gt; 0).sum())  # Count positive values\n\n48\n\n\n\nany and all:\n\nany: Checks if at least one value in a Boolean array is True.\nall: Checks if all values in a Boolean array are True.\n\n\n\nbools = np.array([False, False, True, False])\nprint(bools.any())  # Is there at least one True?\nprint(bools.all())  # Are all values True?\n\nTrue\nFalse"
  },
  {
    "objectID": "qmd/pandas3ed4.html#sorting",
    "href": "qmd/pandas3ed4.html#sorting",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Sorting",
    "text": "Sorting\n\n\nsort Method: Sorts an array in place.\n\n\narr = rng.standard_normal(6)\narr.sort()  # Sort the array in place\nprint(arr)\n\n[-0.72083767 -0.68391322 -0.08241372 -0.05481416  0.07726066  1.12062282]\n\n\n\nSorting Along an Axis:\n\n\narr = rng.standard_normal((5, 3))\narr.sort(axis=0)  # Sort within each column\nprint(arr)\narr.sort(axis=1) # Sort within each row\nprint(arr)\n\n[[-2.05280763 -0.05032522  0.28931754]\n [ 0.17930568 -0.02788771  0.29204679]\n [ 0.40589222  0.38050908  0.75539067]\n [ 0.63840567  1.23853712  1.27279553]\n [ 0.9359865   1.39748056  1.37105185]]\n[[-2.05280763 -0.05032522  0.28931754]\n [-0.02788771  0.17930568  0.29204679]\n [ 0.38050908  0.40589222  0.75539067]\n [ 0.63840567  1.23853712  1.27279553]\n [ 0.9359865   1.37105185  1.39748056]]\n\n\n\nnp.sort Function: Returns a sorted copy of an array (does not modify the original)."
  },
  {
    "objectID": "qmd/pandas3ed4.html#unique-and-other-set-logic",
    "href": "qmd/pandas3ed4.html#unique-and-other-set-logic",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Unique and Other Set Logic",
    "text": "Unique and Other Set Logic\n\n\nnp.unique: Returns the sorted unique values in an array.\n\n\nnames = np.array(['Bob', 'Will', 'Joe', 'Bob', 'Will', 'Joe', 'Joe'])\nprint(np.unique(names)) # Get unique names\n\n['Bob' 'Joe' 'Will']\n\n\n\nnp.in1d: Tests membership of values in one array within another.\n\n\nvalues = np.array([6, 0, 0, 3, 2, 5, 6])\nprint(np.in1d(values, [2, 3, 6]))  # Check if each value in 'values' is in [2, 3, 6]\n\n[ True False False  True  True False  True]\n\n\n/tmp/ipykernel_2711/1961777543.py:2: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n  print(np.in1d(values, [2, 3, 6]))  # Check if each value in 'values' is in [2, 3, 6]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#array-set-operations",
    "href": "qmd/pandas3ed4.html#array-set-operations",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Array Set Operations",
    "text": "Array Set Operations\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nunique(x)\nComputes the sorted, unique elements in x.\n\n\nintersect1d(x, y)\nComputes the sorted, common elements in x and y.\n\n\nunion1d(x, y)\nComputes the sorted union of elements.\n\n\nin1d(x, y)\nComputes a Boolean array indicating whether each element of x is in y.\n\n\nsetdiff1d(x, y)\nSet difference: elements in x that are not in y.\n\n\nsetxor1d(x, y)\nSet symmetric differences; elements that are in either of the arrays, but not both."
  },
  {
    "objectID": "qmd/pandas3ed4.html#file-input-and-output-with-arrays",
    "href": "qmd/pandas3ed4.html#file-input-and-output-with-arrays",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "File Input and Output with Arrays",
    "text": "File Input and Output with Arrays\n\n\nnp.save and np.load: Functions for saving and loading arrays in NumPy’s binary format (.npy).\n\n\narr = np.arange(10)\nnp.save('some_array', arr)  # Save to 'some_array.npy'\nloaded_arr = np.load('some_array.npy')  # Load from 'some_array.npy'\nprint(loaded_arr)\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\n\nnp.savez: Saves multiple arrays into an uncompressed archive (.npz).\n\n\nnp.savez('array_archive.npz', a=arr, b=arr)  # Save multiple arrays\narch = np.load('array_archive.npz')        # Load the archive\nprint(arch['b'])  # Access arrays by name\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\n\nnp.savez_compressed: Saves multiple arrays into a compressed archive."
  },
  {
    "objectID": "qmd/pandas3ed4.html#linear-algebra",
    "href": "qmd/pandas3ed4.html#linear-algebra",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Linear Algebra",
    "text": "Linear Algebra\n\n\nnumpy.linalg Module: Provides functions for linear algebra operations.\nMatrix Multiplication:\n\n\nx = np.array([[1., 2., 3.], [4., 5., 6.]])\ny = np.array([[6., 23.], [-1, 7], [8, 9]])\nprint(x.dot(y))        # Matrix multiplication (method)\nprint(np.dot(x, y))    # Matrix multiplication (function)\nprint( x @ np.ones(3)) # Matrix multiplication using the @ operator\n\n[[ 28.  64.]\n [ 67. 181.]]\n[[ 28.  64.]\n [ 67. 181.]]\n[ 6. 15.]\n\n\n\nInverse and Determinant:\n\n\nfrom numpy.linalg import inv, qr\nX = rng.standard_normal((5, 5))\nmat = X.T @ X\nprint(inv(mat))   # Inverse of a matrix\n\n[[  3.49932285   2.84436268   3.59557002 -16.55376878   4.47325573]\n [  2.84436268   2.56666253   2.9001963  -13.57742      3.76776505]\n [  3.59557002   2.9001963    4.48232906 -18.34525499   4.70660032]\n [-16.55376878 -13.57742    -18.34525499  84.01018808 -22.04840478]\n [  4.47325573   3.76776505   4.70660032 -22.04840478   6.05251342]]"
  },
  {
    "objectID": "qmd/pandas3ed4.html#commonly-used-numpy.linalg-functions",
    "href": "qmd/pandas3ed4.html#commonly-used-numpy.linalg-functions",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Commonly Used numpy.linalg Functions",
    "text": "Commonly Used numpy.linalg Functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ndiag\nReturns the diagonal (or off-diagonal) elements of a square matrix as a 1D array, or converts a 1D array to a square matrix.\n\n\ndot\nMatrix multiplication.\n\n\ntrace\nComputes the sum of the diagonal elements.\n\n\ndet\nComputes the matrix determinant.\n\n\neig\nComputes the eigenvalues and eigenvectors of a square matrix.\n\n\ninv\nComputes the inverse of a square matrix.\n\n\npinv\nComputes the Moore-Penrose pseudoinverse of a matrix.\n\n\nqr\nComputes the QR decomposition.\n\n\nsvd\nComputes the singular value decomposition (SVD).\n\n\nsolve\nSolves the linear system Ax = b for x, where A is a square matrix.\n\n\nlstsq\nComputes the least-squares solution to Ax = b."
  },
  {
    "objectID": "qmd/pandas3ed4.html#example-random-walks",
    "href": "qmd/pandas3ed4.html#example-random-walks",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Example: Random Walks",
    "text": "Example: Random Walks\n\nLet’s simulate a simple random walk using NumPy:\n\nnsteps = 1000\nrng = np.random.default_rng(seed=12345)\ndraws = rng.integers(0, 2, size=nsteps)  # Generate 0s and 1s (coin flips)\nsteps = np.where(draws == 0, 1, -1)      # Convert to 1 and -1\nwalk = steps.cumsum()                    # Cumulative sum (the walk)\n\nFirst 100 steps of a simple random walk:\n\nimport matplotlib.pyplot as plt\nplt.plot(walk[:100])\nplt.show()"
  },
  {
    "objectID": "qmd/pandas3ed4.html#random-walks-analysis",
    "href": "qmd/pandas3ed4.html#random-walks-analysis",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Random Walks: Analysis",
    "text": "Random Walks: Analysis\n\nWe can analyze the random walk:\n\nprint(walk.min())  # Minimum value\nprint(walk.max())  # Maximum value\n\n-8\n50\n\n\n\nFirst Crossing Time: The step at which the walk reaches a particular value.\n\n\nprint((np.abs(walk) &gt;= 10).argmax())  # Find the first step where the absolute value is &gt;= 10\n\n155\n\n\n\n\n\n\n\n\n\nusing argmax here is not always efficient because it always makes a full scan of the array. In this special case, once a True is observed we know it to be the maximum value."
  },
  {
    "objectID": "qmd/pandas3ed4.html#simulating-many-random-walks-at-once",
    "href": "qmd/pandas3ed4.html#simulating-many-random-walks-at-once",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Simulating Many Random Walks at Once",
    "text": "Simulating Many Random Walks at Once\n\nWe can efficiently simulate many random walks simultaneously:\n\nnwalks = 5000\nnsteps = 1000\ndraws = rng.integers(0, 2, size=(nwalks, nsteps))  # Generate draws for all walks\nsteps = np.where(draws &gt; 0, 1, -1)\nwalks = steps.cumsum(axis=1)                     # Cumulative sum for each walk\n\nThen, for example, calculate the average minimum crossing time:\n\nhits30 = (np.abs(walks) &gt;= 30).any(axis=1)\ncrossing_times = (np.abs(walks[hits30]) &gt;= 30).argmax(axis=1)\nprint(crossing_times.mean())\n\n500.5699558173785\n\n\n\n\n\n\n\n\n\nthis vectorized approach requires creating an array with nwalks * nsteps elements, which may use a large amount of memory for large simulations. If memory is more constrained, then a different approach will be required."
  },
  {
    "objectID": "qmd/pandas3ed4.html#summary",
    "href": "qmd/pandas3ed4.html#summary",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Summary",
    "text": "Summary\n\n\nNumPy’s Power: NumPy provides a powerful foundation for numerical computing in Python, thanks to its efficient ndarray and vectorized operations.\nKey Concepts:\n\nndarray: Multidimensional array with homogeneous data.\ndtype: Data type of array elements.\nVectorization: Performing operations on entire arrays without loops.\nBroadcasting: Arithmetic operations on arrays of different shapes.\nIndexing and Slicing: Accessing and modifying array elements and subarrays.\nFancy Indexing: Indexing with integer arrays.\nTransposing: Rearranging data.\nufuncs: Fast element-wise functions.\nnumpy.random: Generating arrays of random numbers.\nLinear Algebra\n\nEfficiency: NumPy is designed for performance, especially with large datasets."
  },
  {
    "objectID": "qmd/pandas3ed4.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed4.html#thoughts-and-discussion",
    "title": "NumPy Basics: Arrays and Vectorized Computation",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\n\nHow does the concept of vectorization in NumPy compare to how you might perform similar operations in other programming languages you know?\nCan you think of specific data analysis tasks where NumPy’s array-oriented approach would be significantly more efficient than using Python lists and loops?\nWhat are the advantages and potential disadvantages of NumPy array slices being views rather than copies? When might you need to explicitly create a copy?\nConsider the np.where function. How could you use it to implement more complex conditional logic than the simple examples we saw?\nWhy is it important to understand NumPy’s data types (dtypes)? How can they impact performance and memory usage?\nDiscuss scenarios where you might use NumPy’s linear algebra functions (e.g., dot, inv, eig)."
  },
  {
    "objectID": "qmd/pandas3ed1.html",
    "href": "qmd/pandas3ed1.html",
    "title": "Python for Data Analysis",
    "section": "",
    "text": "This book focuses on the practical aspects of data manipulation, processing, cleaning, and crunching in Python. It equips you with the essential Python programming skills, libraries, and tools necessary to become an effective data analyst.\n\nGoal: Provide a guide to the parts of Python and its data-oriented libraries that are crucial for data analysis.\nFocus: Emphasizes Python programming, libraries, and tools rather than data analysis methodologies.\nAnalogy: Think of this book as learning the mechanics of a car (Python and its tools) rather than learning how to drive on different terrains (data analysis methods).\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhile the book is titled “Data Analysis,” it centers on the Python tools needed for data analysis, not the analysis techniques themselves. It’s like learning how to use a hammer, saw, and drill before building a house."
  },
  {
    "objectID": "qmd/pandas3ed1.html#what-is-this-book-about",
    "href": "qmd/pandas3ed1.html#what-is-this-book-about",
    "title": "Python for Data Analysis",
    "section": "",
    "text": "This book focuses on the practical aspects of data manipulation, processing, cleaning, and crunching in Python. It equips you with the essential Python programming skills, libraries, and tools necessary to become an effective data analyst.\n\nGoal: Provide a guide to the parts of Python and its data-oriented libraries that are crucial for data analysis.\nFocus: Emphasizes Python programming, libraries, and tools rather than data analysis methodologies.\nAnalogy: Think of this book as learning the mechanics of a car (Python and its tools) rather than learning how to drive on different terrains (data analysis methods).\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhile the book is titled “Data Analysis,” it centers on the Python tools needed for data analysis, not the analysis techniques themselves. It’s like learning how to use a hammer, saw, and drill before building a house."
  },
  {
    "objectID": "qmd/pandas3ed1.html#data-science-an-umbrella-term",
    "href": "qmd/pandas3ed1.html#data-science-an-umbrella-term",
    "title": "Python for Data Analysis",
    "section": "Data Science: An Umbrella Term ☂️",
    "text": "Data Science: An Umbrella Term ☂️\n\nSince the book’s original publication in 2012, the term “data science” has become widely used. It encompasses a broad range of activities, from basic descriptive statistics to sophisticated statistical analysis and machine learning.\n\nData Science Evolution: The field, and Python’s role in it, has grown significantly.\nExpanded Ecosystem: Many new Python libraries and tools have emerged, supporting more advanced data science methodologies.\nFoundation: This book provides the fundamental Python skills needed to explore more specialized data science resources.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThink of “Data Science” as a big umbrella covering various disciplines like statistics, machine learning, data visualization, and more. This book provides the handle (Python skills) to hold that umbrella!"
  },
  {
    "objectID": "qmd/pandas3ed1.html#data-wranglingmunging",
    "href": "qmd/pandas3ed1.html#data-wranglingmunging",
    "title": "Python for Data Analysis",
    "section": "Data Wrangling/Munging 🤼",
    "text": "Data Wrangling/Munging 🤼\n\nA significant portion of data analysis involves data manipulation, also referred to as data wrangling or data munging. These terms all describe the process of transforming and preparing data for analysis.\n\nData Manipulation: The core process of transforming raw data into a usable format.\nSynonyms: Wrangling and munging are interchangeable terms for data manipulation.\nImportance: This is a crucial step, as real-world data is often messy and needs cleaning before it can be analyzed.\n\n\n\n\n\n\n\n\nNote\n\n\n\nImagine you have a box of LEGO bricks scattered all over the floor. Data wrangling is like sorting and organizing those bricks by color, size, and shape before you can start building something meaningful."
  },
  {
    "objectID": "qmd/pandas3ed1.html#what-kinds-of-data",
    "href": "qmd/pandas3ed1.html#what-kinds-of-data",
    "title": "Python for Data Analysis",
    "section": "What Kinds of Data? 🗂️",
    "text": "What Kinds of Data? 🗂️\n\nThe book primarily focuses on structured data, which includes various common forms of data:\n\nTabular Data: Spreadsheet-like data with columns of different types (text, numbers, dates, etc.). This is the most common type and includes data from relational databases (like SQL) and CSV files.\nMultidimensional Arrays: Matrices, often used in numerical computations.\nMultiple Tables: Data spread across multiple related tables, linked by key columns (like in relational databases).\nTime Series: Data points collected over time, either at regular or irregular intervals.\n\n\n\n\n\n\n\n\nNote\n\n\n\nEven unstructured data (like a collection of news articles) can often be transformed into a structured form (like a word frequency table) for analysis. Think of it like turning a pile of ingredients (unstructured data) into a neatly organized recipe (structured data)."
  },
  {
    "objectID": "qmd/pandas3ed1.html#example-structured-data-tabular",
    "href": "qmd/pandas3ed1.html#example-structured-data-tabular",
    "title": "Python for Data Analysis",
    "section": "Example: Structured Data (Tabular)",
    "text": "Example: Structured Data (Tabular)\n\n\n\n\nCustomerID\nName\nCity\nOrderDate\nTotalAmount\n\n\n\n\n1\nAlice\nNew York\n2023-10-26\n120.00\n\n\n2\nBob\nLondon\n2023-10-27\n250.50\n\n\n3\nCharlie\nParis\n2023-10-27\n75.25\n\n\n4\nAlice\nNew York\n2023-10-28\n180.00\n\n\n\n\nColumns: Represent different attributes (CustomerID, Name, City, etc.).\nRows: Represent individual records or observations (each customer’s order).\nData Types: Each column can hold a different type of data (integer, text, date, numeric)."
  },
  {
    "objectID": "qmd/pandas3ed1.html#why-python-for-data-analysis",
    "href": "qmd/pandas3ed1.html#why-python-for-data-analysis",
    "title": "Python for Data Analysis",
    "section": "Why Python for Data Analysis? 🐍",
    "text": "Why Python for Data Analysis? 🐍\n\nPython has become extremely popular for data analysis due to several key advantages:\n\nInterpreted Language: Easier to learn and use, promoting rapid development and experimentation.\nLarge and Active Community: A vast network of users and developers provides support, libraries, and tools.\nRich Ecosystem of Libraries: Powerful libraries like NumPy, pandas, and scikit-learn simplify complex data analysis tasks.\nGeneral-Purpose Language: Suitable for both data analysis and building complete data-driven applications.\nGlue Language: Excellent for integrating with existing code and systems (often written in C, C++, or FORTRAN).\n\n\n\n\n\n\n\n\nNote\n\n\n\nPython is like a Swiss Army knife for data analysis: versatile, with many tools for different tasks, and easy to use."
  },
  {
    "objectID": "qmd/pandas3ed1.html#python-as-glue",
    "href": "qmd/pandas3ed1.html#python-as-glue",
    "title": "Python for Data Analysis",
    "section": "Python as “Glue” 🔗",
    "text": "Python as “Glue” 🔗\n\nA significant advantage of Python is its ability to act as “glue code,” connecting different software components and systems, especially legacy code written in languages like C, C++, and FORTRAN.\n\nIntegration: Easily integrates with existing codebases, particularly those used in scientific computing.\nLegacy Systems: Allows organizations to leverage existing investments in older software while benefiting from Python’s data analysis capabilities.\nOptimization: “Glue code” in Python can connect to optimized, low-level code (e.g., C libraries) for performance-critical computations.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThink of Python as the universal adapter that allows you to connect different types of plugs (software components) into the same socket (your data analysis workflow)."
  },
  {
    "objectID": "qmd/pandas3ed1.html#the-two-language-problem-and-pythons-solution",
    "href": "qmd/pandas3ed1.html#the-two-language-problem-and-pythons-solution",
    "title": "Python for Data Analysis",
    "section": "The “Two-Language” Problem and Python’s Solution ✌️",
    "text": "The “Two-Language” Problem and Python’s Solution ✌️\n\nTraditionally, data analysis often involved a “two-language problem”:\n\nResearch/Prototyping: Using specialized languages like R or MATLAB for initial exploration and model development.\nProduction: Rewriting the code in a different language (e.g., Java, C++) for deployment in larger systems.\n\nPython solves this problem by being suitable for both research/prototyping and production:\n\nSingle Environment: Reduces the need to maintain separate development environments.\nEfficiency: Saves time and resources by using the same language throughout the entire process.\nCollaboration: Facilitates collaboration between researchers and software engineers, who can now use the same tools.\nJIT Compilers: Libraries like Numba provide “just-in-time” compilation, significantly improving performance without leaving the Python environment.\n\n\n\n\n\n\n\n\nNote\n\n\n\nPython bridges the gap between research and production, allowing for a smoother, more efficient workflow. It’s like having a single language that everyone on a team, from data scientists to software engineers, can understand and use."
  },
  {
    "objectID": "qmd/pandas3ed1.html#why-not-python",
    "href": "qmd/pandas3ed1.html#why-not-python",
    "title": "Python for Data Analysis",
    "section": "Why Not Python? 🚫",
    "text": "Why Not Python? 🚫\n\nWhile Python excels in many areas, there are situations where it might not be the ideal choice:\n\nPerformance-Critical Applications: For applications requiring extremely low latency or highly demanding resource utilization (e.g., high-frequency trading), compiled languages like C++ might be more appropriate.\nConcurrency and the GIL: Python’s Global Interpreter Lock (GIL) can limit true multithreading in CPU-bound applications. However, workarounds exist (e.g., using C extensions or multiprocessing).\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe GIL in Python is like a single-lane road that allows only one car (thread) to pass at a time, even if you have multiple cars (cores) available. This can be a bottleneck for some CPU-intensive tasks. But, you can use bypass like C-extension."
  },
  {
    "objectID": "qmd/pandas3ed1.html#essential-python-libraries",
    "href": "qmd/pandas3ed1.html#essential-python-libraries",
    "title": "Python for Data Analysis",
    "section": "Essential Python Libraries 📚",
    "text": "Essential Python Libraries 📚\nThis section introduces some of the core Python libraries that are fundamental to data analysis."
  },
  {
    "objectID": "qmd/pandas3ed1.html#numpy-numerical-python",
    "href": "qmd/pandas3ed1.html#numpy-numerical-python",
    "title": "Python for Data Analysis",
    "section": "NumPy: Numerical Python",
    "text": "NumPy: Numerical Python\n\nNumPy is the foundation for numerical computing in Python. It provides:\n\nndarray: A fast and efficient multidimensional array object for storing and manipulating numerical data.\nMathematical Functions: A wide range of functions for performing element-wise operations on arrays and mathematical computations between arrays.\nLinear Algebra, Fourier Transforms, Random Number Generation: Essential tools for scientific computing and data analysis.\nData Container: Serves as an efficient container for passing data between algorithms and libraries.\nC API: Allow to connect with C, C++, and FORTRAN.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThink of NumPy’s ndarray as a highly optimized container for numbers, like a super-efficient spreadsheet designed for fast calculations."
  },
  {
    "objectID": "qmd/pandas3ed1.html#pandas-data-manipulation-and-analysis",
    "href": "qmd/pandas3ed1.html#pandas-data-manipulation-and-analysis",
    "title": "Python for Data Analysis",
    "section": "pandas: Data Manipulation and Analysis",
    "text": "pandas: Data Manipulation and Analysis\n\npandas builds upon NumPy to provide high-level data structures and functions for working with structured or tabular data. Key features include:\n\nDataFrame: A tabular, column-oriented data structure with row and column labels (similar to a spreadsheet or SQL table).\nSeries: A one-dimensional labeled array object.\nData Alignment: Automatic or explicit data alignment based on labels, preventing common errors caused by misaligned data.\nData Manipulation: Tools for reshaping, slicing, dicing, aggregating, and selecting subsets of data.\nMissing Data Handling: Flexible handling of missing data.\nTime Series Functionality: Specialized tools for working with time series data.\nIntegration with Databases: Support for merging and joining data from different sources, including SQL databases.\nDerived from Panel Data: “pandas” comes from “panel data,” an econometrics term, and “Python data analysis.”\n\n\n\n\n\n\n\n\nNote\n\n\n\npandas is like a supercharged spreadsheet program within Python, allowing you to easily manipulate, clean, and analyze data."
  },
  {
    "objectID": "qmd/pandas3ed1.html#matplotlib-data-visualization",
    "href": "qmd/pandas3ed1.html#matplotlib-data-visualization",
    "title": "Python for Data Analysis",
    "section": "matplotlib: Data Visualization 📊",
    "text": "matplotlib: Data Visualization 📊\n\nmatplotlib is the most widely used Python library for creating static plots and other two-dimensional data visualizations.\n\nPublication-Quality Plots: Designed for generating high-quality plots suitable for publications.\nIntegration: Integrates well with other libraries in the Python data ecosystem.\nDefault Choice: A reliable and widely adopted choice for basic data visualization.\n\n\n\n\n\n\n\n\nNote\n\n\n\nmatplotlib is your go-to tool for creating visual representations of your data, like turning your data into charts and graphs."
  },
  {
    "objectID": "qmd/pandas3ed1.html#ipython-and-jupyter-interactive-computing",
    "href": "qmd/pandas3ed1.html#ipython-and-jupyter-interactive-computing",
    "title": "Python for Data Analysis",
    "section": "IPython and Jupyter: Interactive Computing 💻",
    "text": "IPython and Jupyter: Interactive Computing 💻\n\nIPython and Jupyter provide an interactive environment for Python development and data analysis.\n\nIPython: An enhanced interactive Python shell that promotes an “execute-explore” workflow.\nJupyter Notebook: A web-based notebook environment that supports multiple programming languages (including Python via IPython) and allows you to combine code, text, and visualizations in a single document.\nExploration and Iteration: Ideal for exploring data, trying out different code snippets, and iterating on your analysis.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIPython and Jupyter are like a digital lab notebook for data scientists, allowing you to experiment, document your work, and share your findings."
  },
  {
    "objectID": "qmd/pandas3ed1.html#scipy-scientific-computing-tools",
    "href": "qmd/pandas3ed1.html#scipy-scientific-computing-tools",
    "title": "Python for Data Analysis",
    "section": "SciPy: Scientific Computing Tools",
    "text": "SciPy: Scientific Computing Tools\n\nSciPy is a collection of packages that provide tools for various scientific computing tasks, including:\n\nscipy.integrate: Numerical integration and differential equation solvers.\nscipy.linalg: Linear algebra routines.\nscipy.optimize: Function optimization and root-finding algorithms.\nscipy.signal: Signal processing tools.\nscipy.sparse: Sparse matrices and solvers.\nscipy.special: Special mathematical functions.\nscipy.stats: Statistical distributions, tests, and descriptive statistics.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSciPy is like a toolbox filled with specialized instruments for scientific computing, extending the capabilities of NumPy."
  },
  {
    "objectID": "qmd/pandas3ed1.html#scikit-learn-machine-learning",
    "href": "qmd/pandas3ed1.html#scikit-learn-machine-learning",
    "title": "Python for Data Analysis",
    "section": "scikit-learn: Machine Learning 🤖",
    "text": "scikit-learn: Machine Learning 🤖\n\nscikit-learn is the primary general-purpose machine learning toolkit for Python. It includes submodules for:\n\nClassification: Algorithms for identifying to which category an object belongs (e.g., spam detection).\nRegression: Algorithms for predicting a continuous-valued attribute (e.g., predicting house prices).\nClustering: Algorithms for grouping similar objects (e.g., customer segmentation).\nDimensionality Reduction: Techniques for reducing the number of variables in a dataset.\nModel Selection: Tools for choosing the best model and parameters.\nPreprocessing: Feature extraction and normalization.\n\n\n\n\n\n\n\n\nNote\n\n\n\nscikit-learn is your machine learning workshop, providing a wide range of tools for building and evaluating predictive models."
  },
  {
    "objectID": "qmd/pandas3ed1.html#statsmodels-statistical-modeling",
    "href": "qmd/pandas3ed1.html#statsmodels-statistical-modeling",
    "title": "Python for Data Analysis",
    "section": "statsmodels Statistical Modeling",
    "text": "statsmodels Statistical Modeling\nstatsmodels is a statistical analysis package focused on statistical inference, providing uncertainty estimates and p-values. It includes:\n\nRegression Models: Linear regression, generalized linear models, etc.\nAnalysis of Variance (ANOVA)\nTime Series Analysis: AR, ARMA, ARIMA, VAR models.\nNonparametric Methods: Kernel density estimation, etc.\nVisualization: Tools for visualizing statistical model results.\n\n\n\n\n\n\n\nNote\n\n\n\nstatsmodels is your statistical laboratory, providing tools for conducting rigorous statistical analyses and drawing inferences from data. It complements scikit-learn, which is more focused on prediction."
  },
  {
    "objectID": "qmd/pandas3ed1.html#other-packages",
    "href": "qmd/pandas3ed1.html#other-packages",
    "title": "Python for Data Analysis",
    "section": "Other Packages 📦",
    "text": "Other Packages 📦\n\nThere are many other important Python libraries.\nTensorFlow and PyTorch: popular for machine learning or artificial intelligence work."
  },
  {
    "objectID": "qmd/pandas3ed1.html#installation-and-setup",
    "href": "qmd/pandas3ed1.html#installation-and-setup",
    "title": "Python for Data Analysis",
    "section": "Installation and Setup ⚙️",
    "text": "Installation and Setup ⚙️\nThis section provides instructions for setting up a Python environment for data analysis using Miniconda and conda-forge."
  },
  {
    "objectID": "qmd/pandas3ed1.html#miniconda",
    "href": "qmd/pandas3ed1.html#miniconda",
    "title": "Python for Data Analysis",
    "section": "Miniconda",
    "text": "Miniconda\n\nMiniconda is a minimal installer for conda, a package, dependency, and environment management system. conda-forge is a community-maintained software distribution based on conda.\n\nWhy Miniconda? Provides a lightweight and flexible way to manage Python environments and packages.\nconda-forge: Offers a wide range of packages, including those commonly used in data science.\nPython 3.10: The book uses Python 3.10, but newer versions can also be used.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThink of conda as a virtual container for your Python projects. It keeps your projects isolated and prevents conflicts between different package versions. Miniconda is a small version of Anaconda."
  },
  {
    "objectID": "qmd/pandas3ed1.html#installation-steps-windows-macos-linux",
    "href": "qmd/pandas3ed1.html#installation-steps-windows-macos-linux",
    "title": "Python for Data Analysis",
    "section": "Installation Steps (Windows, macOS, Linux) 💻",
    "text": "Installation Steps (Windows, macOS, Linux) 💻\n\nThe book provides detailed instructions for installing Miniconda on Windows, macOS, and Linux. The general steps are:\n\nDownload: Download the appropriate Miniconda installer from https://conda.io.\nInstall: Run the installer, following the on-screen prompts.\nVerify: Open a terminal (or Anaconda Prompt on Windows) and type python. You should see the Python interpreter start.\nExit: Type exit() or press Ctrl-D (Ctrl-Z then Enter on Windows) to exit the interpreter.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThese steps are like setting up your workbench before you start a woodworking project. You’re getting your tools (Python and its libraries) ready to use."
  },
  {
    "objectID": "qmd/pandas3ed1.html#installing-necessary-packages",
    "href": "qmd/pandas3ed1.html#installing-necessary-packages",
    "title": "Python for Data Analysis",
    "section": "Installing Necessary Packages 📦",
    "text": "Installing Necessary Packages 📦\n\nOnce Miniconda is installed, you can create a conda environment and install the necessary packages:\n\nConfigure conda-forge: bash     conda config --add channels conda-forge     conda config --set channel_priority strict\nCreate Environment: bash     conda create -y -n pydata-book python=3.10\nActivate Environment: bash     conda activate pydata-book\nInstall Packages: bash     conda install -y pandas jupyter matplotlib (or install all packages listed in the book).\n\n\nconda install vs. pip install: Prefer conda install when using Miniconda. Use pip install if a package is not available via conda.\nUpdating Packages: Use conda update package_name or pip install --upgrade package_name.\n\n\n\n\n\n\n\n\nNote\n\n\n\nCreating a conda environment is like setting up a separate workspace for each project. It helps avoid conflicts between different projects that might require different versions of the same package."
  },
  {
    "objectID": "qmd/pandas3ed1.html#integrated-development-environments-ides-and-text-editors",
    "href": "qmd/pandas3ed1.html#integrated-development-environments-ides-and-text-editors",
    "title": "Python for Data Analysis",
    "section": "Integrated Development Environments (IDEs) and Text Editors",
    "text": "Integrated Development Environments (IDEs) and Text Editors\n\n\nThe author suggests “IPython plus a text editor”.\nSome IDEs for you to explore:\n\nPyDev (free)\nPyCharm from JetBrains\nPython Tools for Visual Studio\nSpyder (free)\nKomodo IDE (commercial)"
  },
  {
    "objectID": "qmd/pandas3ed1.html#community-and-conferences",
    "href": "qmd/pandas3ed1.html#community-and-conferences",
    "title": "Python for Data Analysis",
    "section": "Community and Conferences 🤝",
    "text": "Community and Conferences 🤝\n\nEngaging with the Python community is a great way to learn and get help. Useful resources include:\n\nMailing Lists:\n\npydata (general Python for data analysis)\npystatsmodels (statsmodels and pandas)\nscikit-learn (machine learning)\nnumpy-discussion\nscipy-user\n\nConferences:\n\nPyCon and EuroPython (general Python)\nSciPy and EuroSciPy (scientific computing)\nPyData (data science and data analysis)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe Python community is known for being welcoming and helpful. Don’t hesitate to ask questions and connect with other users!"
  },
  {
    "objectID": "qmd/pandas3ed1.html#navigating-this-book",
    "href": "qmd/pandas3ed1.html#navigating-this-book",
    "title": "Python for Data Analysis",
    "section": "Navigating This Book 🗺️",
    "text": "Navigating This Book 🗺️\n\n\nChapters 2 & 3: A condensed tutorial on Python language features, IPython, and Jupyter notebooks (essential for beginners).\nNumPy Introduction: A brief overview of NumPy, with more advanced topics in Appendix A.\npandas Focus: The rest of the book focuses on data analysis using pandas, NumPy, and matplotlib.\nIncremental Structure: The material is presented in a step-by-step manner.\n\nThe book covers the following key areas:\n\nInteracting with the outside world: Reading and writing data.\nPreparation: Cleaning, transforming, and reshaping data.\nTransformation: Applying mathematical and statistical operations.\nModeling and computation: Connecting data to models and algorithms.\nPresentation: Creating visualizations and summaries."
  },
  {
    "objectID": "qmd/pandas3ed1.html#code-examples",
    "href": "qmd/pandas3ed1.html#code-examples",
    "title": "Python for Data Analysis",
    "section": "Code Examples",
    "text": "Code Examples\n\n\nThe code examples are based on IPython shell or Jupyter notebooks.\nFor example:\n\nIn [5]: CODE EXAMPLE\nOut[5]: OUTPUT\n\nReproducibility: The book provides instructions for setting up your environment to match the output shown in the examples.\nData: Datasets for the examples are hosted on GitHub (or Gitee)."
  },
  {
    "objectID": "qmd/pandas3ed1.html#import-conventions",
    "href": "qmd/pandas3ed1.html#import-conventions",
    "title": "Python for Data Analysis",
    "section": "Import Conventions",
    "text": "Import Conventions\n\n\nCommon import statements:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels as sm"
  },
  {
    "objectID": "qmd/pandas3ed1.html#summary",
    "href": "qmd/pandas3ed1.html#summary",
    "title": "Python for Data Analysis",
    "section": "Summary 📝",
    "text": "Summary 📝\n\n\nThis chapter introduced the core concepts and tools that will be used throughout the book.\nWe learned about the scope of the book (Python for data analysis), the meaning of data science, and the importance of data wrangling.\nWe explored the advantages of using Python for data analysis, as well as some potential limitations.\nWe were introduced to key Python libraries: NumPy, pandas, matplotlib, IPython/Jupyter, SciPy, scikit-learn, and statsmodels.\nWe covered the installation and setup of a Python environment using Miniconda.\nFinally, we discussed community resources and how to navigate the book."
  },
  {
    "objectID": "qmd/pandas3ed1.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed1.html#thoughts-and-discussion",
    "title": "Python for Data Analysis",
    "section": "Thoughts and Discussion 💭",
    "text": "Thoughts and Discussion 💭\n\n\nWhat are your initial impressions of Python as a tool for data analysis?\nWhich of the libraries introduced in this chapter are you most excited to learn more about?\nCan you think of any real-world examples where data wrangling would be a crucial step in the analysis process?\nHow does the concept of a “two-language problem” relate to your own experiences (if any) with data analysis or software development?\nWhy is it important to create separate environments for different Python projects?\nDo you perfer using IDE, or text editor plus IPython?"
  },
  {
    "objectID": "qmd/pandas3ed3.html",
    "href": "qmd/pandas3ed3.html",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "",
    "text": "This chapter delves into the fundamental building blocks of Python that are essential for data analysis. We’ll explore Python’s built-in data structures, how to create reusable functions, and how to interact with files.\n\n\n\n\n\n\nNote\n\n\n\nWhile libraries like pandas and NumPy offer advanced functionalities for larger datasets, they are designed to work in conjunction with Python’s core data manipulation tools. Therefore, mastering these basics is extremely important."
  },
  {
    "objectID": "qmd/pandas3ed3.html#chapter-3-built-in-data-structures-functions-and-files",
    "href": "qmd/pandas3ed3.html#chapter-3-built-in-data-structures-functions-and-files",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "",
    "text": "This chapter delves into the fundamental building blocks of Python that are essential for data analysis. We’ll explore Python’s built-in data structures, how to create reusable functions, and how to interact with files.\n\n\n\n\n\n\nNote\n\n\n\nWhile libraries like pandas and NumPy offer advanced functionalities for larger datasets, they are designed to work in conjunction with Python’s core data manipulation tools. Therefore, mastering these basics is extremely important."
  },
  {
    "objectID": "qmd/pandas3ed3.html#data-structures-and-sequences",
    "href": "qmd/pandas3ed3.html#data-structures-and-sequences",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Data Structures and Sequences",
    "text": "Data Structures and Sequences\nPython provides several versatile and powerful data structures. Let’s start with some of the most frequently used ones: tuples, lists, and dictionaries. Understanding these is a crucial step towards becoming proficient in Python."
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-definition",
    "href": "qmd/pandas3ed3.html#tuple-definition",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Definition",
    "text": "Tuple: Definition\nA tuple is a fixed-length, immutable sequence of Python objects. This means once a tuple is created, you cannot change its elements or its size.\n\n\n\n\n\n\nImmutability\n\n\n\nImmutability means that the contents of the tuple cannot be changed after it’s created. This provides data integrity. Think of it like a sealed container – you can see what’s inside, but you can’t swap things out."
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-creation",
    "href": "qmd/pandas3ed3.html#tuple-creation",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Creation",
    "text": "Tuple: Creation\nThe simplest way to create a tuple is with a comma-separated sequence of values, usually enclosed in parentheses:\ntup = (4, 5, 6)\nprint(tup)\nParentheses can often be omitted:\ntup = 4, 5, 6\nprint(tup)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-conversion-and-accessing",
    "href": "qmd/pandas3ed3.html#tuple-conversion-and-accessing",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Conversion and Accessing",
    "text": "Tuple: Conversion and Accessing\nYou can convert any sequence or iterator to a tuple using the tuple() function:\nmy_list = [4, 0, 2]\nmy_tuple = tuple(my_list)\nprint(my_tuple)\n\nstring_tuple = tuple('string')\nprint(string_tuple)\nElements are accessed using square brackets [], and like most programming languages, Python uses zero-based indexing:\nprint(string_tuple[0])  # Access the first element"
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-nested-tuples",
    "href": "qmd/pandas3ed3.html#tuple-nested-tuples",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Nested Tuples",
    "text": "Tuple: Nested Tuples\nTuples can contain other tuples, creating nested structures:\nnested_tup = (4, 5, 6), (7, 8)\nprint(nested_tup)\nprint(nested_tup[0]) # Access the first tuple\nprint(nested_tup[1][0]) #Access the first element from the second tuple."
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-immutability-detailed-example",
    "href": "qmd/pandas3ed3.html#tuple-immutability-detailed-example",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Immutability (Detailed Example)",
    "text": "Tuple: Immutability (Detailed Example)\nWhile the objects within a tuple might be mutable (like a list), the tuple itself, once created, cannot be modified:\ntup = tuple(['foo', [1, 2], True])\n# tup[2] = False  # This will raise a TypeError\n\n# However, if an element is mutable (like a list), you can modify it IN PLACE:\ntup[1].append(3)\nprint(tup) # Output: ('foo', [1, 2, 3], True)\n\n\n\n\n\n\nCaution\n\n\n\nYou cannot assign a new object to a slot in the tuple, but you can modify the contents of a mutable object within the tuple."
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-concatenation-and-multiplication",
    "href": "qmd/pandas3ed3.html#tuple-concatenation-and-multiplication",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Concatenation and Multiplication",
    "text": "Tuple: Concatenation and Multiplication\nTuples can be concatenated using the + operator:\ntuple1 = (4, None, 'foo')\ntuple2 = (6, 0)\ntuple3 = ('bar',)  # Note the comma for a single-element tuple\ncombined_tuple = tuple1 + tuple2 + tuple3\nprint(combined_tuple)\nMultiplying a tuple by an integer repeats the tuple:\nrepeated_tuple = ('foo', 'bar') * 4\nprint(repeated_tuple)\n\n\n\n\n\n\nNote\n\n\n\nOnly references to the objects are copied, not the objects themselves."
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-unpacking",
    "href": "qmd/pandas3ed3.html#tuple-unpacking",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Unpacking",
    "text": "Tuple: Unpacking\nPython allows you to “unpack” tuples, assigning the values to individual variables:\ntup = (4, 5, 6)\na, b, c = tup\nprint(b)\nEven nested tuples can be unpacked:\ntup = 4, 5, (6, 7)\na, b, (c, d) = tup\nprint(d)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-swapping-variables",
    "href": "qmd/pandas3ed3.html#tuple-swapping-variables",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Swapping Variables",
    "text": "Tuple: Swapping Variables\nA classic use of tuple unpacking is swapping variable values elegantly:\na, b = 1, 2\nprint(f\"a: {a}, b: {b}\")\nb, a = a, b  # Swaps the values of a and b\nprint(f\"a: {a}, b: {b}\")"
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-rest-and-_",
    "href": "qmd/pandas3ed3.html#tuple-rest-and-_",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: *rest (and _)",
    "text": "Tuple: *rest (and _)\nSometimes you want to “pluck” a few elements from the beginning of a tuple. The *rest syntax captures the remaining elements:\nvalues = 1, 2, 3, 4, 5\na, b, *rest = values\nprint(a)\nprint(b)\nprint(rest)\nBy convention, the underscore _ is often used for unwanted variables during unpacking:\na, b, *_ = values # We don't care about the rest"
  },
  {
    "objectID": "qmd/pandas3ed3.html#tuple-methods-count",
    "href": "qmd/pandas3ed3.html#tuple-methods-count",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Tuple: Methods (count)",
    "text": "Tuple: Methods (count)\nBecause tuples are immutable, they have very few built-in methods. A useful one is count():\na = (1, 2, 2, 2, 3, 4, 2)\ncount_of_2 = a.count(2)\nprint(count_of_2)  # Output: 4\ncount method returns the number of occurrences of a specified value."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-definition-and-mutability",
    "href": "qmd/pandas3ed3.html#list-definition-and-mutability",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Definition and Mutability",
    "text": "List: Definition and Mutability\nLists, in contrast to tuples, are variable-length and mutable. You can change their contents and size after creation.\n\n\n\n\n\n\nMutability\n\n\n\nMutability means you can change the list’s elements, add new ones, or remove existing ones after the list has been created. This makes lists very flexible for storing and manipulating collections of data."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-creation",
    "href": "qmd/pandas3ed3.html#list-creation",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Creation",
    "text": "List: Creation\nLists are defined using square brackets [] or the list() type function:\na_list = [2, 3, 7, None]\ntup = ('foo', 'bar', 'baz')\nb_list = list(tup)  # Convert a tuple to a list\nprint(b_list)\nYou can modify elements in a list:\nb_list[1] = 'peekaboo'\nprint(b_list)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-materializing-iterators",
    "href": "qmd/pandas3ed3.html#list-materializing-iterators",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Materializing Iterators",
    "text": "List: Materializing Iterators\nThe list() function is frequently used to materialize an iterator or generator expression:\ngen = range(10)\nprint(gen)  # This is a range object (an iterator)\nmy_list = list(gen)  # Convert the iterator to a list\nprint(my_list)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-adding-and-removing-elements",
    "href": "qmd/pandas3ed3.html#list-adding-and-removing-elements",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Adding and Removing Elements",
    "text": "List: Adding and Removing Elements\n\nappend(): Adds an element to the end of the list.\n\nb_list.append('dwarf')\nprint(b_list)\n\ninsert(): Inserts an element at a specific position.\n\nb_list.insert(1, 'red') # insert 'red' at index 1\nprint(b_list)\n\n\n\n\n\n\nCaution\n\n\n\ninsert is computationally more expensive than append because it has to shift subsequent elements."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-removing-elements-pop-and-remove",
    "href": "qmd/pandas3ed3.html#list-removing-elements-pop-and-remove",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Removing Elements (pop and remove)",
    "text": "List: Removing Elements (pop and remove)\n\npop(): Removes and returns an element at a specific index.\n\nremoved_element = b_list.pop(2)\nprint(removed_element)\nprint(b_list)\n\nremove(): Removes the first occurrence of a specific value.\n\nb_list.append('foo')  # Add another 'foo'\nb_list.remove('foo')  # Removes the *first* 'foo'\nprint(b_list)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-checking-for-membership-in-and-not-in",
    "href": "qmd/pandas3ed3.html#list-checking-for-membership-in-and-not-in",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Checking for Membership (in and not in)",
    "text": "List: Checking for Membership (in and not in)\nUse the in and not in keywords to check if a list contains a value:\nprint('dwarf' in b_list)\nprint('dwarf' not in b_list)\n\n\n\n\n\n\nNote\n\n\n\nChecking in or not in in list is slow. Checking membership in a list is much slower than with dictionaries or sets because Python has to perform a linear scan of the list, while it can check dictionaries and sets (which are based on hash tables) in constant time."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-concatenation-and-combining",
    "href": "qmd/pandas3ed3.html#list-concatenation-and-combining",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Concatenation and Combining",
    "text": "List: Concatenation and Combining\nSimilar to tuples, use + to concatenate lists:\nlist1 = [4, None, 'foo']\nlist2 = [7, 8, (2, 3)]\ncombined_list = list1 + list2\nprint(combined_list)\nUse extend() to append multiple elements from another iterable:\nx = [4, None, 'foo']\nx.extend([7, 8, (2, 3)])\nprint(x)\n\n\n\n\n\n\nTip\n\n\n\nextend() is generally faster than using + for combining lists, especially large ones, as + creates a new list and copies elements."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-sorting-sort-and-sorted",
    "href": "qmd/pandas3ed3.html#list-sorting-sort-and-sorted",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Sorting (sort and sorted)",
    "text": "List: Sorting (sort and sorted)\n\nsort(): Sorts the list in place (modifies the original list).\n\na = [7, 2, 5, 1, 3]\na.sort()\nprint(a)\n\nkey argument: provide customized sorting method.\n\nb = ['saw', 'small', 'He', 'foxes', 'six']\nb.sort(key=len)  # Sort by the length of the strings\nprint(b)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-slicing",
    "href": "qmd/pandas3ed3.html#list-slicing",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Slicing",
    "text": "List: Slicing\nSlicing allows you to select a section of a list using the start:stop notation within square brackets:\nseq = [7, 2, 3, 7, 5, 6, 0, 1]\nsub_list = seq[1:5]  # Elements from index 1 (inclusive) to 5 (exclusive)\nprint(sub_list)\n\nseq[3:5] = [6,3] # replace elements using slicing\nprint(seq)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-slicing-omitting-startstop-and-negative-indices",
    "href": "qmd/pandas3ed3.html#list-slicing-omitting-startstop-and-negative-indices",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Slicing (Omitting Start/Stop and Negative Indices)",
    "text": "List: Slicing (Omitting Start/Stop and Negative Indices)\n\nOmitting start: Defaults to the beginning of the list.\nOmitting stop: Defaults to the end of the list.\nNegative indices: Count from the end of the list.\n\nprint(seq[:5])  # First 5 elements\nprint(seq[3:])  # Elements from index 3 to the end\nprint(seq[-4:]) # Last 4 elements\nprint(seq[-6:-2]) # From 6th last (inclusive) to 2nd last (exclusive)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-slicing-step",
    "href": "qmd/pandas3ed3.html#list-slicing-step",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List: Slicing (Step)",
    "text": "List: Slicing (Step)\nA step can be used to select every nth element:\nprint(seq[::2])   # Every other element\nprint(seq[::-1])  # Reverse the list"
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-slicing-illustration",
    "href": "qmd/pandas3ed3.html#list-slicing-illustration",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List slicing illustration",
    "text": "List slicing illustration\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\nH\nE\nL\nL\nO\n!\n\n\n0\n1\n2\n3\n4\n5\n\n\n-6\n-5\n-4\n-3\n-2\n-1\n\n\n\n\nstring = \"HELLO!\"\nprint(string[2:4]) # slicing with positive indices\nprint(string[-5:-2]) # slicing with negative indices\nThis figure illustrates slicing on the string “HELLO!”. Indices are shown at the “bin edges” to help show where the slice selections start and stop using positive or negative indices."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-dict-definition-and-key-value-pairs",
    "href": "qmd/pandas3ed3.html#dictionary-dict-definition-and-key-value-pairs",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary (dict): Definition and Key-Value Pairs",
    "text": "Dictionary (dict): Definition and Key-Value Pairs\nA dictionary (or dict) is a highly important built-in data structure. Also known as a hash map or associative array, it stores a collection of key-value pairs.\n\n\n\n\n\n\nKey-Value Pairs\n\n\n\nEach key is associated with a value. Keys must be unique and immutable (like strings, numbers, or tuples), while values can be of any data type."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-creation",
    "href": "qmd/pandas3ed3.html#dictionary-creation",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Creation",
    "text": "Dictionary: Creation\nUse curly braces {} and colons : to separate keys and values:\nempty_dict = {}\nd1 = {'a': 'some value', 'b': [1, 2, 3, 4]}\nprint(d1)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-accessing-inserting-and-setting-elements",
    "href": "qmd/pandas3ed3.html#dictionary-accessing-inserting-and-setting-elements",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Accessing, Inserting, and Setting Elements",
    "text": "Dictionary: Accessing, Inserting, and Setting Elements\nAccess, insert, or set elements using the same syntax as lists, but with keys instead of indices:\nd1[7] = 'an integer'  # Add a new key-value pair\nprint(d1)\nprint(d1['b'])       # Access the value associated with key 'b'"
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-checking-for-keys-in",
    "href": "qmd/pandas3ed3.html#dictionary-checking-for-keys-in",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Checking for Keys (in)",
    "text": "Dictionary: Checking for Keys (in)\nprint('b' in d1)  # Checks if 'b' is a *key* in d1"
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-deleting-values-del-and-pop",
    "href": "qmd/pandas3ed3.html#dictionary-deleting-values-del-and-pop",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Deleting Values (del and pop)",
    "text": "Dictionary: Deleting Values (del and pop)\n\ndel: Deletes a key-value pair.\n\nd1[5] = 'some value'\nd1['dummy'] = 'another value'\nprint(d1)\ndel d1[5]\nprint(d1)\n\npop(): Removes a key-value pair and returns the value.\n\nret = d1.pop('dummy')\nprint(ret)\nprint(d1)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-keys-and-values-methods",
    "href": "qmd/pandas3ed3.html#dictionary-keys-and-values-methods",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: keys() and values() Methods",
    "text": "Dictionary: keys() and values() Methods\n\nkeys(): Returns an iterator of the dictionary’s keys.\nvalues(): Returns an iterator of the dictionary’s values.\nitems(): Returns an iterator of the dictionary’s items(key-value pairs).\n\nprint(list(d1.keys()))   # Convert the iterator to a list\nprint(list(d1.values())) # Convert the iterator to a list\nprint(list(d1.items()))\n\n\n\n\n\n\nNote\n\n\n\nThe order of keys depends on the insertion order. The keys and values methods return iterators in the same order."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-merging-with-update",
    "href": "qmd/pandas3ed3.html#dictionary-merging-with-update",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Merging with update()",
    "text": "Dictionary: Merging with update()\nThe update() method merges one dictionary into another:\nd1.update({'b': 'foo', 'c': 12})  # Updates existing key 'b', adds new key 'c'\nprint(d1)\n\n\n\n\n\n\nCaution\n\n\n\nupdate() changes dictionaries in place. Any existing keys in the dictionary passed to update() will have their old values discarded."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-creating-from-sequences",
    "href": "qmd/pandas3ed3.html#dictionary-creating-from-sequences",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Creating from Sequences",
    "text": "Dictionary: Creating from Sequences\n# Not how you would normally do it, but illustrates the concept\nkey_list = ['a', 'b', 'c']\nvalue_list = [1, 2, 3]\nmapping = {}\nfor key, value in zip(key_list, value_list):\n    mapping[key] = value\nprint(mapping)\n\n# A more concise way using dict() and zip()\nmapping = dict(zip(range(5), reversed(range(5))))\nprint(mapping)\nzip function can pair up elements of multiple sequences. dict accepts a list of 2-tuples."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-default-values-get-and-setdefault",
    "href": "qmd/pandas3ed3.html#dictionary-default-values-get-and-setdefault",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Default Values (get and setdefault)",
    "text": "Dictionary: Default Values (get and setdefault)\n# Common but verbose way to handle missing keys\nif 'some_key' in some_dict:\n    value = some_dict['some_key']\nelse:\n    value = default_value\n\n# More concise using get()\nvalue = some_dict.get('some_key', default_value)\nget returns None if the key is not present (or a specified default value), pop will raise an exception.\n# setdefault for setting values conditionally\nwords = ['apple', 'bat', 'bar', 'atom', 'book']\nby_letter = {}\nfor word in words:\n    letter = word[0]\n    by_letter.setdefault(letter, []).append(word)  # Use setdefault\nprint(by_letter)\nsetdefault(key, default): If key exists, return its value. If not, insert key with a value of default and return default."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-defaultdict",
    "href": "qmd/pandas3ed3.html#dictionary-defaultdict",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: defaultdict",
    "text": "Dictionary: defaultdict\nThe collections module provides defaultdict, which simplifies the creation of dictionaries where each value is initialized with a default value:\nfrom collections import defaultdict\n\nby_letter = defaultdict(list) # Use defaultdict for a more concise way\nfor word in words:\n    by_letter[word[0]].append(word)\nprint(by_letter)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-valid-key-types-hashability",
    "href": "qmd/pandas3ed3.html#dictionary-valid-key-types-hashability",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary: Valid Key Types (Hashability)",
    "text": "Dictionary: Valid Key Types (Hashability)\n\nKeys must be immutable objects (like scalar types or tuples).\nThe technical term is hashability.\nCheck if an object is hashable using hash():\n\nprint(hash('string'))\nprint(hash((1, 2, (2, 3))))\n# print(hash((1, 2, [2, 3])))  # TypeError: unhashable type: 'list'\n\n# To use a list as a key, convert it to a tuple:\nd = {}\nd[tuple([1, 2, 3])] = 5\nprint(d)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-definition-and-uniqueness",
    "href": "qmd/pandas3ed3.html#set-definition-and-uniqueness",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: Definition and Uniqueness",
    "text": "Set: Definition and Uniqueness\nA set is an unordered collection of unique elements. Think of them like dictionaries, but with only keys and no values."
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-creation",
    "href": "qmd/pandas3ed3.html#set-creation",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: Creation",
    "text": "Set: Creation\nCreate sets using curly braces {} (like dictionaries, but without colons) or the set() function:\nset1 = {2, 2, 2, 1, 3, 3}  # Using curly braces\nprint(set1) # Output: {1, 2, 3}  (duplicates are removed)\nset2 = set([2, 2, 2, 1, 3, 3])  # Using the set() function\nprint(set2)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-operations-union-intersection-etc.",
    "href": "qmd/pandas3ed3.html#set-operations-union-intersection-etc.",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: Operations (Union, Intersection, etc.)",
    "text": "Set: Operations (Union, Intersection, etc.)\nSets support mathematical set operations:\na = {1, 2, 3, 4, 5}\nb = {3, 4, 5, 6, 7, 8}\n\n# Union (| or union())\nprint(a.union(b))\nprint(a | b)\n\n# Intersection (& or intersection())\nprint(a.intersection(b))\nprint(a & b)\n\n# Difference (- or difference())\nprint(a.difference(b)) # elements in a but not in b\nprint(a - b)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-operations",
    "href": "qmd/pandas3ed3.html#set-operations",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set operations",
    "text": "Set operations\n\n\n\n\n\n\n\n\nFunction\nAlternative Syntax\nDescription\n\n\n\n\na.add(x)\nN/A\nAdd element x to set a\n\n\na.clear()\nN/A\nReset set a to an empty state, discarding all of its elements\n\n\na.remove(x)\nN/A\nRemove element x from set a\n\n\na.pop()\nN/A\nRemove an arbitrary element from set a, raising KeyError if the set is empty\n\n\na.union(b)\na \\| b\nAll of the unique elements in a and b\n\n\na.update(b)\na \\|= b\nSet the contents of a to be the union of the elements in a and b\n\n\na.intersection(b)\na & b\nAll of the elements in both a and b\n\n\na.intersection_update(b)\na &= b\nSet the contents of a to be the intersection of the elements in a and b\n\n\na.difference(b)\na - b\nThe elements in a that are not in b\n\n\na.difference_update(b)\na -= b\nSet a to the elements in a that are not in b\n\n\na.symmetric_difference(b)\na ^ b\nAll of the elements in either a or b but not both\n\n\na.symmetric_difference_update(b)\na ^= b\nSet a to contain the elements in either a or b but not both\n\n\na.issubset(b)\n&lt;=\nTrue if the elements of a are all contained in b\n\n\na.issuperset(b)\n&gt;=\nTrue if the elements of b are all contained in a\n\n\na.isdisjoint(b)\nN/A\nTrue if a and b have no elements in common"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-in-place-operations",
    "href": "qmd/pandas3ed3.html#set-in-place-operations",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: In-Place Operations",
    "text": "Set: In-Place Operations\nAll set operations have in-place counterparts (e.g., a |= b for union):\nc = a.copy()\nc |= b  # In-place union (modifies c)\nprint(c)\n\nd = a.copy()\nd &= b\nprint(d)\n\n\n\n\n\n\nTip\n\n\n\nIn-place operation is more efficient, especially when handling large sets."
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-element-hashability",
    "href": "qmd/pandas3ed3.html#set-element-hashability",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: Element Hashability",
    "text": "Set: Element Hashability\nLike dictionary keys, set elements must be immutable and hashable.\nmy_data = [1, 2, 3, 4]\n# my_set = {my_data}  # TypeError: unhashable type: 'list'\nmy_set = {tuple(my_data)}  # Convert the list to a tuple first\nprint(my_set)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-subset-and-superset",
    "href": "qmd/pandas3ed3.html#set-subset-and-superset",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: Subset and Superset",
    "text": "Set: Subset and Superset\na_set = {1, 2, 3, 4, 5}\nprint({1, 2, 3}.issubset(a_set))   # Check if {1, 2, 3} is a subset of a_set\nprint(a_set.issuperset({1, 2, 3}))  # Check if a_set is a superset of {1, 2, 3}"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-equality",
    "href": "qmd/pandas3ed3.html#set-equality",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set: Equality",
    "text": "Set: Equality\nSets are equal if and only if their contents are equal:\nprint({1, 2, 3} == {3, 2, 1})"
  },
  {
    "objectID": "qmd/pandas3ed3.html#built-in-sequence-functions-enumerate",
    "href": "qmd/pandas3ed3.html#built-in-sequence-functions-enumerate",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Built-In Sequence Functions: enumerate",
    "text": "Built-In Sequence Functions: enumerate\nenumerate is a useful function when you need to keep track of the index while iterating over a sequence:\n# Instead of doing this:\ncollection = ['foo', 'bar', 'baz']\ni = 0\nfor value in collection:\n    # do something with value\n    print(f\"Index: {i}, Value: {value}\")\n    i += 1\n\n# Use enumerate:\nfor i, value in enumerate(collection):\n    print(f\"Index: {i}, Value: {value}\")\n    # do something with value\nenumerate returns a sequence of (index, value) tuples."
  },
  {
    "objectID": "qmd/pandas3ed3.html#built-in-sequence-functions-sorted",
    "href": "qmd/pandas3ed3.html#built-in-sequence-functions-sorted",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Built-In Sequence Functions: sorted",
    "text": "Built-In Sequence Functions: sorted\nThe sorted function returns a new sorted list from any sequence:\nprint(sorted([7, 1, 2, 6, 0, 3, 2]))\nprint(sorted('horse race')) # Sorts the characters in the string\n\n\n\n\n\n\nNote\n\n\n\nsorted() returns a new list, while the sort() method of lists sorts in place."
  },
  {
    "objectID": "qmd/pandas3ed3.html#built-in-sequence-functions-zip",
    "href": "qmd/pandas3ed3.html#built-in-sequence-functions-zip",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Built-In Sequence Functions: zip",
    "text": "Built-In Sequence Functions: zip\nzip “pairs up” elements from multiple sequences, creating a list of tuples:\nseq1 = ['foo', 'bar', 'baz']\nseq2 = ['one', 'two', 'three']\nzipped = zip(seq1, seq2)  # Create a zip object\nprint(list(zipped))     # Convert the zip object to a list of tuples\nzip can take any number of sequences. The number of elements produced is determined by the shortest sequence:\nseq3 = [False, True]\nprint(list(zip(seq1, seq2, seq3)))"
  },
  {
    "objectID": "qmd/pandas3ed3.html#built-in-sequence-functions-zip-with-enumerate",
    "href": "qmd/pandas3ed3.html#built-in-sequence-functions-zip-with-enumerate",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Built-In Sequence Functions: zip (with enumerate)",
    "text": "Built-In Sequence Functions: zip (with enumerate)\nA common use of zip is to iterate over multiple sequences simultaneously, often combined with enumerate:\nfor i, (a, b) in enumerate(zip(seq1, seq2)):\n    print(f'{i}: {a}, {b}')"
  },
  {
    "objectID": "qmd/pandas3ed3.html#built-in-sequence-functions-reversed",
    "href": "qmd/pandas3ed3.html#built-in-sequence-functions-reversed",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Built-In Sequence Functions: reversed",
    "text": "Built-In Sequence Functions: reversed\nreversed iterates over a sequence in reverse order:\nprint(list(reversed(range(10))))  # reversed() returns a generator\n\n\n\n\n\n\nNote\n\n\n\nreversed is a generator, so it doesn’t create the reversed sequence until materialized (e.g., with list or a for loop)."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-set-and-dictionary-comprehensions",
    "href": "qmd/pandas3ed3.html#list-set-and-dictionary-comprehensions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List, Set, and Dictionary Comprehensions",
    "text": "List, Set, and Dictionary Comprehensions\nComprehensions provide a concise way to create new lists, sets, or dictionaries by applying an expression and an optional filter to an existing sequence."
  },
  {
    "objectID": "qmd/pandas3ed3.html#list-comprehension-basic-form",
    "href": "qmd/pandas3ed3.html#list-comprehension-basic-form",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "List Comprehension: Basic Form",
    "text": "List Comprehension: Basic Form\n# General form: [expr for val in collection if condition]\n\n# Equivalent for loop:\nresult = []\nfor val in collection:\n    if condition:\n        result.append(expr)\nExample:\nstrings = ['a', 'as', 'bat', 'car', 'dove', 'python']\nupper_case_long_strings = [x.upper() for x in strings if len(x) &gt; 2]\nprint(upper_case_long_strings)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#set-comprehension",
    "href": "qmd/pandas3ed3.html#set-comprehension",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Set Comprehension",
    "text": "Set Comprehension\n# General form: {expr for val in collection if condition}\nstrings = ['a', 'as', 'bat', 'car', 'dove', 'python']\nunique_lengths = {len(x) for x in strings}  # Create a set of unique string lengths\nprint(unique_lengths)\n\n# using map function\nprint(set(map(len, strings)))\nSet comprehension is very similar to list comprehensions, but it uses curly braces {} and creates a set (unique elements)."
  },
  {
    "objectID": "qmd/pandas3ed3.html#dictionary-comprehension",
    "href": "qmd/pandas3ed3.html#dictionary-comprehension",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Dictionary Comprehension",
    "text": "Dictionary Comprehension\n# General form: {key_expr: value_expr for val in collection if condition}\n\n# Example: Create a dictionary mapping strings to their locations in a list\nstrings = ['a', 'as', 'bat', 'car', 'dove', 'python']\nloc_mapping = {val: index for index, val in enumerate(strings)}\nprint(loc_mapping)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#nested-list-comprehensions",
    "href": "qmd/pandas3ed3.html#nested-list-comprehensions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Nested List Comprehensions",
    "text": "Nested List Comprehensions\nList comprehensions can be nested:\nall_data = [['John', 'Emily', 'Michael', 'Mary', 'Steven'],\n            ['Maria', 'Juan', 'Javier', 'Natalia', 'Pilar']]\n\n# Find names with two or more 'a's\nnames_of_interest = [name for names in all_data for name in names\n                     if name.count('a') &gt;= 2]\nprint(names_of_interest)\n\n\n# Flatten a list of tuples into a single list\nsome_tuples = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\nflattened = [x for tup in some_tuples for x in tup]\nprint(flattened)\n\n# List comprehension inside a list comprehension.\nflattened = [[x for x in tup] for tup in some_tuples]\nprint(flattened)\n\n\n\n\n\n\nNote\n\n\n\nThe order of the for expressions in a nested list comprehension is the same as it would be in nested for loops."
  },
  {
    "objectID": "qmd/pandas3ed3.html#functions",
    "href": "qmd/pandas3ed3.html#functions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "3.2 Functions",
    "text": "3.2 Functions\nFunctions are a fundamental way to organize and reuse code in Python. They enhance readability and maintainability."
  },
  {
    "objectID": "qmd/pandas3ed3.html#function-declaration-def",
    "href": "qmd/pandas3ed3.html#function-declaration-def",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Function Declaration (def)",
    "text": "Function Declaration (def)\nFunctions are declared using the def keyword:\ndef my_function(x, y):\n    \"\"\"This is a docstring, explaining what the function does.\"\"\"\n    return x + y\n\nresult = my_function(1, 2)\nprint(result)\nprint(my_function.__doc__)\n\nThe return statement sends a value back to the caller.\nIf a function reaches the end without a return statement, it implicitly returns None."
  },
  {
    "objectID": "qmd/pandas3ed3.html#function-arguments-positional-and-keyword",
    "href": "qmd/pandas3ed3.html#function-arguments-positional-and-keyword",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Function Arguments (Positional and Keyword)",
    "text": "Function Arguments (Positional and Keyword)\ndef my_function2(x, y, z=1.5):  # z is a keyword argument with a default value\n    if z &gt; 1:\n        return z * (x + y)\n    else:\n        return z / (x + y)\n\nprint(my_function2(5, 6, z=0.7))  # Using the keyword\nprint(my_function2(3.14, 7, 3.5))  # Positional arguments\nprint(my_function2(10, 20))        # Using the default value for z\n\nPositional arguments must be provided in the correct order.\nKeyword arguments can be specified in any order and often have default values.\nKeyword arguments must follow positional arguments."
  },
  {
    "objectID": "qmd/pandas3ed3.html#namespaces-scope-and-local-functions",
    "href": "qmd/pandas3ed3.html#namespaces-scope-and-local-functions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Namespaces, Scope, and Local Functions",
    "text": "Namespaces, Scope, and Local Functions\n\nVariables assigned within a function are in the local namespace by default.\nThe local namespace is created when the function is called and destroyed when the function finishes.\n\ndef func():\n    a = []  # 'a' is local to the function\n    for i in range(5):\n        a.append(i)\n\nfunc()\n# print(a)  # NameError: name 'a' is not defined (outside the function's scope)\n\nYou can access variables in enclosing scopes (e.g., global variables), but to modify them, you generally need to use the global or nonlocal keywords.\n\na = []  # 'a' is a global variable\n\ndef func2():\n    for i in range(5):\n        a.append(i)  # Modifies the *global* 'a'\n\nfunc2()\nprint(a)\n\nb = None # 'b' is a global variable\ndef bind_b_variable():\n    global b  # Declare 'b' as global to modify it within the function\n    b = []\nbind_b_variable()\nprint(b)\n\n\n\n\n\n\nCaution\n\n\n\nGenerally, avoid excessive use of the global keyword. It’s often better to design your code to minimize reliance on global state for better modularity."
  },
  {
    "objectID": "qmd/pandas3ed3.html#returning-multiple-values",
    "href": "qmd/pandas3ed3.html#returning-multiple-values",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Returning Multiple Values",
    "text": "Returning Multiple Values\nFunctions can return multiple values using tuples (or other data structures):\ndef f():\n    a = 5\n    b = 6\n    c = 7\n    return a, b, c  # Returns a tuple\n\nx, y, z = f()  # Unpack the returned tuple\nprint(x, y, z)\n\n# Or return a dictionary\ndef f2():\n  a = 5\n  b = 6\n  c = 7\n  return {'a' : a, 'b' : b, 'c' : c}\n\nresult = f2()\nprint(result)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#functions-are-objects",
    "href": "qmd/pandas3ed3.html#functions-are-objects",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Functions Are Objects",
    "text": "Functions Are Objects\nFunctions in Python are first-class objects, which means you can:\n\nPass them as arguments to other functions.\nAssign them to variables.\nReturn them from other functions.\n\n# Example: Data cleaning\nimport re # regular expression operations\n\nstates = ['   Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda',\n          'south   carolina##', 'West virginia?']\n\ndef clean_strings(strings):\n    result = []\n    for value in strings:\n        value = value.strip()  # Remove whitespace\n        value = re.sub('[!#?]', '', value)  # Remove punctuation\n        value = value.title()  # Title case\n        result.append(value)\n    return result\n\nprint(clean_strings(states))\n\n# Alternative approach using a list of functions:\ndef remove_punctuation(value):\n    return re.sub('[!#?]', '', value)\n\nclean_ops = [str.strip, remove_punctuation, str.title]\n\ndef clean_strings_functional(strings, ops):\n    result = []\n    for value in strings:\n        for function in ops:\n            value = function(value)\n        result.append(value)\n    return result\n\nprint(clean_strings_functional(states, clean_ops))\n\n\n# Using functions with map:\nfor x in map(remove_punctuation, states):\n  print(x)\nThis functional approach makes the code very flexible and reusable."
  },
  {
    "objectID": "qmd/pandas3ed3.html#anonymous-lambda-functions",
    "href": "qmd/pandas3ed3.html#anonymous-lambda-functions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Anonymous (Lambda) Functions",
    "text": "Anonymous (Lambda) Functions\nLambda functions are small, anonymous functions defined using the lambda keyword:\n# Equivalent to:\n# def short_function(x):\n#     return x * 2\n\nequiv_anon = lambda x: x * 2\nprint(equiv_anon(4))\nLambda functions are particularly useful when passing short, simple functions as arguments to other functions:\ndef apply_to_list(some_list, f):\n    return [f(x) for x in some_list]\n\nints = [4, 0, 1, 5, 6]\nresult = apply_to_list(ints, lambda x: x * 2) # Pass a lambda function\nprint(result)\n\n# Another example\nstrings = ['foo', 'card', 'bar', 'aaaa', 'abab']\nstrings.sort(key=lambda x: len(set(x))) # Sort by number of distinct letters\nprint(strings)"
  },
  {
    "objectID": "qmd/pandas3ed3.html#generators",
    "href": "qmd/pandas3ed3.html#generators",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Generators",
    "text": "Generators\nGenerators are a special kind of iterator that produce values on demand, rather than computing them all at once. This makes them very memory-efficient, especially when working with large sequences.\ndef squares(n=10):\n    print('Generating squares from 1 to %d' % n ** 2)\n    for i in range(1, n + 1):\n        yield i ** 2  # Use 'yield' instead of 'return'\n\ngen = squares()  # Create a generator object\nprint(gen)\n# Nothing is computed until you request values:\nfor x in gen:\n    print(x, end=' ')\n\nUse the yield keyword instead of return.\nGenerators don’t execute immediately. They produce values only when iterated over."
  },
  {
    "objectID": "qmd/pandas3ed3.html#generator-expressions",
    "href": "qmd/pandas3ed3.html#generator-expressions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Generator Expressions",
    "text": "Generator Expressions\nGenerator expressions are concise ways to create generators, analogous to list/set/dict comprehensions:\n# List comprehension: [x ** 2 for x in range(100)]\n# Generator expression:\ngen = (x ** 2 for x in range(100)) # using parenthese\nprint(gen)\nprint(sum(gen))\n\n# Can be used as function arguments:\nprint(sum(x ** 2 for x in range(100)))\nprint(dict((i, i **2) for i in range(5)))"
  },
  {
    "objectID": "qmd/pandas3ed3.html#itertools-module",
    "href": "qmd/pandas3ed3.html#itertools-module",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "itertools Module",
    "text": "itertools Module\nThe itertools module provides a collection of useful generators for common data algorithms:\nimport itertools\n\ndef first_letter(x):\n    return x[0]\n\nnames = ['Alan', 'Adam', 'Wes', 'Will', 'Albert', 'Steven']\n\nfor letter, names_iter in itertools.groupby(names, first_letter):\n    print(letter, list(names_iter)) # names is a generator\nitertools.groupby groups consecutive elements based on the return value of a function."
  },
  {
    "objectID": "qmd/pandas3ed3.html#useful-itertools-functions",
    "href": "qmd/pandas3ed3.html#useful-itertools-functions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Useful itertools Functions",
    "text": "Useful itertools Functions\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nchain(*iterables)\nGenerates a sequence by chaining iterators.\n\n\ncombinations(iterable, k)\nGenerates k-tuples of elements, ignoring order, without replacement.\n\n\npermutations(iterable, k)\nGenerates k-tuples of elements, respecting order.\n\n\ngroupby(iterable[, keyfunc])\nGenerates (key, sub-iterator) for each unique key.\n\n\nproduct(*iterables, repeat=1)\nGenerates the Cartesian product of input iterables (similar to nested for loops).\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCheck out the official Python documentation for the itertools module. It’s a treasure trove of useful tools!"
  },
  {
    "objectID": "qmd/pandas3ed3.html#errors-and-exception-handling",
    "href": "qmd/pandas3ed3.html#errors-and-exception-handling",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Errors and Exception Handling",
    "text": "Errors and Exception Handling\nHandling errors (exceptions) gracefully is crucial for writing robust code."
  },
  {
    "objectID": "qmd/pandas3ed3.html#try-except-blocks",
    "href": "qmd/pandas3ed3.html#try-except-blocks",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "try-except Blocks",
    "text": "try-except Blocks\ndef attempt_float(x):\n    try:\n        return float(x)\n    except:  # Catches *any* exception\n        return x\n\nprint(attempt_float('1.2345'))\nprint(attempt_float('something'))\n\nThe try block contains the code that might raise an exception.\nThe except block is executed if an exception occurs in the try block."
  },
  {
    "objectID": "qmd/pandas3ed3.html#catching-specific-exceptions",
    "href": "qmd/pandas3ed3.html#catching-specific-exceptions",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Catching Specific Exceptions",
    "text": "Catching Specific Exceptions\ndef attempt_float2(x):\n    try:\n        return float(x)\n    except ValueError:  # Only catch ValueError\n        return x\n\n# print(attempt_float2((1, 2)))  # TypeError will not be caught\nYou can specify the type of exception to catch. This is generally preferred over catching all exceptions, as it allows you to handle specific errors appropriately."
  },
  {
    "objectID": "qmd/pandas3ed3.html#catching-multiple-exception-types",
    "href": "qmd/pandas3ed3.html#catching-multiple-exception-types",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Catching Multiple Exception Types",
    "text": "Catching Multiple Exception Types\ndef attempt_float3(x):\n    try:\n        return float(x)\n    except (TypeError, ValueError):  # Catch multiple exception types\n        return x\nUse a tuple of exception types to catch multiple kinds of exceptions."
  },
  {
    "objectID": "qmd/pandas3ed3.html#finally-and-else",
    "href": "qmd/pandas3ed3.html#finally-and-else",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "finally and else",
    "text": "finally and else\n\nfinally: Code in the finally block always executes, regardless of whether an exception occurred or not. Useful for cleanup (e.g., closing files).\nelse: Code in the else block executes only if the try block completed without raising an exception.\n\n# Example illustrating finally\nf = open(\"tempfile.txt\", mode = \"w\")\ntry:\n    # write_to_file(f)  # Assume this function might raise an exception\n    f.write(\"example text\")\nfinally:\n    f.close()  # Always close the file\n    import os # operating system operation\n    os.remove(\"tempfile.txt\") # Removes the file named \"tempfile.txt\"\n# Example illustrating else\nf = open(\"tempfile.txt\", mode = \"w\")\ntry:\n    #write_to_file(f)\n    f.write(\"example text\")\nexcept:\n    print('Failed')\nelse:\n    print('Succeeded')\nfinally:\n    f.close()\n    import os\n    os.remove(\"tempfile.txt\")"
  },
  {
    "objectID": "qmd/pandas3ed3.html#exceptions-in-ipython",
    "href": "qmd/pandas3ed3.html#exceptions-in-ipython",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Exceptions in IPython",
    "text": "Exceptions in IPython\nIPython provides helpful stack traces (tracebacks) when exceptions occur, making debugging easier. You can control the level of detail using the %xmode magic command (Plain, Context, Verbose)."
  },
  {
    "objectID": "qmd/pandas3ed3.html#files-and-the-operating-system",
    "href": "qmd/pandas3ed3.html#files-and-the-operating-system",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "3.3 Files and the Operating System",
    "text": "3.3 Files and the Operating System\nInteracting with files is a common task in data analysis."
  },
  {
    "objectID": "qmd/pandas3ed3.html#opening-files-open",
    "href": "qmd/pandas3ed3.html#opening-files-open",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Opening Files (open)",
    "text": "Opening Files (open)\npath = 'examples/segismundo.txt'  # Replace with your file path\n# Use a raw string (r'...') or escape backslashes for Windows paths\n# path = r'C:\\Users\\YourName\\Documents\\myfile.txt'\n\n# default encoding varies from platform to platform, better to specify explicitly.\nf = open(path, encoding='utf-8')  # Open in read mode ('r' is the default)\n#f = open(path, mode = \"r\", encoding='utf-8') # is equal to previous line\nfor line in f:\n    print(line.rstrip()) # remove trailing whitespaces.\n\nf.close() # close the file after using it.\n\nopen(path, mode='r', encoding=None) opens a file.\n\npath: The file path (relative or absolute).\nmode: ‘r’ (read), ‘w’ (write), ‘a’ (append), ‘x’ (create, fail if exists), ‘rb’ (binary read), ‘wb’ (binary write), etc.\nencoding: Specify the file encoding (e.g., ‘utf-8’ for text files with Unicode characters). It is a good habit to set encoding parameter.\n\nIt’s essential to close files after you’re finished with them using f.close()."
  },
  {
    "objectID": "qmd/pandas3ed3.html#reading-from-files",
    "href": "qmd/pandas3ed3.html#reading-from-files",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Reading from Files",
    "text": "Reading from Files\n# reading all the lines\nf = open(path, encoding=\"utf-8\")\nlines = [x.rstrip() for x in f]  # Read lines, remove trailing whitespace\nprint(lines)\nf.close()"
  },
  {
    "objectID": "qmd/pandas3ed3.html#using-with-for-automatic-file-closing",
    "href": "qmd/pandas3ed3.html#using-with-for-automatic-file-closing",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Using with for Automatic File Closing",
    "text": "Using with for Automatic File Closing\nThe with statement provides a cleaner way to handle files, automatically closing them when the block finishes:\nwith open(path, encoding=\"utf-8\") as f:\n    lines = [x.rstrip() for x in f]\nprint(lines)\n# The file 'f' is automatically closed here\n\n\n\n\n\n\nTip\n\n\n\nUsing with is the recommended way to work with files in Python. It ensures proper cleanup, even if errors occur."
  },
  {
    "objectID": "qmd/pandas3ed3.html#file-modes",
    "href": "qmd/pandas3ed3.html#file-modes",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "File Modes",
    "text": "File Modes\n\n\n\n\n\n\n\nMode\nDescription\n\n\n\n\nr\nRead-only mode\n\n\nw\nWrite-only mode; creates a new file (erasing any existing file with the same name)\n\n\nx\nWrite-only mode; creates a new file, but fails if the file path already exists\n\n\na\nAppend to existing file (creates the file if it doesn’t exist)\n\n\nr+\nRead and write\n\n\nb\nAdd to mode for binary files (e.g., ‘rb’ or ‘wb’)\n\n\nt\nText mode (automatically decoding bytes to Unicode); this is the default"
  },
  {
    "objectID": "qmd/pandas3ed3.html#read-seek-and-tell",
    "href": "qmd/pandas3ed3.html#read-seek-and-tell",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "read, seek, and tell",
    "text": "read, seek, and tell\nf1 = open(path, encoding = \"utf-8\")\nprint(f1.read(10))  # Read the first 10 *characters*\n\nf2 = open(path, mode='rb')  # Open in binary mode\nprint(f2.read(10))  # Read the first 10 *bytes*\n\nprint(f1.tell())  # Current file position (characters)\nprint(f2.tell())  # Current file position (bytes)\n\nimport sys\nprint(sys.getdefaultencoding()) # get the default encoding\n\nf1.seek(3)  # Move to the 3rd byte (character) in the file\nprint(f1.read(1))\n\nf1.close()\nf2.close()\n\nread(n): Reads n characters (text mode) or bytes (binary mode).\ntell(): Returns the current file position.\nseek(position): Moves the file pointer to a specific position (in bytes).\nBe cautious using seek with text files encoded in UTF-8, as seeking to a position in the middle of a multi-byte character can lead to errors."
  },
  {
    "objectID": "qmd/pandas3ed3.html#writing-to-files",
    "href": "qmd/pandas3ed3.html#writing-to-files",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Writing to Files",
    "text": "Writing to Files\nwith open('tmp.txt', 'w', encoding = \"utf-8\") as handle:\n    handle.writelines(x for x in open(path, encoding = \"utf-8\") if len(x) &gt; 1) # write lines into a file\n\nwith open('tmp.txt', encoding = \"utf-8\") as f:\n    lines = f.readlines()\nprint(lines)\n\nimport os\nos.remove(\"tmp.txt\")\n\nwrite(string): Writes a string to the file.\nwritelines(list_of_strings): Writes a list of strings to the file."
  },
  {
    "objectID": "qmd/pandas3ed3.html#important-file-methodsattributes",
    "href": "qmd/pandas3ed3.html#important-file-methodsattributes",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Important File Methods/Attributes",
    "text": "Important File Methods/Attributes\n\n\n\n\n\n\n\nMethod/Attribute\nDescription\n\n\n\n\nread([size])\nReturn data from file as bytes or string, with optional size argument.\n\n\nreadable()\nReturn True if the file supports read operations.\n\n\nreadlines([size])\nReturn list of lines in the file, with optional size argument.\n\n\nwrite(string)\nWrite passed string to file.\n\n\nwritable()\nReturn True if the file supports write operations.\n\n\nwritelines(strings)\nWrite passed sequence of strings to the file.\n\n\nclose()\nClose the file object.\n\n\nflush()\nFlush the internal I/O buffer to disk.\n\n\nseek(pos)\nMove to indicated file position (integer).\n\n\nseekable()\nReturn True if the file object supports seeking.\n\n\ntell()\nReturn current file position as integer.\n\n\nclosed\nTrue if the file is closed.\n\n\nencoding\nThe encoding used to interpret bytes in the file as Unicode (typically UTF-8)."
  },
  {
    "objectID": "qmd/pandas3ed3.html#bytes-and-unicode-with-files",
    "href": "qmd/pandas3ed3.html#bytes-and-unicode-with-files",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Bytes and Unicode with Files",
    "text": "Bytes and Unicode with Files\n\nDefault behavior is text mode (working with strings/Unicode).\nUse mode='rb' or 'wb' for binary mode (working with raw bytes).\n\nwith open(path, encoding = \"utf-8\") as f:\n    chars = f.read(10)  # read 10 characters\nprint(len(chars))\n\nwith open(path, 'rb') as f:\n    data = f.read(10) # read 10 bytes\nprint(data)\n\nprint(data.decode('utf-8'))  # Decode bytes to a string\n\n# print(data[:4].decode('utf-8')) # UnicodeDecodeError if incomplete character\n\nUTF-8 is a variable-length encoding. Reading a specific number of characters might involve reading a different number of bytes.\nIn binary mode, read returns exactly the requested number of bytes.\nWhen decoding bytes to strings, ensure that you’re decoding complete characters.\n\nsink_path = 'sink.txt'\nwith open(path, encoding = \"utf-8\") as source:\n    with open(sink_path, 'x', encoding='iso-8859-1') as sink:\n        sink.write(source.read())\n\nwith open(sink_path, encoding='iso-8859-1') as f:\n    print(f.read(10))\n\nimport os\nos.remove(sink_path)\n\n# caution\nf = open(path, encoding = \"utf-8\")\nprint(f.read(5))\nf.seek(4)\n# print(f.read(1)) # UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte\nf.close()\n\n\n\n\n\n\nCaution\n\n\n\nBeware using seek when opening files in any mode other than binary."
  },
  {
    "objectID": "qmd/pandas3ed3.html#summary",
    "href": "qmd/pandas3ed3.html#summary",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Summary",
    "text": "Summary\nThis chapter covered essential Python concepts for data analysis:\n\nData Structures: Tuples (immutable), Lists (mutable), Dictionaries (key-value pairs), Sets (unique, unordered collections).\nBuilt-in Functions: enumerate, sorted, zip, reversed.\nComprehensions: Concise ways to create lists, sets, and dictionaries.\nFunctions: Defining functions, arguments (positional and keyword), namespaces, returning multiple values, functions as objects, lambda functions.\nGenerators: Memory-efficient iterators using yield and generator expressions.\nitertools Module: Useful functions for working with iterators.\nError Handling: try, except, finally, else.\nFile Handling: Opening, reading, writing, and closing files; text vs. binary mode; Unicode and encodings.\n\nThese fundamentals provide a solid foundation for working with data in Python. You’ll build upon these concepts as you learn more advanced libraries like NumPy and pandas."
  },
  {
    "objectID": "qmd/pandas3ed3.html#thoughts-and-discussion",
    "href": "qmd/pandas3ed3.html#thoughts-and-discussion",
    "title": "Built-In Data Structures, Functions, and Files",
    "section": "Thoughts and Discussion 🤔",
    "text": "Thoughts and Discussion 🤔\n\nConsider a scenario where you are reading data from a very large CSV file (larger than your computer’s RAM). How would you use the concepts from this chapter (specifically generators and file handling) to process this data efficiently without loading the entire file into memory at once?\nDiscuss the trade-offs between using lists and tuples. When would you choose one over the other? Give specific examples.\nExplain the difference between a list comprehension and a generator expression. When would you prefer to use a generator expression?\nWhy is it important to handle exceptions in your code? Provide an example of a situation where exception handling is crucial in a data analysis context.\nWhat are the advantages of using the with statement when working with files?\nExplain the difference between text mode and binary mode when working with files. Why is it important to understand the encoding of a text file?\nHow to decide to use dict or set?"
  }
]