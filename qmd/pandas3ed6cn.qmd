---
title: "ç¬¬6ç« ï¼šæ•°æ®åŠ è½½ã€å­˜å‚¨ä¸æ–‡ä»¶æ ¼å¼"
---

## ç®€ä»‹ï¼šä¸ºä»€ä¹ˆæ•°æ®åŠ è½½å¾ˆé‡è¦

æ¬¢è¿æ¥åˆ°æ•°æ®åˆ†æçš„ä¸–ç•Œï¼ğŸŒ åœ¨æˆ‘ä»¬ä»æ•°æ®ä¸­è§£é”æ´å¯ŸåŠ›ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå°†æ•°æ®å¯¼å…¥åˆ°æˆ‘ä»¬çš„ Python ç¯å¢ƒä¸­ã€‚æœ¬ç« é‡ç‚¹å…³æ³¨è¿™å…³é”®çš„ç¬¬ä¸€æ­¥ï¼š**æ•°æ®åŠ è½½**ã€‚

å¯ä»¥è¿™æ ·ç†è§£ï¼šåœ¨ä½ çƒ¹é¥ªä¸€é“ç¾å‘³ä½³è‚´ ğŸ³ ä¹‹å‰ï¼Œä½ é¦–å…ˆéœ€è¦æ”¶é›†ä½ çš„é£Ÿæ ğŸ…ğŸ¥•ğŸ¥¦ã€‚æ•°æ®åŠ è½½å°±åƒæ˜¯ä¸ºä½ çš„æ•°æ®åˆ†æé£Ÿè°±æ”¶é›†é£Ÿæã€‚

## ç®€ä»‹ï¼šæˆ‘ä»¬å°†æ¶µç›–çš„å†…å®¹

æˆ‘ä»¬å°†æ¶µç›–å„ç§åŠ è½½æ•°æ®çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š

-   æ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚ CSVï¼‰
-   äºŒè¿›åˆ¶æ ¼å¼
-   æ•°æ®åº“
-   Web API

## æ ¸å¿ƒæ¦‚å¿µï¼šæ•°æ®åˆ†æ ğŸ“Š

æ•°æ®åˆ†ææ˜¯å¯¹æ•°æ®è¿›è¡Œæ£€æŸ¥ã€æ¸…ç†ã€è½¬æ¢å’Œå»ºæ¨¡çš„è¿‡ç¨‹ï¼Œä»¥å‘ç°æœ‰ç”¨çš„ä¿¡æ¯ã€å¾—å‡ºç»“è®ºå¹¶æ”¯æŒå†³ç­–ã€‚è¿™å°±åƒæˆä¸ºä¸€åä¾¦æ¢ ğŸ•µï¸â€â™€ï¸ï¼Œä½†ä½ ä¸æ˜¯åœ¨ç ´æ¡ˆï¼Œè€Œæ˜¯åœ¨è§£å†³éšè—åœ¨æ•°æ®ä¸­çš„éš¾é¢˜ã€‚

## æ ¸å¿ƒæ¦‚å¿µï¼šæœºå™¨å­¦ä¹  ğŸ¤–

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½ (AI) çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ— éœ€è¿›è¡Œæ˜¾å¼ç¼–ç¨‹ã€‚å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆæ•™è®¡ç®—æœºåƒå­©å­ä¸€æ ·å­¦ä¹  ğŸ‘¶ï¼Œé€šè¿‡å‘å®ƒå±•ç¤ºç¤ºä¾‹è€Œä¸æ˜¯ç»™å®ƒä¸¥æ ¼çš„è§„åˆ™ã€‚

## æ ¸å¿ƒæ¦‚å¿µï¼šPython ğŸ

Python æ˜¯ä¸€ç§é€šç”¨çš„é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ ã€‚å®ƒä»¥å…¶å¯è¯»æ€§å’Œå¹¿æ³›çš„åº“è€Œé—»åï¼Œè¿™ä½¿å¾—æ‰§è¡Œå¤æ‚ä»»åŠ¡å˜å¾—æ›´åŠ å®¹æ˜“ã€‚è¿™å°±åƒæ‹¥æœ‰ä¸€ä¸ªæ•°æ®åˆ†æçš„ç‘å£«å†›åˆ€ ğŸ› ï¸ã€‚

## æ ¸å¿ƒæ¦‚å¿µï¼šæ•°æ®ç§‘å­¦ç»´æ©å›¾

![æ•°æ®ç§‘å­¦ç»´æ©å›¾ã€‚æ¥æºï¼š[Drew Conway](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram)](data_science_venn.png){width=80%}

## ä½¿ç”¨ Pandas è¿›è¡Œæ•°æ®è¾“å…¥/è¾“å‡º

`pandas` åº“æ˜¯ä½ åœ¨ Python ä¸­å¤„ç†è¡¨æ ¼æ•°æ®çš„æœ€å¥½æœ‹å‹ã€‚å®ƒæä¾›äº† `DataFrame` å¯¹è±¡ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå­˜å‚¨å’Œæ“ä½œè¡Œå’Œåˆ—ä¸­æ•°æ®ï¼ˆå¦‚ç”µå­è¡¨æ ¼ï¼‰çš„å¼ºå¤§ç»“æ„ã€‚`pandas` æä¾›äº†å‡ ä¸ªç”¨äºè¯»å–å’Œå†™å…¥å„ç§æ ¼å¼æ•°æ®çš„å‡½æ•°ã€‚

## æ•°æ®è§£æ

::: {.callout-note appearance="minimal"}
**æ•°æ®è§£æ**ï¼Œé€šå¸¸ç§°ä¸º*æ•°æ®åŠ è½½*ï¼ŒåŒ…æ‹¬ä»æ–‡ä»¶æˆ–å…¶ä»–æ¥æºè¯»å–æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¯ç”¨çš„æ ¼å¼ï¼ˆå¦‚ DataFrameï¼‰ã€‚å®ƒé€šå¸¸è¿˜åŒ…æ‹¬å¯¹æ•°æ®ä¸­æ•°æ®ç±»å‹çš„åˆæ­¥è§£é‡Šã€‚
:::

## å¸¸ç”¨çš„ `pandas` æ•°æ®åŠ è½½å‡½æ•° (1/2)

ä¸‹è¡¨åˆ—å‡ºäº† `pandas` ä¸­ä¸€äº›æœ€å¸¸ç”¨çš„æ•°æ®åŠ è½½å‡½æ•°ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ `read_csv`ã€‚

| å‡½æ•°             | æè¿°                                                                                                                  |
| :--------------- | :--------------------------------------------------------------------------------------------------------------------------- |
| `read_csv`       | ä»æ–‡ä»¶ã€URL æˆ–ç±»æ–‡ä»¶å¯¹è±¡åŠ è½½åˆ†éš”æ•°æ®ï¼›é»˜è®¤ä½¿ç”¨é€—å·ä½œä¸ºåˆ†éš”ç¬¦ã€‚                         |
| `read_fwf`       | è¯»å–å›ºå®šå®½åº¦åˆ—æ ¼å¼çš„æ•°æ®ï¼ˆå³ï¼Œæ²¡æœ‰åˆ†éš”ç¬¦ï¼‰ã€‚                                                             |
| `read_clipboard` | `read_csv` çš„å˜ä½“ï¼Œä»å‰ªè´´æ¿è¯»å–æ•°æ®ï¼›ç”¨äºè½¬æ¢ç½‘é¡µä¸­çš„è¡¨æ ¼ã€‚                |
| `read_excel`     | ä» Excel XLS æˆ– XLSX æ–‡ä»¶è¯»å–è¡¨æ ¼æ•°æ®ã€‚                                                                            |
| `read_hdf`       | è¯»å–ç”± pandas å†™å…¥çš„ HDF5 æ–‡ä»¶ã€‚                                                                                          |
| `read_html`      | è¯»å–ç»™å®š HTML æ–‡æ¡£ä¸­çš„æ‰€æœ‰è¡¨æ ¼ã€‚                                                                         |
| `read_json`      | ä» JSONï¼ˆJavaScript å¯¹è±¡è¡¨ç¤ºæ³•ï¼‰å­—ç¬¦ä¸²è¡¨ç¤ºã€æ–‡ä»¶ã€URL æˆ–ç±»æ–‡ä»¶å¯¹è±¡è¯»å–æ•°æ®ã€‚                |

## å¸¸ç”¨çš„ `pandas` æ•°æ®åŠ è½½å‡½æ•° (2/2)

| å‡½æ•°             | æè¿°                                                       |
| :---------------- | :---------------------------------------------------------------- |
| `read_feather`    | è¯»å– Feather äºŒè¿›åˆ¶æ–‡ä»¶æ ¼å¼ã€‚                              |
| `read_orc`        | è¯»å– Apache ORC äºŒè¿›åˆ¶æ–‡ä»¶æ ¼å¼ã€‚                            |
| `read_parquet`    | è¯»å– Apache Parquet äºŒè¿›åˆ¶æ–‡ä»¶æ ¼å¼ã€‚                        |
| `read_pickle`     | è¯»å–ä½¿ç”¨ Python pickle æ ¼å¼å­˜å‚¨çš„ pandas å¯¹è±¡ã€‚     |
| `read_sas`        | è¯»å–ä»¥ SAS ç³»ç»Ÿè‡ªå®šä¹‰æ ¼å¼ä¹‹ä¸€å­˜å‚¨çš„ SAS æ•°æ®é›†ã€‚|
| `read_spss`       | è¯»å–ç”± SPSS åˆ›å»ºçš„æ•°æ®æ–‡ä»¶ã€‚                                 |
| `read_sql`        | è¯»å– SQL æŸ¥è¯¢çš„ç»“æœï¼ˆä½¿ç”¨ SQLAlchemyï¼‰ã€‚              |
| `read_sql_table` | è¯»å–æ•´ä¸ª SQL è¡¨ï¼ˆä½¿ç”¨ SQLAlchemyï¼‰ã€‚                         |
| `read_stata`      | ä» Stata æ–‡ä»¶æ ¼å¼è¯»å–æ•°æ®é›†ã€‚                             |
| `read_xml`        | ä»XMLæ–‡ä»¶ä¸­è¯»å–æ•°æ®è¡¨ã€‚                              |

## é‡ç‚¹ï¼š`read_csv`

`read_csv` æ˜¯å¤„ç†é€—å·åˆ†éš”å€¼æ–‡ä»¶çš„åŸºçŸ³ï¼Œä¹Ÿæ˜¯æœ€å¸¸ç”¨çš„å‡½æ•°ä¹‹ä¸€ã€‚

## å¯é€‰å‚æ•°ï¼šæ¦‚è¿°

æ•°æ®åŠ è½½å‡½æ•°æœ‰è®¸å¤šå¯é€‰å‚æ•°æ¥è‡ªå®šä¹‰åŠ è½½è¿‡ç¨‹ã€‚å®ƒä»¬é€šå¸¸åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

-   **ç´¢å¼•ï¼š** é€‰æ‹©ç´¢å¼•åˆ—å’Œå¤„ç†åˆ—åã€‚
-   **ç±»å‹æ¨æ–­å’Œæ•°æ®è½¬æ¢ï¼š** è‡ªå®šä¹‰æ•°æ®ç±»å‹æ£€æµ‹å’Œç¼ºå¤±å€¼è¡¨ç¤ºã€‚
-   **æ—¥æœŸå’Œæ—¶é—´è§£æï¼š** åˆå¹¶å’Œè½¬æ¢æ—¥æœŸ/æ—¶é—´ä¿¡æ¯ã€‚
-   **è¿­ä»£ï¼š** åˆ†å—å¤„ç†å¤§æ–‡ä»¶ã€‚
-   **ä¸å¹²å‡€çš„æ•°æ®é—®é¢˜ï¼š** è·³è¿‡è¡Œã€å¤„ç†æ³¨é‡Šç­‰ã€‚

## `pandas` æ–‡æ¡£

::: {.callout-note appearance="minimal"}
ä¸è¦è¢«å“å€’ï¼`pandas` åœ¨çº¿æ–‡æ¡£æœ‰å¾ˆå¤šå¾ˆæ£’çš„ä¾‹å­ã€‚åƒ "pandas read_csv skip header" è¿™æ ·çš„ Google æœç´¢é€šå¸¸ä¼šæœ‰å¸®åŠ©ã€‚
:::

## ä½¿ç”¨ `read_csv` è¯»å– CSV æ–‡ä»¶ - åŸºæœ¬ç¤ºä¾‹

è®©æˆ‘ä»¬ä»è¯»å–é€—å·åˆ†éš”å€¼ (CSV) æ–‡ä»¶å¼€å§‹ã€‚

```{python}
#| echo: false
#| output: false
# åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„ CSV æ–‡ä»¶ã€‚
import pandas as pd
data = {'a': [1, 5, 9], 'b': [2, 6, 10], 'c': [3, 7, 11], 'd': [4, 8, 12], 'message': ['hello', 'world', 'foo']}
df = pd.DataFrame(data)
df.to_csv('ex1.csv', index=False)
```

```{python}
# å¯¼å…¥ pandas
import pandas as pd

# è¯»å– CSV æ–‡ä»¶
df = pd.read_csv("examples/ex1.csv")

# æ˜¾ç¤º DataFrame
df
```

::: {.callout-note appearance="minimal"}
`pd.read_csv()` æ£€æµ‹æ ‡é¢˜è¡Œå¹¶ä½¿ç”¨é€—å·ä½œä¸ºåˆ†éš”ç¬¦ã€‚ç´¢å¼•æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ã€‚
:::

## æŒ‡å®šæ ‡é¢˜è¡Œï¼šæ— æ ‡é¢˜

æœ‰æ—¶ï¼Œä½ çš„ CSV æ–‡ä»¶å¯èƒ½æ²¡æœ‰æ ‡é¢˜è¡Œã€‚

```{python}
#| echo: false
#| output: false
# åˆ›å»ºä¸€ä¸ªæ²¡æœ‰æ ‡é¢˜çš„ CSV æ–‡ä»¶ã€‚
data = {'col1': [1, 5, 9], 'col2': [2, 6, 10], 'col3': [3, 7, 11], 'col4': [4, 8, 12], 'col5': ['hello', 'world', 'foo']}
df = pd.DataFrame(data)
df.to_csv('ex2.csv', index=False, header=False)

```

## æŒ‡å®šæ ‡é¢˜è¡Œï¼šé»˜è®¤åˆ—å

å‘Šè¯‰ `pandas` ä½¿ç”¨é»˜è®¤åˆ—åï¼š

```{python}
# è®© pandas åˆ†é…é»˜è®¤çš„åˆ—å
pd.read_csv("examples/ex2.csv", header=None)
```

## æŒ‡å®šæ ‡é¢˜è¡Œï¼šè‡ªå®šä¹‰åˆ—å

æˆ–è€…ï¼Œæä¾›ä½ è‡ªå·±çš„åˆ—åï¼š

```{python}
# æä¾›ä½ è‡ªå·±çš„åˆ—å
column_names = ["a", "b", "c", "d", "message"]
pd.read_csv("examples/ex2.csv", names=column_names)
```

## è®¾ç½®ç´¢å¼•åˆ—

ä½¿ç”¨ `index_col` å‚æ•°å°†ä¸€åˆ—ç”¨ä½œç´¢å¼•ï¼š

```{python}
# ä½¿ç”¨ 'message' åˆ—ä½œä¸ºç´¢å¼•
column_names = ["a", "b", "c", "d", "message"]
pd.read_csv("examples/ex2.csv", names=column_names, index_col="message")
```

::: {.callout-note appearance="minimal"}
ç°åœ¨è¡Œæ ‡ç­¾æ˜¯ 'hello'ã€'world' å’Œ 'foo'ã€‚
:::

## åˆ†å±‚ç´¢å¼•

é€šè¿‡æŒ‡å®šå¤šä¸ªåˆ—æ¥åˆ›å»º*åˆ†å±‚ç´¢å¼•*ï¼š

```{python}
#| echo: false
#| output: false
data = {'key1': ['one', 'one', 'one', 'one', 'two', 'two', 'two', 'two'],
        'key2': ['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd'],
        'value1': [1, 3, 5, 7, 9, 11, 13, 15],
        'value2': [2, 4, 6, 8, 10, 12, 14, 16]}
df = pd.DataFrame(data)
df.to_csv("csv_mindex.csv", index=False)
```

```{python}
# åˆ›å»ºä¸€ä¸ªåˆ†å±‚ç´¢å¼•
parsed = pd.read_csv("examples/csv_mindex.csv", index_col=["key1", "key2"])
parsed
```

::: {.callout-note appearance="minimal"}
åˆ†å±‚ç´¢å¼•å¯¹äºæ›´é«˜ç»´åº¦çš„æ•°æ®å¾ˆæœ‰ç”¨ã€‚
:::

## å¤„ç†éæ ‡å‡†åˆ†éš”ç¬¦

æ–‡ä»¶æœ‰æ—¶ä½¿ç”¨é€—å·ä»¥å¤–çš„åˆ†éš”ç¬¦ã€‚ç©ºæ ¼ç¤ºä¾‹ï¼š

```{python}
#| echo: false
#| output: false
# åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ç©ºæ ¼åˆ†éš”ç¬¦çš„æ–‡ä»¶
data = """
A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
"""
with open('ex3.txt', 'w') as f:
    f.write(data)

```

## å¤„ç†éæ ‡å‡†åˆ†éš”ç¬¦ï¼šæ­£åˆ™è¡¨è¾¾å¼

å°† `sep` å‚æ•°ä¸æ­£åˆ™è¡¨è¾¾å¼ä¸€èµ·ä½¿ç”¨ï¼š

```{python}
# ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç©ºæ ¼
result = pd.read_csv("examples/ex3.txt", sep=r"\s+")
result
```

::: {.callout-note appearance="minimal"}
`\s+` åŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªç©ºæ ¼å­—ç¬¦ã€‚`pandas` æ¨æ–­ç´¢å¼•ã€‚
:::

## è·³è¿‡è¡Œ

ä½¿ç”¨ `skiprows` å¿½ç•¥ç‰¹å®šè¡Œï¼š

```{python}
#| echo: false
#| output: false
data = """# hey!
a,b,c,d,message
# just wanted to make things more difficult for you
# who reads CSV files with computers, anyway?
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
"""
with open('ex4.csv', 'w') as f:
    f.write(data)
```

```{python}
# è·³è¿‡æŒ‡å®šçš„è¡Œ
pd.read_csv("examples/ex4.csv", skiprows=[0, 2, 3])
```

## å¤„ç†ç¼ºå¤±å€¼ï¼šé»˜è®¤æ ‡è®°

ç¼ºå¤±æ•°æ®å¾ˆå¸¸è§ã€‚`pandas` å¯ä»¥è¯†åˆ«åƒ "NA" è¿™æ ·çš„æ ‡è®°ï¼š

```{python}
#| echo: false
#| output: false
data = """something,a,b,c,d,message
one,1,2,3,4,NA
two,5,6,,8,world
three,9,10,11,12,foo
"""
with open('ex5.csv', 'w') as f:
    f.write(data)
```

```{python}
# è¯»å–æ–‡ä»¶ï¼Œæ£€æµ‹ 'NA'
result = pd.read_csv("examples/ex5.csv")
result
```

## å¤„ç†ç¼ºå¤±å€¼ï¼šæ£€æŸ¥ç¼ºå¤±æ€§

æ£€æŸ¥ç¼ºå¤±å€¼ï¼š

```{python}
# æ£€æŸ¥ç¼ºå¤±å€¼
pd.isna(result)
```

## å¤„ç†ç¼ºå¤±å€¼ï¼šè‡ªå®šä¹‰æ ‡è®°

ä½¿ç”¨ `na_values` æŒ‡å®šå…¶ä»–ç¼ºå¤±å€¼å­—ç¬¦ä¸²ï¼š

```{python}
# å°† 'NULL' è§†ä¸ºç¼ºå¤±å€¼
result = pd.read_csv("examples/ex5.csv", na_values=["NULL"])
result
```

## ç¦ç”¨é»˜è®¤çš„ NA å€¼

ä½¿ç”¨ `keep_default_na=False` ç¦ç”¨é»˜è®¤çš„ NA å¤„ç†ï¼š

```{python}
# ç¦ç”¨é»˜è®¤çš„ NA å¤„ç†
result2 = pd.read_csv("examples/ex5.csv", keep_default_na=False)
result2
```

```{python}
# æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼Œæ­¤æ—¶'NA'ä¸ä¼šè¢«è¯†åˆ«ä¸ºç¼ºå¤±å€¼
result2.isna()
```

##  ç¦ç”¨é»˜è®¤ NA å€¼ï¼šæ¯åˆ—çš„æ ‡è®°

ä¸ºæ¯ä¸€åˆ—æŒ‡å®šä¸åŒçš„ NA å€¼ï¼š

```{python}
# ä¸ºæ¯ä¸€åˆ—æŒ‡å®šä¸åŒçš„ NA å€¼
sentinels = {"message": ["foo", "NA"], "something": ["two"]}
pd.read_csv("examples/ex5.csv", na_values=sentinels, keep_default_na=False)
```

## `read_csv`/`read_table` å‡½æ•°å‚æ•°ï¼šæ‘˜è¦ (1/3)

ä»¥ä¸‹æ˜¯å…³é”®å‚æ•°çš„æ‘˜è¦ï¼š

| å‚æ•°             | æè¿°                                                                                                            |
| :--------------- | :--------------------------------------------------------------------------------------------------------------------- |
| `path`           | å­—ç¬¦ä¸²ï¼šæ–‡ä»¶è·¯å¾„ã€URL æˆ–ç±»æ–‡ä»¶å¯¹è±¡ã€‚                                                              |
| `sep` æˆ– `delimiter` | ç”¨äºåˆ†éš”å­—æ®µçš„å­—ç¬¦åºåˆ—æˆ–æ­£åˆ™è¡¨è¾¾å¼ã€‚                                                            |
| `header`         | åˆ—åçš„è¡Œå·ï¼ˆé»˜è®¤ä¸º 0ï¼‰ã€‚å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œåˆ™ä¸º `None`ã€‚                                               |
| `index_col`      | ç”¨ä½œè¡Œç´¢å¼•çš„åˆ—ã€‚                                                                  |
| `names`          | å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œåˆ™ä¸ºåˆ—ååˆ—è¡¨ã€‚                                                                           |
| `skiprows`       | è¦è·³è¿‡çš„è¡Œå·åˆ—è¡¨ã€‚                                                                                           |

##  `read_csv`/`read_table` å‡½æ•°å‚æ•°ï¼šæ‘˜è¦ (2/3)

| å‚æ•°             | æè¿°                                                                                                            |
| :--------------- | :--------------------------------------------------------------------------------------------------------------------- |
| `na_values`      | è¦æ›¿æ¢ä¸º `NaN` çš„å€¼ã€‚                                                                           |
| `keep_default_na` | ä½¿ç”¨é»˜è®¤çš„ `NaN` å€¼ï¼ˆé»˜è®¤ä¸º `True`ï¼‰ã€‚                                                         |
|`comment`|	ç”¨äºåˆ†å‰²è¡Œå°¾æ³¨é‡Šçš„å­—ç¬¦ã€‚|
|`parse_dates`|	å°è¯•å°†æ•°æ®è§£æä¸º `datetime`ã€‚|
|`keep_date_col`|	å¦‚æœè¿æ¥åˆ—ä»¥è§£ææ—¥æœŸï¼Œåˆ™ä¿ç•™è¿æ¥çš„åˆ—ã€‚|
|`converters`|	å°†åˆ—å·/åç§°æ˜ å°„åˆ°å‡½æ•°çš„å­—å…¸ã€‚|

##  `read_csv`/`read_table` å‡½æ•°å‚æ•°ï¼šæ‘˜è¦ (3/3)
| å‚æ•°             | æè¿°                                                                                                            |
| :--------------- | :--------------------------------------------------------------------------------------------------------------------- |
|`dayfirst`|	è§£ææœ‰æ­§ä¹‰çš„æ—¥æœŸæ—¶ï¼Œå°†å…¶è§†ä¸ºå›½é™…æ ¼å¼ã€‚|
|`date_parser`|	ç”¨äºè§£ææ—¥æœŸçš„å‡½æ•°ã€‚|
|`nrows`|	ä»å¤´å¼€å§‹è¯»å–çš„è¡Œæ•°ã€‚|
|`iterator`|	è¿”å›ä¸€ä¸ª `TextFileReader` ä»¥è¿›è¡Œåˆ†æ®µè¯»å–ã€‚|
|`chunksize`|	å¯¹äºè¿­ä»£ï¼Œæ–‡ä»¶å—çš„å¤§å°ã€‚|
|`skip_footer`|	è¦å¿½ç•¥çš„æœ«å°¾è¡Œæ•°ã€‚|
|`verbose`|	æ‰“å°è§£æä¿¡æ¯ã€‚|
|`encoding`|	æ–‡æœ¬ç¼–ç ã€‚|
|`squeeze`|	å¦‚æœåªæœ‰ä¸€åˆ—ï¼Œåˆ™è¿”å›ä¸€ä¸ª Seriesã€‚|
|`thousands`|	åƒä½åˆ†éš”ç¬¦ã€‚|
|`decimal`|	å°æ•°ç‚¹åˆ†éš”ç¬¦ã€‚|
|`engine`|	è§£æå¼•æ“: `c`, `python`, æˆ– `pyarrow`.|

## åˆ†å—è¯»å–å¤§æ–‡ä»¶ï¼š`nrows`

å¯¹äºå¤§æ–‡ä»¶ï¼Œè¯»å–ä¸€å°éƒ¨åˆ†æˆ–åˆ†å—å¤„ç†ã€‚

```{python}
#| echo: false
#| output: false
import numpy as np
# åˆ›å»ºä¸€ä¸ªå¤§çš„ csv æ–‡ä»¶
data = {'one': np.random.rand(10000),
        'two': np.random.rand(10000),
        'three': np.random.rand(10000),
        'four': np.random.rand(10000),
        'key': [chr(ord('A') + np.random.randint(0, 26)) for _ in range(10000)]}  # éšæœºå­—æ¯
df = pd.DataFrame(data)

df.to_csv("ex6.csv", index=False)
```

```{python}
# åªè¯»å–å‰ 5 è¡Œ
pd.read_csv("examples/ex6.csv", nrows=5)
```

## åˆ†å—è¯»å–å¤§æ–‡ä»¶ï¼š`chunksize`

ä½¿ç”¨ `chunksize` åˆ†å—è¯»å–æ–‡ä»¶ï¼š

```{python}
# ä»¥ 1000 è¡Œä¸ºä¸€å—è¯»å–æ–‡ä»¶
chunker = pd.read_csv("examples/ex6.csv", chunksize=1000)
type(chunker)
```

## åˆ†å—è¯»å–å¤§æ–‡ä»¶ï¼šè¿­ä»£

`chunker` æ˜¯ä¸€ä¸ª `TextFileReader`ã€‚éå†å®ƒï¼š

```{python}
# é€å—å¤„ç†
chunker = pd.read_csv("examples/ex6.csv", chunksize=1000)

# åˆ›å»ºä¸€ä¸ªç©ºçš„ Series æ¥å­˜å‚¨ç»“æœ, æŒ‡å®šæ•°æ®ç±»å‹ä¸º int64
tot = pd.Series([], dtype='int64')
for piece in chunker:
    # ç»Ÿè®¡æ¯ä¸ªæ•°æ®å—ä¸­ 'key' åˆ—çš„å€¼ï¼Œå¹¶å°†ç»“æœç´¯åŠ åˆ° tot ä¸­ï¼Œç¼ºå¤±å€¼å¡«å……ä¸º 0
    tot = tot.add(piece["key"].value_counts(), fill_value=0)

# å¯¹ç»“æœè¿›è¡Œé™åºæ’åº
tot = tot.sort_values(ascending=False)
# æ˜¾ç¤ºå‰ 10 ä¸ªç»“æœ
tot[:10]
```

## å°†æ•°æ®å†™å…¥æ–‡æœ¬æ ¼å¼ï¼š`to_csv`

å°†æ•°æ®å†™å…¥å„ç§æ ¼å¼ã€‚`to_csv` æ˜¯ `read_csv` çš„å¯¹åº”å‡½æ•°ã€‚

```{python}
# ä» CSV æ–‡ä»¶è¯»å–æ•°æ®
data = pd.read_csv("examples/ex5.csv")
data
```

```{python}
# å†™å…¥ CSV æ–‡ä»¶
data.to_csv("out.csv")

#ä¸ºäº†è¯æ˜æ•°æ®è¢«æˆåŠŸå†™å…¥ï¼Œå†æ¬¡è¯»å–æŸ¥çœ‹ã€‚
pd.read_csv("out.csv")
```

::: {.callout-note appearance="minimal"}
é»˜è®¤æƒ…å†µä¸‹ä¼šå†™å…¥è¡Œå’Œåˆ—æ ‡ç­¾ã€‚
:::

## å†™å…¥æ•°æ®ï¼šä¸åŒçš„åˆ†éš”ç¬¦

æŒ‡å®šä¸åŒçš„åˆ†éš”ç¬¦ï¼š

```{python}
# å¯¼å…¥ sys æ¨¡å—ä»¥å†™å…¥æ§åˆ¶å°
import sys
# ä½¿ç”¨ '|' åˆ†éš”ç¬¦å†™å…¥æ§åˆ¶å°
data.to_csv(sys.stdout, sep="|")
```

## å†™å…¥æ•°æ®ï¼šè¡¨ç¤ºç¼ºå¤±å€¼

ä»¥ä¸åŒçš„æ–¹å¼è¡¨ç¤ºç¼ºå¤±å€¼ï¼š

```{python}
# å°†ç¼ºå¤±å€¼è¡¨ç¤ºä¸º 'NULL'
data.to_csv(sys.stdout, na_rep="NULL")
```

## å†™å…¥æ•°æ®ï¼šç¦ç”¨æ ‡ç­¾

ç¦ç”¨è¡Œå’Œåˆ—æ ‡ç­¾ï¼š

```{python}
# ä¸å†™å…¥æ ‡ç­¾
data.to_csv(sys.stdout, index=False, header=False)
```

## å†™å…¥æ•°æ®ï¼šå­é›†åˆ—

æŒ‰ç‰¹å®šé¡ºåºå†™å…¥åˆ—çš„å­é›†ï¼š

```{python}
# åªå†™å…¥ 'a'ã€'b'ã€'c' åˆ—
data.to_csv(sys.stdout, index=False, columns=["a", "b", "c"])
```

## å¤„ç†å…¶ä»–åˆ†éš”æ ¼å¼ï¼š`csv` æ¨¡å—

å¯¹äºå•å­—ç¬¦åˆ†éš”ç¬¦ï¼Œä½¿ç”¨ Python çš„ `csv` æ¨¡å—ï¼š

```{python}
#| echo: false
#| output: false
data = '''"a","b","c"
"1","2","3"
"1","2","3"
'''
with open('ex7.csv', "w") as f:
	f.write(data)
```

```{python}
import csv

# æ‰“å¼€ CSV æ–‡ä»¶
f = open("examples/ex7.csv")
# åˆ›å»º csv è¯»å–å™¨
reader = csv.reader(f)

# é€è¡Œæ‰“å°
for line in reader:
    print(line)
# å…³é—­æ–‡ä»¶
f.close()
```

## å¤„ç†å…¶ä»–åˆ†éš”æ ¼å¼ï¼šå¤„ç†æ•°æ®

å°†æ•°æ®å¤„ç†æˆå¯ç”¨çš„å½¢å¼ï¼š

```{python}
# æ‰“å¼€ CSV æ–‡ä»¶
with open("examples/ex7.csv") as f:
    # å°† csv.reader çš„ç»“æœè½¬æ¢ä¸ºåˆ—è¡¨
    lines = list(csv.reader(f))

# å°†ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜ï¼Œå…¶ä½™è¡Œä½œä¸ºå€¼
header, values = lines[0], lines[1:]

# åˆ›å»ºä¸€ä¸ªæ•°æ®åˆ—çš„å­—å…¸
data_dict = {h: v for h, v in zip(header, zip(*values))}
data_dict
```

å¯¹äºå¤æ‚çš„æ–‡ä»¶ï¼Œä½¿ç”¨å­—ç¬¦ä¸²æ“ä½œæˆ–æ­£åˆ™è¡¨è¾¾å¼ã€‚`pandas.read_csv` é€šå¸¸å°±è¶³å¤Ÿäº†ã€‚

## CSV æ–¹è¨€é€‰é¡¹

`csv` æ¨¡å—æœ‰æ–¹è¨€é€‰é¡¹æ¥è‡ªå®šä¹‰è§£æï¼š

| å‚æ•°             | æè¿°                                                                                                                    |
| :--------------- | :----------------------------------------------------------------------------------------------------------------------------- |
| `delimiter`      | ç”¨äºåˆ†éš”å­—æ®µçš„å•å­—ç¬¦å­—ç¬¦ä¸²ï¼ˆé»˜è®¤ä¸º ','ï¼‰ã€‚                                                                   |
| `lineterminator` | å†™å…¥æ—¶çš„è¡Œç»ˆæ­¢ç¬¦ï¼ˆé»˜è®¤ä¸º '\r\n'ï¼‰ã€‚è¯»å–å™¨ä¼šå¿½ç•¥å¹¶è¯†åˆ«è·¨å¹³å°ã€‚          |
| `quotechar`      | åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å­—æ®µçš„å¼•ç”¨å­—ç¬¦ï¼ˆé»˜è®¤ä¸º '"'ï¼‰ã€‚                                                         |
| `quoting`        | å¼•ç”¨çº¦å®šã€‚                     |
| `skipinitialspace` | å¿½ç•¥åˆ†éš”ç¬¦åçš„ç©ºæ ¼ï¼ˆé»˜è®¤ä¸º `False`ï¼‰ã€‚                                                               |
| `doublequote`    | å¤„ç†å­—æ®µå†…çš„å¼•ç”¨å­—ç¬¦ã€‚                                                    |
| `escapechar`     | å¦‚æœ `quoting` ä¸º `csv.QUOTE_NONE`ï¼Œåˆ™ç”¨äºè½¬ä¹‰åˆ†éš”ç¬¦çš„å­—ç¬¦ä¸²ã€‚                                 |

## CSV æ–¹è¨€ï¼šè‡ªå®šä¹‰å­ç±»

å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„æ–¹è¨€å­ç±»ï¼š

```{python}
#| eval: false
# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„æ–¹è¨€å­ç±»
class MyDialect(csv.Dialect):
    lineterminator = "\n"  # è¡Œç»ˆæ­¢ç¬¦
    delimiter = ";"       # åˆ†éš”ç¬¦
    quotechar = '"'        # å¼•ç”¨å­—ç¬¦
    quoting = csv.QUOTE_MINIMAL  # å¼•ç”¨çº¦å®š

# ä½¿ç”¨è‡ªå®šä¹‰æ–¹è¨€åˆ›å»º csv è¯»å–å™¨
#reader = csv.reader(f, dialect=my_dialect)
```

## CSV æ–¹è¨€ï¼šç›´æ¥é€‰é¡¹

æˆ–è€…ç›´æ¥ä¼ é€’æ–¹è¨€é€‰é¡¹ï¼š

```{python}
#| eval: false
# ä½¿ç”¨ '|' ä½œä¸ºåˆ†éš”ç¬¦åˆ›å»º csv è¯»å–å™¨
#reader = csv.reader(f, delimiter="|")
```

## JSON æ•°æ®

JSON æ˜¯ä¸€ç§çµæ´»çš„æ ¼å¼ï¼Œç”¨äºåœ¨ Web ä¸Šè¿›è¡Œæ•°æ®äº¤æ¢ã€‚

```{python}
# ç¤ºä¾‹ JSON å­—ç¬¦ä¸²
obj = """
{"name": "Wes",
 "cities_lived": ["Akron", "Nashville", "New York", "San Francisco"],
 "pet": null,
 "siblings": [{"name": "Scott", "age": 34, "hobbies": ["guitars", "soccer"]},
              {"name": "Katie", "age": 42, "hobbies": ["diving", "art"]}]
}
"""
```

::: {.callout-note appearance="minimal"}
JSON æ¥è¿‘æœ‰æ•ˆçš„ Python ä»£ç ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨ `null` è€Œä¸æ˜¯ `None`ï¼‰ã€‚
:::

## JSONï¼š`json.loads` å’Œ `json.dumps`

```{python}
import json

# å°† JSON å­—ç¬¦ä¸²è½¬æ¢ä¸º Python å¯¹è±¡
result = json.loads(obj)
result
```

```{python}
# å°† Python å¯¹è±¡è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
asjson = json.dumps(result)
asjson
```

## ä½¿ç”¨ Pandas è¯»å– JSONï¼šä»å­—å…¸åˆ—è¡¨

ä»å­—å…¸åˆ—è¡¨åˆ›å»ºä¸€ä¸ª DataFrameï¼š

```{python}
# æå– 'siblings' æ•°æ®
siblings = pd.DataFrame(result["siblings"], columns=["name", "age"])
siblings
```

## ä½¿ç”¨ Pandas è¯»å– JSONï¼š`read_json`

`pandas.read_json` å°† JSON è½¬æ¢ä¸º Series/DataFrameï¼š

```{python}
#| echo: false
#| output: false
data = """[{"a": 1, "b": 2, "c": 3},
{"a": 4, "b": 5, "c": 6},
{"a": 7, "b": 8, "c": 9}]
"""
with open("example.json", "w") as f:
    f.write(data)

```

```{python}
# è¯»å– JSON æ–‡ä»¶
data = pd.read_json("examples/example.json")
data
```

## å¯¼å‡ºåˆ° JSONï¼š`to_json`

ä½¿ç”¨ `to_json` ä» pandas å¯¼å‡ºåˆ° JSONï¼š

```{python}
# å¯¼å‡ºåˆ° JSONï¼ˆé¢å‘åˆ—ï¼‰
print(data.to_json())
```

```{python}
# å¯¼å‡ºåˆ° JSONï¼ˆé¢å‘è¡Œï¼‰
print(data.to_json(orient="records"))
```

## XML å’Œ HTMLï¼šWeb æŠ“å–

åƒ `lxml`ã€`Beautiful Soup`ã€`html5lib` è¿™æ ·çš„åº“å¯ä»¥å¤„ç† HTML/XMLã€‚`pandas` ä½¿ç”¨ `read_html` æ¥å¤„ç† HTML è¡¨æ ¼ã€‚

å®‰è£…ï¼š

```{python}
#| eval: false
conda install lxml beautifulsoup4 html5lib
# æˆ–
pip install lxml beautifulsoup4 html5lib
```

## Web æŠ“å–ç¤ºä¾‹

```{python}
#| eval: false
# ä» HTML è§£æè¡¨æ ¼
tables = pd.read_html("examples/fdic_failed_bank_list.html")
len(tables)
failures = tables[0]
failures.head()

```
å› ä¸º notebook æ–‡ä»¶ä¸èƒ½ç›´æ¥è®¿é—®æœ¬åœ°æ–‡ä»¶ï¼Œæ‰€ä»¥ä¸Šé¢è¿™æ®µä»£ç åœ¨æ‰§è¡Œæ—¶ä¼šæŠ¥é”™ï¼Œä½†åœ¨å®é™…æƒ…æ™¯ä¸­ï¼Œæ˜¯å¯ä»¥æ­£å¸¸è¿è¡Œçš„ã€‚

è¿™é‡Œæˆ‘ä»¬æŠ“å–äº†ç½‘ç«™å†…å®¹ï¼Œæ‰€ä»¥ä¾ç„¶å¯ä»¥ç”¨è¿™ä¸ªç½‘å€åšæ¼”ç¤ºã€‚

```{python}
# ä» FDIC ç½‘ç«™è¯»å– HTML è¡¨æ ¼
tables = pd.read_html("https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/")
# æ£€æŸ¥æ‰¾åˆ°äº†å¤šå°‘ä¸ªè¡¨æ ¼
len(tables)
# è·å–ç¬¬ä¸€ä¸ªè¡¨æ ¼
failures = tables[0]
# æ˜¾ç¤ºç¬¬ä¸€ä¸ªè¡¨æ ¼çš„å‰å‡ è¡Œ
failures.head()
```

## Web æŠ“å–åçš„æ•°æ®æ¸…ç†å’Œåˆ†æ

æ¸…ç†å’Œåˆ†æåŠ è½½çš„æ•°æ®ï¼š

```{python}
# å°† "Closing Date" åˆ—è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´ç±»å‹
close_timestamps = pd.to_datetime(failures["Closing Date"])

# æŒ‰å¹´ä»½ç»Ÿè®¡å€’é—­é“¶è¡Œçš„æ•°é‡
close_timestamps.dt.year.value_counts()
```

## ä½¿ç”¨ `lxml.objectify` è§£æ XML

XML æ¯” HTML æ›´é€šç”¨ã€‚ä»¥ MTA æ•°æ®ä¸ºä¾‹ï¼š

```{python}
#| eval: false
from lxml import objectify

# XML æ–‡ä»¶è·¯å¾„
path = "datasets/mta_perf/Performance_MNR.xml"
# æ‰“å¼€æ–‡ä»¶å¹¶è§£æ XML
with open(path) as f:
    parsed = objectify.parse(f)
# è·å–æ ¹å…ƒç´ 
root = parsed.getroot()

data = []
# è¦è·³è¿‡çš„å­—æ®µ
skip_fields = ["PARENT_SEQ", "INDICATOR_SEQ", "DESIRED_CHANGE", "DECIMAL_PLACES"]

# éå†æ ¹å…ƒç´ çš„ INDICATOR å­å…ƒç´ 
for elt in root.INDICATOR:
    el_data = {}
    # éå† INDICATOR å…ƒç´ çš„å­å…ƒç´ 
    for child in elt.getchildren():
        # è·³è¿‡æŒ‡å®šå­—æ®µ
        if child.tag in skip_fields:
            continue
        # å°†å­å…ƒç´ çš„æ ‡ç­¾å’Œå€¼æ·»åŠ åˆ°å­—å…¸ä¸­
        el_data[child.tag] = child.pyval
    # å°†å­—å…¸æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    data.append(el_data)

# ä»åˆ—è¡¨åˆ›å»º DataFrame
perf = pd.DataFrame(data)
perf.head()
```
å› ä¸º notebook æ–‡ä»¶ä¸èƒ½ç›´æ¥è®¿é—®æœ¬åœ°æ–‡ä»¶ï¼Œæ‰€ä»¥ä¸Šé¢è¿™æ®µä»£ç åœ¨æ‰§è¡Œæ—¶ä¼šæŠ¥é”™ï¼Œä½†åœ¨å®é™…æƒ…æ™¯ä¸­ï¼Œæ˜¯å¯ä»¥æ­£å¸¸è¿è¡Œçš„ã€‚

## è§£æ XMLï¼š`pandas.read_xml`

`pandas` ä¹Ÿæœ‰ `read_xml`ï¼š

```{python}
#| eval: false
perf2 = pd.read_xml(path)
perf2.head()

```

## äºŒè¿›åˆ¶æ•°æ®æ ¼å¼

äºŒè¿›åˆ¶æ ¼å¼å¯èƒ½æ¯”æ–‡æœ¬æ ¼å¼æ›´æœ‰æ•ˆã€‚

### Pickle

Python çš„ `pickle` æ¨¡å—å¯ä»¥åºåˆ—åŒ–/ååºåˆ—åŒ–å¯¹è±¡ã€‚ä½¿ç”¨ `to_pickle`ï¼š

```{python}
# ä» CSV æ–‡ä»¶è¯»å–æ•°æ®
frame = pd.read_csv("examples/ex1.csv")
frame
```

```{python}
# å°† DataFrame ä¿å­˜ä¸º pickle æ–‡ä»¶
frame.to_pickle("frame_pickle")
```

## Pickleï¼š`read_pickle`

ä½¿ç”¨ `pandas.read_pickle` è¯»å– pickled å¯¹è±¡ï¼š

```{python}

pd.read_pickle("frame_pickle")
```

::: {.callout-note appearance="minimal"}
`pickle` ä»…ç”¨äº*çŸ­æœŸ*å­˜å‚¨ã€‚
:::

### HDF5

HDF5 å­˜å‚¨å¤§å‹æ•°ç»„ï¼Œæ”¯æŒå‹ç¼©ï¼Œé«˜æ•ˆçš„å­é›†ã€‚

å®‰è£… PyTablesï¼š

```{python}
#| eval: false
conda install pytables
# æˆ–
pip install tables
```

## ä½¿ç”¨ HDF5 æ ¼å¼

HDF5 å­˜å‚¨å¤šä¸ªå¸¦æœ‰å…ƒæ•°æ®çš„æ•°æ®é›†ã€‚`HDFStore` å°±åƒä¸€ä¸ªå­—å…¸ï¼š

```{python}
#| eval: false

import numpy as np
# åˆ›å»ºä¸€ä¸ª DataFrame
frame = pd.DataFrame({"a": np.random.standard_normal(100)})
# åˆ›å»ºä¸€ä¸ª HDFStore å¯¹è±¡
store = pd.HDFStore("mydata.h5")
# å°† DataFrame å­˜å‚¨ä¸º 'obj1'
store["obj1"] = frame
# å°† DataFrame çš„ 'a' åˆ—å­˜å‚¨ä¸º 'obj1_col'
store["obj1_col"] = frame["a"]
store
```

## ä½¿ç”¨ HDF5ï¼šè®¿é—®æ•°æ®

```{python}
#| eval: false
# è®¿é—®å­˜å‚¨çš„ 'obj1'
store["obj1"]
```

## HDF5ï¼šå­˜å‚¨æ¨¡å¼

"fixed"ï¼ˆé»˜è®¤ï¼‰å’Œ "table"ã€‚"table" è¾ƒæ…¢ï¼Œæ”¯æŒæŸ¥è¯¢ï¼š

```{python}
#| eval: false
# ä½¿ç”¨ "table" æ ¼å¼å­˜å‚¨ 'obj2'
store.put("obj2", frame, format="table")
# æŸ¥è¯¢ 'obj2' ä¸­ç´¢å¼•åœ¨ 10 åˆ° 15 ä¹‹é—´çš„è¡Œ
store.select("obj2", where=["index >= 10 and index <= 15"])

```

## HDF5ï¼š`pandas.read_hdf`

`pandas.read_hdf` æ˜¯ä¸€ä¸ªå¿«æ·æ–¹å¼ï¼š

```{python}
#| eval: false

# å°† DataFrame ä»¥ "table" æ ¼å¼ä¿å­˜åˆ° HDF5 æ–‡ä»¶ä¸­çš„ 'obj3'
frame.to_hdf("mydata.h5", "obj3", format="table")
# ä» HDF5 æ–‡ä»¶ä¸­è¯»å– 'obj3'ï¼Œå¹¶æŸ¥è¯¢ç´¢å¼•å°äº 5 çš„è¡Œ
pd.read_hdf("mydata.h5", "obj3", where=["index < 5"])
```

::: {.callout-note appearance="minimal"}
HDF5 *ä¸æ˜¯*æ•°æ®åº“ã€‚ä¸€æ¬¡å†™å…¥ï¼Œå¤šæ¬¡è¯»å–ã€‚å¹¶å‘å†™å…¥ä¼šæŸåæ•°æ®ã€‚
:::

## è¯»å– Microsoft Excel æ–‡ä»¶

`pandas` ä½¿ç”¨ `ExcelFile` æˆ– `read_excel`ã€‚éœ€è¦ `xlrd`ã€`openpyxl`ï¼š

```{python}
#| eval: false
conda install openpyxl xlrd
# æˆ–
pip install openpyxl xlrd
```

## Excelï¼š`ExcelFile`

```{python}
#| eval: false
# åˆ›å»º ExcelFile å¯¹è±¡
xlsx = pd.ExcelFile("examples/ex1.xlsx")

```
å› ä¸º notebook æ–‡ä»¶ä¸èƒ½ç›´æ¥è®¿é—®æœ¬åœ°æ–‡ä»¶ï¼Œæ‰€ä»¥ä¸Šé¢è¿™æ®µä»£ç åœ¨æ‰§è¡Œæ—¶ä¼šæŠ¥é”™ï¼Œä½†åœ¨å®é™…æƒ…æ™¯ä¸­ï¼Œæ˜¯å¯ä»¥æ­£å¸¸è¿è¡Œçš„ã€‚

## Excel ç¤ºä¾‹å‡†å¤‡

```{python}
#| echo: false
#| output: false
import openpyxl
data = {'a': [1, 5, 9], 'b': [2, 6, 10], 'c': [3, 7, 11], 'd': [4, 8, 12], 'message': ['hello', 'world', 'foo']}
df = pd.DataFrame(data)

# åˆ›å»ºä¸€ä¸ª Excel å†™å…¥å™¨å¯¹è±¡
excel_writer = pd.ExcelWriter('ex1.xlsx')

# å°† DataFrame å†™å…¥åˆ°åä¸º 'Sheet1' çš„å·¥ä½œè¡¨ä¸­ï¼Œä¸åŒ…å«ç´¢å¼•
df.to_excel(excel_writer, sheet_name='Sheet1', index=False)

# ä¿å­˜ Excel æ–‡ä»¶
excel_writer.close()
```

## Excelï¼šå·¥ä½œè¡¨åç§°

```{python}
# æ˜¾ç¤ºå·¥ä½œè¡¨åç§°
xlsx = pd.ExcelFile("ex1.xlsx") # è¯»å–æœ¬åœ° excel æ–‡ä»¶
xlsx.sheet_names
```

## Excelï¼šè¯»å–å·¥ä½œè¡¨

```{python}
# è¯»å–ä¸€ä¸ªå·¥ä½œè¡¨
xlsx.parse(sheet_name="Sheet1")
```

## Excelï¼šæŒ‡å®šç´¢å¼•

```{python}
# æŒ‡å®šç´¢å¼•åˆ—
xlsx.parse(sheet_name="Sheet1", index_col=0)
```

## Excelï¼š`read_excel`

å¯¹äºå¤šä¸ªå·¥ä½œè¡¨ï¼Œ`ExcelFile` æ›´å¿«ã€‚æˆ–è€…ä½¿ç”¨ `read_excel`ï¼š

```{python}
# è¯»å– Excel æ–‡ä»¶ä¸­çš„ 'Sheet1' å·¥ä½œè¡¨
frame = pd.read_excel("ex1.xlsx", sheet_name="Sheet1")
frame
```

## å†™å…¥ Excelï¼š`ExcelWriter`

åˆ›å»º `ExcelWriter`ï¼Œç„¶åå†™å…¥ï¼š

```{python}
#| eval: false
# åˆ›å»º ExcelWriter å¯¹è±¡
writer = pd.ExcelWriter("ex2.xlsx")
# å°† DataFrame å†™å…¥åˆ° 'Sheet1' å·¥ä½œè¡¨
frame.to_excel(writer, "Sheet1")
# å…³é—­å†™å…¥å™¨
writer.close()

```

## å†™å…¥ Excelï¼š`to_excel`

æˆ–è€…ï¼Œæ›´ç®€æ´åœ°ï¼š

```{python}
#| eval: false
# å°† DataFrame å†™å…¥åˆ° Excel æ–‡ä»¶
frame.to_excel("ex2.xlsx")
```

## ä¸ Web API äº¤äº’

ç½‘ç«™é€šè¿‡ API æä¾›æ•°æ®ï¼Œé€šå¸¸æ˜¯ JSON æ ¼å¼ã€‚`requests` åº“å¾ˆæ–¹ä¾¿ã€‚

å®‰è£…ï¼š

```{python}
#| eval: false
conda install requests
# æˆ–
pip install requests
```

## Web APIï¼š`requests` ç¤ºä¾‹

```{python}
import requests

# GitHub API çš„ URLï¼Œç”¨äºè·å– pandas é¡¹ç›®çš„é—®é¢˜
url = "https://api.github.com/repos/pandas-dev/pandas/issues"
# å‘é€ GET è¯·æ±‚
resp = requests.get(url)
# æ£€æŸ¥ HTTP é”™è¯¯
resp.raise_for_status()
# æ˜¾ç¤ºå“åº”å¯¹è±¡
resp
```

## Web APIï¼šè§£æ JSON å“åº”

```{python}
# å°† JSON å“åº”è§£æä¸º Python å¯¹è±¡
data = resp.json()
# æ˜¾ç¤ºç¬¬ä¸€ä¸ªé—®é¢˜çš„æ ‡é¢˜
data[0]["title"]
```

## Web APIï¼šåˆ›å»º DataFrame

```{python}
# ä»é—®é¢˜æ•°æ®åˆ›å»º DataFrameï¼Œé€‰æ‹© 'number'ã€'title'ã€'labels'ã€'state' åˆ—
issues = pd.DataFrame(data, columns=["number", "title", "labels", "state"])
#æ˜¾ç¤ºæ•°æ®çš„å‰å‡ è¡Œ
issues.head()
```

æ„å»ºæ›´é«˜çº§åˆ«çš„æ¥å£ä»¥è¿”å› DataFrameã€‚

## ä¸æ•°æ®åº“äº¤äº’

SQL æ•°æ®åº“å¾ˆå¸¸è§ã€‚`pandas` ç®€åŒ–äº†ä»æŸ¥è¯¢ä¸­åŠ è½½æ•°æ®çš„è¿‡ç¨‹ã€‚

SQLite3 ç¤ºä¾‹ï¼ˆå†…ç½®ï¼‰ï¼š

```{python}
#| eval: false
import sqlite3

# åˆ›å»ºè¡¨çš„ SQL æŸ¥è¯¢
query = """
CREATE TABLE test
(a VARCHAR(20), b VARCHAR(20),
 c REAL,        d INTEGER
);"""

# è¿æ¥åˆ° SQLite æ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
con = sqlite3.connect("mydata.sqlite")
# æ‰§è¡Œ SQL æŸ¥è¯¢
con.execute(query)
# æäº¤æ›´æ”¹
con.commit()

```

## æ•°æ®åº“ï¼šæ’å…¥æ•°æ®

```{python}
#| eval: false
# è¦æ’å…¥çš„æ•°æ®
data = [("Atlanta", "Georgia", 1.25, 6),
        ("Tallahassee", "Florida", 2.6, 3),
        ("Sacramento", "California", 1.7, 5)]
# æ’å…¥æ•°æ®çš„ SQL è¯­å¥
stmt = "INSERT INTO test VALUES(?, ?, ?, ?)"
# æ‰§è¡Œå¤šè¡Œæ’å…¥
con.executemany(stmt, data)
# æäº¤æ›´æ”¹
con.commit()
```

## æ•°æ®åº“ï¼šæ£€ç´¢æ•°æ®

```{python}
#| eval: false

# æ‰§è¡Œ SELECT æŸ¥è¯¢
cursor = con.execute("SELECT * FROM test")
# è·å–æ‰€æœ‰ç»“æœ
rows = cursor.fetchall()
rows
```

## æ•°æ®åº“ï¼šåˆ—å

```{python}
#| eval: false
# è·å–åˆ—å
cursor.description
```

## æ•°æ®åº“ï¼šåˆ›å»º DataFrame

```{python}
#| eval: false
# ä»æŸ¥è¯¢ç»“æœåˆ›å»º DataFrame
pd.DataFrame(rows, columns=[x[0] for x in cursor.description])
```

## ä½¿ç”¨ SQLAlchemy

SQLAlchemy æä¾›äº†æ›´é«˜çº§åˆ«çš„æŠ½è±¡ã€‚`pandas` çš„ `read_sql` å‡½æ•°å¯ä»¥ä½¿ç”¨å®ƒã€‚

å®‰è£…ï¼š

```{python}
#| eval: false
conda install sqlalchemy
```

## SQLAlchemy ç¤ºä¾‹

```{python}
#| eval: false
import sqlalchemy as sqla

# åˆ›å»º SQLAlchemy å¼•æ“ï¼Œè¿æ¥åˆ° SQLite æ•°æ®åº“
db = sqla.create_engine("sqlite:///mydata.sqlite")
# ä½¿ç”¨ pandas çš„ read_sql å‡½æ•°æ‰§è¡Œ SQL æŸ¥è¯¢
pd.read_sql("SELECT * FROM test", db)
```

## ç»“è®º

è®¿é—®æ•°æ®æ˜¯ç¬¬ä¸€æ­¥ã€‚æœ¬ç« ä»‹ç»äº†åŠ è½½/å­˜å‚¨æ•°æ®çš„å·¥å…·ï¼šæ–‡æœ¬ã€äºŒè¿›åˆ¶ã€æ•°æ®åº“ã€APIã€‚ä¸‹ä¸€æ­¥ï¼šæ¸…ç†ã€è½¬æ¢ã€åˆ†æã€‚

## æ€»ç»“

*   **æ•°æ®åŠ è½½è‡³å…³é‡è¦ï¼š** å°†æ•°æ®åŠ è½½åˆ° Python ä¸­ã€‚
*   **`pandas` æ˜¯ä½ çš„æœ‹å‹ï¼š** ç”¨äºè¯»å–/å†™å…¥æ•°æ®ã€‚
*   **`read_csv` æ˜¯å…³é”®ï¼š** ç”¨äºé€—å·åˆ†éš”å€¼æ–‡ä»¶ã€‚
*   **å¤„ç†æ··ä¹±çš„æ•°æ®ï¼š** ç¼ºå¤±å€¼ã€è·³è¿‡è¡Œã€åˆ†éš”ç¬¦ã€‚
*   **äºŒè¿›åˆ¶æ ¼å¼é«˜æ•ˆï¼š** Pickleã€HDF5ã€‚
*   **Web API æ˜¯ä¸€ä¸ªæ¥æºï¼š** `requests` åº“ã€‚
*   **æ•°æ®åº“å¾ˆå¸¸è§ï¼š** `pandas`ã€SQLAlchemyã€‚
*   **å®è·µæ˜¯å…³é”®ï¼š** ç»ƒä¹ åŠ è½½ä¸åŒçš„æ•°æ®æºã€‚ğŸ¥³

## æ€è€ƒä¸è®¨è®º ğŸ¤”

*   ä½ é‡åˆ°è¿‡å“ªäº›æ•°æ®ç±»å‹ï¼Ÿæ ¼å¼ï¼Ÿ
*   å¤„ç†æ··ä¹±/ä¸å®Œæ•´æ•°æ®çš„ç»éªŒï¼Ÿ
*   ä¸åŒå­˜å‚¨æ ¼å¼ä¹‹é—´çš„æƒè¡¡ï¼Ÿ
*   æ¢ç´¢ `pandas` æ–‡æ¡£ã€‚
*   å°è¯• SQL æ•°æ®åº“è¿æ¥ã€‚
*   æ‰¾åˆ°ä¸€ä¸ªå…¬å…± APIï¼Œä½¿ç”¨ Python è®¿é—®å®ƒã€‚



